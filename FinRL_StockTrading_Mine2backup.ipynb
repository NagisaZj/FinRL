{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)   \n",
    "* [RLlib Section](#7)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "ef0ba8d0-f57a-4c74-bb0b-46737762677d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-8i1_yu6g\n",
      "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-8i1_yu6g\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.19.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.1.5)\n",
      "Collecting stockstats\n",
      "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Collecting elegantrl\n",
      "  Downloading elegantrl-0.3.2-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.3.0-py3-none-any.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 65.2 MB/s \n",
      "\u001b[?25hCollecting ray[default]\n",
      "  Downloading ray-1.9.1-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 57.6 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 42.9 MB/s \n",
      "\u001b[?25hCollecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 71.5 MB/s \n",
      "\u001b[?25hCollecting gputil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "Collecting exchange_calendars\n",
      "  Downloading exchange_calendars-3.5.tar.gz (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 35.6 MB/s \n",
      "\u001b[?25hCollecting alpaca_trade_api\n",
      "  Downloading alpaca_trade_api-1.4.3-py3-none-any.whl (36 kB)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting jqdatasdk\n",
      "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting wrds\n",
      "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n",
      "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n",
      "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n",
      "Collecting pre-commit\n",
      "  Downloading pre_commit-2.16.0-py2.py3-none-any.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 55.1 MB/s \n",
      "\u001b[?25hCollecting pybullet\n",
      "  Downloading pybullet-3.2.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (90.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 90.8 MB 244 bytes/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n",
      "Collecting box2d-py\n",
      "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 50.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n",
      "Collecting websocket-client<2,>=0.56.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting PyYAML==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 52.7 MB/s \n",
      "\u001b[?25hCollecting msgpack==1.0.2\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 60.4 MB/s \n",
      "\u001b[?25hCollecting aiohttp==3.7.4\n",
      "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 55.5 MB/s \n",
      "\u001b[?25hCollecting websockets<10,>=8.0\n",
      "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 48.7 MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 56.6 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 57.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 68.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 28.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 21.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 70.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 14.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 65.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.85-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 59.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.84-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.83-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.82-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.81-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.80-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 35.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.79-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.78-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 20.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.77-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.76-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.75-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.74-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 34.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.73-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.72-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.71-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.70-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.69-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.68-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 60.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.67-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.66-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.65-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.64-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.63-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.62-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.61-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.60-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 57.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.59-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.58-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.57-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.56-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.55-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.54-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.53-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.52-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.51-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.6 MB/s \n",
      "\u001b[?25hCollecting aiodns>=1.1.1\n",
      "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 60.7 MB/s \n",
      "\u001b[?25hCollecting cryptography>=2.6.1\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 42.6 MB/s \n",
      "\u001b[?25hCollecting pycares>=4.0.0\n",
      "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 44.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n",
      "Collecting pyluach\n",
      "  Downloading pyluach-1.3.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.11.2)\n",
      "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.2.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.27)\n",
      "Collecting thriftpy2>=0.3.9\n",
      "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
      "\u001b[K     |████████████████████████████████| 361 kB 50.4 MB/s \n",
      "\u001b[?25hCollecting pymysql>=0.7.6\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n",
      "Collecting ply<4.0,>=3.4\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n",
      "Collecting cfgv>=2.0.0\n",
      "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n",
      "Collecting identify>=1.0.0\n",
      "  Downloading identify-2.4.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting virtualenv>=20.0.8\n",
      "  Downloading virtualenv-20.11.0-py2.py3-none-any.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 39.6 MB/s \n",
      "\u001b[?25hCollecting nodeenv>=0.11.1\n",
      "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.4.0)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "\u001b[K     |████████████████████████████████| 461 kB 32.3 MB/s \n",
      "\u001b[?25hCollecting platformdirs<3,>=2\n",
      "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.12.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.0-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 57.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n",
      "Collecting aioredis<2\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 50.8 MB/s \n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 70.8 MB/s \n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (5.2.1)\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
      "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 213 kB/s \n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 53.5 MB/s \n",
      "\u001b[?25hCollecting hiredis\n",
      "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n",
      "Collecting blessed>=1.17.1\n",
      "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n",
      "Collecting int-date>=0.1.7\n",
      "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting mock\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 45.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.10)\n",
      "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat\n",
      "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for finrl: filename=finrl-0.3.3-py3-none-any.whl size=3885640 sha256=1667a85b9c8c0a7a8efbf04d5ebf154d5d1ea119a32e922d094820030ce0e7e4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/17/ff/bd/1bc602a0352762b0b24041b88536d803ae343ed0a711fcf55e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for elegantrl: filename=elegantrl-0.3.2-py3-none-any.whl size=168744 sha256=7773813204e1a2954730bd149444640d5155458fc82b6910ec4e661879797016\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75775 sha256=e3753b24d032afc5ef0b133c50557002ca9fed8416e2205e1547fc81af5c124a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39777 sha256=6cc78a6b3f88187e2798221487acba0361bb1d094b6c82496348fb4c85f7686b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
      "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for exchange-calendars: filename=exchange_calendars-3.5-py3-none-any.whl size=179487 sha256=3d877d78e29a28c4b098f4a0b1d0106458d7f73b52f6c7a43d0757d55c11d44b\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/21/43/b6ae2605dd767f6cd5a5b0b70c93a9a75823e44b3ccb92bce7\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=33dcd980f1b32f0582d029fcef126ae53327fb90724eee8c33bc3b4dbebda4b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
      "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940507 sha256=429244bf5fd89014c79f01bf0e4a59477258cd2b88978e3125b54f4bd62a88f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=b831a9dba6682b3e0a7ae05d7c2ba465918426c72474917e56e0850ac8c73263\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
      "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat\n",
      "Installing collected packages: multidict, yarl, lxml, deprecated, async-timeout, redis, PyYAML, pycares, ply, platformdirs, opencensus-context, msgpack, hiredis, frozenlist, distlib, blessed, aiohttp, websockets, websocket-client, virtualenv, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, opencensus, nodeenv, mock, int-date, identify, gpustat, empyrical, cryptography, colorful, cfgv, box2d-py, aiosignal, aioredis, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "Successfully installed PyYAML-5.4.1 aiodns-3.0.0 aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 alpaca-trade-api-1.4.3 async-timeout-3.0.1 blessed-1.19.0 box2d-py-2.3.8 ccxt-1.61.51 cfgv-3.3.1 colorful-0.5.4 cryptography-36.0.1 deprecated-1.2.13 distlib-0.3.4 elegantrl-0.3.2 empyrical-0.5.5 exchange-calendars-3.5 finrl-0.3.3 frozenlist-1.2.0 gpustat-1.0.0b1 gputil-1.4.0 hiredis-2.0.0 identify-2.4.1 int-date-0.1.8 jqdatasdk-1.8.10 lxml-4.7.1 lz4-3.1.10 mock-4.0.3 msgpack-1.0.2 multidict-5.2.0 nodeenv-1.6.0 opencensus-0.8.0 opencensus-context-0.1.2 platformdirs-2.4.1 ply-3.11 pre-commit-2.16.0 psycopg2-binary-2.9.2 py-spy-0.3.11 pybullet-3.2.1 pycares-4.1.2 pyfolio-0.9.2+75.g4b901f6 pyluach-1.3.0 pymysql-1.0.2 ray-1.9.1 redis-4.1.0 stable-baselines3-1.3.0 stockstats-0.3.2 tensorboardX-2.4.1 thriftpy2-0.4.14 virtualenv-20.11.0 websocket-client-1.2.3 websockets-9.1 wrds-3.1.1 yarl-1.6.3 yfinance-0.1.67\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zj/anaconda3/envs/finrl/lib/python3.7/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.tusharedownloader import TushareDownloader\n",
    "from finrl.finrl_meta.data_processors.processor_alpaca import AlpacaProcessor\n",
    "from finrl.finrl_meta.data_processors.processor_wrds import WrdsProcessor\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading_conservative import StockTradingEnvCon\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot2 import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "5302d7c0-1c68-4c6e-b30e-b1395bdc109e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-01'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "config.TRAIN_START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FUnY8WEfLq3C",
    "outputId": "35dd8c5b-d58f-49b8-e4df-ae7e122448cd"
   },
   "outputs": [],
   "source": [
    "# from config.py TRAIN_END_DATE is a string\n",
    "# config.TRAIN_END_DATE\n",
    "# df2=TushareDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83c7f894-3757-473b-8afb-a904e6caabda",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "7a991dfe-f39c-40db-ec44-7c416cdce7dc"
   },
   "outputs": [],
   "source": [
    "# print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94360, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "210fade5-e912-40df-be99-4ad00bdb9d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date       open       high        low      close  \\\n",
       "0           0  2008-12-31   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31  43.700001  45.099998  43.700001  30.628819   \n",
       "\n",
       "      volume   tic  day  \n",
       "0  607541200  AAPL    2  \n",
       "1    6287200  AMGN    2  \n",
       "2    9625600   AXP    2  \n",
       "3    5443100    BA    2  \n",
       "4    6277400   CAT    2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fe = FeatureEngineer(\n",
    "#                     use_technical_indicator=True,\n",
    "#                     tech_indicator_list = config.INDICATORS,\n",
    "#                     use_vix=True,\n",
    "#                     use_turbulence=True,\n",
    "#                     user_defined_feature = False)\n",
    "\n",
    "# processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "# list_ticker = processed[\"tic\"].unique().tolist()\n",
    "# list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "# combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "# processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "# processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "grvhGJJII3Xn",
    "outputId": "733758c3-3552-4aa5-e1f9-789bd4ce0c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CRM</td>\n",
       "      <td>7.712500</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>5367600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.180000</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.120001</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>37513700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>74.629997</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>9964300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>DIS</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>22.520000</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>9012100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>GS</td>\n",
       "      <td>82.239998</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>81.120003</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>14894100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic       open       high        low      close  \\\n",
       "0           0  2008-12-31  AAPL   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  AMGN  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31   AXP  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31    BA  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31   CAT  43.700001  45.099998  43.700001  30.628819   \n",
       "5           5  2008-12-31   CRM   7.712500   8.130000   7.707500   8.002500   \n",
       "6           6  2008-12-31  CSCO  16.180000  16.549999  16.120001  11.787783   \n",
       "7           7  2008-12-31   CVX  72.900002  74.629997  72.900002  43.314438   \n",
       "8           8  2008-12-31   DIS  22.570000  22.950001  22.520000  19.538342   \n",
       "9           9  2008-12-31    GS  82.239998  86.150002  81.120003  69.224182   \n",
       "\n",
       "        volume  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  607541200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "1    6287200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "2    9625600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "3    5443100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "4    6277400.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "5    5367600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "6   37513700.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "7    9964300.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "8    9012100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "9   14894100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma   vix  turbulence  \n",
       "0      2.606277      2.606277  40.0         0.0  \n",
       "1     43.924454     43.924454  40.0         0.0  \n",
       "2     14.908465     14.908465  40.0         0.0  \n",
       "3     32.005894     32.005894  40.0         0.0  \n",
       "4     30.628819     30.628819  40.0         0.0  \n",
       "5      8.002500      8.002500  40.0         0.0  \n",
       "6     11.787783     11.787783  40.0         0.0  \n",
       "7     43.314438     43.314438  40.0         0.0  \n",
       "8     19.538342     19.538342  40.0         0.0  \n",
       "9     69.224182     69.224182  40.0         0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full=pd.read_csv('./2.csv')\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01\n",
    "## Trade data split: 2020-07-01 to 2021-10-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "9744\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121795</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>288.570007</td>\n",
       "      <td>296.450012</td>\n",
       "      <td>287.660004</td>\n",
       "      <td>287.776794</td>\n",
       "      <td>2932900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>303.925869</td>\n",
       "      <td>271.251255</td>\n",
       "      <td>52.413046</td>\n",
       "      <td>-25.838431</td>\n",
       "      <td>1.846804</td>\n",
       "      <td>288.020689</td>\n",
       "      <td>281.001438</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121796</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>193.750000</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>190.737244</td>\n",
       "      <td>9040100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048786</td>\n",
       "      <td>198.750528</td>\n",
       "      <td>185.041391</td>\n",
       "      <td>53.021033</td>\n",
       "      <td>-51.550760</td>\n",
       "      <td>2.013358</td>\n",
       "      <td>191.485037</td>\n",
       "      <td>181.677683</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121797</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.919998</td>\n",
       "      <td>55.290001</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>50.376743</td>\n",
       "      <td>17414800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.437111</td>\n",
       "      <td>53.918425</td>\n",
       "      <td>48.729324</td>\n",
       "      <td>48.097044</td>\n",
       "      <td>-51.018262</td>\n",
       "      <td>8.508886</td>\n",
       "      <td>51.012123</td>\n",
       "      <td>51.464679</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121798</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>42.580002</td>\n",
       "      <td>41.759998</td>\n",
       "      <td>39.035732</td>\n",
       "      <td>4782100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083986</td>\n",
       "      <td>42.609305</td>\n",
       "      <td>36.487095</td>\n",
       "      <td>48.830181</td>\n",
       "      <td>-14.508130</td>\n",
       "      <td>1.500723</td>\n",
       "      <td>39.135190</td>\n",
       "      <td>38.935129</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121799</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>119.220001</td>\n",
       "      <td>120.129997</td>\n",
       "      <td>118.540001</td>\n",
       "      <td>116.121765</td>\n",
       "      <td>6836400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.886569</td>\n",
       "      <td>119.473758</td>\n",
       "      <td>113.510454</td>\n",
       "      <td>48.159665</td>\n",
       "      <td>-69.938795</td>\n",
       "      <td>3.847271</td>\n",
       "      <td>117.787627</td>\n",
       "      <td>119.723273</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date  tic        open        high         low  \\\n",
       "2892      121795  2020-06-30  UNH  288.570007  296.450012  287.660004   \n",
       "2892      121796  2020-06-30    V  191.490005  193.750000  190.160004   \n",
       "2892      121797  2020-06-30   VZ   54.919998   55.290001   54.360001   \n",
       "2892      121798  2020-06-30  WBA   42.119999   42.580002   41.759998   \n",
       "2892      121799  2020-06-30  WMT  119.220001  120.129997  118.540001   \n",
       "\n",
       "           close      volume  day      macd     boll_ub     boll_lb  \\\n",
       "2892  287.776794   2932900.0  1.0 -0.019475  303.925869  271.251255   \n",
       "2892  190.737244   9040100.0  1.0  1.048786  198.750528  185.041391   \n",
       "2892   50.376743  17414800.0  1.0 -0.437111   53.918425   48.729324   \n",
       "2892   39.035732   4782100.0  1.0 -0.083986   42.609305   36.487095   \n",
       "2892  116.121765   6836400.0  1.0 -0.886569  119.473758  113.510454   \n",
       "\n",
       "         rsi_30     cci_30     dx_30  close_30_sma  close_60_sma    vix  \\\n",
       "2892  52.413046 -25.838431  1.846804    288.020689    281.001438  30.43   \n",
       "2892  53.021033 -51.550760  2.013358    191.485037    181.677683  30.43   \n",
       "2892  48.097044 -51.018262  8.508886     51.012123     51.464679  30.43   \n",
       "2892  48.830181 -14.508130  1.500723     39.135190     38.935129  30.43   \n",
       "2892  48.159665 -69.938795  3.847271    117.787627    119.723273  30.43   \n",
       "\n",
       "      turbulence  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "e_train_gym_conservative = StockTradingEnvCon(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "env_train_con, _ = e_train_gym_conservative.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "agent_con = DRLAgent(env = env_train_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 67         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -1.41      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -72.8      |\n",
      "|    reward             | 0.19451597 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.68       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 68         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -0.115     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -70.2      |\n",
      "|    reward             | -1.4624771 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.55       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -167     |\n",
      "|    reward             | 5.02583  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    reward             | 5.606354 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 368       |\n",
      "|    reward             | -7.546301 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 164       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0.0793    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 145       |\n",
      "|    reward             | 0.4507672 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -0.0998    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -78.4      |\n",
      "|    reward             | -2.1521304 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0.00557     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | -0.80710465 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 70.3        |\n",
      "|    reward             | -0.11950674 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -35.7      |\n",
      "|    reward             | -4.1389766 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -245     |\n",
      "|    reward             | 6.363784 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -63.1      |\n",
      "|    reward             | 0.07753525 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | -0.000831 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 48.9      |\n",
      "|    reward             | -4.088032 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 179       |\n",
      "|    reward             | 2.0626597 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 40.8      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 169       |\n",
      "|    reward             | 4.8591986 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 21.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 85.1       |\n",
      "|    reward             | 0.85958314 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.29       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -141     |\n",
      "|    reward             | 5.65319  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -41       |\n",
      "|    reward             | 1.1973313 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.57      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -26.6      |\n",
      "|    reward             | 0.36287376 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40         |\n",
      "|    explained_variance | -0.0091     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -83.6       |\n",
      "|    reward             | -0.30971453 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 13.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 204       |\n",
      "|    reward             | 1.7650424 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -153       |\n",
      "|    reward             | -7.5710273 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 23.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -2.04e+03  |\n",
      "|    reward             | -14.886115 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3e+03      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 51        |\n",
      "|    reward             | 0.0559524 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -46.7     |\n",
      "|    reward             | -0.434364 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 5.71      |\n",
      "|    reward             | 4.8586307 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | -0.4118847 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 328       |\n",
      "|    reward             | 1.0554261 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 66.3      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.88      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -116      |\n",
      "|    reward             | 2.3091433 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -20.7      |\n",
      "|    reward             | 0.38583377 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 223        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 43.7       |\n",
      "|    reward             | -0.3664559 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -38.8      |\n",
      "|    reward             | -0.4616701 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 96.4       |\n",
      "|    reward             | 0.11014476 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.58       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -3.93     |\n",
      "|    reward             | 2.1390972 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 76.4       |\n",
      "|    reward             | 0.16336557 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.35       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -85.2     |\n",
      "|    reward             | 1.0221922 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 225       |\n",
      "|    reward             | 1.1701288 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 38.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 33.2      |\n",
      "|    reward             | 2.4472284 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 41.3       |\n",
      "|    reward             | -1.2081411 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -0.481    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -5.13     |\n",
      "|    reward             | 1.3224076 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2         |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | -0.25540048 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.837       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.000881  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | 1.3826902 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -64       |\n",
      "|    reward             | 3.9822705 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 63.9       |\n",
      "|    reward             | 0.95108056 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 86.2       |\n",
      "|    reward             | -2.1539907 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 102       |\n",
      "|    reward             | 4.8509326 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0.00948     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -105        |\n",
      "|    reward             | -0.22313617 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 8.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -104        |\n",
      "|    reward             | -0.99914765 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 353        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -33.2      |\n",
      "|    reward             | 0.20132123 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.946      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 360        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -7.57e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 46.2       |\n",
      "|    reward             | 0.26696855 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 367        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -83.4      |\n",
      "|    reward             | -1.8360271 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 374       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -359      |\n",
      "|    reward             | 3.2874866 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 92.2      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3161472.69\n",
      "total_reward: 2161472.69\n",
      "total_cost: 19221.41\n",
      "total_trades: 41334\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -7.54     |\n",
      "|    reward             | 0.2828299 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.19252001 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 396       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -15       |\n",
      "|    reward             | 2.0577734 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.6       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -46.9       |\n",
      "|    reward             | -0.06746031 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0.00117    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -37.6      |\n",
      "|    reward             | 0.18157594 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 418       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0.0166    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    reward             | 0.6473793 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | 0.22656512 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.251      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 59.9       |\n",
      "|    reward             | -0.8028962 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 439        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | -1.7693416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 446         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 20.2        |\n",
      "|    reward             | -0.10761352 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 454      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 203      |\n",
      "|    reward             | 3.869458 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 34.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -0.0428   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 110       |\n",
      "|    reward             | 1.2343621 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.67      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | -2.028344 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -66.8      |\n",
      "|    reward             | 0.33169752 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.98       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 483      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.00675  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -869     |\n",
      "|    reward             | -8.09732 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 536      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 490        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 28.9       |\n",
      "|    reward             | 0.56556416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -176       |\n",
      "|    reward             | -2.9329143 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 88.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 504        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 72.3       |\n",
      "|    reward             | 0.22214015 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 511        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 105        |\n",
      "|    reward             | -0.6425189 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -360        |\n",
      "|    reward             | -0.22756429 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 80.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -430        |\n",
      "|    reward             | -0.44158605 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 131         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 533        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 404        |\n",
      "|    reward             | -5.8487034 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 540       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 1.07e+03  |\n",
      "|    reward             | -14.82644 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 832       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 548       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -141      |\n",
      "|    reward             | 1.4826734 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | -0.0473    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -184       |\n",
      "|    reward             | 0.34629944 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -42       |\n",
      "|    reward             | -2.415951 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 55.1      |\n",
      "|    reward             | 5.0485888 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 42.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 576        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -207       |\n",
      "|    reward             | -3.2154734 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 56.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 257       |\n",
      "|    reward             | 5.370093  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 56.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -160       |\n",
      "|    reward             | 0.03019213 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 118        |\n",
      "|    reward             | -1.1561224 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12.6       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 605         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -214        |\n",
      "|    reward             | -0.94865924 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 30.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 613       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -250      |\n",
      "|    reward             | 1.1797212 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 41.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 411        |\n",
      "|    reward             | -22.785406 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 144        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 627       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 72.4      |\n",
      "|    reward             | 3.2164123 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 87          |\n",
      "|    reward             | -0.17441794 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 262         |\n",
      "|    reward             | -0.85795397 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 48.9        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 72.7       |\n",
      "|    reward             | -2.2230675 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 22.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 656       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -49.2     |\n",
      "|    reward             | 2.6728501 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 663      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -238     |\n",
      "|    reward             | 8.656925 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 86.3     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 670         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0.000219    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -187        |\n",
      "|    reward             | -0.62001467 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 27.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 55.6      |\n",
      "|    reward             | 1.1713017 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 685       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | 1.3898315 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 692       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -52.5     |\n",
      "|    reward             | -6.044222 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 699       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 67.7      |\n",
      "|    reward             | 1.8213228 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 706      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 177      |\n",
      "|    reward             | 8.957433 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 58.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 714         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.26523116 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.559       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | -0.00926   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | -0.6623605 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ppo/1_1\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 124         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 16          |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.021770535 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016675381 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.00593    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.58        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    reward               | 0.7566478   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013469603 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00192     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | -1.0269263  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019718751 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 1.3513193   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014888378 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.00167     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.34        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    reward               | 2.0667596   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 116       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 105       |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0212233 |\n",
      "|    clip_fraction        | 0.217     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.3     |\n",
      "|    explained_variance   | -0.0121   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 18.2      |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -0.0185   |\n",
      "|    reward               | 1.9054247 |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 27.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020878887 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.006      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | 0.92972904  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3120500.62\n",
      "total_reward: 2120500.62\n",
      "total_cost: 336701.09\n",
      "total_trades: 79917\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013989583 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.0276     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.5         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | 0.12193802  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018592928 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00384    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | 1.3936107   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023986287 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.00318    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | 0.6740019   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021929748 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0.000857    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    reward               | 2.4588823   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025821913 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0203     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | 0.07737823  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024437804 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.000461   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | 0.69850457  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01842508  |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.0232      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    reward               | -0.89629084 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016529243 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.00237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | 5.236368    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01935794  |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.0129      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    reward               | -0.54648864 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 67.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022583518 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | -0.0212     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 0.77770835  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019884925 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.00242     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -0.30006135 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 67.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026573904 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.47        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | -1.1045699  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021574277 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | -0.6094093  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021440234 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.0054      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -7.4816556  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 66.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3368339.43\n",
      "total_reward: 2368339.43\n",
      "total_cost: 323580.50\n",
      "total_trades: 78402\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020597888 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.00184     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | 2.116288    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025419272 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.00767     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.12921782  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023217298 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.0155      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 6.650812    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 458         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025960952 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.0172      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | -0.329882   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026841579 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.05        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    reward               | -0.17807537 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 495         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033123083 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.00232     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | 0.01667811  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 513        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04112288 |\n",
      "|    clip_fraction        | 0.387      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.3      |\n",
      "|    explained_variance   | -0.0043    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.3       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.00974   |\n",
      "|    reward               | -1.6375614 |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 52.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027736831 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.5         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | 5.3998404   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028462913 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | -0.00482    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 1.5061715   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023440327 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.0171      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | 12.555673   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 71.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037518755 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | -0.0236     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    reward               | -0.6000197  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022428794 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0434      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | -0.7472867  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 623        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02040462 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | -0.00863   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.6       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    reward               | 1.5609344  |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 43.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 640        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02252449 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | 0.0354     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.2       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    reward               | -0.1399209 |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 32         |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4952262.37\n",
      "total_reward: 3952262.37\n",
      "total_cost: 326617.95\n",
      "total_trades: 77686\n",
      "Sharpe: 0.918\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 658        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0468523  |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | 0.0202     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.75       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0042    |\n",
      "|    reward               | -4.6093917 |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 17.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 678         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025643572 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0188      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.8        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -0.22714326 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 84.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 697         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035886526 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00922     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | -7.394546   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 715        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03443244 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | -0.0184    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.35       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00549   |\n",
      "|    reward               | -2.6219864 |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 24.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 734        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04139459 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.0134     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.9       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    reward               | -1.2735374 |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 48.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 752        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03102872 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | -0.0108    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.1       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    reward               | 0.16605416 |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 85.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 770        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03518012 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | -0.00032   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.5       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00434   |\n",
      "|    reward               | -0.5073143 |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 54.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 788         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029382546 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0507      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.07        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | -0.3503291  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 807         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028012104 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.20920065  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 72.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 825         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024898939 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0183      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.000372   |\n",
      "|    reward               | -1.3149991  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 843         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046475917 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0042      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | -5.5651045  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 862        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02440867 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0173     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23         |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    reward               | 1.512706   |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 52.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 881         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033496894 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.00471     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    reward               | 8.997686    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 900         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036057744 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.00345     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | -1.0405978  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4518011.54\n",
      "total_reward: 3518011.54\n",
      "total_cost: 298660.58\n",
      "total_trades: 76742\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 919        |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04017932 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0339     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.34       |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.00942   |\n",
      "|    reward               | -0.8478739 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 18.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 937         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028643675 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.00733     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 0.24888499  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 99          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 955         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030218782 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0114      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.4        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.000609   |\n",
      "|    reward               | -1.248837   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 75.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 974         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044647314 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0167      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.96        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | 1.3761941   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 991         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026322713 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.022       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.5        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 0.7850242   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1009        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029887829 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.00437    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | 5.644665    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 75.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 56        |\n",
      "|    time_elapsed         | 1028      |\n",
      "|    total_timesteps      | 114688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0336897 |\n",
      "|    clip_fraction        | 0.262     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.9     |\n",
      "|    explained_variance   | 0.0132    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 13.5      |\n",
      "|    n_updates            | 550       |\n",
      "|    policy_gradient_loss | -0.0154   |\n",
      "|    reward               | 1.176873  |\n",
      "|    std                  | 1.1       |\n",
      "|    value_loss           | 32.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1047        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032846116 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.024       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -0.5674123  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 70.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1065        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037229065 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.00212    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.4        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    reward               | 0.36335358  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1084        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040543873 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.000347    |\n",
      "|    reward               | 1.2489759   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1103        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03612705  |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | -0.0332     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    reward               | -0.12682314 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1121        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051951952 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.00984     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.9        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.000505   |\n",
      "|    reward               | 1.3554562   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1140        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032515235 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 5.309159    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1160        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043136228 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.092       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 4.5189247   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6554605.72\n",
      "total_reward: 5554605.72\n",
      "total_cost: 280266.14\n",
      "total_trades: 73534\n",
      "Sharpe: 0.955\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 1179       |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03380079 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0328     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 95.6       |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    reward               | -0.5950608 |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 123        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1199        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030449092 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0324      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    reward               | -1.1400722  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 1219       |\n",
      "|    total_timesteps      | 135168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03806865 |\n",
      "|    clip_fraction        | 0.361      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.00692    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.2       |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | -0.00163   |\n",
      "|    reward               | 3.2339742  |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 227        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 1239       |\n",
      "|    total_timesteps      | 137216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03332702 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.26       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.4       |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.00757   |\n",
      "|    reward               | -2.1138053 |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 25.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1258        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033554833 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0572      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.4        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.5879518  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 1277       |\n",
      "|    total_timesteps      | 141312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03580976 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0669     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 57.9       |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | 0.00204    |\n",
      "|    reward               | -4.0902257 |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 181        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1296        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027227787 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 1.7438614   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1314        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034721524 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | 0.4261852   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1334        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024974383 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.3        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | -27.624176  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 252         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1353        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055110283 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.056       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.2        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.000493   |\n",
      "|    reward               | -1.5265653  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1372        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022249797 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47          |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | -2.2579684  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 92          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1390        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019560516 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    reward               | 1.1844258   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 289         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1409        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021257062 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0979      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | -2.941679   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1428        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023557074 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.00354     |\n",
      "|    reward               | -0.38777223 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7506931.46\n",
      "total_reward: 6506931.46\n",
      "total_cost: 239701.19\n",
      "total_trades: 70205\n",
      "Sharpe: 1.008\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1446        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028324526 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 240         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | 0.0028      |\n",
      "|    reward               | 2.6992874   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1465        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026763143 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 251         |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | -3.2850988  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 1484       |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03271363 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.2       |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.00154   |\n",
      "|    reward               | 0.26669505 |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 93.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1503        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028613036 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0772      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | -0.29900646 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1522        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029730117 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00655    |\n",
      "|    reward               | -0.9988302  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1541        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016875573 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0596      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.9        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | 2.4358575   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 84         |\n",
      "|    time_elapsed         | 1561       |\n",
      "|    total_timesteps      | 172032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0349723  |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | 0.357      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.8       |\n",
      "|    n_updates            | 830        |\n",
      "|    policy_gradient_loss | -0.00342   |\n",
      "|    reward               | 0.38004005 |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 27.2       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 85            |\n",
      "|    time_elapsed         | 1579          |\n",
      "|    total_timesteps      | 174080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.022511214   |\n",
      "|    clip_fraction        | 0.205         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -45.3         |\n",
      "|    explained_variance   | 0.16          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 53.1          |\n",
      "|    n_updates            | 840           |\n",
      "|    policy_gradient_loss | -0.00613      |\n",
      "|    reward               | -0.0109992055 |\n",
      "|    std                  | 1.15          |\n",
      "|    value_loss           | 102           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1600        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043863237 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.5        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | 0.00754     |\n",
      "|    reward               | -1.6069763  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 86.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1619        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030370113 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | 0.00293     |\n",
      "|    reward               | 2.9835663   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 1638       |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02268851 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | 0.0856     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42         |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    reward               | -2.1585262 |\n",
      "|    std                  | 1.16       |\n",
      "|    value_loss           | 68.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1657        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024805233 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0436      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | -0.09749627 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 80          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1676        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026359202 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0544      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | 1.228437    |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 90.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1695        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021300664 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | -0.69223315 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4444616.00\n",
      "total_reward: 3444616.00\n",
      "total_cost: 215889.48\n",
      "total_trades: 68091\n",
      "Sharpe: 0.816\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1714        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013762552 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0881      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | -1.9625988  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 85.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1733        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025590826 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0453      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | -0.7843865  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 79.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1752        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039299656 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | 0.000195    |\n",
      "|    reward               | 2.1168745   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1771        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023219049 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53          |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -0.18285431 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1790        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022366654 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.6        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.000866   |\n",
      "|    reward               | -0.6576443  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1808        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017765887 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.000123   |\n",
      "|    reward               | 0.7336262   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 98         |\n",
      "|    time_elapsed         | 1828       |\n",
      "|    total_timesteps      | 200704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02475373 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.6      |\n",
      "|    explained_variance   | 0.0723     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.5       |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    reward               | 0.6693909  |\n",
      "|    std                  | 1.17       |\n",
      "|    value_loss           | 35.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 1847       |\n",
      "|    total_timesteps      | 202752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04865522 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.7      |\n",
      "|    explained_variance   | 0.0557     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29         |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.00264   |\n",
      "|    reward               | -2.2085009 |\n",
      "|    std                  | 1.17       |\n",
      "|    value_loss           | 83.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 1866       |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04031522 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.8      |\n",
      "|    explained_variance   | 0.185      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.2       |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | -0.00102   |\n",
      "|    reward               | -0.8231322 |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 67.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 1886        |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026418881 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | 0.00185     |\n",
      "|    reward               | -0.36570835 |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1906        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028208815 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | 0.00558     |\n",
      "|    reward               | -1.6960285  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 1925        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025750592 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | 0.0567      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | 2.0594049   |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1943        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029545523 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -0.66344184 |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 1962        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028557945 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.0482      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -3.232674   |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3277755.20\n",
      "total_reward: 2277755.20\n",
      "total_cost: 327390.08\n",
      "total_trades: 77369\n",
      "Sharpe: 0.658\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1980        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019925106 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.0306      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | -0.2354839  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 82.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 1999        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053310636 |\n",
      "|    clip_fraction        | 0.424       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | -0.0047     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44          |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | 0.56631625  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 2018       |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0425533  |\n",
      "|    clip_fraction        | 0.398      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.2      |\n",
      "|    explained_variance   | 0.0123     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.53       |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.00812   |\n",
      "|    reward               | -0.3129211 |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 14.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 2036       |\n",
      "|    total_timesteps      | 223232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03393358 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.2      |\n",
      "|    explained_variance   | 0.09       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.4       |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | -0.00435   |\n",
      "|    reward               | 0.13449031 |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 40.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 2055        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053771578 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.3       |\n",
      "|    explained_variance   | 0.0391      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | 1.297896    |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 109       |\n",
      "|    iterations           | 111       |\n",
      "|    time_elapsed         | 2075      |\n",
      "|    total_timesteps      | 227328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0408274 |\n",
      "|    clip_fraction        | 0.357     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -46.4     |\n",
      "|    explained_variance   | -0.0455   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 9.1       |\n",
      "|    n_updates            | 1100      |\n",
      "|    policy_gradient_loss | 0.00833   |\n",
      "|    reward               | 5.647482  |\n",
      "|    std                  | 1.2       |\n",
      "|    value_loss           | 22.7      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 2093        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034454226 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | 0.0447      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -2.8606803  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 2113        |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023972478 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.5       |\n",
      "|    explained_variance   | -0.00632    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65          |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | -1.1925921  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 2131        |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016110415 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.5       |\n",
      "|    explained_variance   | 0.0456      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    reward               | -1.0894417  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 55.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 2151        |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031821635 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.5       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.68        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | -1.1500826  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 2170        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026578281 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    reward               | -1.4675409  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 117        |\n",
      "|    time_elapsed         | 2189       |\n",
      "|    total_timesteps      | 239616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02241535 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.6      |\n",
      "|    explained_variance   | 0.0276     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 63.9       |\n",
      "|    n_updates            | 1160       |\n",
      "|    policy_gradient_loss | -0.00282   |\n",
      "|    reward               | 0.989159   |\n",
      "|    std                  | 1.21       |\n",
      "|    value_loss           | 126        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 118        |\n",
      "|    time_elapsed         | 2207       |\n",
      "|    total_timesteps      | 241664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03021804 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.6      |\n",
      "|    explained_variance   | 0.0402     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.62       |\n",
      "|    n_updates            | 1170       |\n",
      "|    policy_gradient_loss | -0.00976   |\n",
      "|    reward               | 2.9407117  |\n",
      "|    std                  | 1.21       |\n",
      "|    value_loss           | 23.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 2226        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035611443 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | -0.0139     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    reward               | 1.3030994   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 2244        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041709736 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.00177     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.9        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | 0.00508     |\n",
      "|    reward               | -2.415605   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3371968.52\n",
      "total_reward: 2371968.52\n",
      "total_cost: 248433.72\n",
      "total_trades: 71834\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 121           |\n",
      "|    time_elapsed         | 2263          |\n",
      "|    total_timesteps      | 247808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0431521     |\n",
      "|    clip_fraction        | 0.364         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -46.7         |\n",
      "|    explained_variance   | 0.105         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.7          |\n",
      "|    n_updates            | 1200          |\n",
      "|    policy_gradient_loss | 0.00263       |\n",
      "|    reward               | -0.0144250775 |\n",
      "|    std                  | 1.21          |\n",
      "|    value_loss           | 28.4          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 2282        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026874889 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.0663      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 1.1695658   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 109       |\n",
      "|    iterations           | 123       |\n",
      "|    time_elapsed         | 2301      |\n",
      "|    total_timesteps      | 251904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0316105 |\n",
      "|    clip_fraction        | 0.289     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -46.8     |\n",
      "|    explained_variance   | 0.0279    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 15        |\n",
      "|    n_updates            | 1220      |\n",
      "|    policy_gradient_loss | -0.015    |\n",
      "|    reward               | 2.6552792 |\n",
      "|    std                  | 1.22      |\n",
      "|    value_loss           | 31        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 2320       |\n",
      "|    total_timesteps      | 253952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01897077 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.8      |\n",
      "|    explained_variance   | 0.0506     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.6       |\n",
      "|    n_updates            | 1230       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | 1.4291863  |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 64.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 2339       |\n",
      "|    total_timesteps      | 256000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02446344 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.9      |\n",
      "|    explained_variance   | 0.104      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.6       |\n",
      "|    n_updates            | 1240       |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    reward               | 1.1752468  |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 20.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 2358        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02947921  |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | -0.19487737 |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 2376        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021609973 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | 0.00316     |\n",
      "|    reward               | -5.7195487  |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 63.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 2395        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018725986 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 0.2702661   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 2414       |\n",
      "|    total_timesteps      | 264192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04347495 |\n",
      "|    clip_fraction        | 0.401      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.1      |\n",
      "|    explained_variance   | 0.0459     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.9       |\n",
      "|    n_updates            | 1280       |\n",
      "|    policy_gradient_loss | 0.00181    |\n",
      "|    reward               | 0.47700006 |\n",
      "|    std                  | 1.23       |\n",
      "|    value_loss           | 43.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 2435        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033690862 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.3        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | -0.03508005 |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 79.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 2453        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021290142 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.066       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | -3.0820618  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 55.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 2472        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022990465 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | -0.00287    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | 1.9085146   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 2490        |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027419392 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.0465      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | 2.469415    |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 92.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 134        |\n",
      "|    time_elapsed         | 2509       |\n",
      "|    total_timesteps      | 274432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03547658 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.5      |\n",
      "|    explained_variance   | 0.0456     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 90.6       |\n",
      "|    n_updates            | 1330       |\n",
      "|    policy_gradient_loss | 0.00298    |\n",
      "|    reward               | -3.0601277 |\n",
      "|    std                  | 1.24       |\n",
      "|    value_loss           | 160        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5135554.44\n",
      "total_reward: 4135554.44\n",
      "total_cost: 243834.51\n",
      "total_trades: 69922\n",
      "Sharpe: 0.872\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 2527        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.05550487  |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | 0.00368     |\n",
      "|    reward               | -0.25916153 |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 2545        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034373596 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.0915      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    reward               | 0.7289046   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 2564        |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033754464 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | 0.00219     |\n",
      "|    reward               | -0.14742416 |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 138        |\n",
      "|    time_elapsed         | 2582       |\n",
      "|    total_timesteps      | 282624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03879991 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.7      |\n",
      "|    explained_variance   | 0.0163     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.9       |\n",
      "|    n_updates            | 1370       |\n",
      "|    policy_gradient_loss | -0.00189   |\n",
      "|    reward               | 1.5305496  |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 121        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 2601        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028207812 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | -1.1908541  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 2620        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031621393 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.0172      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    reward               | 0.6324758   |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 141        |\n",
      "|    time_elapsed         | 2638       |\n",
      "|    total_timesteps      | 288768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02915724 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.8      |\n",
      "|    explained_variance   | 0.0212     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.6       |\n",
      "|    n_updates            | 1400       |\n",
      "|    policy_gradient_loss | -0.00244   |\n",
      "|    reward               | 3.7275221  |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 2657        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034135416 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | -0.00617    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.000728   |\n",
      "|    reward               | -1.742822   |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 143        |\n",
      "|    time_elapsed         | 2676       |\n",
      "|    total_timesteps      | 292864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03596595 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.9      |\n",
      "|    explained_variance   | 0.0349     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 126        |\n",
      "|    n_updates            | 1420       |\n",
      "|    policy_gradient_loss | -0.00496   |\n",
      "|    reward               | 0.75683093 |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 138        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 144        |\n",
      "|    time_elapsed         | 2694       |\n",
      "|    total_timesteps      | 294912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03972637 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.9      |\n",
      "|    explained_variance   | 0.0362     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 113        |\n",
      "|    n_updates            | 1430       |\n",
      "|    policy_gradient_loss | 0.00571    |\n",
      "|    reward               | -2.0879514 |\n",
      "|    std                  | 1.27       |\n",
      "|    value_loss           | 134        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 2713        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039484657 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.0192      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | 0.00507     |\n",
      "|    reward               | -0.69491976 |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 2732        |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020717386 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.071       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.3        |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    reward               | 1.1614509   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 74.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 2750        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036507558 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0549      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | -1.141471   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 77.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 2768        |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027108014 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0918      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.7        |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | -0.17371656 |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5172369.92\n",
      "total_reward: 4172369.92\n",
      "total_cost: 266340.88\n",
      "total_trades: 71570\n",
      "Sharpe: 0.842\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 2789        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023544945 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.0692      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    reward               | 1.3723567   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 2808        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021766014 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.0433      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -0.47447044 |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 2826       |\n",
      "|    total_timesteps      | 309248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04525836 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.2      |\n",
      "|    explained_variance   | -0.00644   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.1       |\n",
      "|    n_updates            | 1500       |\n",
      "|    policy_gradient_loss | 0.00394    |\n",
      "|    reward               | -1.0817349 |\n",
      "|    std                  | 1.28       |\n",
      "|    value_loss           | 109        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 2844        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042242467 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.0197      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.000349   |\n",
      "|    reward               | -2.3885849  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 153        |\n",
      "|    time_elapsed         | 2863       |\n",
      "|    total_timesteps      | 313344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03567949 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.3      |\n",
      "|    explained_variance   | 0.0562     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 54.2       |\n",
      "|    n_updates            | 1520       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    reward               | -0.8571348 |\n",
      "|    std                  | 1.28       |\n",
      "|    value_loss           | 75.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 154        |\n",
      "|    time_elapsed         | 2882       |\n",
      "|    total_timesteps      | 315392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03084042 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.4      |\n",
      "|    explained_variance   | 0.0249     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 92.8       |\n",
      "|    n_updates            | 1530       |\n",
      "|    policy_gradient_loss | -0.00146   |\n",
      "|    reward               | -0.7674769 |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 145        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 2901        |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037686497 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.0546      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.3        |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.000275   |\n",
      "|    reward               | 0.55156714  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 89.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 2920        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047767654 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.18        |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | 0.00172     |\n",
      "|    reward               | -2.0394895  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 157        |\n",
      "|    time_elapsed         | 2939       |\n",
      "|    total_timesteps      | 321536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04497107 |\n",
      "|    clip_fraction        | 0.384      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.4      |\n",
      "|    explained_variance   | 0.0621     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.7       |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | -0.00271   |\n",
      "|    reward               | -1.6355392 |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 57.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 158        |\n",
      "|    time_elapsed         | 2958       |\n",
      "|    total_timesteps      | 323584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04918871 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.5      |\n",
      "|    explained_variance   | 0.0197     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.6       |\n",
      "|    n_updates            | 1570       |\n",
      "|    policy_gradient_loss | -0.0022    |\n",
      "|    reward               | -8.2800865 |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 54.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 2977        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053601332 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    reward               | -0.14913397 |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 2996        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032457836 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.0467      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    reward               | 0.89448565  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 3015        |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017269544 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 24.073412   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 3033        |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029355118 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.02        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | 0.00548     |\n",
      "|    reward               | -0.40571308 |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3575552.56\n",
      "total_reward: 2575552.56\n",
      "total_cost: 316407.50\n",
      "total_trades: 75459\n",
      "Sharpe: 0.727\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 163        |\n",
      "|    time_elapsed         | 3053       |\n",
      "|    total_timesteps      | 333824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04068572 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.7      |\n",
      "|    explained_variance   | 0.0541     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.4       |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | -0.00942   |\n",
      "|    reward               | -2.0961885 |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 28.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 3072        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035818182 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.0834      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    reward               | 0.1070473   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 3091        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021901488 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | 6.715261    |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 3110        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.06044063  |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | -0.0297     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | 0.00445     |\n",
      "|    reward               | -0.45664552 |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 3128        |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036302656 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.0597      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.39962584  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 67.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 3147        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017362166 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    reward               | 2.8963473   |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 67.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 169        |\n",
      "|    time_elapsed         | 3165       |\n",
      "|    total_timesteps      | 346112     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03324727 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.9      |\n",
      "|    explained_variance   | 0.0605     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.7       |\n",
      "|    n_updates            | 1680       |\n",
      "|    policy_gradient_loss | 0.00353    |\n",
      "|    reward               | -3.6993845 |\n",
      "|    std                  | 1.31       |\n",
      "|    value_loss           | 42.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 3184        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024872247 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -2.0092776  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 171        |\n",
      "|    time_elapsed         | 3203       |\n",
      "|    total_timesteps      | 350208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03994343 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49        |\n",
      "|    explained_variance   | 0.0204     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 51.6       |\n",
      "|    n_updates            | 1700       |\n",
      "|    policy_gradient_loss | 0.000271   |\n",
      "|    reward               | -1.0882446 |\n",
      "|    std                  | 1.31       |\n",
      "|    value_loss           | 76.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 3221        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012734976 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | 0.8588058   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 3240        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030565858 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.81        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | -1.2210686  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 174        |\n",
      "|    time_elapsed         | 3258       |\n",
      "|    total_timesteps      | 356352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01630084 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.1      |\n",
      "|    explained_variance   | 0.201      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.8       |\n",
      "|    n_updates            | 1730       |\n",
      "|    policy_gradient_loss | -0.00597   |\n",
      "|    reward               | 0.6073437  |\n",
      "|    std                  | 1.32       |\n",
      "|    value_loss           | 36.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 3276        |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014148504 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -1.0586625  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 3295        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031459354 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.0707      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    reward               | -2.3104577  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3247915.04\n",
      "total_reward: 2247915.04\n",
      "total_cost: 308823.90\n",
      "total_trades: 73505\n",
      "Sharpe: 0.690\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 3313        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03904465  |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    reward               | -0.17772134 |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 3333        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045553796 |\n",
      "|    clip_fraction        | 0.439       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.0492      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | -1.3739885  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 3351        |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021559881 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | 0.6087344   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 180        |\n",
      "|    time_elapsed         | 3370       |\n",
      "|    total_timesteps      | 368640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04445488 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.4      |\n",
      "|    explained_variance   | -0.0616    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.8        |\n",
      "|    n_updates            | 1790       |\n",
      "|    policy_gradient_loss | -0.00483   |\n",
      "|    reward               | -0.7853197 |\n",
      "|    std                  | 1.33       |\n",
      "|    value_loss           | 19.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 181          |\n",
      "|    time_elapsed         | 3389         |\n",
      "|    total_timesteps      | 370688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.029752381  |\n",
      "|    clip_fraction        | 0.263        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.4        |\n",
      "|    explained_variance   | 0.0585       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 0.0126085505 |\n",
      "|    std                  | 1.33         |\n",
      "|    value_loss           | 65.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 3407        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035993554 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.0222      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.2        |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | -1.4716673  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 3426        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04025495  |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.97        |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    reward               | -0.20547248 |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 3444        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025296286 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.032       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | -3.4079263  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 63.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 3463        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027357066 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | -0.00692    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | 4.433744    |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 82.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 186        |\n",
      "|    time_elapsed         | 3482       |\n",
      "|    total_timesteps      | 380928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04492794 |\n",
      "|    clip_fraction        | 0.385      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.8      |\n",
      "|    explained_variance   | 0.014      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.4       |\n",
      "|    n_updates            | 1850       |\n",
      "|    policy_gradient_loss | 0.00927    |\n",
      "|    reward               | -6.8260784 |\n",
      "|    std                  | 1.35       |\n",
      "|    value_loss           | 47.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 187        |\n",
      "|    time_elapsed         | 3500       |\n",
      "|    total_timesteps      | 382976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03070177 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.8      |\n",
      "|    explained_variance   | 0.0243     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.7       |\n",
      "|    n_updates            | 1860       |\n",
      "|    policy_gradient_loss | -0.00757   |\n",
      "|    reward               | 1.5141946  |\n",
      "|    std                  | 1.35       |\n",
      "|    value_loss           | 43.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 188        |\n",
      "|    time_elapsed         | 3518       |\n",
      "|    total_timesteps      | 385024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03147775 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.9      |\n",
      "|    explained_variance   | 0.0228     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.7       |\n",
      "|    n_updates            | 1870       |\n",
      "|    policy_gradient_loss | -0.00847   |\n",
      "|    reward               | 0.6606849  |\n",
      "|    std                  | 1.35       |\n",
      "|    value_loss           | 75.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 189        |\n",
      "|    time_elapsed         | 3537       |\n",
      "|    total_timesteps      | 387072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0406005  |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.9      |\n",
      "|    explained_variance   | 0.0243     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.9       |\n",
      "|    n_updates            | 1880       |\n",
      "|    policy_gradient_loss | -0.00271   |\n",
      "|    reward               | -5.1175327 |\n",
      "|    std                  | 1.36       |\n",
      "|    value_loss           | 80.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 3556        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030774286 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.0539      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    reward               | 4.493161    |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4327593.09\n",
      "total_reward: 3327593.09\n",
      "total_cost: 260286.57\n",
      "total_trades: 70016\n",
      "Sharpe: 0.795\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 3575        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019368853 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.0298      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 1.3694227   |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 192        |\n",
      "|    time_elapsed         | 3593       |\n",
      "|    total_timesteps      | 393216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0199944  |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.1      |\n",
      "|    explained_variance   | 0.0407     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.9       |\n",
      "|    n_updates            | 1910       |\n",
      "|    policy_gradient_loss | -0.0052    |\n",
      "|    reward               | -4.5427675 |\n",
      "|    std                  | 1.36       |\n",
      "|    value_loss           | 81.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 3612        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026928134 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | 0.0208      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | 0.00415     |\n",
      "|    reward               | 0.5897313   |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 194        |\n",
      "|    time_elapsed         | 3630       |\n",
      "|    total_timesteps      | 397312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02421568 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.1      |\n",
      "|    explained_variance   | 0.0392     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.6       |\n",
      "|    n_updates            | 1930       |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    reward               | 1.0085199  |\n",
      "|    std                  | 1.36       |\n",
      "|    value_loss           | 48.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 3648        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029849576 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.0269      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | 0.00233     |\n",
      "|    reward               | 1.344799    |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 196        |\n",
      "|    time_elapsed         | 3667       |\n",
      "|    total_timesteps      | 401408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04144963 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.2      |\n",
      "|    explained_variance   | 0.0237     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.6       |\n",
      "|    n_updates            | 1950       |\n",
      "|    policy_gradient_loss | 0.00739    |\n",
      "|    reward               | 3.3923779  |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 75.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 3685        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045898605 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.07        |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | 0.00484     |\n",
      "|    reward               | 1.351732    |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 3704        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030880276 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | 0.0699      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | 0.5018628   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 68.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 3723       |\n",
      "|    total_timesteps      | 407552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03390631 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.4      |\n",
      "|    explained_variance   | 0.0925     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.6       |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | 0.00295    |\n",
      "|    reward               | 3.7388546  |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 63.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 3741        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036569104 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.89        |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -4.95e-05   |\n",
      "|    reward               | 0.9191367   |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 3760        |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029660244 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | 0.0017      |\n",
      "|    reward               | -0.7423073  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 3779        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032345608 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.00381     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | -4.4733596  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 3798        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031857558 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.0919      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | 0.57442427  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 3817        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035940293 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | -0.000998   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.62        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    reward               | 0.6032219   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3889435.50\n",
      "total_reward: 2889435.50\n",
      "total_cost: 208499.09\n",
      "total_trades: 65866\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 3836        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030513678 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | 2.6564298   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 3855        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021146845 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | -1.0515475  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 3873        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035813283 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.0873      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | -0.77205324 |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 208        |\n",
      "|    time_elapsed         | 3892       |\n",
      "|    total_timesteps      | 425984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03291502 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.8      |\n",
      "|    explained_variance   | 0.053      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.4       |\n",
      "|    n_updates            | 2070       |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    reward               | -3.6240125 |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 32.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 3910        |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030010274 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.0918      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.000465   |\n",
      "|    reward               | 6.688533    |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 3929        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029454662 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.000616   |\n",
      "|    reward               | -1.0406114  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 3947         |\n",
      "|    total_timesteps      | 432128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0364533    |\n",
      "|    clip_fraction        | 0.3          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -51          |\n",
      "|    explained_variance   | 0.0989       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 2100         |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    reward               | -0.088684365 |\n",
      "|    std                  | 1.41         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 3966        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0236976   |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | -0.19275466 |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 3986        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029681472 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.0877      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | 0.00189     |\n",
      "|    reward               | 3.9252005   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 4005        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030241847 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | 0.00503     |\n",
      "|    reward               | -0.6695421  |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 4025        |\n",
      "|    total_timesteps      | 440320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016972413 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    reward               | -0.15735778 |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 4045       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03215362 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.2      |\n",
      "|    explained_variance   | 0.0606     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.1       |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | -0.00434   |\n",
      "|    reward               | 1.6525705  |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 45.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 4064        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022592934 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.0333      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | 0.000612    |\n",
      "|    reward               | -0.35115334 |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 4082        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022677943 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    reward               | 0.23650385  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3141634.33\n",
      "total_reward: 2141634.33\n",
      "total_cost: 245893.82\n",
      "total_trades: 68552\n",
      "Sharpe: 0.599\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 4100        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031971492 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    reward               | -0.48756954 |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 4119        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027738787 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    reward               | 2.0819967   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 50.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 4138        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03268058  |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.53        |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.92896307 |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 4157        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015250949 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | -0.20103128 |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 4177        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017537083 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.0543      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | 1.5539623   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 4196        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033626236 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.0173      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.99        |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    reward               | 1.1440465   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 225        |\n",
      "|    time_elapsed         | 4215       |\n",
      "|    total_timesteps      | 460800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02169689 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.4      |\n",
      "|    explained_variance   | 0.0916     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.9       |\n",
      "|    n_updates            | 2240       |\n",
      "|    policy_gradient_loss | -0.00597   |\n",
      "|    reward               | 2.0358028  |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 33.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 4233        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022144876 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.0785      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | 4.5434213   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 4254        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027032198 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | 0.8021367   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 4273        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040716004 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.53        |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    reward               | -0.16898344 |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 4292        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03014968  |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.0819      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | -0.83416444 |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 4310        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023353029 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | 0.00338     |\n",
      "|    reward               | 0.068863146 |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 4328        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030182093 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | 0.000144    |\n",
      "|    reward               | -2.8272865  |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 4347        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032742485 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | -0.26191932 |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 4365        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044231623 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | 1.9409474   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2767884.08\n",
      "total_reward: 1767884.08\n",
      "total_cost: 323043.80\n",
      "total_trades: 74164\n",
      "Sharpe: 0.562\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 4383        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026983986 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | 0.00213     |\n",
      "|    reward               | 0.35144153  |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 4402        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032534245 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | -0.0316     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -2.9517157  |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 4420        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029299304 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 2.6001117   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 237        |\n",
      "|    time_elapsed         | 4439       |\n",
      "|    total_timesteps      | 485376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02146288 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.9      |\n",
      "|    explained_variance   | 0.207      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.5       |\n",
      "|    n_updates            | 2360       |\n",
      "|    policy_gradient_loss | -0.000429  |\n",
      "|    reward               | -0.7726274 |\n",
      "|    std                  | 1.45       |\n",
      "|    value_loss           | 50.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 4458        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02706998  |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.0571      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.2         |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -0.85035044 |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 4477        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023536436 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.86212045  |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 4495        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021355368 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | 0.57439214  |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 4514        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041913003 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.12        |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    reward               | -0.6406616  |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 4534        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030230975 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 0.9389994   |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 4553        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029259626 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | 0.8949805   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 4571        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023429543 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | 1.7261611   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 4591        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02823727  |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.000678    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.49        |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | -0.84733415 |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 4610        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024219222 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | -0.0356     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | 1.958026    |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 4629        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022957066 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 5.760875    |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2345602.49\n",
      "total_reward: 1345602.49\n",
      "total_cost: 277912.52\n",
      "total_trades: 71965\n",
      "Sharpe: 0.489\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 4648        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036707588 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.94        |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | -2.561389   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 4666        |\n",
      "|    total_timesteps      | 509952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021386515 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | 1.1434895   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 4684        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017923633 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | -1.9276489  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 4704        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018682946 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    reward               | -1.019872   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 4723        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040094554 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.44        |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | 0.09476104  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 4742        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034890335 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.00098    |\n",
      "|    reward               | -0.1603729  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 4761        |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020804714 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -0.6172172  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 49.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 4779        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052110203 |\n",
      "|    clip_fraction        | 0.44        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.7         |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | 0.00182     |\n",
      "|    reward               | 0.4302069   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 4798        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017888341 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | 5.040405    |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 257        |\n",
      "|    time_elapsed         | 4816       |\n",
      "|    total_timesteps      | 526336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01892889 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53        |\n",
      "|    explained_variance   | 0.352      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.8       |\n",
      "|    n_updates            | 2560       |\n",
      "|    policy_gradient_loss | 0.000964   |\n",
      "|    reward               | 1.6345496  |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 42.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 4835        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023287844 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.4         |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 2.4486487   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 4855        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028801281 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 0.48009092  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 4874        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010389493 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    reward               | -0.6159595  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 4893        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032332283 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.0719      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.000953   |\n",
      "|    reward               | 3.2666957   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3860862.81\n",
      "total_reward: 2860862.81\n",
      "total_cost: 314751.64\n",
      "total_trades: 74093\n",
      "Sharpe: 0.733\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 4912        |\n",
      "|    total_timesteps      | 536576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038828112 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.0892      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.34        |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | 0.5520563   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 4931        |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027398057 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.0819      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    reward               | 0.09753947  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 264         |\n",
      "|    time_elapsed         | 4950        |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030644756 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.036       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | -0.16184905 |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 98.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 4968        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042468745 |\n",
      "|    clip_fraction        | 0.407       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | 0.00753     |\n",
      "|    reward               | -3.2946062  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 4987        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032701068 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.0396      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | -1.4822159  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 5006        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030171338 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.3       |\n",
      "|    explained_variance   | 0.0551      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -1.3227721  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 268        |\n",
      "|    time_elapsed         | 5025       |\n",
      "|    total_timesteps      | 548864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02256366 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.3      |\n",
      "|    explained_variance   | 0.05       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.9       |\n",
      "|    n_updates            | 2670       |\n",
      "|    policy_gradient_loss | 0.000845   |\n",
      "|    reward               | -1.3282597 |\n",
      "|    std                  | 1.53       |\n",
      "|    value_loss           | 69.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 269        |\n",
      "|    time_elapsed         | 5044       |\n",
      "|    total_timesteps      | 550912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04424428 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.4      |\n",
      "|    explained_variance   | 0.129      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.42       |\n",
      "|    n_updates            | 2680       |\n",
      "|    policy_gradient_loss | -0.00753   |\n",
      "|    reward               | 0.4227256  |\n",
      "|    std                  | 1.53       |\n",
      "|    value_loss           | 12         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 270        |\n",
      "|    time_elapsed         | 5063       |\n",
      "|    total_timesteps      | 552960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03375319 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.5      |\n",
      "|    explained_variance   | 0.0882     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.6       |\n",
      "|    n_updates            | 2690       |\n",
      "|    policy_gradient_loss | -0.00269   |\n",
      "|    reward               | 2.0937557  |\n",
      "|    std                  | 1.53       |\n",
      "|    value_loss           | 32.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 271        |\n",
      "|    time_elapsed         | 5081       |\n",
      "|    total_timesteps      | 555008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0288491  |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.5      |\n",
      "|    explained_variance   | 0.072      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.4       |\n",
      "|    n_updates            | 2700       |\n",
      "|    policy_gradient_loss | -0.0099    |\n",
      "|    reward               | -1.6139768 |\n",
      "|    std                  | 1.54       |\n",
      "|    value_loss           | 20.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 5100        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036802948 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | -0.0359     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.43        |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    reward               | 1.078453    |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 273        |\n",
      "|    time_elapsed         | 5120       |\n",
      "|    total_timesteps      | 559104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0263183  |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.7      |\n",
      "|    explained_variance   | -0.00192   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.1       |\n",
      "|    n_updates            | 2720       |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    reward               | -0.5686705 |\n",
      "|    std                  | 1.54       |\n",
      "|    value_loss           | 30.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 5139        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031457793 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.0449      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.000601   |\n",
      "|    reward               | -10.251227  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 5157        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041363128 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.54        |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    reward               | 0.9180991   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2944012.92\n",
      "total_reward: 1944012.92\n",
      "total_cost: 313169.03\n",
      "total_trades: 73279\n",
      "Sharpe: 0.569\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 5176        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022844229 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.077       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 1.9217094   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 5195        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020541389 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    reward               | 0.70468056  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 278        |\n",
      "|    time_elapsed         | 5213       |\n",
      "|    total_timesteps      | 569344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02122735 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.9      |\n",
      "|    explained_variance   | 0.0323     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.3       |\n",
      "|    n_updates            | 2770       |\n",
      "|    policy_gradient_loss | -0.00552   |\n",
      "|    reward               | 1.610574   |\n",
      "|    std                  | 1.55       |\n",
      "|    value_loss           | 38.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 5232        |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037370346 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.0321      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.94        |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | 0.4322612   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 280        |\n",
      "|    time_elapsed         | 5251       |\n",
      "|    total_timesteps      | 573440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03683421 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54        |\n",
      "|    explained_variance   | 0.0267     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 2790       |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    reward               | 0.7319748  |\n",
      "|    std                  | 1.56       |\n",
      "|    value_loss           | 26.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 281        |\n",
      "|    time_elapsed         | 5271       |\n",
      "|    total_timesteps      | 575488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01984415 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.1      |\n",
      "|    explained_variance   | 0.00386    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.2       |\n",
      "|    n_updates            | 2800       |\n",
      "|    policy_gradient_loss | -0.00834   |\n",
      "|    reward               | 3.7939208  |\n",
      "|    std                  | 1.57       |\n",
      "|    value_loss           | 31.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 5290        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030319719 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.89        |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    reward               | 0.71569437  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 5310        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027445525 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.0598      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | 0.3190865   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 5328        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019689444 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.00376     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 2.8449032   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 69.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 285        |\n",
      "|    time_elapsed         | 5348       |\n",
      "|    total_timesteps      | 583680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02752441 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.2      |\n",
      "|    explained_variance   | -0.0168    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.4       |\n",
      "|    n_updates            | 2840       |\n",
      "|    policy_gradient_loss | 1.36e-05   |\n",
      "|    reward               | 4.129117   |\n",
      "|    std                  | 1.57       |\n",
      "|    value_loss           | 68.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 286        |\n",
      "|    time_elapsed         | 5367       |\n",
      "|    total_timesteps      | 585728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02138339 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.3      |\n",
      "|    explained_variance   | -0.00277   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.83       |\n",
      "|    n_updates            | 2850       |\n",
      "|    policy_gradient_loss | -0.00611   |\n",
      "|    reward               | -1.3852679 |\n",
      "|    std                  | 1.58       |\n",
      "|    value_loss           | 17.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 5387        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014267825 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.00976     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    reward               | 0.72165567  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 49.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 5406        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015552741 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.0147      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    reward               | 0.6366817   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 63.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 289        |\n",
      "|    time_elapsed         | 5425       |\n",
      "|    total_timesteps      | 591872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01943663 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.3      |\n",
      "|    explained_variance   | 0.152      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.2       |\n",
      "|    n_updates            | 2880       |\n",
      "|    policy_gradient_loss | -0.00869   |\n",
      "|    reward               | 3.596809   |\n",
      "|    std                  | 1.58       |\n",
      "|    value_loss           | 30         |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4897341.96\n",
      "total_reward: 3897341.96\n",
      "total_cost: 324066.16\n",
      "total_trades: 73651\n",
      "Sharpe: 0.863\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 5444        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017029688 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.1        |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    reward               | 0.4187026   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 79.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 291          |\n",
      "|    time_elapsed         | 5463         |\n",
      "|    total_timesteps      | 595968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.02143145   |\n",
      "|    clip_fraction        | 0.219        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -54.4        |\n",
      "|    explained_variance   | 0.0201       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.8         |\n",
      "|    n_updates            | 2900         |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    reward               | -0.040912192 |\n",
      "|    std                  | 1.58         |\n",
      "|    value_loss           | 72.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 5482        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018972535 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.1        |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | 0.71743625  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 5501        |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030673303 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.25        |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    reward               | 0.18487045  |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 5520        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019582806 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.0986      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | -0.42232108 |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 87.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 5538        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020416513 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.000813   |\n",
      "|    reward               | 0.49944922  |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 5558        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018970057 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | 0.000893    |\n",
      "|    reward               | -1.3619118  |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 5577        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027337842 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.0973      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | -1.265413   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 5596        |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024166632 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | -1.2024957  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 5616        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021897761 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.0161      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.000457   |\n",
      "|    reward               | -0.28438944 |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 5635        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028552635 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.0983      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.3        |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | 0.6224964   |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 69.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 5654        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029090792 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    reward               | 0.3906776   |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 5674        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030097093 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 0.0243      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | 0.00185     |\n",
      "|    reward               | -9.453128   |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 84.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 5694        |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032073442 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.0499      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    reward               | -4.3516235  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3039768.28\n",
      "total_reward: 2039768.28\n",
      "total_cost: 246155.24\n",
      "total_trades: 68859\n",
      "Sharpe: 0.585\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 5713        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024770517 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.0458      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    reward               | -0.19593883 |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 90.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 305        |\n",
      "|    time_elapsed         | 5732       |\n",
      "|    total_timesteps      | 624640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0195184  |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55        |\n",
      "|    explained_variance   | 0.182      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.1       |\n",
      "|    n_updates            | 3040       |\n",
      "|    policy_gradient_loss | -0.00719   |\n",
      "|    reward               | 0.11795902 |\n",
      "|    std                  | 1.62       |\n",
      "|    value_loss           | 68.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 5752        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024333335 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -2.546227   |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 5771        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022805117 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    reward               | 1.3529924   |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 5791        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023241378 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | -0.3863849  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 5810        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025965318 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | 0.68313843  |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 76.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 5828        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03956107  |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | -0.064      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | 0.00623     |\n",
      "|    reward               | -0.79580194 |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 311        |\n",
      "|    time_elapsed         | 5847       |\n",
      "|    total_timesteps      | 636928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03516589 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.3      |\n",
      "|    explained_variance   | 0.0691     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.3       |\n",
      "|    n_updates            | 3100       |\n",
      "|    policy_gradient_loss | 0.00108    |\n",
      "|    reward               | 0.14086857 |\n",
      "|    std                  | 1.63       |\n",
      "|    value_loss           | 96.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 5865        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027969645 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | 0.058       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.4        |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.768669   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 5885        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022982795 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | 0.000411    |\n",
      "|    reward               | -11.351116  |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 314          |\n",
      "|    time_elapsed         | 5904         |\n",
      "|    total_timesteps      | 643072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143413935 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -55.4        |\n",
      "|    explained_variance   | 0.216        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.3         |\n",
      "|    n_updates            | 3130         |\n",
      "|    policy_gradient_loss | -0.00935     |\n",
      "|    reward               | -1.9138806   |\n",
      "|    std                  | 1.64         |\n",
      "|    value_loss           | 81           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 315        |\n",
      "|    time_elapsed         | 5922       |\n",
      "|    total_timesteps      | 645120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03581187 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.4      |\n",
      "|    explained_variance   | 0.0657     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.2       |\n",
      "|    n_updates            | 3140       |\n",
      "|    policy_gradient_loss | -0.000286  |\n",
      "|    reward               | 4.2909665  |\n",
      "|    std                  | 1.64       |\n",
      "|    value_loss           | 95.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 5941        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021228429 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    reward               | 1.3798374   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 80.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 5960        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033352043 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | 0.00294     |\n",
      "|    reward               | 0.6729598   |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3945844.57\n",
      "total_reward: 2945844.57\n",
      "total_cost: 250881.39\n",
      "total_trades: 69684\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 318        |\n",
      "|    time_elapsed         | 5978       |\n",
      "|    total_timesteps      | 651264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02538161 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.6      |\n",
      "|    explained_variance   | 0.114      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47.4       |\n",
      "|    n_updates            | 3170       |\n",
      "|    policy_gradient_loss | -0.00583   |\n",
      "|    reward               | 3.6138194  |\n",
      "|    std                  | 1.65       |\n",
      "|    value_loss           | 82.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 5997        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017151749 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.0734      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    reward               | -1.78964    |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 87.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 6016        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020619217 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    reward               | -0.9995006  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 6036        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024667248 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | -0.36783794 |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 6056        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021962892 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    reward               | 2.3639388   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 6078        |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045892715 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.0948      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    reward               | -2.5330353  |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 6097        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025642522 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.0938      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    reward               | 0.6036516   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 6115        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020501055 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | 0.65003014  |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 63.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 6134        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028975628 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.0867      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | 0.00277     |\n",
      "|    reward               | 0.7214415   |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 64.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 6153        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038711727 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.79        |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | 0.00142     |\n",
      "|    reward               | 0.20683886  |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 6172        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025138468 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.0582      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.7        |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.000628   |\n",
      "|    reward               | 0.46864343  |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 6190        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023500208 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31          |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.000375   |\n",
      "|    reward               | -1.5078081  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 330        |\n",
      "|    time_elapsed         | 6209       |\n",
      "|    total_timesteps      | 675840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03198179 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.1      |\n",
      "|    explained_variance   | 0.041      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.9       |\n",
      "|    n_updates            | 3290       |\n",
      "|    policy_gradient_loss | -0.00235   |\n",
      "|    reward               | -6.3790264 |\n",
      "|    std                  | 1.68       |\n",
      "|    value_loss           | 31.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 331          |\n",
      "|    time_elapsed         | 6228         |\n",
      "|    total_timesteps      | 677888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.021992711  |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -56.1        |\n",
      "|    explained_variance   | 0.259        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 3300         |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | -0.008576864 |\n",
      "|    std                  | 1.68         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3047602.05\n",
      "total_reward: 2047602.05\n",
      "total_cost: 265525.30\n",
      "total_trades: 70037\n",
      "Sharpe: 0.596\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 6247        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020978307 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | -0.66439843 |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 333        |\n",
      "|    time_elapsed         | 6265       |\n",
      "|    total_timesteps      | 681984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01873834 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.2      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.6       |\n",
      "|    n_updates            | 3320       |\n",
      "|    policy_gradient_loss | -0.00517   |\n",
      "|    reward               | 3.2245412  |\n",
      "|    std                  | 1.68       |\n",
      "|    value_loss           | 54.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 6284        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037965678 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.2         |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.000833   |\n",
      "|    reward               | -0.11894977 |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 6302        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032303497 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | 0.00666     |\n",
      "|    reward               | -0.45094684 |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 6321        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026299499 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.0611      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    reward               | 1.0662082   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 66.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 6340        |\n",
      "|    total_timesteps      | 690176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020776974 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | 0.27338848  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 6359        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028563695 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | -0.2665194  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 6378        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033207156 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | 0.0111      |\n",
      "|    reward               | 0.93222684  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 6397        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020511776 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.095       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 3390        |\n",
      "|    policy_gradient_loss | 0.000498    |\n",
      "|    reward               | 0.6961229   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 6416        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037129883 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | -0.0264     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | 0.00352     |\n",
      "|    reward               | -0.3217638  |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 6435        |\n",
      "|    total_timesteps      | 700416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027519114 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.0967      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 0.70230323  |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 63.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 6453        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025750125 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | 2.8571534   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 6472        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020444328 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    reward               | 3.8590124   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 6490        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016725685 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 3440        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 2.151701    |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 6509        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023682864 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.2        |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.00086    |\n",
      "|    reward               | 7.350208    |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 97.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3406914.21\n",
      "total_reward: 2406914.21\n",
      "total_cost: 223518.94\n",
      "total_trades: 66358\n",
      "Sharpe: 0.643\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 347           |\n",
      "|    time_elapsed         | 6527          |\n",
      "|    total_timesteps      | 710656        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.022590265   |\n",
      "|    clip_fraction        | 0.284         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -56.7         |\n",
      "|    explained_variance   | 0.316         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.9          |\n",
      "|    n_updates            | 3460          |\n",
      "|    policy_gradient_loss | 0.000602      |\n",
      "|    reward               | -0.0035241155 |\n",
      "|    std                  | 1.72          |\n",
      "|    value_loss           | 38.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 6546        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026754128 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -0.6461525  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 6564        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026260504 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.000352   |\n",
      "|    reward               | 0.9877569   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 50.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 6583        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017549701 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | 1.2641419   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 6601        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025455507 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | 1.819488    |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 352        |\n",
      "|    time_elapsed         | 6620       |\n",
      "|    total_timesteps      | 720896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04506599 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.9      |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.1       |\n",
      "|    n_updates            | 3510       |\n",
      "|    policy_gradient_loss | -0.00189   |\n",
      "|    reward               | -0.9773779 |\n",
      "|    std                  | 1.73       |\n",
      "|    value_loss           | 51.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 6639        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01682105  |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.000417   |\n",
      "|    reward               | -0.85197645 |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 6658        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030512871 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | -0.000758   |\n",
      "|    reward               | -4.5974407  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 6676        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024129888 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    reward               | 0.83164114  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 95.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 6695        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019078672 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | -1.15043    |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 6713        |\n",
      "|    total_timesteps      | 731136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022590756 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.7        |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    reward               | -0.3084015  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 6732        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043561615 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.86        |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | 0.00407     |\n",
      "|    reward               | -0.49783087 |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 6751        |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023589775 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | -1.9529712  |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 6770        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015058976 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.0334      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | -0.9116195  |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5040563.32\n",
      "total_reward: 4040563.32\n",
      "total_cost: 233235.01\n",
      "total_trades: 67277\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 6788        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027854737 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.0587      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | 0.00232     |\n",
      "|    reward               | 0.5577557   |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 6807        |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018371064 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.4       |\n",
      "|    explained_variance   | 0.0614      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    reward               | 0.86582     |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 97.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 6826        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022752706 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | 0.0933      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | -60.226467  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 97.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 6844        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028546806 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | -0.0257     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.000923   |\n",
      "|    reward               | 0.31439337  |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 6863        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025497269 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.0589      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    reward               | 1.5835549   |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 6881        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010888481 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.0319      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.9        |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | 2.5432594   |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 367         |\n",
      "|    time_elapsed         | 6900        |\n",
      "|    total_timesteps      | 751616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018577158 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.0411      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | 0.00319     |\n",
      "|    reward               | 2.620834    |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 6918        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018981554 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    reward               | -0.70568925 |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 6937        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018221468 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.000214   |\n",
      "|    reward               | -1.2680472  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 251         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 6955        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015950294 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | -1.4276267  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 6974        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020170486 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | -4.4003778  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 372        |\n",
      "|    time_elapsed         | 6992       |\n",
      "|    total_timesteps      | 761856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01626734 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.8      |\n",
      "|    explained_variance   | 0.166      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 182        |\n",
      "|    n_updates            | 3710       |\n",
      "|    policy_gradient_loss | -0.0059    |\n",
      "|    reward               | 2.9586604  |\n",
      "|    std                  | 1.78       |\n",
      "|    value_loss           | 150        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 7010        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016606882 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | -0.87796736 |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 322         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 374        |\n",
      "|    time_elapsed         | 7030       |\n",
      "|    total_timesteps      | 765952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00613717 |\n",
      "|    clip_fraction        | 0.0517     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.8      |\n",
      "|    explained_variance   | 0.000135   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 178        |\n",
      "|    n_updates            | 3730       |\n",
      "|    policy_gradient_loss | -0.00532   |\n",
      "|    reward               | -0.8710174 |\n",
      "|    std                  | 1.78       |\n",
      "|    value_loss           | 592        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6905511.46\n",
      "total_reward: 5905511.46\n",
      "total_cost: 262737.80\n",
      "total_trades: 68407\n",
      "Sharpe: 0.850\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 7048        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027869806 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    reward               | 0.52145886  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 7067        |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026610471 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.0368      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 276         |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | 0.22218324  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 554         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 377        |\n",
      "|    time_elapsed         | 7086       |\n",
      "|    total_timesteps      | 772096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01661729 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.8      |\n",
      "|    explained_variance   | 0.052      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 143        |\n",
      "|    n_updates            | 3760       |\n",
      "|    policy_gradient_loss | -0.00561   |\n",
      "|    reward               | -1.8543805 |\n",
      "|    std                  | 1.78       |\n",
      "|    value_loss           | 544        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 378        |\n",
      "|    time_elapsed         | 7104       |\n",
      "|    total_timesteps      | 774144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02652814 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.9      |\n",
      "|    explained_variance   | 0.0375     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.8       |\n",
      "|    n_updates            | 3770       |\n",
      "|    policy_gradient_loss | -0.00334   |\n",
      "|    reward               | 6.479168   |\n",
      "|    std                  | 1.79       |\n",
      "|    value_loss           | 51.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 7123        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022294562 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | -1.2312889  |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 7142        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021223016 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.0372      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.9        |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | 0.34373093  |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 381         |\n",
      "|    time_elapsed         | 7161        |\n",
      "|    total_timesteps      | 780288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009397272 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.075       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 376         |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | 0.00173     |\n",
      "|    reward               | -0.17812896 |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 555         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 382        |\n",
      "|    time_elapsed         | 7180       |\n",
      "|    total_timesteps      | 782336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04927942 |\n",
      "|    clip_fraction        | 0.372      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58        |\n",
      "|    explained_variance   | 0.0557     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.3       |\n",
      "|    n_updates            | 3810       |\n",
      "|    policy_gradient_loss | 0.00533    |\n",
      "|    reward               | 1.2010971  |\n",
      "|    std                  | 1.8        |\n",
      "|    value_loss           | 25.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 7198        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010188643 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.0864      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -3.48e-05   |\n",
      "|    reward               | 0.80662805  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 355         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 7217        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013922426 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 204         |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | 6.8089843   |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 7235         |\n",
      "|    total_timesteps      | 788480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.021603711  |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -58.1        |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 3840         |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 0.0049760086 |\n",
      "|    std                  | 1.8          |\n",
      "|    value_loss           | 52.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 7254        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015016122 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.089       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 172         |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -0.08501584 |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 387        |\n",
      "|    time_elapsed         | 7273       |\n",
      "|    total_timesteps      | 792576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02471545 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.2      |\n",
      "|    explained_variance   | 0.083      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 114        |\n",
      "|    n_updates            | 3860       |\n",
      "|    policy_gradient_loss | -0.00715   |\n",
      "|    reward               | 8.071438   |\n",
      "|    std                  | 1.81       |\n",
      "|    value_loss           | 494        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 7291        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021627799 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 0.17611383  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3797600.31\n",
      "total_reward: 2797600.31\n",
      "total_cost: 250907.97\n",
      "total_trades: 67097\n",
      "Sharpe: 0.578\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 7310        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020164035 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.0309      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 3.2408118   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 7328        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006671685 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.0754      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 258         |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.00026    |\n",
      "|    reward               | 1.9426188   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 424         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 7347        |\n",
      "|    total_timesteps      | 800768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023006884 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.00756     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 205         |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.000379   |\n",
      "|    reward               | 4.212551    |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 341         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 7365        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016443845 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | -0.0501     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 0.22326037  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 7385        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014086214 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.0196      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    reward               | -0.6770376  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 7404        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019467648 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.0569      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | -2.3549123  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 246         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 7423        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026578767 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.0475      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.3        |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 4.3406143   |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 7443        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019938719 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.009       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | 2.0865147   |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 7463        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015372911 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.0634      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | -0.8439057  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 360         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 7482        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018915474 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.00739     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 315         |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | -4.8509526  |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 433         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 7500        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031850055 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | 0.00654     |\n",
      "|    reward               | -5.284399   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 7519        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020237159 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.0741      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 291         |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | -0.73609895 |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 405         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 7538        |\n",
      "|    total_timesteps      | 821248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022323232 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | 0.002       |\n",
      "|    reward               | -14.098129  |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 306         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 7557        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028150888 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.3        |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | -0.000369   |\n",
      "|    reward               | 1.732305    |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7481665.78\n",
      "total_reward: 6481665.78\n",
      "total_cost: 197460.23\n",
      "total_trades: 64379\n",
      "Sharpe: 0.867\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 7576        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011315841 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 9.42e-06    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.7        |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -0.666808   |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 542         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 7595        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013260333 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.0505      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 632         |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    reward               | 1.9487759   |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 540         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 7614        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017965287 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.0186      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 3.9048412   |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 706         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 406         |\n",
      "|    time_elapsed         | 7632        |\n",
      "|    total_timesteps      | 831488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018390633 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 4050        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 2.3885896   |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 7651        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012358928 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.0888      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 592         |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.00754    |\n",
      "|    reward               | 3.3364959   |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 749         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 7670        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016207993 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.0452      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 279         |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | -0.000739   |\n",
      "|    reward               | 3.415846    |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 804         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 7689        |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028031692 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.6        |\n",
      "|    n_updates            | 4080        |\n",
      "|    policy_gradient_loss | 0.000293    |\n",
      "|    reward               | -4.588205   |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 90.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 410        |\n",
      "|    time_elapsed         | 7707       |\n",
      "|    total_timesteps      | 839680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01979552 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.1      |\n",
      "|    explained_variance   | 0.0732     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 118        |\n",
      "|    n_updates            | 4090       |\n",
      "|    policy_gradient_loss | -0.00257   |\n",
      "|    reward               | 1.5271055  |\n",
      "|    std                  | 1.86       |\n",
      "|    value_loss           | 483        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 7726        |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015266937 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.0791      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 266         |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | -1.7523015  |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 412         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 7745        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019534571 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53          |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | 0.000658    |\n",
      "|    reward               | 0.7449922   |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 7763        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022176322 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 411         |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -1.1021508  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 376         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 7783        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017190613 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | -1.7942139  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 469         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 7801        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029636955 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.0747      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | 1.7332536   |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 450         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 416          |\n",
      "|    time_elapsed         | 7820         |\n",
      "|    total_timesteps      | 851968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.026636947  |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -59.3        |\n",
      "|    explained_variance   | 0.321        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 4150         |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | -0.040933922 |\n",
      "|    std                  | 1.88         |\n",
      "|    value_loss           | 55.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8529801.96\n",
      "total_reward: 7529801.96\n",
      "total_cost: 231477.07\n",
      "total_trades: 66668\n",
      "Sharpe: 1.013\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 7840        |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014657987 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.079       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 256         |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | -0.45657772 |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 420         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 7859        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017589416 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.0929      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | -1.4265261  |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 7879        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028521977 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.4        |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.2989397   |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 7897        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019438354 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.0747      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 258         |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -0.75438344 |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 378         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 7917        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017222896 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | -0.49517387 |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 300         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 7937        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020776173 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.0721      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 265         |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | 2.040589    |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 367         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 7956        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027227756 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | 0.9443416   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 7975        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022224303 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | -2.454626   |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 322         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 7995        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015918452 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 181         |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.000315   |\n",
      "|    reward               | -11.022047  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 655         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 426           |\n",
      "|    time_elapsed         | 8013          |\n",
      "|    total_timesteps      | 872448        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.030166004   |\n",
      "|    clip_fraction        | 0.215         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -59.8         |\n",
      "|    explained_variance   | 0.112         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.6          |\n",
      "|    n_updates            | 4250          |\n",
      "|    policy_gradient_loss | 0.000313      |\n",
      "|    reward               | -0.0110722445 |\n",
      "|    std                  | 1.91          |\n",
      "|    value_loss           | 69.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 8033        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015966192 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.9        |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | -0.4327787  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 8051        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017620884 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.9       |\n",
      "|    explained_variance   | 0.0567      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 315         |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | -10.484532  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 609         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 8070        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030847507 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.9       |\n",
      "|    explained_variance   | 0.0011      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.000874   |\n",
      "|    reward               | -1.1602134  |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 464         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 430       |\n",
      "|    time_elapsed         | 8088      |\n",
      "|    total_timesteps      | 880640    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0256383 |\n",
      "|    clip_fraction        | 0.282     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -60       |\n",
      "|    explained_variance   | 0.256     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 22.6      |\n",
      "|    n_updates            | 4290      |\n",
      "|    policy_gradient_loss | -0.0148   |\n",
      "|    reward               | 3.1273613 |\n",
      "|    std                  | 1.92      |\n",
      "|    value_loss           | 59.1      |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5106952.79\n",
      "total_reward: 4106952.79\n",
      "total_cost: 289838.96\n",
      "total_trades: 69032\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 431          |\n",
      "|    time_elapsed         | 8106         |\n",
      "|    total_timesteps      | 882688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077124354 |\n",
      "|    clip_fraction        | 0.0607       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60          |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 282          |\n",
      "|    n_updates            | 4300         |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | -2.0373392   |\n",
      "|    std                  | 1.92         |\n",
      "|    value_loss           | 533          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 8125        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014564843 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 326         |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    reward               | 0.3250608   |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 355         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 8143        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014813044 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    reward               | -7.664106   |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 8162        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017391423 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.0529      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    reward               | 2.769191    |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 315         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 8182        |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012318642 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | -0.0493     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 6.539958    |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 401         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 8201        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028240047 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.2        |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | 3.1195505   |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 8219        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031939067 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.0591      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | -0.8631415  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 8238        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023976805 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.0536      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    reward               | 0.32682118  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 348         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 8256        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023562849 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.000272    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.2        |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | 0.000582    |\n",
      "|    reward               | 3.5851705   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 274         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 8275        |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021109326 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | -0.0146     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | -2.4017675  |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 8293        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02348054  |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.0129      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -0.99703294 |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 8312        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020309681 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.0818      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    reward               | 2.8074775   |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 374         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 443        |\n",
      "|    time_elapsed         | 8330       |\n",
      "|    total_timesteps      | 907264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03409168 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.5      |\n",
      "|    explained_variance   | -0.021     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.7       |\n",
      "|    n_updates            | 4420       |\n",
      "|    policy_gradient_loss | -0.00482   |\n",
      "|    reward               | 2.6316457  |\n",
      "|    std                  | 1.95       |\n",
      "|    value_loss           | 121        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 444          |\n",
      "|    time_elapsed         | 8355         |\n",
      "|    total_timesteps      | 909312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.028191026  |\n",
      "|    clip_fraction        | 0.274        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.5        |\n",
      "|    explained_variance   | 0.0277       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.7         |\n",
      "|    n_updates            | 4430         |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | -0.077431634 |\n",
      "|    std                  | 1.96         |\n",
      "|    value_loss           | 283          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4287859.55\n",
      "total_reward: 3287859.55\n",
      "total_cost: 251965.95\n",
      "total_trades: 66698\n",
      "Sharpe: 0.630\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 8375        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011357479 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | -0.00247    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | -0.6155779  |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 398         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 8393        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015544308 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 2.4208395   |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 537         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 447        |\n",
      "|    time_elapsed         | 8412       |\n",
      "|    total_timesteps      | 915456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03183266 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.7      |\n",
      "|    explained_variance   | 0.392      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.6       |\n",
      "|    n_updates            | 4460       |\n",
      "|    policy_gradient_loss | -0.00409   |\n",
      "|    reward               | -0.4170411 |\n",
      "|    std                  | 1.98       |\n",
      "|    value_loss           | 26.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 8430        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012326215 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | 0.7558913   |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 336         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 449        |\n",
      "|    time_elapsed         | 8449       |\n",
      "|    total_timesteps      | 919552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02013895 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.9      |\n",
      "|    explained_variance   | 0.000877   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 208        |\n",
      "|    n_updates            | 4480       |\n",
      "|    policy_gradient_loss | 0.000186   |\n",
      "|    reward               | 22.213327  |\n",
      "|    std                  | 1.99       |\n",
      "|    value_loss           | 409        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 8467        |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015614005 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.4        |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | -1.027766   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 8486        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016395815 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.0183      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 442         |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    reward               | 0.69570464  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 703         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 8505        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015793175 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.0199      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 181         |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -7.1218657  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 794         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 453          |\n",
      "|    time_elapsed         | 8523         |\n",
      "|    total_timesteps      | 927744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072408924 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -61.1        |\n",
      "|    explained_variance   | 0.0476       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 370          |\n",
      "|    n_updates            | 4520         |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    reward               | -0.70508224  |\n",
      "|    std                  | 2            |\n",
      "|    value_loss           | 772          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 8542        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023335963 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 5.007365    |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 79.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 455        |\n",
      "|    time_elapsed         | 8561       |\n",
      "|    total_timesteps      | 931840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01353975 |\n",
      "|    clip_fraction        | 0.098      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.2      |\n",
      "|    explained_variance   | 0.079      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 711        |\n",
      "|    n_updates            | 4540       |\n",
      "|    policy_gradient_loss | -0.00961   |\n",
      "|    reward               | 2.161847   |\n",
      "|    std                  | 2          |\n",
      "|    value_loss           | 751        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 8580        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009852599 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.0429      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 510         |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    reward               | -16.083626  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 864         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 457        |\n",
      "|    time_elapsed         | 8599       |\n",
      "|    total_timesteps      | 935936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02258256 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.2      |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 55.3       |\n",
      "|    n_updates            | 4560       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | -3.94066   |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 111        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 8618        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009196098 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 526         |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | -7.3820906  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 544         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 8637        |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011705747 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.0298      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 706         |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | 9.314356    |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 889         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4893781.54\n",
      "total_reward: 3893781.54\n",
      "total_cost: 240597.15\n",
      "total_trades: 65688\n",
      "Sharpe: 0.654\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 8656        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016512658 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.0461      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | -3.757984   |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 8675        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014393141 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.0115      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 289         |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -1.9060816  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 582         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 462        |\n",
      "|    time_elapsed         | 8694       |\n",
      "|    total_timesteps      | 946176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00653586 |\n",
      "|    clip_fraction        | 0.0287     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.2      |\n",
      "|    explained_variance   | 0.0848     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 684        |\n",
      "|    n_updates            | 4610       |\n",
      "|    policy_gradient_loss | -0.00353   |\n",
      "|    reward               | -0.3328044 |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 880        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 8713        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011260287 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.0575      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 338         |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    reward               | -1.7824035  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 695         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 8732        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010080031 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | -4.965458   |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 79.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 8750        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010624681 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.0436      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 744         |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | 0.7046477   |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 980         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 8769        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013271477 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.0676      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -21.92637   |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 629         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 467        |\n",
      "|    time_elapsed         | 8787       |\n",
      "|    total_timesteps      | 956416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02292515 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.4      |\n",
      "|    explained_variance   | 0.0966     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 205        |\n",
      "|    n_updates            | 4660       |\n",
      "|    policy_gradient_loss | -0.00312   |\n",
      "|    reward               | -1.5647793 |\n",
      "|    std                  | 2.02       |\n",
      "|    value_loss           | 292        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 468        |\n",
      "|    time_elapsed         | 8806       |\n",
      "|    total_timesteps      | 958464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01970294 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.4      |\n",
      "|    explained_variance   | 0.0793     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 304        |\n",
      "|    n_updates            | 4670       |\n",
      "|    policy_gradient_loss | -0.00498   |\n",
      "|    reward               | -1.3364098 |\n",
      "|    std                  | 2.02       |\n",
      "|    value_loss           | 596        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 469        |\n",
      "|    time_elapsed         | 8825       |\n",
      "|    total_timesteps      | 960512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01467135 |\n",
      "|    clip_fraction        | 0.0889     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.4      |\n",
      "|    explained_variance   | 0.122      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 168        |\n",
      "|    n_updates            | 4680       |\n",
      "|    policy_gradient_loss | -0.00759   |\n",
      "|    reward               | -0.6881203 |\n",
      "|    std                  | 2.02       |\n",
      "|    value_loss           | 759        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 8844        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017051814 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.0342      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 397         |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | -1.3454245  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 690         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 471          |\n",
      "|    time_elapsed         | 8862         |\n",
      "|    total_timesteps      | 964608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.039741844  |\n",
      "|    clip_fraction        | 0.317        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -61.5        |\n",
      "|    explained_variance   | -0.104       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 4700         |\n",
      "|    policy_gradient_loss | 0.00331      |\n",
      "|    reward               | -0.102295265 |\n",
      "|    std                  | 2.02         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 8881        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025302656 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.0783      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | -0.8039278  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 429         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 473          |\n",
      "|    time_elapsed         | 8901         |\n",
      "|    total_timesteps      | 968704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111487005 |\n",
      "|    clip_fraction        | 0.0555       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -61.5        |\n",
      "|    explained_variance   | 0.196        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 208          |\n",
      "|    n_updates            | 4720         |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 4.999202     |\n",
      "|    std                  | 2.02         |\n",
      "|    value_loss           | 467          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4796357.14\n",
      "total_reward: 3796357.14\n",
      "total_cost: 217056.20\n",
      "total_trades: 65419\n",
      "Sharpe: 0.690\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 474         |\n",
      "|    time_elapsed         | 8920        |\n",
      "|    total_timesteps      | 970752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030049402 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | -0.000763   |\n",
      "|    reward               | 6.098093    |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 475          |\n",
      "|    time_elapsed         | 8939         |\n",
      "|    total_timesteps      | 972800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072583724 |\n",
      "|    clip_fraction        | 0.0645       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -61.5        |\n",
      "|    explained_variance   | 0.133        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 4740         |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | 0.25375074   |\n",
      "|    std                  | 2.03         |\n",
      "|    value_loss           | 361          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 8958        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023190461 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.0557      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 202         |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | 4.83e-05    |\n",
      "|    reward               | 0.17396688  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 338         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 477        |\n",
      "|    time_elapsed         | 8976       |\n",
      "|    total_timesteps      | 976896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01441147 |\n",
      "|    clip_fraction        | 0.0963     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.5      |\n",
      "|    explained_variance   | 0.09       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 95.6       |\n",
      "|    n_updates            | 4760       |\n",
      "|    policy_gradient_loss | -0.00533   |\n",
      "|    reward               | -1.0519774 |\n",
      "|    std                  | 2.03       |\n",
      "|    value_loss           | 240        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 478        |\n",
      "|    time_elapsed         | 8995       |\n",
      "|    total_timesteps      | 978944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01639305 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.6      |\n",
      "|    explained_variance   | 0.0138     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 185        |\n",
      "|    n_updates            | 4770       |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    reward               | 2.6366026  |\n",
      "|    std                  | 2.04       |\n",
      "|    value_loss           | 300        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 9013        |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026508614 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.0568      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | 0.000256    |\n",
      "|    reward               | -3.3281012  |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 706         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 480          |\n",
      "|    time_elapsed         | 9032         |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151136145 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -61.7        |\n",
      "|    explained_variance   | 0.0959       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 335          |\n",
      "|    n_updates            | 4790         |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -10.451485   |\n",
      "|    std                  | 2.04         |\n",
      "|    value_loss           | 546          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 9050        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011432383 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.034       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 2.6154456   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 84.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 482        |\n",
      "|    time_elapsed         | 9069       |\n",
      "|    total_timesteps      | 987136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01853802 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.8      |\n",
      "|    explained_variance   | 0.0657     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 353        |\n",
      "|    n_updates            | 4810       |\n",
      "|    policy_gradient_loss | -0.00626   |\n",
      "|    reward               | -1.1941545 |\n",
      "|    std                  | 2.04       |\n",
      "|    value_loss           | 571        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 9087        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009444505 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 371         |\n",
      "|    n_updates            | 4820        |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    reward               | -27.303284  |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 673         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 484         |\n",
      "|    time_elapsed         | 9106        |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024267672 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.0201      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | 0.000149    |\n",
      "|    reward               | 2.1085668   |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 282         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 9125        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01673685  |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | 0.0256      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 331         |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | 0.056967005 |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 536         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 486        |\n",
      "|    time_elapsed         | 9144       |\n",
      "|    total_timesteps      | 995328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02339204 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62        |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 708        |\n",
      "|    n_updates            | 4850       |\n",
      "|    policy_gradient_loss | -0.00843   |\n",
      "|    reward               | 1.3244791  |\n",
      "|    std                  | 2.06       |\n",
      "|    value_loss           | 649        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 487        |\n",
      "|    time_elapsed         | 9163       |\n",
      "|    total_timesteps      | 997376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01855241 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.1      |\n",
      "|    explained_variance   | 0.0611     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 202        |\n",
      "|    n_updates            | 4860       |\n",
      "|    policy_gradient_loss | -0.00788   |\n",
      "|    reward               | -4.9701505 |\n",
      "|    std                  | 2.07       |\n",
      "|    value_loss           | 835        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5298518.88\n",
      "total_reward: 4298518.88\n",
      "total_cost: 180530.66\n",
      "total_trades: 62630\n",
      "Sharpe: 0.652\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 9182        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025338601 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.000508   |\n",
      "|    reward               | 0.9545898   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 70.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 489          |\n",
      "|    time_elapsed         | 9200         |\n",
      "|    total_timesteps      | 1001472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078004175 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.1        |\n",
      "|    explained_variance   | 0.048        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 519          |\n",
      "|    n_updates            | 4880         |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    reward               | 0.16494608   |\n",
      "|    std                  | 2.07         |\n",
      "|    value_loss           | 1.09e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 9219        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024818238 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 650         |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | 0.19712038  |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 9238        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016741311 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.0941      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | 6.340255    |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 9256        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015080182 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    reward               | 4.394712    |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 590         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 9275        |\n",
      "|    total_timesteps      | 1009664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00602472  |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 4920        |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    reward               | 0.012923033 |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 799         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 494        |\n",
      "|    time_elapsed         | 9294       |\n",
      "|    total_timesteps      | 1011712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0070095  |\n",
      "|    clip_fraction        | 0.0828     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.2      |\n",
      "|    explained_variance   | 0.248      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 414        |\n",
      "|    n_updates            | 4930       |\n",
      "|    policy_gradient_loss | 0.00138    |\n",
      "|    reward               | -1.1129788 |\n",
      "|    std                  | 2.08       |\n",
      "|    value_loss           | 899        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 9313        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022368468 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | 7.9054623   |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 496          |\n",
      "|    time_elapsed         | 9333         |\n",
      "|    total_timesteps      | 1015808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031739024 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.3        |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 394          |\n",
      "|    n_updates            | 4950         |\n",
      "|    policy_gradient_loss | -0.000707    |\n",
      "|    reward               | -0.33138353  |\n",
      "|    std                  | 2.08         |\n",
      "|    value_loss           | 852          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 497         |\n",
      "|    time_elapsed         | 9352        |\n",
      "|    total_timesteps      | 1017856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001815486 |\n",
      "|    clip_fraction        | 0.00747     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 495         |\n",
      "|    n_updates            | 4960        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | -1.9599094  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 775         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 498        |\n",
      "|    time_elapsed         | 9371       |\n",
      "|    total_timesteps      | 1019904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01499339 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.3      |\n",
      "|    explained_variance   | 0.32       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 57.6       |\n",
      "|    n_updates            | 4970       |\n",
      "|    policy_gradient_loss | -0.00267   |\n",
      "|    reward               | 1.0877213  |\n",
      "|    std                  | 2.09       |\n",
      "|    value_loss           | 160        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 9390        |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005674501 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 476         |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    reward               | 0.43987104  |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 811         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 9409        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004273148 |\n",
      "|    clip_fraction        | 0.0174      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.4       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 217         |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | 6.9088473   |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 693         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 501        |\n",
      "|    time_elapsed         | 9428       |\n",
      "|    total_timesteps      | 1026048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01455871 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.4      |\n",
      "|    explained_variance   | 0.283      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 173        |\n",
      "|    n_updates            | 5000       |\n",
      "|    policy_gradient_loss | -0.0028    |\n",
      "|    reward               | -1.4563489 |\n",
      "|    std                  | 2.09       |\n",
      "|    value_loss           | 353        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5831265.61\n",
      "total_reward: 4831265.61\n",
      "total_cost: 166385.83\n",
      "total_trades: 61649\n",
      "Sharpe: 0.733\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 9447        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011169801 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.4       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 233         |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | -0.44107243 |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 518         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 503        |\n",
      "|    time_elapsed         | 9466       |\n",
      "|    total_timesteps      | 1030144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01614957 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.5      |\n",
      "|    explained_variance   | 0.104      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 695        |\n",
      "|    n_updates            | 5020       |\n",
      "|    policy_gradient_loss | -0.00896   |\n",
      "|    reward               | 1.136345   |\n",
      "|    std                  | 2.09       |\n",
      "|    value_loss           | 765        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 9485        |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007211974 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 601         |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    reward               | -7.0966907  |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 9503        |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025068386 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | -2.0428429  |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 89.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 9521        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010335255 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 376         |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | 0.13974798  |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 724         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 507        |\n",
      "|    time_elapsed         | 9540       |\n",
      "|    total_timesteps      | 1038336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00932551 |\n",
      "|    clip_fraction        | 0.0706     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.6      |\n",
      "|    explained_variance   | 0.0657     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 560        |\n",
      "|    n_updates            | 5060       |\n",
      "|    policy_gradient_loss | -0.00772   |\n",
      "|    reward               | 2.084647   |\n",
      "|    std                  | 2.1        |\n",
      "|    value_loss           | 911        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 508         |\n",
      "|    time_elapsed         | 9558        |\n",
      "|    total_timesteps      | 1040384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025529161 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.000415   |\n",
      "|    reward               | -0.6034653  |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 9577        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014546717 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 5080        |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -0.24467732 |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 9595        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01975222  |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 0.098390006 |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 315         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 9614        |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020824166 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 227         |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | 0.000502    |\n",
      "|    reward               | 15.63532    |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 357         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 9632        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027523745 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.0748      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | 0.000566    |\n",
      "|    reward               | -3.4029582  |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 513        |\n",
      "|    time_elapsed         | 9650       |\n",
      "|    total_timesteps      | 1050624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01520767 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.8      |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.9       |\n",
      "|    n_updates            | 5120       |\n",
      "|    policy_gradient_loss | -0.00562   |\n",
      "|    reward               | 0.23997213 |\n",
      "|    std                  | 2.12       |\n",
      "|    value_loss           | 265        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 9670        |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012592433 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 5130        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | 4.667725    |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 9689        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018090032 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | -3.2918892  |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 89.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5606477.93\n",
      "total_reward: 4606477.93\n",
      "total_cost: 191101.71\n",
      "total_trades: 62083\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 9707        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018312184 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.1        |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    reward               | -3.382799   |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 517        |\n",
      "|    time_elapsed         | 9726       |\n",
      "|    total_timesteps      | 1058816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01329946 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.9      |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 148        |\n",
      "|    n_updates            | 5160       |\n",
      "|    policy_gradient_loss | -0.00357   |\n",
      "|    reward               | 3.5105002  |\n",
      "|    std                  | 2.13       |\n",
      "|    value_loss           | 319        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 9746        |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009800399 |\n",
      "|    clip_fraction        | 0.0848      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    reward               | 0.66597086  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 9765        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024612838 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | 0.6903095   |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 9784        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014434012 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | -2.6518514  |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 521          |\n",
      "|    time_elapsed         | 9803         |\n",
      "|    total_timesteps      | 1067008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031019677 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.1        |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 5200         |\n",
      "|    policy_gradient_loss | -0.000695    |\n",
      "|    reward               | 2.23495      |\n",
      "|    std                  | 2.14         |\n",
      "|    value_loss           | 401          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 9823        |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019783162 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 5210        |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    reward               | 0.29288766  |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 57.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 9842        |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013955777 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 209         |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 2.4418035   |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 9861        |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010499037 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | 5.6950173   |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 375         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 9881        |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019476641 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.061       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 5240        |\n",
      "|    policy_gradient_loss | 0.000853    |\n",
      "|    reward               | 0.89995486  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 99.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 9899        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012776728 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.0521      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 1.6098299   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 9919        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019775935 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    reward               | -2.41647    |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 528         |\n",
      "|    time_elapsed         | 9938        |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010449263 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.1        |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | 2.0334656   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 304         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 9958        |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015458688 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    reward               | 0.7773475   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5045549.87\n",
      "total_reward: 4045549.87\n",
      "total_cost: 220530.72\n",
      "total_trades: 63174\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 9977        |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012916107 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.6        |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | -0.3592058  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 9995        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027446333 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    reward               | -0.5267925  |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 10014       |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024432987 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | 0.00464     |\n",
      "|    reward               | 2.4318802   |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 533         |\n",
      "|    time_elapsed         | 10032       |\n",
      "|    total_timesteps      | 1091584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013283462 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 5320        |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | -1.5531436  |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 10051       |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01832404  |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.1        |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    reward               | -0.67926234 |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 10070       |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019004265 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78          |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.41332915  |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 10089       |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032805875 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | -0.08226138 |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 10110       |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015543801 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.8727332  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 538         |\n",
      "|    time_elapsed         | 10129       |\n",
      "|    total_timesteps      | 1101824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016317546 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | -7.25921    |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 539         |\n",
      "|    time_elapsed         | 10147       |\n",
      "|    total_timesteps      | 1103872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026816072 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 5380        |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    reward               | 0.84249747  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 84.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 540       |\n",
      "|    time_elapsed         | 10166     |\n",
      "|    total_timesteps      | 1105920   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0208144 |\n",
      "|    clip_fraction        | 0.241     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -63.7     |\n",
      "|    explained_variance   | 0.0953    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 192       |\n",
      "|    n_updates            | 5390      |\n",
      "|    policy_gradient_loss | -0.00202  |\n",
      "|    reward               | 0.6291378 |\n",
      "|    std                  | 2.19      |\n",
      "|    value_loss           | 336       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 10185       |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029724207 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    reward               | -22.060915  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 542         |\n",
      "|    time_elapsed         | 10204       |\n",
      "|    total_timesteps      | 1110016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010066174 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 277         |\n",
      "|    n_updates            | 5410        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | 6.2884007   |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 537         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 10223       |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018812142 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | 2.7892587   |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5294771.10\n",
      "total_reward: 4294771.10\n",
      "total_cost: 191186.85\n",
      "total_trades: 61464\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 544          |\n",
      "|    time_elapsed         | 10242        |\n",
      "|    total_timesteps      | 1114112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015541345  |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.9        |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 5430         |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    reward               | -0.066635944 |\n",
      "|    std                  | 2.2          |\n",
      "|    value_loss           | 636          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 545         |\n",
      "|    time_elapsed         | 10261       |\n",
      "|    total_timesteps      | 1116160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008386775 |\n",
      "|    clip_fraction        | 0.0423      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 251         |\n",
      "|    n_updates            | 5440        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | -1.5109032  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 823         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 546          |\n",
      "|    time_elapsed         | 10280        |\n",
      "|    total_timesteps      | 1118208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015109545  |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.9        |\n",
      "|    explained_variance   | 0.0429       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40           |\n",
      "|    n_updates            | 5450         |\n",
      "|    policy_gradient_loss | -0.00738     |\n",
      "|    reward               | -0.027578678 |\n",
      "|    std                  | 2.2          |\n",
      "|    value_loss           | 85.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 547         |\n",
      "|    time_elapsed         | 10299       |\n",
      "|    total_timesteps      | 1120256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012146981 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 366         |\n",
      "|    n_updates            | 5460        |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    reward               | 3.7627997   |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 494         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 10318       |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016499512 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 204         |\n",
      "|    n_updates            | 5470        |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | -1.6321346  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 456         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 10337       |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017953647 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.0891      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.6        |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | 2.4321542   |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 92.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 10355       |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027819138 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81          |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | -0.83275187 |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 551         |\n",
      "|    time_elapsed         | 10374       |\n",
      "|    total_timesteps      | 1128448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019652281 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.8        |\n",
      "|    n_updates            | 5500        |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | 0.22440496  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 552         |\n",
      "|    time_elapsed         | 10392       |\n",
      "|    total_timesteps      | 1130496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014771858 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.7        |\n",
      "|    n_updates            | 5510        |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | 0.9993388   |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 10411       |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017757762 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    reward               | -1.4583555  |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 10430       |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016673375 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | -0.5669844  |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 10448       |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017899437 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | 1.3172107   |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 241         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 10467       |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016187487 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    reward               | -2.1151597  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 10486       |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018472053 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.048       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | -1.3179164  |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 79.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5096277.84\n",
      "total_reward: 4096277.84\n",
      "total_cost: 208489.36\n",
      "total_trades: 62542\n",
      "Sharpe: 0.768\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 10505       |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015807975 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.6        |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    reward               | -0.4950975  |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 10523       |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011234023 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.0264      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | -2.5325317  |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 10542       |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016060703 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.86        |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    reward               | 1.4066585   |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 10561       |\n",
      "|    total_timesteps      | 1148928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019328358 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.5        |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | -0.51428056 |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 96.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 562          |\n",
      "|    time_elapsed         | 10579        |\n",
      "|    total_timesteps      | 1150976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126680005 |\n",
      "|    clip_fraction        | 0.0986       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.6        |\n",
      "|    explained_variance   | 0.154        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.1         |\n",
      "|    n_updates            | 5610         |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | 0.20737825   |\n",
      "|    std                  | 2.26         |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 10598       |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019731835 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.0978      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -0.44442028 |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 564         |\n",
      "|    time_elapsed         | 10616       |\n",
      "|    total_timesteps      | 1155072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015401559 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 5630        |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | 1.0271155   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 10635       |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013458727 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | -28.9438    |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 566         |\n",
      "|    time_elapsed         | 10653       |\n",
      "|    total_timesteps      | 1159168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006541208 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 5650        |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    reward               | 4.453486    |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 80.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 567         |\n",
      "|    time_elapsed         | 10673       |\n",
      "|    total_timesteps      | 1161216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015954651 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | -5.3127027  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 10692       |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013473766 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.5        |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    reward               | 0.03412401  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 10711       |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016923502 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.4        |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    reward               | -10.822125  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 10730       |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020635698 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    reward               | 1.0466807   |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 10749       |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009397412 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    reward               | 0.015849737 |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 572         |\n",
      "|    time_elapsed         | 10768       |\n",
      "|    total_timesteps      | 1171456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009191861 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 5710        |\n",
      "|    policy_gradient_loss | -0.000288   |\n",
      "|    reward               | -10.957346  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 320         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4369620.79\n",
      "total_reward: 3369620.79\n",
      "total_cost: 156139.12\n",
      "total_trades: 59462\n",
      "Sharpe: 0.691\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 10787       |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015080649 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.6        |\n",
      "|    n_updates            | 5720        |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | 0.6548409   |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 10806       |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021686833 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 5730        |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | -1.1279738  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 575        |\n",
      "|    time_elapsed         | 10825      |\n",
      "|    total_timesteps      | 1177600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02032601 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65        |\n",
      "|    explained_variance   | 0.249      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 191        |\n",
      "|    n_updates            | 5740       |\n",
      "|    policy_gradient_loss | -0.00589   |\n",
      "|    reward               | 0.84101075 |\n",
      "|    std                  | 2.29       |\n",
      "|    value_loss           | 204        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 576        |\n",
      "|    time_elapsed         | 10845      |\n",
      "|    total_timesteps      | 1179648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0049996  |\n",
      "|    clip_fraction        | 0.0534     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65        |\n",
      "|    explained_variance   | 0.357      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 158        |\n",
      "|    n_updates            | 5750       |\n",
      "|    policy_gradient_loss | -0.000404  |\n",
      "|    reward               | -2.7762592 |\n",
      "|    std                  | 2.29       |\n",
      "|    value_loss           | 334        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 10864       |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014239207 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 0.80976737  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 10882       |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018982358 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 251         |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | 0.27787587  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 579          |\n",
      "|    time_elapsed         | 10902        |\n",
      "|    total_timesteps      | 1185792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107616745 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.1        |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.2         |\n",
      "|    n_updates            | 5780         |\n",
      "|    policy_gradient_loss | -3.72e-05    |\n",
      "|    reward               | 4.9915614    |\n",
      "|    std                  | 2.3          |\n",
      "|    value_loss           | 305          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 10920       |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014407799 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | -0.0164     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | 0.00312     |\n",
      "|    reward               | 0.7009718   |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 10939       |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014946245 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 2.074259    |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 582         |\n",
      "|    time_elapsed         | 10959       |\n",
      "|    total_timesteps      | 1191936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011275205 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 264         |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | -0.16194381 |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 391         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 10977       |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015352387 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.4        |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    reward               | 1.6008083   |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 584        |\n",
      "|    time_elapsed         | 10996      |\n",
      "|    total_timesteps      | 1196032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01520219 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.3      |\n",
      "|    explained_variance   | 0.133      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.5       |\n",
      "|    n_updates            | 5830       |\n",
      "|    policy_gradient_loss | -0.00629   |\n",
      "|    reward               | -0.5002057 |\n",
      "|    std                  | 2.32       |\n",
      "|    value_loss           | 40.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 11015       |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009698585 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 5840        |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | -0.0872248  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 425         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 586         |\n",
      "|    time_elapsed         | 11034       |\n",
      "|    total_timesteps      | 1200128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011977306 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.5        |\n",
      "|    n_updates            | 5850        |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | -2.2111864  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 287         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4546543.14\n",
      "total_reward: 3546543.14\n",
      "total_cost: 158171.14\n",
      "total_trades: 59272\n",
      "Sharpe: 0.746\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 11052       |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014795532 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.0441      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 5860        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.0147171   |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 588        |\n",
      "|    time_elapsed         | 11071      |\n",
      "|    total_timesteps      | 1204224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02083995 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.6      |\n",
      "|    explained_variance   | 0.284      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.5       |\n",
      "|    n_updates            | 5870       |\n",
      "|    policy_gradient_loss | -0.00723   |\n",
      "|    reward               | 0.941947   |\n",
      "|    std                  | 2.33       |\n",
      "|    value_loss           | 164        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 589       |\n",
      "|    time_elapsed         | 11090     |\n",
      "|    total_timesteps      | 1206272   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0132674 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -65.6     |\n",
      "|    explained_variance   | 0.293     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 81.5      |\n",
      "|    n_updates            | 5880      |\n",
      "|    policy_gradient_loss | -0.00637  |\n",
      "|    reward               | -9.313406 |\n",
      "|    std                  | 2.33      |\n",
      "|    value_loss           | 297       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 11109       |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016454972 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | 1.4502062   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 76.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 591         |\n",
      "|    time_elapsed         | 11127       |\n",
      "|    total_timesteps      | 1210368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013644349 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 0.8962507   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 11145       |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014529901 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 5910        |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    reward               | 0.39176098  |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 11171       |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009962205 |\n",
      "|    clip_fraction        | 0.0749      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.9        |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    reward               | 1.146318    |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 274         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 11189       |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020866841 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.0773      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | -3.940332   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 595          |\n",
      "|    time_elapsed         | 11208        |\n",
      "|    total_timesteps      | 1218560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070162583 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.8        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 115          |\n",
      "|    n_updates            | 5940         |\n",
      "|    policy_gradient_loss | -0.00786     |\n",
      "|    reward               | -5.1804156   |\n",
      "|    std                  | 2.35         |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 596         |\n",
      "|    time_elapsed         | 11227       |\n",
      "|    total_timesteps      | 1220608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018576857 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | 0.42016816  |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 11245       |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017051104 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.0562      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.8        |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.00103    |\n",
      "|    reward               | 3.0776398   |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 11264       |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016634416 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 297         |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    reward               | 0.5965203   |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 599          |\n",
      "|    time_elapsed         | 11283        |\n",
      "|    total_timesteps      | 1226752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072330027 |\n",
      "|    clip_fraction        | 0.0567       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.9        |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 427          |\n",
      "|    n_updates            | 5980         |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | 2.1384566    |\n",
      "|    std                  | 2.36         |\n",
      "|    value_loss           | 682          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 11301       |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019277504 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 680         |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | 0.000347    |\n",
      "|    reward               | 3.8138967   |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 666         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4425628.32\n",
      "total_reward: 3425628.32\n",
      "total_cost: 174906.86\n",
      "total_trades: 59952\n",
      "Sharpe: 0.645\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 601       |\n",
      "|    time_elapsed         | 11320     |\n",
      "|    total_timesteps      | 1230848   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0316688 |\n",
      "|    clip_fraction        | 0.184     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -66       |\n",
      "|    explained_variance   | 0.207     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 27.8      |\n",
      "|    n_updates            | 6000      |\n",
      "|    policy_gradient_loss | -0.00233  |\n",
      "|    reward               | -3.70762  |\n",
      "|    std                  | 2.37      |\n",
      "|    value_loss           | 57.8      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 602          |\n",
      "|    time_elapsed         | 11339        |\n",
      "|    total_timesteps      | 1232896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067763748 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66          |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 6010         |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 2.859426     |\n",
      "|    std                  | 2.37         |\n",
      "|    value_loss           | 466          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 11358       |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013493827 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 209         |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | 0.77910376  |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 415         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 604         |\n",
      "|    time_elapsed         | 11376       |\n",
      "|    total_timesteps      | 1236992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018304916 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.6        |\n",
      "|    n_updates            | 6030        |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    reward               | 8.121114    |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 11395       |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015476928 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.9        |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | 0.9528876   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 606         |\n",
      "|    time_elapsed         | 11413       |\n",
      "|    total_timesteps      | 1241088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011920689 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | -2.4595416  |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 320         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 607        |\n",
      "|    time_elapsed         | 11432      |\n",
      "|    total_timesteps      | 1243136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01231348 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.2      |\n",
      "|    explained_variance   | 0.491      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 139        |\n",
      "|    n_updates            | 6060       |\n",
      "|    policy_gradient_loss | -0.0079    |\n",
      "|    reward               | -0.78598   |\n",
      "|    std                  | 2.39       |\n",
      "|    value_loss           | 442        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 11450       |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021453258 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | 0.49650452  |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 609        |\n",
      "|    time_elapsed         | 11469      |\n",
      "|    total_timesteps      | 1247232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00935575 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.3      |\n",
      "|    explained_variance   | 0.53       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 125        |\n",
      "|    n_updates            | 6080       |\n",
      "|    policy_gradient_loss | 0.0019     |\n",
      "|    reward               | -1.8919458 |\n",
      "|    std                  | 2.39       |\n",
      "|    value_loss           | 362        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 610        |\n",
      "|    time_elapsed         | 11487      |\n",
      "|    total_timesteps      | 1249280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00390774 |\n",
      "|    clip_fraction        | 0.0133     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.3      |\n",
      "|    explained_variance   | 0.473      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 184        |\n",
      "|    n_updates            | 6090       |\n",
      "|    policy_gradient_loss | -0.00497   |\n",
      "|    reward               | 5.259017   |\n",
      "|    std                  | 2.4        |\n",
      "|    value_loss           | 247        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 611         |\n",
      "|    time_elapsed         | 11506       |\n",
      "|    total_timesteps      | 1251328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011778552 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    reward               | 1.114836    |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 59.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 11525       |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016042866 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.4        |\n",
      "|    n_updates            | 6110        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | 5.027483    |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 613          |\n",
      "|    time_elapsed         | 11543        |\n",
      "|    total_timesteps      | 1255424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010936301  |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.4        |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 173          |\n",
      "|    n_updates            | 6120         |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    reward               | -0.048419327 |\n",
      "|    std                  | 2.4          |\n",
      "|    value_loss           | 377          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 11562       |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01711433  |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.5       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 6130        |\n",
      "|    policy_gradient_loss | -0.000211   |\n",
      "|    reward               | -0.65666217 |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3816612.73\n",
      "total_reward: 2816612.73\n",
      "total_cost: 208997.94\n",
      "total_trades: 63012\n",
      "Sharpe: 0.579\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 615          |\n",
      "|    time_elapsed         | 11580        |\n",
      "|    total_timesteps      | 1259520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.022236038  |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.5        |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 142          |\n",
      "|    n_updates            | 6140         |\n",
      "|    policy_gradient_loss | -0.00733     |\n",
      "|    reward               | -0.051095113 |\n",
      "|    std                  | 2.41         |\n",
      "|    value_loss           | 275          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 616          |\n",
      "|    time_elapsed         | 11599        |\n",
      "|    total_timesteps      | 1261568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079130335 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.5        |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 6150         |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 2.0143936    |\n",
      "|    std                  | 2.41         |\n",
      "|    value_loss           | 368          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 617          |\n",
      "|    time_elapsed         | 11617        |\n",
      "|    total_timesteps      | 1263616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060685077 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.5        |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 6160         |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 17.558367    |\n",
      "|    std                  | 2.41         |\n",
      "|    value_loss           | 438          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 618         |\n",
      "|    time_elapsed         | 11636       |\n",
      "|    total_timesteps      | 1265664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023935001 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.5       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | 0.000992    |\n",
      "|    reward               | -1.2555152  |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 11654       |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015703414 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 241         |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | 1.0290495   |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 458         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 620          |\n",
      "|    time_elapsed         | 11673        |\n",
      "|    total_timesteps      | 1269760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068534827 |\n",
      "|    clip_fraction        | 0.0528       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.6        |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 289          |\n",
      "|    n_updates            | 6190         |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | -5.1960387   |\n",
      "|    std                  | 2.42         |\n",
      "|    value_loss           | 513          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 621        |\n",
      "|    time_elapsed         | 11691      |\n",
      "|    total_timesteps      | 1271808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00860217 |\n",
      "|    clip_fraction        | 0.0815     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.6      |\n",
      "|    explained_variance   | 0.281      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.8       |\n",
      "|    n_updates            | 6200       |\n",
      "|    policy_gradient_loss | -0.0055    |\n",
      "|    reward               | 3.7052646  |\n",
      "|    std                  | 2.42       |\n",
      "|    value_loss           | 176        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 11710       |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017023865 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | -0.34135854 |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 359         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 11729       |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014542855 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 261         |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | -0.000226   |\n",
      "|    reward               | 0.72390634  |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 462         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 11747       |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005517697 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | 2.1964993   |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 520         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 625         |\n",
      "|    time_elapsed         | 11766       |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010635432 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 6240        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | -3.3522284  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 626          |\n",
      "|    time_elapsed         | 11785        |\n",
      "|    total_timesteps      | 1282048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037388029 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.7        |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 6250         |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | -0.06638229  |\n",
      "|    std                  | 2.43         |\n",
      "|    value_loss           | 473          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 11803       |\n",
      "|    total_timesteps      | 1284096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008426605 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 254         |\n",
      "|    n_updates            | 6260        |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 18.280216   |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 430         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 628        |\n",
      "|    time_elapsed         | 11822      |\n",
      "|    total_timesteps      | 1286144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02135204 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.8      |\n",
      "|    explained_variance   | 0.193      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 59.3       |\n",
      "|    n_updates            | 6270       |\n",
      "|    policy_gradient_loss | 0.00311    |\n",
      "|    reward               | 1.3918043  |\n",
      "|    std                  | 2.44       |\n",
      "|    value_loss           | 135        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4576223.51\n",
      "total_reward: 3576223.51\n",
      "total_cost: 187203.61\n",
      "total_trades: 61012\n",
      "Sharpe: 0.623\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 11840       |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011587417 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 288         |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    reward               | -0.5039931  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 410         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 630         |\n",
      "|    time_elapsed         | 11859       |\n",
      "|    total_timesteps      | 1290240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012962442 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    reward               | 13.232718   |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 572         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 631          |\n",
      "|    time_elapsed         | 11877        |\n",
      "|    total_timesteps      | 1292288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023712232 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.9        |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 219          |\n",
      "|    n_updates            | 6300         |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | -0.36801454  |\n",
      "|    std                  | 2.44         |\n",
      "|    value_loss           | 412          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 11896       |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019306757 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    reward               | -0.199948   |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 69.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 633          |\n",
      "|    time_elapsed         | 11915        |\n",
      "|    total_timesteps      | 1296384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031296932 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.9        |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 6320         |\n",
      "|    policy_gradient_loss | -0.000664    |\n",
      "|    reward               | -0.1914158   |\n",
      "|    std                  | 2.44         |\n",
      "|    value_loss           | 400          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 634          |\n",
      "|    time_elapsed         | 11934        |\n",
      "|    total_timesteps      | 1298432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052288654 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.9        |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 6330         |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | -9.634272    |\n",
      "|    std                  | 2.45         |\n",
      "|    value_loss           | 549          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 635         |\n",
      "|    time_elapsed         | 11953       |\n",
      "|    total_timesteps      | 1300480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018046703 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 6340        |\n",
      "|    policy_gradient_loss | -0.00655    |\n",
      "|    reward               | 0.20531705  |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 95.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 636          |\n",
      "|    time_elapsed         | 11972        |\n",
      "|    total_timesteps      | 1302528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069462834 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -67          |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 412          |\n",
      "|    n_updates            | 6350         |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    reward               | 1.1433715    |\n",
      "|    std                  | 2.45         |\n",
      "|    value_loss           | 454          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 11990       |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009866945 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | -11.99253   |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 505         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 12009       |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019394591 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 210         |\n",
      "|    n_updates            | 6370        |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    reward               | 4.0858192   |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 358         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 12027       |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029835267 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | 0.36212626  |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 494         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 640        |\n",
      "|    time_elapsed         | 12046      |\n",
      "|    total_timesteps      | 1310720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01871497 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.1      |\n",
      "|    explained_variance   | 0.594      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 416        |\n",
      "|    n_updates            | 6390       |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    reward               | 1.165971   |\n",
      "|    std                  | 2.46       |\n",
      "|    value_loss           | 690        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 641          |\n",
      "|    time_elapsed         | 12065        |\n",
      "|    total_timesteps      | 1312768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072252606 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -67.1        |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 223          |\n",
      "|    n_updates            | 6400         |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | -4.1563225   |\n",
      "|    std                  | 2.46         |\n",
      "|    value_loss           | 552          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 12083       |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025210898 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | 0.00167     |\n",
      "|    reward               | 3.0638964   |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4321133.20\n",
      "total_reward: 3321133.20\n",
      "total_cost: 228578.81\n",
      "total_trades: 64362\n",
      "Sharpe: 0.592\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 12102       |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00911054  |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 719         |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.000341   |\n",
      "|    reward               | -0.51286167 |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 951         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 12121       |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008049088 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 217         |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | -1.8178903  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 699         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 12139       |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012494701 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.00108    |\n",
      "|    reward               | -5.5335565  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 646        |\n",
      "|    time_elapsed         | 12158      |\n",
      "|    total_timesteps      | 1323008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02369598 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.2      |\n",
      "|    explained_variance   | 0.563      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 138        |\n",
      "|    n_updates            | 6450       |\n",
      "|    policy_gradient_loss | -0.00795   |\n",
      "|    reward               | 0.72510904 |\n",
      "|    std                  | 2.47       |\n",
      "|    value_loss           | 434        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 12177       |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015330709 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 1.1655903   |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 710         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 12196       |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009938096 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    reward               | 4.6970277   |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 493         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 12214       |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031405903 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | -3.4816284  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 58.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 650         |\n",
      "|    time_elapsed         | 12233       |\n",
      "|    total_timesteps      | 1331200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010453736 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 202         |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 1.175239    |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 492         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 12252       |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007226615 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 6500        |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | -4.121154   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 377         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 12270       |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021574166 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    reward               | 0.8263335   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 12289       |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023229126 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    reward               | 2.9549665   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 357         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 12307       |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018168995 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 239         |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    reward               | 32.104115   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 532         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 12326       |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013869812 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 298         |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | 0.00135     |\n",
      "|    reward               | 4.4293494   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 391         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 12345       |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023554489 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | -0.7557485  |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 76.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3815091.03\n",
      "total_reward: 2815091.03\n",
      "total_cost: 184747.75\n",
      "total_trades: 61104\n",
      "Sharpe: 0.572\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 12364       |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008511592 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | 0.48889482  |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 394         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 12382       |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010855071 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | 12.05612    |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 393         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 12401       |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015284242 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | -0.9263654  |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 76.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 12419       |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016715735 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88          |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | 0.00255     |\n",
      "|    reward               | 0.7062301   |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 393         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 12438       |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020828988 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | 0.00337     |\n",
      "|    reward               | -6.3404007  |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 12457       |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020166278 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    reward               | 0.743377    |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 12476       |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019703053 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.6541532   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 664        |\n",
      "|    time_elapsed         | 12494      |\n",
      "|    total_timesteps      | 1359872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01608254 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.8      |\n",
      "|    explained_variance   | 0.708      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 150        |\n",
      "|    n_updates            | 6630       |\n",
      "|    policy_gradient_loss | 0.00675    |\n",
      "|    reward               | 0.59508014 |\n",
      "|    std                  | 2.52       |\n",
      "|    value_loss           | 303        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 665         |\n",
      "|    time_elapsed         | 12512       |\n",
      "|    total_timesteps      | 1361920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018285392 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.000786   |\n",
      "|    reward               | -0.2765564  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 12533       |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022126086 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | 4.8150043   |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 12551       |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014499728 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -1.7809595  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 668        |\n",
      "|    time_elapsed         | 12570      |\n",
      "|    total_timesteps      | 1368064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00617713 |\n",
      "|    clip_fraction        | 0.0478     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.9      |\n",
      "|    explained_variance   | 0.642      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 138        |\n",
      "|    n_updates            | 6670       |\n",
      "|    policy_gradient_loss | -0.00318   |\n",
      "|    reward               | -1.9956318 |\n",
      "|    std                  | 2.53       |\n",
      "|    value_loss           | 289        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 669         |\n",
      "|    time_elapsed         | 12589       |\n",
      "|    total_timesteps      | 1370112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021982908 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | -0.43882638 |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 98.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 12610       |\n",
      "|    total_timesteps      | 1372160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019950546 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.7        |\n",
      "|    n_updates            | 6690        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 1.6588976   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3772777.87\n",
      "total_reward: 2772777.87\n",
      "total_cost: 249840.67\n",
      "total_trades: 65345\n",
      "Sharpe: 0.581\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 671          |\n",
      "|    time_elapsed         | 12629        |\n",
      "|    total_timesteps      | 1374208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073663453 |\n",
      "|    clip_fraction        | 0.0698       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68          |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 205          |\n",
      "|    n_updates            | 6700         |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | -0.38762796  |\n",
      "|    std                  | 2.54         |\n",
      "|    value_loss           | 386          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 12649       |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006800134 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 188         |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -1.1624396  |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 12667       |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038011193 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | 0.00235     |\n",
      "|    reward               | -0.13218142 |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 674         |\n",
      "|    time_elapsed         | 12686       |\n",
      "|    total_timesteps      | 1380352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018045332 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 2.4009814   |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 505         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 12704       |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009112104 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | 6.2701793   |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 430         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 12723       |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025343772 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | -0.161      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    reward               | -2.2354505  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 677         |\n",
      "|    time_elapsed         | 12742       |\n",
      "|    total_timesteps      | 1386496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011757574 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 6760        |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    reward               | 0.4636149   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 478         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 12760       |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004385072 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 302         |\n",
      "|    n_updates            | 6770        |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | 0.13821556  |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 498         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 12779       |\n",
      "|    total_timesteps      | 1390592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015139774 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.9        |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | -0.07978858 |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 12797       |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019999377 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    reward               | -1.9307508  |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 12816       |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017120326 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 403         |\n",
      "|    n_updates            | 6800        |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    reward               | 1.2141107   |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 602         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 682         |\n",
      "|    time_elapsed         | 12834       |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016243175 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 294         |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | 2.9996388   |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 593         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 12853       |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025841711 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 3.8161705   |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 684         |\n",
      "|    time_elapsed         | 12871       |\n",
      "|    total_timesteps      | 1400832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008760914 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | 1.804319    |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 12890       |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015815172 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | -0.25750542 |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 488         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3917595.97\n",
      "total_reward: 2917595.97\n",
      "total_cost: 278909.09\n",
      "total_trades: 67338\n",
      "Sharpe: 0.598\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 12909       |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010804501 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.4        |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | 0.20822673  |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 687        |\n",
      "|    time_elapsed         | 12927      |\n",
      "|    total_timesteps      | 1406976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01698622 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.7      |\n",
      "|    explained_variance   | 0.633      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.3       |\n",
      "|    n_updates            | 6860       |\n",
      "|    policy_gradient_loss | -0.00773   |\n",
      "|    reward               | 1.0030022  |\n",
      "|    std                  | 2.6        |\n",
      "|    value_loss           | 210        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 688          |\n",
      "|    time_elapsed         | 12946        |\n",
      "|    total_timesteps      | 1409024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061034625 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.8        |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 276          |\n",
      "|    n_updates            | 6870         |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 3.1609228    |\n",
      "|    std                  | 2.6          |\n",
      "|    value_loss           | 364          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 689         |\n",
      "|    time_elapsed         | 12965       |\n",
      "|    total_timesteps      | 1411072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0106728   |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | -0.42558548 |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 321         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 12983       |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024031807 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.000163   |\n",
      "|    reward               | -1.9068842  |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 62.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 691        |\n",
      "|    time_elapsed         | 13003      |\n",
      "|    total_timesteps      | 1415168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01063141 |\n",
      "|    clip_fraction        | 0.0746     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.8      |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 461        |\n",
      "|    n_updates            | 6900       |\n",
      "|    policy_gradient_loss | -0.00827   |\n",
      "|    reward               | 0.32079268 |\n",
      "|    std                  | 2.61       |\n",
      "|    value_loss           | 494        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 13021       |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010888539 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | 14.953168   |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 478         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 13040       |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011773601 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.1        |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | 1.9327403   |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 694          |\n",
      "|    time_elapsed         | 13059        |\n",
      "|    total_timesteps      | 1421312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147742685 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.9        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 167          |\n",
      "|    n_updates            | 6930         |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    reward               | -0.9584014   |\n",
      "|    std                  | 2.61         |\n",
      "|    value_loss           | 254          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 695          |\n",
      "|    time_elapsed         | 13077        |\n",
      "|    total_timesteps      | 1423360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015708476  |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.9        |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 384          |\n",
      "|    n_updates            | 6940         |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    reward               | -0.110491864 |\n",
      "|    std                  | 2.61         |\n",
      "|    value_loss           | 602          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 13096       |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009021703 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 0.68726027  |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 445         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 13114       |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030566022 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    reward               | 0.87466085  |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 56.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 13133       |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009060657 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | 1.5872597   |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 469         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 699         |\n",
      "|    time_elapsed         | 13152       |\n",
      "|    total_timesteps      | 1431552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019661063 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 201         |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | 7.177347    |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 633         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4567246.25\n",
      "total_reward: 3567246.25\n",
      "total_cost: 252995.29\n",
      "total_trades: 65924\n",
      "Sharpe: 0.618\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 13171       |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027408952 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | -0.0277     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | 0.00332     |\n",
      "|    reward               | -2.7271967  |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 13189       |\n",
      "|    total_timesteps      | 1435648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017381882 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | -5.297081   |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 536         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 13208       |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008417863 |\n",
      "|    clip_fraction        | 0.0838      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 246         |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    reward               | 12.17482    |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 557         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 13227       |\n",
      "|    total_timesteps      | 1439744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011442281 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    reward               | -0.8220554  |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 704         |\n",
      "|    time_elapsed         | 13246       |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014249995 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 7030        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | -1.5709624  |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 309         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 13265       |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012470249 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    reward               | 1.1153837   |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 480         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 706        |\n",
      "|    time_elapsed         | 13284      |\n",
      "|    total_timesteps      | 1445888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01618039 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.2      |\n",
      "|    explained_variance   | 0.112      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 426        |\n",
      "|    n_updates            | 7050       |\n",
      "|    policy_gradient_loss | -0.00887   |\n",
      "|    reward               | 15.287465  |\n",
      "|    std                  | 2.64       |\n",
      "|    value_loss           | 633        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 707        |\n",
      "|    time_elapsed         | 13302      |\n",
      "|    total_timesteps      | 1447936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01692496 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.2      |\n",
      "|    explained_variance   | 0.0292     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.4       |\n",
      "|    n_updates            | 7060       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | 0.4250666  |\n",
      "|    std                  | 2.65       |\n",
      "|    value_loss           | 95.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 13321       |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008050381 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 7070        |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | 0.8335692   |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 670         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 13340       |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008537636 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | -0.14798845 |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 739         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 13358       |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018268742 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -4.1840496  |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 286         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 13377       |\n",
      "|    total_timesteps      | 1456128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01495894  |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 210         |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -0.65233487 |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 444         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 13396       |\n",
      "|    total_timesteps      | 1458176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012426237 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | -0.3782896  |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 754         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 713        |\n",
      "|    time_elapsed         | 13415      |\n",
      "|    total_timesteps      | 1460224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00793571 |\n",
      "|    clip_fraction        | 0.0557     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.4      |\n",
      "|    explained_variance   | 0.533      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 394        |\n",
      "|    n_updates            | 7120       |\n",
      "|    policy_gradient_loss | -0.00659   |\n",
      "|    reward               | 2.8669918  |\n",
      "|    std                  | 2.66       |\n",
      "|    value_loss           | 776        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4478115.03\n",
      "total_reward: 3478115.03\n",
      "total_cost: 278680.96\n",
      "total_trades: 67509\n",
      "Sharpe: 0.627\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 714        |\n",
      "|    time_elapsed         | 13434      |\n",
      "|    total_timesteps      | 1462272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02772886 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.4      |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.6       |\n",
      "|    n_updates            | 7130       |\n",
      "|    policy_gradient_loss | -0.00675   |\n",
      "|    reward               | 1.1183709  |\n",
      "|    std                  | 2.67       |\n",
      "|    value_loss           | 51.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 13453        |\n",
      "|    total_timesteps      | 1464320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034838445 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.5        |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 147          |\n",
      "|    n_updates            | 7140         |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | 0.27517012   |\n",
      "|    std                  | 2.67         |\n",
      "|    value_loss           | 545          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 13471       |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007950118 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 181         |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | -14.890923  |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 518         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 13490       |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011058323 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.4        |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 1.2330233   |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 718         |\n",
      "|    time_elapsed         | 13508       |\n",
      "|    total_timesteps      | 1470464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012372496 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 257         |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    reward               | -2.234479   |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 362         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 13527       |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012678647 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 486         |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | 11.37435    |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 839         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 13545       |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015954077 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 503         |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    reward               | -1.846894   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 815         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 721        |\n",
      "|    time_elapsed         | 13564      |\n",
      "|    total_timesteps      | 1476608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02292195 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.6      |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.1       |\n",
      "|    n_updates            | 7200       |\n",
      "|    policy_gradient_loss | -0.00906   |\n",
      "|    reward               | 2.613112   |\n",
      "|    std                  | 2.68       |\n",
      "|    value_loss           | 82.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 13583       |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011502137 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 365         |\n",
      "|    n_updates            | 7210        |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | -3.308543   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 733         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 723          |\n",
      "|    time_elapsed         | 13601        |\n",
      "|    total_timesteps      | 1480704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078784395 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.6        |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 381          |\n",
      "|    n_updates            | 7220         |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | -17.48629    |\n",
      "|    std                  | 2.68         |\n",
      "|    value_loss           | 856          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 13620       |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020320062 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    reward               | 1.2363033   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 13638       |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008876944 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 342         |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | 0.81939906  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 419         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 726          |\n",
      "|    time_elapsed         | 13657        |\n",
      "|    total_timesteps      | 1486848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023755543 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.6        |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 565          |\n",
      "|    n_updates            | 7250         |\n",
      "|    policy_gradient_loss | -0.000677    |\n",
      "|    reward               | -4.307532    |\n",
      "|    std                  | 2.68         |\n",
      "|    value_loss           | 652          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 13675       |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017064763 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    reward               | -1.3515652  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4787333.88\n",
      "total_reward: 3787333.88\n",
      "total_cost: 255388.86\n",
      "total_trades: 66205\n",
      "Sharpe: 0.640\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 13694       |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015631918 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.61284035  |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 423         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 13712       |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006033187 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | -1.4537276  |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 634         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 13731       |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009406967 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 248         |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | 12.569094   |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 791         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 13750       |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019744169 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | -0.0231     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | -2.8840206  |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 95.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 13769       |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010843372 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 333         |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | -0.24144928 |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 675         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 733         |\n",
      "|    time_elapsed         | 13788       |\n",
      "|    total_timesteps      | 1501184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005866957 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    reward               | 1.7626072   |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 607         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 734          |\n",
      "|    time_elapsed         | 13807        |\n",
      "|    total_timesteps      | 1503232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109268725 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.9        |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 7330         |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    reward               | -9.181275    |\n",
      "|    std                  | 2.71         |\n",
      "|    value_loss           | 374          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 13825       |\n",
      "|    total_timesteps      | 1505280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014862338 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    reward               | 0.56160146  |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 548         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 736           |\n",
      "|    time_elapsed         | 13844         |\n",
      "|    total_timesteps      | 1507328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009488923   |\n",
      "|    clip_fraction        | 0.117         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -70           |\n",
      "|    explained_variance   | 0.416         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 182           |\n",
      "|    n_updates            | 7350          |\n",
      "|    policy_gradient_loss | -0.00675      |\n",
      "|    reward               | -0.0020193148 |\n",
      "|    std                  | 2.72          |\n",
      "|    value_loss           | 579           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 737          |\n",
      "|    time_elapsed         | 13863        |\n",
      "|    total_timesteps      | 1509376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051027173 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70          |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 331          |\n",
      "|    n_updates            | 7360         |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 0.854093     |\n",
      "|    std                  | 2.72         |\n",
      "|    value_loss           | 647          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 13882       |\n",
      "|    total_timesteps      | 1511424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023614168 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.000694   |\n",
      "|    reward               | -2.767585   |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 13901       |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009065911 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 351         |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | -0.85198647 |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 702         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 13921        |\n",
      "|    total_timesteps      | 1515520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057237833 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70          |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 534          |\n",
      "|    n_updates            | 7390         |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | 0.8955013    |\n",
      "|    std                  | 2.72         |\n",
      "|    value_loss           | 814          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 13940       |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016812695 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 7400        |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | 1.4837196   |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5425586.99\n",
      "total_reward: 4425586.99\n",
      "total_cost: 217237.71\n",
      "total_trades: 63913\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 13959       |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007755836 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 284         |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | -0.14099106 |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 627         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 743          |\n",
      "|    time_elapsed         | 13978        |\n",
      "|    total_timesteps      | 1521664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033605858 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.1        |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 370          |\n",
      "|    n_updates            | 7420         |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 5.7554607    |\n",
      "|    std                  | 2.72         |\n",
      "|    value_loss           | 671          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 744        |\n",
      "|    time_elapsed         | 13997      |\n",
      "|    total_timesteps      | 1523712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00961918 |\n",
      "|    clip_fraction        | 0.0723     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.1      |\n",
      "|    explained_variance   | 0.76       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 272        |\n",
      "|    n_updates            | 7430       |\n",
      "|    policy_gradient_loss | -0.00728   |\n",
      "|    reward               | -0.6388345 |\n",
      "|    std                  | 2.72       |\n",
      "|    value_loss           | 681        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 14016       |\n",
      "|    total_timesteps      | 1525760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020869391 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.5        |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | -1.7052817  |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 99.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 746          |\n",
      "|    time_elapsed         | 14034        |\n",
      "|    total_timesteps      | 1527808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059625767 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.2        |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 295          |\n",
      "|    n_updates            | 7450         |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    reward               | -0.28981167  |\n",
      "|    std                  | 2.73         |\n",
      "|    value_loss           | 720          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 747          |\n",
      "|    time_elapsed         | 14053        |\n",
      "|    total_timesteps      | 1529856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043184785 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.2        |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 596          |\n",
      "|    n_updates            | 7460         |\n",
      "|    policy_gradient_loss | 9.17e-05     |\n",
      "|    reward               | -3.574163    |\n",
      "|    std                  | 2.73         |\n",
      "|    value_loss           | 812          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 748         |\n",
      "|    time_elapsed         | 14071       |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016251165 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73          |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    reward               | 1.5159848   |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 14090       |\n",
      "|    total_timesteps      | 1533952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008711219 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 377         |\n",
      "|    n_updates            | 7480        |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | -6.108653   |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 492         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 14108       |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010121372 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 468         |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 3.0231347   |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 809         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 14127       |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009768304 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | 0.03865082  |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 752         |\n",
      "|    time_elapsed         | 14145       |\n",
      "|    total_timesteps      | 1540096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015227865 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 208         |\n",
      "|    n_updates            | 7510        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 1.5066366   |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 377         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 14164       |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008502539 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | 0.29037818  |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 676         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 14183       |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008675788 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 276         |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | -1.9083618  |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 800         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 755         |\n",
      "|    time_elapsed         | 14201       |\n",
      "|    total_timesteps      | 1546240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023296801 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 7540        |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    reward               | -2.4328527  |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 82.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5126512.76\n",
      "total_reward: 4126512.76\n",
      "total_cost: 209970.43\n",
      "total_trades: 63087\n",
      "Sharpe: 0.696\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 756          |\n",
      "|    time_elapsed         | 14220        |\n",
      "|    total_timesteps      | 1548288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008864404  |\n",
      "|    clip_fraction        | 0.072        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.4        |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 187          |\n",
      "|    n_updates            | 7550         |\n",
      "|    policy_gradient_loss | -0.000998    |\n",
      "|    reward               | -0.036396947 |\n",
      "|    std                  | 2.76         |\n",
      "|    value_loss           | 581          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 757         |\n",
      "|    time_elapsed         | 14238       |\n",
      "|    total_timesteps      | 1550336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010809379 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 222         |\n",
      "|    n_updates            | 7560        |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -6.965036   |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 568         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 14257       |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012405079 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 7570        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | -0.8648053  |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 288         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 759          |\n",
      "|    time_elapsed         | 14275        |\n",
      "|    total_timesteps      | 1554432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113618355 |\n",
      "|    clip_fraction        | 0.0971       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.5        |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 215          |\n",
      "|    n_updates            | 7580         |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    reward               | 1.7834358    |\n",
      "|    std                  | 2.76         |\n",
      "|    value_loss           | 494          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 14293       |\n",
      "|    total_timesteps      | 1556480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008773126 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 337         |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | 0.20282385  |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 688         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 761        |\n",
      "|    time_elapsed         | 14312      |\n",
      "|    total_timesteps      | 1558528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01153486 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.5      |\n",
      "|    explained_variance   | 0.59       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 423        |\n",
      "|    n_updates            | 7600       |\n",
      "|    policy_gradient_loss | -0.00833   |\n",
      "|    reward               | 2.295953   |\n",
      "|    std                  | 2.77       |\n",
      "|    value_loss           | 744        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 762         |\n",
      "|    time_elapsed         | 14331       |\n",
      "|    total_timesteps      | 1560576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017821101 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    reward               | 0.23724109  |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 14349       |\n",
      "|    total_timesteps      | 1562624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007305406 |\n",
      "|    clip_fraction        | 0.0394      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 252         |\n",
      "|    n_updates            | 7620        |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | -5.858853   |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 648         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 764          |\n",
      "|    time_elapsed         | 14368        |\n",
      "|    total_timesteps      | 1564672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052897604 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.6        |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 675          |\n",
      "|    n_updates            | 7630         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 9.361619     |\n",
      "|    std                  | 2.78         |\n",
      "|    value_loss           | 1.03e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 765         |\n",
      "|    time_elapsed         | 14386       |\n",
      "|    total_timesteps      | 1566720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013889175 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | -4.9466805  |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 14405       |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006126764 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | -0.9125134  |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 629         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 767          |\n",
      "|    time_elapsed         | 14423        |\n",
      "|    total_timesteps      | 1570816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055643264 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.8        |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 660          |\n",
      "|    n_updates            | 7660         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    reward               | 9.745183     |\n",
      "|    std                  | 2.79         |\n",
      "|    value_loss           | 914          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 14442       |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009727726 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    reward               | -0.7630292  |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 393         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 769        |\n",
      "|    time_elapsed         | 14461      |\n",
      "|    total_timesteps      | 1574912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01726893 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.9      |\n",
      "|    explained_variance   | 0.46       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 52         |\n",
      "|    n_updates            | 7680       |\n",
      "|    policy_gradient_loss | -0.00826   |\n",
      "|    reward               | 2.0041096  |\n",
      "|    std                  | 2.8        |\n",
      "|    value_loss           | 171        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4397527.59\n",
      "total_reward: 3397527.59\n",
      "total_cost: 196584.83\n",
      "total_trades: 61171\n",
      "Sharpe: 0.608\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 770          |\n",
      "|    time_elapsed         | 14480        |\n",
      "|    total_timesteps      | 1576960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061554294 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.9        |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 608          |\n",
      "|    n_updates            | 7690         |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | -0.7159264   |\n",
      "|    std                  | 2.8          |\n",
      "|    value_loss           | 766          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 14498       |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005905902 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 251         |\n",
      "|    n_updates            | 7700        |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -17.347174  |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 700         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 14517       |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014921142 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.3        |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | 0.51128346  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 14535       |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002966439 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.3        |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    reward               | -1.5064493  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 634         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 774          |\n",
      "|    time_elapsed         | 14554        |\n",
      "|    total_timesteps      | 1585152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031438717 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71          |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 414          |\n",
      "|    n_updates            | 7730         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | 10.096141    |\n",
      "|    std                  | 2.81         |\n",
      "|    value_loss           | 753          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 14573       |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006830995 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 7740        |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    reward               | -3.971474   |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 776       |\n",
      "|    time_elapsed         | 14591     |\n",
      "|    total_timesteps      | 1589248   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0128531 |\n",
      "|    clip_fraction        | 0.089     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -71       |\n",
      "|    explained_variance   | 0.715     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 121       |\n",
      "|    n_updates            | 7750      |\n",
      "|    policy_gradient_loss | -0.00533  |\n",
      "|    reward               | 1.5547147 |\n",
      "|    std                  | 2.82      |\n",
      "|    value_loss           | 417       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 777          |\n",
      "|    time_elapsed         | 14610        |\n",
      "|    total_timesteps      | 1591296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068644905 |\n",
      "|    clip_fraction        | 0.0551       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.1        |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 181          |\n",
      "|    n_updates            | 7760         |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    reward               | 0.9770781    |\n",
      "|    std                  | 2.82         |\n",
      "|    value_loss           | 637          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 14628       |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013286496 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 313         |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    reward               | 6.2818036   |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 648         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 14656       |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023513552 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -1.1397107  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 85.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 14675       |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007121587 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 326         |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | 2.2081301   |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 581         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 781          |\n",
      "|    time_elapsed         | 14694        |\n",
      "|    total_timesteps      | 1599488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023683636 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.2        |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 214          |\n",
      "|    n_updates            | 7800         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 4.6310325    |\n",
      "|    std                  | 2.83         |\n",
      "|    value_loss           | 672          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 782         |\n",
      "|    time_elapsed         | 14712       |\n",
      "|    total_timesteps      | 1601536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015976826 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 7810        |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    reward               | -16.011456  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 14731       |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007773616 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | 0.30597812  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 355         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5492194.76\n",
      "total_reward: 4492194.76\n",
      "total_cost: 183274.84\n",
      "total_trades: 60227\n",
      "Sharpe: 0.673\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 784          |\n",
      "|    time_elapsed         | 14751        |\n",
      "|    total_timesteps      | 1605632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050672544 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.2        |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 438          |\n",
      "|    n_updates            | 7830         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 0.7977951    |\n",
      "|    std                  | 2.84         |\n",
      "|    value_loss           | 713          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 785          |\n",
      "|    time_elapsed         | 14770        |\n",
      "|    total_timesteps      | 1607680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027682954 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.3        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 355          |\n",
      "|    n_updates            | 7840         |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | 2.597714     |\n",
      "|    std                  | 2.84         |\n",
      "|    value_loss           | 889          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 786        |\n",
      "|    time_elapsed         | 14789      |\n",
      "|    total_timesteps      | 1609728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01928527 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.3      |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.9       |\n",
      "|    n_updates            | 7850       |\n",
      "|    policy_gradient_loss | -0.0079    |\n",
      "|    reward               | 0.5382527  |\n",
      "|    std                  | 2.84       |\n",
      "|    value_loss           | 52.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 787          |\n",
      "|    time_elapsed         | 14809        |\n",
      "|    total_timesteps      | 1611776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048466315 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.3        |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 305          |\n",
      "|    n_updates            | 7860         |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | -0.81069744  |\n",
      "|    std                  | 2.84         |\n",
      "|    value_loss           | 530          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 788          |\n",
      "|    time_elapsed         | 14828        |\n",
      "|    total_timesteps      | 1613824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055871527 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.3        |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 356          |\n",
      "|    n_updates            | 7870         |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | 0.09852351   |\n",
      "|    std                  | 2.84         |\n",
      "|    value_loss           | 509          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 14846       |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010229526 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 7880        |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | -2.3244941  |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 14865       |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009636455 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    reward               | 0.8627435   |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 14883       |\n",
      "|    total_timesteps      | 1619968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009827034 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 7900        |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    reward               | -8.270897   |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 613         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 792        |\n",
      "|    time_elapsed         | 14902      |\n",
      "|    total_timesteps      | 1622016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00973974 |\n",
      "|    clip_fraction        | 0.0635     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.4      |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 171        |\n",
      "|    n_updates            | 7910       |\n",
      "|    policy_gradient_loss | -0.00543   |\n",
      "|    reward               | 4.486535   |\n",
      "|    std                  | 2.85       |\n",
      "|    value_loss           | 364        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 14921       |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018374905 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.7        |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.33816853  |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 14939       |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008949947 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 292         |\n",
      "|    n_updates            | 7930        |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    reward               | -0.19712664 |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 479         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 14958       |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016357472 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    reward               | 0.22141443  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 377         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 796          |\n",
      "|    time_elapsed         | 14976        |\n",
      "|    total_timesteps      | 1630208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013217326  |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.5        |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.7         |\n",
      "|    n_updates            | 7950         |\n",
      "|    policy_gradient_loss | -0.00801     |\n",
      "|    reward               | -0.090481095 |\n",
      "|    std                  | 2.86         |\n",
      "|    value_loss           | 95.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 14995       |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005326084 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 287         |\n",
      "|    n_updates            | 7960        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | 0.6148001   |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 409         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 798          |\n",
      "|    time_elapsed         | 15013        |\n",
      "|    total_timesteps      | 1634304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073749414 |\n",
      "|    clip_fraction        | 0.0506       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.5        |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 238          |\n",
      "|    n_updates            | 7970         |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | -13.661065   |\n",
      "|    std                  | 2.86         |\n",
      "|    value_loss           | 597          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4546149.85\n",
      "total_reward: 3546149.85\n",
      "total_cost: 184928.15\n",
      "total_trades: 59975\n",
      "Sharpe: 0.644\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 15032       |\n",
      "|    total_timesteps      | 1636352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014545985 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.9        |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    reward               | 0.77787626  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 15051       |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015524739 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.7        |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | -1.5625513  |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 801         |\n",
      "|    time_elapsed         | 15069       |\n",
      "|    total_timesteps      | 1640448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006053522 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | -3.1708732  |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 405         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 15089       |\n",
      "|    total_timesteps      | 1642496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009804622 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 260         |\n",
      "|    n_updates            | 8010        |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | -5.933605   |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 416         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 15108       |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019417081 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 0.44046184  |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 62.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 804          |\n",
      "|    time_elapsed         | 15126        |\n",
      "|    total_timesteps      | 1646592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053062155 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.7        |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 276          |\n",
      "|    n_updates            | 8030         |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | 1.3291628    |\n",
      "|    std                  | 2.88         |\n",
      "|    value_loss           | 469          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 805          |\n",
      "|    time_elapsed         | 15145        |\n",
      "|    total_timesteps      | 1648640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031614876 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.7        |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 351          |\n",
      "|    n_updates            | 8040         |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 0.18788713   |\n",
      "|    std                  | 2.88         |\n",
      "|    value_loss           | 388          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 806          |\n",
      "|    time_elapsed         | 15164        |\n",
      "|    total_timesteps      | 1650688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102908015 |\n",
      "|    clip_fraction        | 0.0547       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.7        |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.2         |\n",
      "|    n_updates            | 8050         |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    reward               | 6.511259     |\n",
      "|    std                  | 2.88         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 15182       |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011750426 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.029989412 |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 808          |\n",
      "|    time_elapsed         | 15201        |\n",
      "|    total_timesteps      | 1654784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071204454 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.8        |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 575          |\n",
      "|    n_updates            | 8070         |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | 2.5600874    |\n",
      "|    std                  | 2.89         |\n",
      "|    value_loss           | 802          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 809        |\n",
      "|    time_elapsed         | 15219      |\n",
      "|    total_timesteps      | 1656832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01098061 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.8      |\n",
      "|    explained_variance   | 0.803      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 156        |\n",
      "|    n_updates            | 8080       |\n",
      "|    policy_gradient_loss | -0.00725   |\n",
      "|    reward               | 0.27153316 |\n",
      "|    std                  | 2.89       |\n",
      "|    value_loss           | 363        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 15237       |\n",
      "|    total_timesteps      | 1658880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018997345 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 8090        |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | 1.3701172   |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 84.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 811         |\n",
      "|    time_elapsed         | 15256       |\n",
      "|    total_timesteps      | 1660928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010336712 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 362         |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.000113   |\n",
      "|    reward               | -2.0559537  |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 977         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 812          |\n",
      "|    time_elapsed         | 15274        |\n",
      "|    total_timesteps      | 1662976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070619024 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72          |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 233          |\n",
      "|    n_updates            | 8110         |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 15.20873     |\n",
      "|    std                  | 2.91         |\n",
      "|    value_loss           | 547          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4589790.75\n",
      "total_reward: 3589790.75\n",
      "total_cost: 176393.40\n",
      "total_trades: 59423\n",
      "Sharpe: 0.612\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 15293       |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014759755 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 5.7189403   |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 15312       |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011077853 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | 3.2804048   |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 572         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 15330       |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009689968 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 391         |\n",
      "|    n_updates            | 8140        |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | -7.114058   |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 728         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 816          |\n",
      "|    time_elapsed         | 15349        |\n",
      "|    total_timesteps      | 1671168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065443795 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.2        |\n",
      "|    explained_variance   | 0.259        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 225          |\n",
      "|    n_updates            | 8150         |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | -0.9702048   |\n",
      "|    std                  | 2.93         |\n",
      "|    value_loss           | 515          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 817          |\n",
      "|    time_elapsed         | 15367        |\n",
      "|    total_timesteps      | 1673216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123186875 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.2        |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 282          |\n",
      "|    n_updates            | 8160         |\n",
      "|    policy_gradient_loss | -0.00718     |\n",
      "|    reward               | -0.010689571 |\n",
      "|    std                  | 2.93         |\n",
      "|    value_loss           | 494          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 15386       |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010788437 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 750         |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 0.62084043  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 819          |\n",
      "|    time_elapsed         | 15404        |\n",
      "|    total_timesteps      | 1677312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066494383 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.2        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 496          |\n",
      "|    n_updates            | 8180         |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    reward               | 4.074619     |\n",
      "|    std                  | 2.93         |\n",
      "|    value_loss           | 957          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 820          |\n",
      "|    time_elapsed         | 15423        |\n",
      "|    total_timesteps      | 1679360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123600755 |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.2        |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.2         |\n",
      "|    n_updates            | 8190         |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    reward               | 1.6280129    |\n",
      "|    std                  | 2.93         |\n",
      "|    value_loss           | 99.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 821          |\n",
      "|    time_elapsed         | 15441        |\n",
      "|    total_timesteps      | 1681408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074632387 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.2        |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 400          |\n",
      "|    n_updates            | 8200         |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    reward               | 0.25392467   |\n",
      "|    std                  | 2.93         |\n",
      "|    value_loss           | 660          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 15460       |\n",
      "|    total_timesteps      | 1683456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009273129 |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 316         |\n",
      "|    n_updates            | 8210        |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | 4.6854305   |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 607         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 823         |\n",
      "|    time_elapsed         | 15478       |\n",
      "|    total_timesteps      | 1685504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008117003 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 8220        |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | -25.276072  |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 432         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 15496       |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008791493 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 8230        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | -0.5493755  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 488         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 15515       |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004466594 |\n",
      "|    clip_fraction        | 0.00615     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 337         |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    reward               | -2.3413692  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 766         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 826          |\n",
      "|    time_elapsed         | 15533        |\n",
      "|    total_timesteps      | 1691648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024399406 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.4        |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 693          |\n",
      "|    n_updates            | 8250         |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | 0.8572462    |\n",
      "|    std                  | 2.95         |\n",
      "|    value_loss           | 1.28e+03     |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4093797.22\n",
      "total_reward: 3093797.22\n",
      "total_cost: 208896.65\n",
      "total_trades: 62247\n",
      "Sharpe: 0.556\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 15552       |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028564945 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 8260        |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    reward               | 2.362035    |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 828         |\n",
      "|    time_elapsed         | 15570       |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007820055 |\n",
      "|    clip_fraction        | 0.0423      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 454         |\n",
      "|    n_updates            | 8270        |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    reward               | -0.31382364 |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 680         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 829          |\n",
      "|    time_elapsed         | 15589        |\n",
      "|    total_timesteps      | 1697792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059589404 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.5        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 208          |\n",
      "|    n_updates            | 8280         |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | 37.46496     |\n",
      "|    std                  | 2.96         |\n",
      "|    value_loss           | 927          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 830        |\n",
      "|    time_elapsed         | 15608      |\n",
      "|    total_timesteps      | 1699840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01129467 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.6      |\n",
      "|    explained_variance   | 0.591      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 92.1       |\n",
      "|    n_updates            | 8290       |\n",
      "|    policy_gradient_loss | -0.00835   |\n",
      "|    reward               | -0.7055346 |\n",
      "|    std                  | 2.97       |\n",
      "|    value_loss           | 229        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 831         |\n",
      "|    time_elapsed         | 15626       |\n",
      "|    total_timesteps      | 1701888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012167784 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 8300        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 2.5776622   |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 590         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 832          |\n",
      "|    time_elapsed         | 15645        |\n",
      "|    total_timesteps      | 1703936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074012205 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.6        |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 458          |\n",
      "|    n_updates            | 8310         |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | -4.7284036   |\n",
      "|    std                  | 2.97         |\n",
      "|    value_loss           | 491          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 833          |\n",
      "|    time_elapsed         | 15663        |\n",
      "|    total_timesteps      | 1705984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049074916 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.6        |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 469          |\n",
      "|    n_updates            | 8320         |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | 1.8901013    |\n",
      "|    std                  | 2.98         |\n",
      "|    value_loss           | 944          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 15682       |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010886882 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | -3.0240312  |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 835         |\n",
      "|    time_elapsed         | 15701       |\n",
      "|    total_timesteps      | 1710080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008322166 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 486         |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | 0.49522063  |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 767         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 15720       |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004884071 |\n",
      "|    clip_fraction        | 0.00874     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 207         |\n",
      "|    n_updates            | 8350        |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    reward               | 2.2876797   |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 815         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 15738       |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012070714 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.6        |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 1.5176971   |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 15757       |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013096938 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 8370        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 4.477001    |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 532         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 839          |\n",
      "|    time_elapsed         | 15777        |\n",
      "|    total_timesteps      | 1718272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061657643 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.7        |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 383          |\n",
      "|    n_updates            | 8380         |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | 2.727801     |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 1.06e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 840         |\n",
      "|    time_elapsed         | 15796       |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006474192 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 179         |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 6.143178    |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 511         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4498115.94\n",
      "total_reward: 3498115.94\n",
      "total_cost: 239594.14\n",
      "total_trades: 64599\n",
      "Sharpe: 0.588\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 15815       |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017423585 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 283         |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    reward               | -1.0917237  |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 336         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 15835       |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009385144 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 538         |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | -3.1624568  |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 759         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 843          |\n",
      "|    time_elapsed         | 15854        |\n",
      "|    total_timesteps      | 1726464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072140377 |\n",
      "|    clip_fraction        | 0.039        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.9        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 464          |\n",
      "|    n_updates            | 8420         |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    reward               | -3.18869     |\n",
      "|    std                  | 3            |\n",
      "|    value_loss           | 795          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 15873       |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016528524 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.2        |\n",
      "|    n_updates            | 8430        |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    reward               | -1.0629905  |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 87          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 845         |\n",
      "|    time_elapsed         | 15892       |\n",
      "|    total_timesteps      | 1730560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007953055 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 575         |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -0.29954025 |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 860         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 15911       |\n",
      "|    total_timesteps      | 1732608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007625037 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 537         |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | 16.28538    |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 1.09e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 15930       |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005940065 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -3.577532   |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 848       |\n",
      "|    time_elapsed         | 15948     |\n",
      "|    total_timesteps      | 1736704   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.016905  |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -73       |\n",
      "|    explained_variance   | 0.79      |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 220       |\n",
      "|    n_updates            | 8470      |\n",
      "|    policy_gradient_loss | -0.00889  |\n",
      "|    reward               | 2.7965121 |\n",
      "|    std                  | 3.02      |\n",
      "|    value_loss           | 540       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 849          |\n",
      "|    time_elapsed         | 15967        |\n",
      "|    total_timesteps      | 1738752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045857485 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73          |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 452          |\n",
      "|    n_updates            | 8480         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -1.9771645   |\n",
      "|    std                  | 3.02         |\n",
      "|    value_loss           | 912          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 850          |\n",
      "|    time_elapsed         | 15985        |\n",
      "|    total_timesteps      | 1740800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016628916 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73          |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 492          |\n",
      "|    n_updates            | 8490         |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | -9.469884    |\n",
      "|    std                  | 3.02         |\n",
      "|    value_loss           | 790          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 16004       |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015128205 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | 1.3167708   |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 72.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 852          |\n",
      "|    time_elapsed         | 16023        |\n",
      "|    total_timesteps      | 1744896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034655407 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.2        |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 587          |\n",
      "|    n_updates            | 8510         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | -2.0420187   |\n",
      "|    std                  | 3.03         |\n",
      "|    value_loss           | 857          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 853          |\n",
      "|    time_elapsed         | 16041        |\n",
      "|    total_timesteps      | 1746944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015235601 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.2        |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 348          |\n",
      "|    n_updates            | 8520         |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    reward               | -6.4940286   |\n",
      "|    std                  | 3.03         |\n",
      "|    value_loss           | 898          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 16060       |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010917148 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 8530        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 2.9573123   |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 213         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4758212.66\n",
      "total_reward: 3758212.66\n",
      "total_cost: 189802.90\n",
      "total_trades: 60819\n",
      "Sharpe: 0.590\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 855          |\n",
      "|    time_elapsed         | 16079        |\n",
      "|    total_timesteps      | 1751040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030857425 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.3        |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 399          |\n",
      "|    n_updates            | 8540         |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | 0.2355718    |\n",
      "|    std                  | 3.04         |\n",
      "|    value_loss           | 593          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 856          |\n",
      "|    time_elapsed         | 16098        |\n",
      "|    total_timesteps      | 1753088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029803114 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.3        |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 224          |\n",
      "|    n_updates            | 8550         |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    reward               | 26.160553    |\n",
      "|    std                  | 3.04         |\n",
      "|    value_loss           | 799          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 857          |\n",
      "|    time_elapsed         | 16116        |\n",
      "|    total_timesteps      | 1755136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066092843 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.3        |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 401          |\n",
      "|    n_updates            | 8560         |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    reward               | 7.5883884    |\n",
      "|    std                  | 3.04         |\n",
      "|    value_loss           | 889          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 16135       |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015560022 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 2.9426067   |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 16154       |\n",
      "|    total_timesteps      | 1759232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010723342 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 883         |\n",
      "|    n_updates            | 8580        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -1.0999529  |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 1.32e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 860          |\n",
      "|    time_elapsed         | 16173        |\n",
      "|    total_timesteps      | 1761280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028002602 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.4        |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 504          |\n",
      "|    n_updates            | 8590         |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | 6.385144     |\n",
      "|    std                  | 3.06         |\n",
      "|    value_loss           | 883          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 16191       |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007360601 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    reward               | -1.4768974  |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 862          |\n",
      "|    time_elapsed         | 16210        |\n",
      "|    total_timesteps      | 1765376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033345374 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.5        |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 374          |\n",
      "|    n_updates            | 8610         |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | -0.86033845  |\n",
      "|    std                  | 3.06         |\n",
      "|    value_loss           | 724          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 863          |\n",
      "|    time_elapsed         | 16229        |\n",
      "|    total_timesteps      | 1767424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031003437 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.5        |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 368          |\n",
      "|    n_updates            | 8620         |\n",
      "|    policy_gradient_loss | -0.000402    |\n",
      "|    reward               | 13.119601    |\n",
      "|    std                  | 3.06         |\n",
      "|    value_loss           | 853          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 864          |\n",
      "|    time_elapsed         | 16248        |\n",
      "|    total_timesteps      | 1769472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047260486 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.5        |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 206          |\n",
      "|    n_updates            | 8630         |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    reward               | -2.5191574   |\n",
      "|    std                  | 3.06         |\n",
      "|    value_loss           | 411          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 865         |\n",
      "|    time_elapsed         | 16266       |\n",
      "|    total_timesteps      | 1771520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021061312 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -2.5307944  |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 388         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 16285       |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002862093 |\n",
      "|    clip_fraction        | 0.00747     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 540         |\n",
      "|    n_updates            | 8650        |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    reward               | 1.4815656   |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 723         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 867           |\n",
      "|    time_elapsed         | 16304         |\n",
      "|    total_timesteps      | 1775616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0040447554  |\n",
      "|    clip_fraction        | 0.00879       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -73.6         |\n",
      "|    explained_variance   | 0.817         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 186           |\n",
      "|    n_updates            | 8660          |\n",
      "|    policy_gradient_loss | -0.00373      |\n",
      "|    reward               | -0.0013559987 |\n",
      "|    std                  | 3.07          |\n",
      "|    value_loss           | 833           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 16324       |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015966002 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.5        |\n",
      "|    n_updates            | 8670        |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    reward               | -0.06760346 |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5373095.15\n",
      "total_reward: 4373095.15\n",
      "total_cost: 194702.78\n",
      "total_trades: 61210\n",
      "Sharpe: 0.654\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 16342       |\n",
      "|    total_timesteps      | 1779712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005380391 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 350         |\n",
      "|    n_updates            | 8680        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | 0.51816595  |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 750         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 870          |\n",
      "|    time_elapsed         | 16361        |\n",
      "|    total_timesteps      | 1781760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032471363 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.7        |\n",
      "|    explained_variance   | 0.81         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 485          |\n",
      "|    n_updates            | 8690         |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | -7.350137    |\n",
      "|    std                  | 3.09         |\n",
      "|    value_loss           | 702          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 871        |\n",
      "|    time_elapsed         | 16380      |\n",
      "|    total_timesteps      | 1783808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01772305 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.7      |\n",
      "|    explained_variance   | 0.811      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 109        |\n",
      "|    n_updates            | 8700       |\n",
      "|    policy_gradient_loss | -0.00431   |\n",
      "|    reward               | 1.0439527  |\n",
      "|    std                  | 3.09       |\n",
      "|    value_loss           | 319        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 16398       |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019984292 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 491         |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | 1.6042842   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 457         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 873          |\n",
      "|    time_elapsed         | 16416        |\n",
      "|    total_timesteps      | 1787904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093320375 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.8        |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 363          |\n",
      "|    n_updates            | 8720         |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | -1.1367252   |\n",
      "|    std                  | 3.1          |\n",
      "|    value_loss           | 542          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 16435       |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008968625 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 487         |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    reward               | -3.4017475  |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 758         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 875         |\n",
      "|    time_elapsed         | 16454       |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013785711 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | -5.552022   |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 16472       |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008909881 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 413         |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 1.1864445   |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 674         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 877         |\n",
      "|    time_elapsed         | 16490       |\n",
      "|    total_timesteps      | 1796096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004911931 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 250         |\n",
      "|    n_updates            | 8760        |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    reward               | 9.518028    |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 655         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 16509       |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015741684 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | -5.8081074  |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 879         |\n",
      "|    time_elapsed         | 16527       |\n",
      "|    total_timesteps      | 1800192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010129431 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 229         |\n",
      "|    n_updates            | 8780        |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | 0.87634957  |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 424         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 16546       |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009753953 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 8790        |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 16.06105    |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 482         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 881        |\n",
      "|    time_elapsed         | 16564      |\n",
      "|    total_timesteps      | 1804288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00997621 |\n",
      "|    clip_fraction        | 0.0678     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.9      |\n",
      "|    explained_variance   | 0.686      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 143        |\n",
      "|    n_updates            | 8800       |\n",
      "|    policy_gradient_loss | -0.00521   |\n",
      "|    reward               | -3.3016007 |\n",
      "|    std                  | 3.11       |\n",
      "|    value_loss           | 384        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 16583       |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013579261 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    reward               | 2.3524394   |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4191452.58\n",
      "total_reward: 3191452.58\n",
      "total_cost: 168478.16\n",
      "total_trades: 59026\n",
      "Sharpe: 0.599\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 883          |\n",
      "|    time_elapsed         | 16602        |\n",
      "|    total_timesteps      | 1808384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032560914 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74          |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 275          |\n",
      "|    n_updates            | 8820         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | 1.1058204    |\n",
      "|    std                  | 3.12         |\n",
      "|    value_loss           | 641          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 884          |\n",
      "|    time_elapsed         | 16621        |\n",
      "|    total_timesteps      | 1810432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051986193 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74          |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 140          |\n",
      "|    n_updates            | 8830         |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 16.13553     |\n",
      "|    std                  | 3.12         |\n",
      "|    value_loss           | 678          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 16640       |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012758888 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.8        |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | 1.2463491   |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 886          |\n",
      "|    time_elapsed         | 16658        |\n",
      "|    total_timesteps      | 1814528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060608247 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74          |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 267          |\n",
      "|    n_updates            | 8850         |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | -1.912652    |\n",
      "|    std                  | 3.12         |\n",
      "|    value_loss           | 530          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 887          |\n",
      "|    time_elapsed         | 16676        |\n",
      "|    total_timesteps      | 1816576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042357356 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74          |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 277          |\n",
      "|    n_updates            | 8860         |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 4.2578325    |\n",
      "|    std                  | 3.12         |\n",
      "|    value_loss           | 590          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 888         |\n",
      "|    time_elapsed         | 16695       |\n",
      "|    total_timesteps      | 1818624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011208463 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 8870        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | -0.08849947 |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 305         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 889         |\n",
      "|    time_elapsed         | 16714       |\n",
      "|    total_timesteps      | 1820672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011974223 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 8880        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -0.98276955 |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 386         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 16732       |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007458376 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 242         |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    reward               | -0.07614928 |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 592         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 891           |\n",
      "|    time_elapsed         | 16751         |\n",
      "|    total_timesteps      | 1824768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066747353 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -74.1         |\n",
      "|    explained_variance   | 0.814         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 282           |\n",
      "|    n_updates            | 8900          |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | 2.5115168     |\n",
      "|    std                  | 3.13          |\n",
      "|    value_loss           | 783           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 892         |\n",
      "|    time_elapsed         | 16769       |\n",
      "|    total_timesteps      | 1826816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016752925 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 8910        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.33875322 |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 90.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 893          |\n",
      "|    time_elapsed         | 16788        |\n",
      "|    total_timesteps      | 1828864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029795738 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.2        |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 226          |\n",
      "|    n_updates            | 8920         |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | -0.9202813   |\n",
      "|    std                  | 3.15         |\n",
      "|    value_loss           | 787          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 894          |\n",
      "|    time_elapsed         | 16806        |\n",
      "|    total_timesteps      | 1830912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026116949 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.2        |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 248          |\n",
      "|    n_updates            | 8930         |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | -3.5815825   |\n",
      "|    std                  | 3.15         |\n",
      "|    value_loss           | 635          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 16825       |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007881857 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 8940        |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    reward               | -3.481704   |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 896         |\n",
      "|    time_elapsed         | 16843       |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009373081 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 8950        |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | -0.5389414  |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4695950.29\n",
      "total_reward: 3695950.29\n",
      "total_cost: 195002.00\n",
      "total_trades: 61041\n",
      "Sharpe: 0.600\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 16861       |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009862714 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 214         |\n",
      "|    n_updates            | 8960        |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | -15.1679945 |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 437         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 898          |\n",
      "|    time_elapsed         | 16880        |\n",
      "|    total_timesteps      | 1839104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057395264 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.4        |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 361          |\n",
      "|    n_updates            | 8970         |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | 3.1605878    |\n",
      "|    std                  | 3.16         |\n",
      "|    value_loss           | 791          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 899         |\n",
      "|    time_elapsed         | 16899       |\n",
      "|    total_timesteps      | 1841152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015685845 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 8980        |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | -1.6459891  |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 80.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 900          |\n",
      "|    time_elapsed         | 16919        |\n",
      "|    total_timesteps      | 1843200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064292056 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.5        |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 219          |\n",
      "|    n_updates            | 8990         |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 1.6303505    |\n",
      "|    std                  | 3.17         |\n",
      "|    value_loss           | 541          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 901         |\n",
      "|    time_elapsed         | 16938       |\n",
      "|    total_timesteps      | 1845248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012817265 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    reward               | 7.359956    |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 324         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 902         |\n",
      "|    time_elapsed         | 16957       |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012452955 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60          |\n",
      "|    n_updates            | 9010        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | -3.0450425  |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 903          |\n",
      "|    time_elapsed         | 16977        |\n",
      "|    total_timesteps      | 1849344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071202926 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.5        |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 163          |\n",
      "|    n_updates            | 9020         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | -0.7100462   |\n",
      "|    std                  | 3.18         |\n",
      "|    value_loss           | 376          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 904         |\n",
      "|    time_elapsed         | 16996       |\n",
      "|    total_timesteps      | 1851392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003312598 |\n",
      "|    clip_fraction        | 0.00503     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 275         |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    reward               | 0.26879558  |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 799         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 905          |\n",
      "|    time_elapsed         | 17014        |\n",
      "|    total_timesteps      | 1853440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068302983 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.5        |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 220          |\n",
      "|    n_updates            | 9040         |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    reward               | 0.417253     |\n",
      "|    std                  | 3.18         |\n",
      "|    value_loss           | 328          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 17033       |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013472956 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | 0.7633023   |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 17052       |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012522357 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 9060        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 1.979905    |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 688         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 908          |\n",
      "|    time_elapsed         | 17070        |\n",
      "|    total_timesteps      | 1859584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035807432 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.6        |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 309          |\n",
      "|    n_updates            | 9070         |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 0.86106634   |\n",
      "|    std                  | 3.19         |\n",
      "|    value_loss           | 767          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 909        |\n",
      "|    time_elapsed         | 17089      |\n",
      "|    total_timesteps      | 1861632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01581917 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.6      |\n",
      "|    explained_variance   | 0.598      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 58.6       |\n",
      "|    n_updates            | 9080       |\n",
      "|    policy_gradient_loss | -0.00565   |\n",
      "|    reward               | -1.4425601 |\n",
      "|    std                  | 3.2        |\n",
      "|    value_loss           | 155        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 910          |\n",
      "|    time_elapsed         | 17107        |\n",
      "|    total_timesteps      | 1863680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029623732 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.7        |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 371          |\n",
      "|    n_updates            | 9090         |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | -1.2196412   |\n",
      "|    std                  | 3.2          |\n",
      "|    value_loss           | 690          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 911          |\n",
      "|    time_elapsed         | 17126        |\n",
      "|    total_timesteps      | 1865728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034714714 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.7        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 258          |\n",
      "|    n_updates            | 9100         |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    reward               | -11.198638   |\n",
      "|    std                  | 3.2          |\n",
      "|    value_loss           | 729          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4642459.12\n",
      "total_reward: 3642459.12\n",
      "total_cost: 174824.81\n",
      "total_trades: 59881\n",
      "Sharpe: 0.582\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 912          |\n",
      "|    time_elapsed         | 17145        |\n",
      "|    total_timesteps      | 1867776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070737777 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.7        |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 147          |\n",
      "|    n_updates            | 9110         |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | 6.128211     |\n",
      "|    std                  | 3.2          |\n",
      "|    value_loss           | 388          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 17164       |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012407083 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | 0.6237218   |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 417         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 914        |\n",
      "|    time_elapsed         | 17183      |\n",
      "|    total_timesteps      | 1871872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01383174 |\n",
      "|    clip_fraction        | 0.0888     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.8      |\n",
      "|    explained_variance   | 0.766      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 332        |\n",
      "|    n_updates            | 9130       |\n",
      "|    policy_gradient_loss | -0.00701   |\n",
      "|    reward               | 0.9082884  |\n",
      "|    std                  | 3.21       |\n",
      "|    value_loss           | 384        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 17201        |\n",
      "|    total_timesteps      | 1873920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018600231 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.9        |\n",
      "|    explained_variance   | 0.792        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 617          |\n",
      "|    n_updates            | 9140         |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | -1.1849388   |\n",
      "|    std                  | 3.22         |\n",
      "|    value_loss           | 793          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 17220       |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011938364 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | -2.2164905  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 917         |\n",
      "|    time_elapsed         | 17238       |\n",
      "|    total_timesteps      | 1878016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004331301 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 236         |\n",
      "|    n_updates            | 9160        |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    reward               | 0.56730396  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 649         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 918           |\n",
      "|    time_elapsed         | 17256         |\n",
      "|    total_timesteps      | 1880064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069219247 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -74.9         |\n",
      "|    explained_variance   | 0.797         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 254           |\n",
      "|    n_updates            | 9170          |\n",
      "|    policy_gradient_loss | -0.00138      |\n",
      "|    reward               | 25.883099     |\n",
      "|    std                  | 3.22          |\n",
      "|    value_loss           | 784           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 17275       |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006361941 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 9180        |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | -3.7200155  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 17294       |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009810179 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 227         |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | 0.65857023  |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 484         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 921          |\n",
      "|    time_elapsed         | 17313        |\n",
      "|    total_timesteps      | 1886208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029537682 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.9        |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 495          |\n",
      "|    n_updates            | 9200         |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | 13.558368    |\n",
      "|    std                  | 3.22         |\n",
      "|    value_loss           | 550          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 17332       |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004789668 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 298         |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 0.6196216   |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 625         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 923         |\n",
      "|    time_elapsed         | 17351       |\n",
      "|    total_timesteps      | 1890304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018423991 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 9220        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | 2.515581    |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 77.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 924          |\n",
      "|    time_elapsed         | 17370        |\n",
      "|    total_timesteps      | 1892352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060934355 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.1        |\n",
      "|    explained_variance   | 0.808        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 194          |\n",
      "|    n_updates            | 9230         |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | -2.949267    |\n",
      "|    std                  | 3.24         |\n",
      "|    value_loss           | 628          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 925          |\n",
      "|    time_elapsed         | 17389        |\n",
      "|    total_timesteps      | 1894400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052101854 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.1        |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 158          |\n",
      "|    n_updates            | 9240         |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | -2.8464816   |\n",
      "|    std                  | 3.24         |\n",
      "|    value_loss           | 580          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4089750.37\n",
      "total_reward: 3089750.37\n",
      "total_cost: 189369.58\n",
      "total_trades: 60956\n",
      "Sharpe: 0.550\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 926        |\n",
      "|    time_elapsed         | 17409      |\n",
      "|    total_timesteps      | 1896448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01715665 |\n",
      "|    clip_fraction        | 0.0934     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.1      |\n",
      "|    explained_variance   | 0.735      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.8       |\n",
      "|    n_updates            | 9250       |\n",
      "|    policy_gradient_loss | -0.00342   |\n",
      "|    reward               | 3.342864   |\n",
      "|    std                  | 3.25       |\n",
      "|    value_loss           | 156        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 927         |\n",
      "|    time_elapsed         | 17428       |\n",
      "|    total_timesteps      | 1898496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007349591 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 298         |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | 4.5180626   |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 441         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 928          |\n",
      "|    time_elapsed         | 17446        |\n",
      "|    total_timesteps      | 1900544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039626174 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.2        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 269          |\n",
      "|    n_updates            | 9270         |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 11.142628    |\n",
      "|    std                  | 3.26         |\n",
      "|    value_loss           | 1.21e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 929          |\n",
      "|    time_elapsed         | 17465        |\n",
      "|    total_timesteps      | 1902592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036912803 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.2        |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 152          |\n",
      "|    n_updates            | 9280         |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | 5.717817     |\n",
      "|    std                  | 3.26         |\n",
      "|    value_loss           | 349          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 17483       |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010216387 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | 0.99825335  |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 322         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 931          |\n",
      "|    time_elapsed         | 17502        |\n",
      "|    total_timesteps      | 1906688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071123615 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.3        |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 342          |\n",
      "|    n_updates            | 9300         |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -1.0203557   |\n",
      "|    std                  | 3.27         |\n",
      "|    value_loss           | 622          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 932          |\n",
      "|    time_elapsed         | 17521        |\n",
      "|    total_timesteps      | 1908736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019808677 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.3        |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 415          |\n",
      "|    n_updates            | 9310         |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | 7.6540456    |\n",
      "|    std                  | 3.27         |\n",
      "|    value_loss           | 602          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 933         |\n",
      "|    time_elapsed         | 17541       |\n",
      "|    total_timesteps      | 1910784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024315206 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 9320        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -0.24972184 |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 97.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 934          |\n",
      "|    time_elapsed         | 17561        |\n",
      "|    total_timesteps      | 1912832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075640767 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.4        |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 9330         |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    reward               | 1.2799623    |\n",
      "|    std                  | 3.28         |\n",
      "|    value_loss           | 525          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 935          |\n",
      "|    time_elapsed         | 17580        |\n",
      "|    total_timesteps      | 1914880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026519333 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.4        |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 344          |\n",
      "|    n_updates            | 9340         |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 12.030983    |\n",
      "|    std                  | 3.28         |\n",
      "|    value_loss           | 644          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 936        |\n",
      "|    time_elapsed         | 17600      |\n",
      "|    total_timesteps      | 1916928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00684578 |\n",
      "|    clip_fraction        | 0.0248     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.5      |\n",
      "|    explained_variance   | 0.822      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 124        |\n",
      "|    n_updates            | 9350       |\n",
      "|    policy_gradient_loss | -0.00508   |\n",
      "|    reward               | -9.417066  |\n",
      "|    std                  | 3.28       |\n",
      "|    value_loss           | 282        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 17619       |\n",
      "|    total_timesteps      | 1918976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013464422 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | -0.9600308  |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 295         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 938          |\n",
      "|    time_elapsed         | 17639        |\n",
      "|    total_timesteps      | 1921024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037677493 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.5        |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 438          |\n",
      "|    n_updates            | 9370         |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    reward               | 0.015263301  |\n",
      "|    std                  | 3.28         |\n",
      "|    value_loss           | 882          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 939          |\n",
      "|    time_elapsed         | 17659        |\n",
      "|    total_timesteps      | 1923072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010000824 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.5        |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 454          |\n",
      "|    n_updates            | 9380         |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | -5.126125    |\n",
      "|    std                  | 3.28         |\n",
      "|    value_loss           | 749          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4573425.47\n",
      "total_reward: 3573425.47\n",
      "total_cost: 179234.07\n",
      "total_trades: 60003\n",
      "Sharpe: 0.586\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 940        |\n",
      "|    time_elapsed         | 17680      |\n",
      "|    total_timesteps      | 1925120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0141245  |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.5      |\n",
      "|    explained_variance   | 0.677      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30         |\n",
      "|    n_updates            | 9390       |\n",
      "|    policy_gradient_loss | -0.00602   |\n",
      "|    reward               | -0.3564687 |\n",
      "|    std                  | 3.29       |\n",
      "|    value_loss           | 69.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 941        |\n",
      "|    time_elapsed         | 17700      |\n",
      "|    total_timesteps      | 1927168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00614531 |\n",
      "|    clip_fraction        | 0.0367     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.5      |\n",
      "|    explained_variance   | 0.842      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 204        |\n",
      "|    n_updates            | 9400       |\n",
      "|    policy_gradient_loss | -0.00116   |\n",
      "|    reward               | 0.4111796  |\n",
      "|    std                  | 3.29       |\n",
      "|    value_loss           | 581        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 942          |\n",
      "|    time_elapsed         | 17720        |\n",
      "|    total_timesteps      | 1929216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027183879 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.5        |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 395          |\n",
      "|    n_updates            | 9410         |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    reward               | 8.968386     |\n",
      "|    std                  | 3.29         |\n",
      "|    value_loss           | 551          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 943         |\n",
      "|    time_elapsed         | 17739       |\n",
      "|    total_timesteps      | 1931264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010876868 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 9420        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | -0.06368794 |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 944          |\n",
      "|    time_elapsed         | 17759        |\n",
      "|    total_timesteps      | 1933312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029950705 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.5        |\n",
      "|    explained_variance   | 0.847        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 177          |\n",
      "|    n_updates            | 9430         |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 0.2374898    |\n",
      "|    std                  | 3.29         |\n",
      "|    value_loss           | 398          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 945         |\n",
      "|    time_elapsed         | 17778       |\n",
      "|    total_timesteps      | 1935360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003395496 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 259         |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    reward               | 12.092318   |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 479         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 946          |\n",
      "|    time_elapsed         | 17798        |\n",
      "|    total_timesteps      | 1937408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011627774 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.5        |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 283          |\n",
      "|    n_updates            | 9450         |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | 3.6881578    |\n",
      "|    std                  | 3.29         |\n",
      "|    value_loss           | 654          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 17817       |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012173595 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.2        |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -1.7861083  |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 948          |\n",
      "|    time_elapsed         | 17836        |\n",
      "|    total_timesteps      | 1941504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023947638 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.6        |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 474          |\n",
      "|    n_updates            | 9470         |\n",
      "|    policy_gradient_loss | -0.000647    |\n",
      "|    reward               | -0.42628855  |\n",
      "|    std                  | 3.3          |\n",
      "|    value_loss           | 666          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 17855       |\n",
      "|    total_timesteps      | 1943552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001810011 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | 14.329546   |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 589         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 950         |\n",
      "|    time_elapsed         | 17875       |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019691752 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.5        |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    reward               | 3.462021    |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 951        |\n",
      "|    time_elapsed         | 17894      |\n",
      "|    total_timesteps      | 1947648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01103379 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | 0.841      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 302        |\n",
      "|    n_updates            | 9500       |\n",
      "|    policy_gradient_loss | -0.00745   |\n",
      "|    reward               | 2.0365684  |\n",
      "|    std                  | 3.31       |\n",
      "|    value_loss           | 444        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 952          |\n",
      "|    time_elapsed         | 17914        |\n",
      "|    total_timesteps      | 1949696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063247606 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.7        |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 9510         |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    reward               | 8.8180895    |\n",
      "|    std                  | 3.31         |\n",
      "|    value_loss           | 542          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 953         |\n",
      "|    time_elapsed         | 17934       |\n",
      "|    total_timesteps      | 1951744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010583426 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | 0.91553354  |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4452164.15\n",
      "total_reward: 3452164.15\n",
      "total_cost: 148457.28\n",
      "total_trades: 56941\n",
      "Sharpe: 0.582\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 17954       |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017930137 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.7        |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | 1.5799842   |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 275         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 955          |\n",
      "|    time_elapsed         | 17973        |\n",
      "|    total_timesteps      | 1955840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041172733 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.8        |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 623          |\n",
      "|    n_updates            | 9540         |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | 1.0517639    |\n",
      "|    std                  | 3.33         |\n",
      "|    value_loss           | 623          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 17993       |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004446219 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 343         |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    reward               | 1.8733997   |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 698         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 957         |\n",
      "|    time_elapsed         | 18013       |\n",
      "|    total_timesteps      | 1959936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019514441 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 9560        |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | -1.3965261  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 94.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 958         |\n",
      "|    time_elapsed         | 18034       |\n",
      "|    total_timesteps      | 1961984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008664142 |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 251         |\n",
      "|    n_updates            | 9570        |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    reward               | 0.38857716  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 398         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 959          |\n",
      "|    time_elapsed         | 18054        |\n",
      "|    total_timesteps      | 1964032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038913037 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76          |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 238          |\n",
      "|    n_updates            | 9580         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | -1.9862778   |\n",
      "|    std                  | 3.34         |\n",
      "|    value_loss           | 485          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 960          |\n",
      "|    time_elapsed         | 18075        |\n",
      "|    total_timesteps      | 1966080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075695235 |\n",
      "|    clip_fraction        | 0.0635       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76          |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 161          |\n",
      "|    n_updates            | 9590         |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | 1.5389783    |\n",
      "|    std                  | 3.35         |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 18095       |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008544654 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | 0.075257935 |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 426         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 962        |\n",
      "|    time_elapsed         | 18114      |\n",
      "|    total_timesteps      | 1970176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00881294 |\n",
      "|    clip_fraction        | 0.0382     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76        |\n",
      "|    explained_variance   | 0.852      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 182        |\n",
      "|    n_updates            | 9610       |\n",
      "|    policy_gradient_loss | -0.00119   |\n",
      "|    reward               | -0.1272905 |\n",
      "|    std                  | 3.35       |\n",
      "|    value_loss           | 500        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 963          |\n",
      "|    time_elapsed         | 18134        |\n",
      "|    total_timesteps      | 1972224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070366813 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76          |\n",
      "|    explained_variance   | 0.855        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 270          |\n",
      "|    n_updates            | 9620         |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | 3.0380208    |\n",
      "|    std                  | 3.35         |\n",
      "|    value_loss           | 424          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 18153       |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019802632 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.1        |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | 1.7594482   |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 63.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 965         |\n",
      "|    time_elapsed         | 18173       |\n",
      "|    total_timesteps      | 1976320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009606186 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 9640        |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | 0.09040606  |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 392         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 18192       |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008626228 |\n",
      "|    clip_fraction        | 0.0552      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -1.567501   |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 580         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 967         |\n",
      "|    time_elapsed         | 18211       |\n",
      "|    total_timesteps      | 1980416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013435811 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.3        |\n",
      "|    n_updates            | 9660        |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | -0.26702654 |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4555639.06\n",
      "total_reward: 3555639.06\n",
      "total_cost: 178786.29\n",
      "total_trades: 57884\n",
      "Sharpe: 0.620\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 18231       |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007745932 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | 0.4979098   |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 347         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 969          |\n",
      "|    time_elapsed         | 18251        |\n",
      "|    total_timesteps      | 1984512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049204663 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.2        |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 224          |\n",
      "|    n_updates            | 9680         |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | -25.662632   |\n",
      "|    std                  | 3.37         |\n",
      "|    value_loss           | 454          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 970          |\n",
      "|    time_elapsed         | 18271        |\n",
      "|    total_timesteps      | 1986560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034074087 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.2        |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 9690         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 1.7829938    |\n",
      "|    std                  | 3.37         |\n",
      "|    value_loss           | 333          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 18290       |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013053883 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | -1.7363894  |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 972         |\n",
      "|    time_elapsed         | 18310       |\n",
      "|    total_timesteps      | 1990656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010421653 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 259         |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    reward               | 0.84314775  |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 324         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 973          |\n",
      "|    time_elapsed         | 18329        |\n",
      "|    total_timesteps      | 1992704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029066927 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.3        |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 9720         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -31.707712   |\n",
      "|    std                  | 3.38         |\n",
      "|    value_loss           | 344          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 974        |\n",
      "|    time_elapsed         | 18348      |\n",
      "|    total_timesteps      | 1994752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02356267 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.3      |\n",
      "|    explained_variance   | 0.688      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.9       |\n",
      "|    n_updates            | 9730       |\n",
      "|    policy_gradient_loss | -0.00221   |\n",
      "|    reward               | 0.8268657  |\n",
      "|    std                  | 3.39       |\n",
      "|    value_loss           | 94.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 975          |\n",
      "|    time_elapsed         | 18367        |\n",
      "|    total_timesteps      | 1996800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072618327 |\n",
      "|    clip_fraction        | 0.0717       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.4        |\n",
      "|    explained_variance   | 0.861        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 169          |\n",
      "|    n_updates            | 9740         |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    reward               | -0.09559916  |\n",
      "|    std                  | 3.39         |\n",
      "|    value_loss           | 301          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 18386       |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005661091 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | 2.4087996   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 317         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 977         |\n",
      "|    time_elapsed         | 18406       |\n",
      "|    total_timesteps      | 2000896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009379181 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.5        |\n",
      "|    n_updates            | 9760        |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | 0.6947543   |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 978         |\n",
      "|    time_elapsed         | 18426       |\n",
      "|    total_timesteps      | 2002944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0139952   |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.5        |\n",
      "|    n_updates            | 9770        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.28638512 |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 979          |\n",
      "|    time_elapsed         | 18446        |\n",
      "|    total_timesteps      | 2004992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051956745 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.5        |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 223          |\n",
      "|    n_updates            | 9780         |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | -0.3370138   |\n",
      "|    std                  | 3.41         |\n",
      "|    value_loss           | 484          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 980          |\n",
      "|    time_elapsed         | 18465        |\n",
      "|    total_timesteps      | 2007040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058238963 |\n",
      "|    clip_fraction        | 0.0544       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.5        |\n",
      "|    explained_variance   | 0.873        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 352          |\n",
      "|    n_updates            | 9790         |\n",
      "|    policy_gradient_loss | -4.24e-05    |\n",
      "|    reward               | 7.071909     |\n",
      "|    std                  | 3.41         |\n",
      "|    value_loss           | 431          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 981        |\n",
      "|    time_elapsed         | 18484      |\n",
      "|    total_timesteps      | 2009088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01952897 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.6      |\n",
      "|    explained_variance   | 0.767      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42.7       |\n",
      "|    n_updates            | 9800       |\n",
      "|    policy_gradient_loss | -0.00999   |\n",
      "|    reward               | 1.3334005  |\n",
      "|    std                  | 3.42       |\n",
      "|    value_loss           | 96.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4895175.50\n",
      "total_reward: 3895175.50\n",
      "total_cost: 167194.20\n",
      "total_trades: 57906\n",
      "Sharpe: 0.681\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 982          |\n",
      "|    time_elapsed         | 18505        |\n",
      "|    total_timesteps      | 2011136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048535056 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.6        |\n",
      "|    explained_variance   | 0.873        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 208          |\n",
      "|    n_updates            | 9810         |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | 0.3424139    |\n",
      "|    std                  | 3.42         |\n",
      "|    value_loss           | 387          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 983          |\n",
      "|    time_elapsed         | 18524        |\n",
      "|    total_timesteps      | 2013184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050486736 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.6        |\n",
      "|    explained_variance   | 0.885        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 174          |\n",
      "|    n_updates            | 9820         |\n",
      "|    policy_gradient_loss | 0.000556     |\n",
      "|    reward               | 6.073203     |\n",
      "|    std                  | 3.42         |\n",
      "|    value_loss           | 380          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 984          |\n",
      "|    time_elapsed         | 18543        |\n",
      "|    total_timesteps      | 2015232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134445485 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.7        |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.8         |\n",
      "|    n_updates            | 9830         |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | 0.716003     |\n",
      "|    std                  | 3.43         |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 18564       |\n",
      "|    total_timesteps      | 2017280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008821946 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.9        |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    reward               | 0.542752    |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 986          |\n",
      "|    time_elapsed         | 18583        |\n",
      "|    total_timesteps      | 2019328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009926667  |\n",
      "|    clip_fraction        | 0.0859       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.7        |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 150          |\n",
      "|    n_updates            | 9850         |\n",
      "|    policy_gradient_loss | -0.000771    |\n",
      "|    reward               | -0.071057335 |\n",
      "|    std                  | 3.43         |\n",
      "|    value_loss           | 364          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 987          |\n",
      "|    time_elapsed         | 18603        |\n",
      "|    total_timesteps      | 2021376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073572653 |\n",
      "|    clip_fraction        | 0.0584       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.7        |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 220          |\n",
      "|    n_updates            | 9860         |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    reward               | -0.14914116  |\n",
      "|    std                  | 3.44         |\n",
      "|    value_loss           | 397          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 18623       |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017622082 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | 3.9508977   |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 989         |\n",
      "|    time_elapsed         | 18642       |\n",
      "|    total_timesteps      | 2025472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006989142 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | 0.9116963   |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 308         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 990          |\n",
      "|    time_elapsed         | 18662        |\n",
      "|    total_timesteps      | 2027520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018790306 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.9        |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 244          |\n",
      "|    n_updates            | 9890         |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    reward               | 2.5946052    |\n",
      "|    std                  | 3.45         |\n",
      "|    value_loss           | 346          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 18681       |\n",
      "|    total_timesteps      | 2029568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013058941 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.6        |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | 1.794448    |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 992          |\n",
      "|    time_elapsed         | 18701        |\n",
      "|    total_timesteps      | 2031616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126405815 |\n",
      "|    clip_fraction        | 0.0859       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.9        |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 9910         |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    reward               | -3.2068596   |\n",
      "|    std                  | 3.46         |\n",
      "|    value_loss           | 281          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 993        |\n",
      "|    time_elapsed         | 18721      |\n",
      "|    total_timesteps      | 2033664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00473876 |\n",
      "|    clip_fraction        | 0.0233     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.9      |\n",
      "|    explained_variance   | 0.879      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 142        |\n",
      "|    n_updates            | 9920       |\n",
      "|    policy_gradient_loss | -0.00241   |\n",
      "|    reward               | 4.135064   |\n",
      "|    std                  | 3.46       |\n",
      "|    value_loss           | 357        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 994         |\n",
      "|    time_elapsed         | 18740       |\n",
      "|    total_timesteps      | 2035712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00960117  |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    reward               | -0.89789116 |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 243         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 18759       |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014341315 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.25274473 |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 95.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4246600.78\n",
      "total_reward: 3246600.78\n",
      "total_cost: 169376.53\n",
      "total_trades: 56965\n",
      "Sharpe: 0.642\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 18778       |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007299278 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.842       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    reward               | -0.6049389  |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 997         |\n",
      "|    time_elapsed         | 18797       |\n",
      "|    total_timesteps      | 2041856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007863232 |\n",
      "|    clip_fraction        | 0.0412      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 9960        |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | -27.213331  |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 998        |\n",
      "|    time_elapsed         | 18816      |\n",
      "|    total_timesteps      | 2043904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01806428 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.1      |\n",
      "|    explained_variance   | 0.697      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 36.5       |\n",
      "|    n_updates            | 9970       |\n",
      "|    policy_gradient_loss | -0.00322   |\n",
      "|    reward               | -4.59336   |\n",
      "|    std                  | 3.48       |\n",
      "|    value_loss           | 81.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 18836       |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009526519 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97          |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | -1.8892311  |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1000        |\n",
      "|    time_elapsed         | 18856       |\n",
      "|    total_timesteps      | 2048000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003875278 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    reward               | -5.318349   |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 365         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1001        |\n",
      "|    time_elapsed         | 18876       |\n",
      "|    total_timesteps      | 2050048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010087319 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.8        |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | 2.835028    |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1002        |\n",
      "|    time_elapsed         | 18896       |\n",
      "|    total_timesteps      | 2052096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010917816 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -0.51500976 |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1003         |\n",
      "|    time_elapsed         | 18915        |\n",
      "|    total_timesteps      | 2054144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056503606 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.3        |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 204          |\n",
      "|    n_updates            | 10020        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | -0.26614577  |\n",
      "|    std                  | 3.5          |\n",
      "|    value_loss           | 452          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1004         |\n",
      "|    time_elapsed         | 18935        |\n",
      "|    total_timesteps      | 2056192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027974853 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.3        |\n",
      "|    explained_variance   | 0.873        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 205          |\n",
      "|    n_updates            | 10030        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | -1.1989831   |\n",
      "|    std                  | 3.5          |\n",
      "|    value_loss           | 347          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 18954       |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016092869 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | 2.1228583   |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1006        |\n",
      "|    time_elapsed         | 18973       |\n",
      "|    total_timesteps      | 2060288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008947903 |\n",
      "|    clip_fraction        | 0.0676      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | -1.31831    |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 237         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 18993        |\n",
      "|    total_timesteps      | 2062336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034281118 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.4        |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 271          |\n",
      "|    n_updates            | 10060        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 17.859764    |\n",
      "|    std                  | 3.51         |\n",
      "|    value_loss           | 453          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1008        |\n",
      "|    time_elapsed         | 19026       |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010830791 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 10070       |\n",
      "|    policy_gradient_loss | -0.00136    |\n",
      "|    reward               | 1.090207    |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1009        |\n",
      "|    time_elapsed         | 19045       |\n",
      "|    total_timesteps      | 2066432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013134823 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.5        |\n",
      "|    n_updates            | 10080       |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | -1.1217247  |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1010       |\n",
      "|    time_elapsed         | 19064      |\n",
      "|    total_timesteps      | 2068480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00712729 |\n",
      "|    clip_fraction        | 0.0406     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.5      |\n",
      "|    explained_variance   | 0.661      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 172        |\n",
      "|    n_updates            | 10090      |\n",
      "|    policy_gradient_loss | -0.00603   |\n",
      "|    reward               | -15.805489 |\n",
      "|    std                  | 3.53       |\n",
      "|    value_loss           | 359        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4276248.92\n",
      "total_reward: 3276248.92\n",
      "total_cost: 183076.86\n",
      "total_trades: 58499\n",
      "Sharpe: 0.656\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1011        |\n",
      "|    time_elapsed         | 19084       |\n",
      "|    total_timesteps      | 2070528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007884998 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 10100       |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    reward               | -2.6162822  |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 19103       |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016102426 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 1.6150746   |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 58          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1013        |\n",
      "|    time_elapsed         | 19122       |\n",
      "|    total_timesteps      | 2074624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014313061 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.2        |\n",
      "|    n_updates            | 10120       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | -3.1059687  |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1014        |\n",
      "|    time_elapsed         | 19143       |\n",
      "|    total_timesteps      | 2076672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009433492 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 10130       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | -3.4190109  |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 19162       |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012783917 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | -2.6807415  |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1016         |\n",
      "|    time_elapsed         | 19182        |\n",
      "|    total_timesteps      | 2080768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139200725 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.7        |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 10150        |\n",
      "|    policy_gradient_loss | -0.00971     |\n",
      "|    reward               | -1.0041472   |\n",
      "|    std                  | 3.56         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1017         |\n",
      "|    time_elapsed         | 19202        |\n",
      "|    total_timesteps      | 2082816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058244513 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.7        |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 196          |\n",
      "|    n_updates            | 10160        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | -4.261879    |\n",
      "|    std                  | 3.56         |\n",
      "|    value_loss           | 424          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1018         |\n",
      "|    time_elapsed         | 19222        |\n",
      "|    total_timesteps      | 2084864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051183878 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.8        |\n",
      "|    explained_variance   | 0.842        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.2         |\n",
      "|    n_updates            | 10170        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | 1.8731215    |\n",
      "|    std                  | 3.56         |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1019         |\n",
      "|    time_elapsed         | 19243        |\n",
      "|    total_timesteps      | 2086912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015418794  |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.8        |\n",
      "|    explained_variance   | 0.863        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.7         |\n",
      "|    n_updates            | 10180        |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | -0.054737385 |\n",
      "|    std                  | 3.57         |\n",
      "|    value_loss           | 95.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1020         |\n",
      "|    time_elapsed         | 19263        |\n",
      "|    total_timesteps      | 2088960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067222826 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.9        |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 191          |\n",
      "|    n_updates            | 10190        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | -0.11142046  |\n",
      "|    std                  | 3.58         |\n",
      "|    value_loss           | 426          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1021        |\n",
      "|    time_elapsed         | 19283       |\n",
      "|    total_timesteps      | 2091008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008745717 |\n",
      "|    clip_fraction        | 0.0213      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 10200       |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | 0.52295315  |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 501         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1022        |\n",
      "|    time_elapsed         | 19303       |\n",
      "|    total_timesteps      | 2093056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014862426 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    reward               | 2.6472054   |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 85.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 19323       |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010499312 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    reward               | 0.43505707  |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1024         |\n",
      "|    time_elapsed         | 19342        |\n",
      "|    total_timesteps      | 2097152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039761057 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78          |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 185          |\n",
      "|    n_updates            | 10230        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | -3.044149    |\n",
      "|    std                  | 3.58         |\n",
      "|    value_loss           | 304          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4668904.83\n",
      "total_reward: 3668904.83\n",
      "total_cost: 189913.38\n",
      "total_trades: 59046\n",
      "Sharpe: 0.707\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 19361       |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012655919 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.4        |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | 2.2282488   |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1026       |\n",
      "|    time_elapsed         | 19381      |\n",
      "|    total_timesteps      | 2101248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01344067 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78        |\n",
      "|    explained_variance   | 0.869      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 74.2       |\n",
      "|    n_updates            | 10250      |\n",
      "|    policy_gradient_loss | -0.00327   |\n",
      "|    reward               | 0.5669383  |\n",
      "|    std                  | 3.59       |\n",
      "|    value_loss           | 137        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1027        |\n",
      "|    time_elapsed         | 19400       |\n",
      "|    total_timesteps      | 2103296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014270648 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 10260       |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | 1.3241825   |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1028         |\n",
      "|    time_elapsed         | 19420        |\n",
      "|    total_timesteps      | 2105344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125038475 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.1        |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 100          |\n",
      "|    n_updates            | 10270        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    reward               | 2.7570474    |\n",
      "|    std                  | 3.6          |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 19440       |\n",
      "|    total_timesteps      | 2107392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020472432 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 10280       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 1.191855    |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1030        |\n",
      "|    time_elapsed         | 19459       |\n",
      "|    total_timesteps      | 2109440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010315875 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | 0.21953295  |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1031        |\n",
      "|    time_elapsed         | 19478       |\n",
      "|    total_timesteps      | 2111488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003322424 |\n",
      "|    clip_fraction        | 0.0252      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.2        |\n",
      "|    n_updates            | 10300       |\n",
      "|    policy_gradient_loss | -0.00134    |\n",
      "|    reward               | -3.713332   |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1032        |\n",
      "|    time_elapsed         | 19498       |\n",
      "|    total_timesteps      | 2113536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021620553 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.8        |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | -0.5005022  |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 89.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 19517       |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008178454 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59          |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    reward               | 0.98057103  |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1034         |\n",
      "|    time_elapsed         | 19537        |\n",
      "|    total_timesteps      | 2117632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103745535 |\n",
      "|    clip_fraction        | 0.0649       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.3        |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.7         |\n",
      "|    n_updates            | 10330        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | -0.89574426  |\n",
      "|    std                  | 3.62         |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 19556       |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007977447 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.6        |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | 0.51470494  |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1036       |\n",
      "|    time_elapsed         | 19576      |\n",
      "|    total_timesteps      | 2121728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02189793 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.3      |\n",
      "|    explained_variance   | 0.387      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.3       |\n",
      "|    n_updates            | 10350      |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    reward               | -1.2769816 |\n",
      "|    std                  | 3.63       |\n",
      "|    value_loss           | 35.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 19596       |\n",
      "|    total_timesteps      | 2123776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007854992 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | -0.8379897  |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1038         |\n",
      "|    time_elapsed         | 19616        |\n",
      "|    total_timesteps      | 2125824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059285387 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.4        |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.2         |\n",
      "|    n_updates            | 10370        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | -12.266365   |\n",
      "|    std                  | 3.64         |\n",
      "|    value_loss           | 221          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4714255.10\n",
      "total_reward: 3714255.10\n",
      "total_cost: 179096.21\n",
      "total_trades: 58225\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1039        |\n",
      "|    time_elapsed         | 19635       |\n",
      "|    total_timesteps      | 2127872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017607847 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 10380       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -0.438803   |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 73.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1040        |\n",
      "|    time_elapsed         | 19655       |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009900922 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 215         |\n",
      "|    n_updates            | 10390       |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    reward               | -1.6663508  |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1041        |\n",
      "|    time_elapsed         | 19675       |\n",
      "|    total_timesteps      | 2131968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004795165 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.4        |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 3.2937174   |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 19694       |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007764674 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    reward               | -0.16398436 |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 19714       |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014672817 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.3        |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | 0.67574066  |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 19734       |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009493014 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.2        |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    reward               | 1.8387814   |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1045        |\n",
      "|    time_elapsed         | 19753       |\n",
      "|    total_timesteps      | 2140160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006140124 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.4        |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | 0.09444995  |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 19773       |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011693254 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | -0.27322185 |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1047         |\n",
      "|    time_elapsed         | 19793        |\n",
      "|    total_timesteps      | 2144256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071721794 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.6        |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.2         |\n",
      "|    n_updates            | 10460        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | -2.1438262   |\n",
      "|    std                  | 3.67         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 19813       |\n",
      "|    total_timesteps      | 2146304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005067423 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.2        |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | 0.00334     |\n",
      "|    reward               | -5.1462436  |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1049        |\n",
      "|    time_elapsed         | 19832       |\n",
      "|    total_timesteps      | 2148352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011171313 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | -1.825366   |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 70.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1050        |\n",
      "|    time_elapsed         | 19852       |\n",
      "|    total_timesteps      | 2150400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011531742 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 10490       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -1.6240813  |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 76.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1051         |\n",
      "|    time_elapsed         | 19871        |\n",
      "|    total_timesteps      | 2152448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066771703 |\n",
      "|    clip_fraction        | 0.0474       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.7        |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.7         |\n",
      "|    n_updates            | 10500        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 0.47799662   |\n",
      "|    std                  | 3.68         |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 19890       |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011903991 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.5        |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | -1.3288864  |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4515003.39\n",
      "total_reward: 3515003.39\n",
      "total_cost: 202530.33\n",
      "total_trades: 59930\n",
      "Sharpe: 0.759\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 19909       |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018503133 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | 0.50150585  |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1054        |\n",
      "|    time_elapsed         | 19929       |\n",
      "|    total_timesteps      | 2158592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008732635 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89          |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.20083195 |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1055        |\n",
      "|    time_elapsed         | 19948       |\n",
      "|    total_timesteps      | 2160640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005930877 |\n",
      "|    clip_fraction        | 0.0217      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.1        |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | 8.322537    |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 19967       |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015797567 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 10550       |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    reward               | -0.89413285 |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 62          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1057        |\n",
      "|    time_elapsed         | 19987       |\n",
      "|    total_timesteps      | 2164736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012912987 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 10560       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.9578761  |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1058        |\n",
      "|    time_elapsed         | 20006       |\n",
      "|    total_timesteps      | 2166784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009690067 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.1        |\n",
      "|    n_updates            | 10570       |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | -14.929316  |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1059        |\n",
      "|    time_elapsed         | 20025       |\n",
      "|    total_timesteps      | 2168832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011257276 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 10580       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.2126456  |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1060        |\n",
      "|    time_elapsed         | 20045       |\n",
      "|    total_timesteps      | 2170880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014355333 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 0.72737974  |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 20064       |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009578023 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 10600       |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | -0.18743265 |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1062       |\n",
      "|    time_elapsed         | 20083      |\n",
      "|    total_timesteps      | 2174976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0059025  |\n",
      "|    clip_fraction        | 0.0314     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79        |\n",
      "|    explained_variance   | 0.835      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47         |\n",
      "|    n_updates            | 10610      |\n",
      "|    policy_gradient_loss | -0.00196   |\n",
      "|    reward               | -5.9029856 |\n",
      "|    std                  | 3.72       |\n",
      "|    value_loss           | 90.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1063        |\n",
      "|    time_elapsed         | 20103       |\n",
      "|    total_timesteps      | 2177024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017351244 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 10620       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -2.9351048  |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 20122       |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010522282 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    reward               | 0.054846026 |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 99.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1065         |\n",
      "|    time_elapsed         | 20142        |\n",
      "|    total_timesteps      | 2181120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024514776 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.2        |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.2         |\n",
      "|    n_updates            | 10640        |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    reward               | 1.3953388    |\n",
      "|    std                  | 3.74         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1066        |\n",
      "|    time_elapsed         | 20162       |\n",
      "|    total_timesteps      | 2183168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009115908 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 10650       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | -1.1856275  |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 80.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5031995.39\n",
      "total_reward: 4031995.39\n",
      "total_cost: 234024.05\n",
      "total_trades: 61560\n",
      "Sharpe: 0.832\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1067        |\n",
      "|    time_elapsed         | 20182       |\n",
      "|    total_timesteps      | 2185216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017190097 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -0.6187962  |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1068         |\n",
      "|    time_elapsed         | 20201        |\n",
      "|    total_timesteps      | 2187264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073146876 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.3        |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.4         |\n",
      "|    n_updates            | 10670        |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | -1.8899372   |\n",
      "|    std                  | 3.76         |\n",
      "|    value_loss           | 79.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1069         |\n",
      "|    time_elapsed         | 20221        |\n",
      "|    total_timesteps      | 2189312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047590546 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.3        |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 10680        |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | -0.13665259  |\n",
      "|    std                  | 3.76         |\n",
      "|    value_loss           | 87           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1070       |\n",
      "|    time_elapsed         | 20240      |\n",
      "|    total_timesteps      | 2191360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01397438 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.3      |\n",
      "|    explained_variance   | 0.26       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.8        |\n",
      "|    n_updates            | 10690      |\n",
      "|    policy_gradient_loss | -0.00816   |\n",
      "|    reward               | 1.3264315  |\n",
      "|    std                  | 3.76       |\n",
      "|    value_loss           | 24.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1071        |\n",
      "|    time_elapsed         | 20259       |\n",
      "|    total_timesteps      | 2193408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012068186 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 10700       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 2.3678813   |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 69.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1072        |\n",
      "|    time_elapsed         | 20279       |\n",
      "|    total_timesteps      | 2195456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009900996 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 10710       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | 4.383819    |\n",
      "|    std                  | 3.78        |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 20298       |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013820855 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | 0.1306467   |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1074        |\n",
      "|    time_elapsed         | 20317       |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019245008 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.0284      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 10730       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 1.2153771   |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1075        |\n",
      "|    time_elapsed         | 20337       |\n",
      "|    total_timesteps      | 2201600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008986125 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 10740       |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 0.74936306  |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1076        |\n",
      "|    time_elapsed         | 20356       |\n",
      "|    total_timesteps      | 2203648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011439843 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 10750       |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    reward               | 1.0015061   |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 20376       |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013384633 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.51        |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -3.1180239  |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1078        |\n",
      "|    time_elapsed         | 20395       |\n",
      "|    total_timesteps      | 2207744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009364128 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.1        |\n",
      "|    n_updates            | 10770       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -0.18161829 |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 73.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1079        |\n",
      "|    time_elapsed         | 20414       |\n",
      "|    total_timesteps      | 2209792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005738668 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 10780       |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | -0.5693639  |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1080        |\n",
      "|    time_elapsed         | 20434       |\n",
      "|    total_timesteps      | 2211840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010527911 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 10790       |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    reward               | -0.7587291  |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7248811.23\n",
      "total_reward: 6248811.23\n",
      "total_cost: 226043.84\n",
      "total_trades: 62001\n",
      "Sharpe: 1.029\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1081         |\n",
      "|    time_elapsed         | 20453        |\n",
      "|    total_timesteps      | 2213888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124737695 |\n",
      "|    clip_fraction        | 0.0911       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.9        |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 10800        |\n",
      "|    policy_gradient_loss | -0.00878     |\n",
      "|    reward               | -0.85879886  |\n",
      "|    std                  | 3.84         |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1082         |\n",
      "|    time_elapsed         | 20473        |\n",
      "|    total_timesteps      | 2215936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142054595 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.9        |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 10810        |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    reward               | 4.802826     |\n",
      "|    std                  | 3.85         |\n",
      "|    value_loss           | 91.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1083         |\n",
      "|    time_elapsed         | 20493        |\n",
      "|    total_timesteps      | 2217984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123412935 |\n",
      "|    clip_fraction        | 0.094        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80          |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 10820        |\n",
      "|    policy_gradient_loss | -0.0083      |\n",
      "|    reward               | -2.3767536   |\n",
      "|    std                  | 3.86         |\n",
      "|    value_loss           | 48.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1084       |\n",
      "|    time_elapsed         | 20512      |\n",
      "|    total_timesteps      | 2220032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01350682 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80        |\n",
      "|    explained_variance   | 0.467      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.7       |\n",
      "|    n_updates            | 10830      |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | -0.5898779 |\n",
      "|    std                  | 3.86       |\n",
      "|    value_loss           | 37.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 20532       |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010602015 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | 0.066943035 |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 20552       |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008914368 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 10850       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | -6.298473   |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 20571       |\n",
      "|    total_timesteps      | 2226176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012832178 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 2.7327957   |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1088        |\n",
      "|    time_elapsed         | 20590       |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015819773 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 10870       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -2.438031   |\n",
      "|    std                  | 3.89        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1089       |\n",
      "|    time_elapsed         | 20611      |\n",
      "|    total_timesteps      | 2230272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01060516 |\n",
      "|    clip_fraction        | 0.0729     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.3      |\n",
      "|    explained_variance   | 0.345      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39         |\n",
      "|    n_updates            | 10880      |\n",
      "|    policy_gradient_loss | -0.00536   |\n",
      "|    reward               | -3.4882689 |\n",
      "|    std                  | 3.9        |\n",
      "|    value_loss           | 73.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1090       |\n",
      "|    time_elapsed         | 20631      |\n",
      "|    total_timesteps      | 2232320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01612867 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.3      |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.7       |\n",
      "|    n_updates            | 10890      |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    reward               | -1.3678006 |\n",
      "|    std                  | 3.91       |\n",
      "|    value_loss           | 46.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 20651       |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014249457 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | 0.27230987  |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 20671       |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009761916 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 10910       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | -1.5963986  |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1093        |\n",
      "|    time_elapsed         | 20690       |\n",
      "|    total_timesteps      | 2238464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008849894 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 10920       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | -0.74879    |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1094        |\n",
      "|    time_elapsed         | 20710       |\n",
      "|    total_timesteps      | 2240512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019004434 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 10930       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 2.0336163   |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4473646.96\n",
      "total_reward: 3473646.96\n",
      "total_cost: 139883.07\n",
      "total_trades: 58763\n",
      "Sharpe: 0.771\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 20730       |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011505283 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 10940       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | -0.30242178 |\n",
      "|    std                  | 3.95        |\n",
      "|    value_loss           | 79.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1096         |\n",
      "|    time_elapsed         | 20750        |\n",
      "|    total_timesteps      | 2244608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073451493 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.7        |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.5         |\n",
      "|    n_updates            | 10950        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | 0.40863386   |\n",
      "|    std                  | 3.95         |\n",
      "|    value_loss           | 67           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1097        |\n",
      "|    time_elapsed         | 20769       |\n",
      "|    total_timesteps      | 2246656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009378362 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | -0.56602854 |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 44.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1098        |\n",
      "|    time_elapsed         | 20789       |\n",
      "|    total_timesteps      | 2248704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012509806 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 10970       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | -0.8730104  |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1099        |\n",
      "|    time_elapsed         | 20809       |\n",
      "|    total_timesteps      | 2250752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016014721 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 10980       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 2.4751134   |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1100        |\n",
      "|    time_elapsed         | 20829       |\n",
      "|    total_timesteps      | 2252800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010946386 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 10990       |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | 1.6106833   |\n",
      "|    std                  | 3.98        |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 20850       |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014335876 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.49        |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 6.1387095   |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1102        |\n",
      "|    time_elapsed         | 20870       |\n",
      "|    total_timesteps      | 2256896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011920834 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 0.2134503   |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1103        |\n",
      "|    time_elapsed         | 20889       |\n",
      "|    total_timesteps      | 2258944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010608983 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    reward               | -0.6924999  |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 67.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1104        |\n",
      "|    time_elapsed         | 20909       |\n",
      "|    total_timesteps      | 2260992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011139735 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.69        |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | 3.2866385   |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 20928       |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012996657 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -3.8516936  |\n",
      "|    std                  | 4.04        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1106         |\n",
      "|    time_elapsed         | 20948        |\n",
      "|    total_timesteps      | 2265088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059359786 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.3        |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.3         |\n",
      "|    n_updates            | 11050        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | -4.4760027   |\n",
      "|    std                  | 4.04         |\n",
      "|    value_loss           | 62.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1107        |\n",
      "|    time_elapsed         | 20968       |\n",
      "|    total_timesteps      | 2267136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008869564 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 11060       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | -1.4431643  |\n",
      "|    std                  | 4.04        |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1108       |\n",
      "|    time_elapsed         | 20987      |\n",
      "|    total_timesteps      | 2269184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01553157 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.3      |\n",
      "|    explained_variance   | 0.307      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.74       |\n",
      "|    n_updates            | 11070      |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    reward               | 2.3163304  |\n",
      "|    std                  | 4.05       |\n",
      "|    value_loss           | 28.7       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3788442.97\n",
      "total_reward: 2788442.97\n",
      "total_cost: 137275.66\n",
      "total_trades: 58069\n",
      "Sharpe: 0.685\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1109        |\n",
      "|    time_elapsed         | 21007       |\n",
      "|    total_timesteps      | 2271232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008354682 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 0.013037024 |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 62          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1110        |\n",
      "|    time_elapsed         | 21026       |\n",
      "|    total_timesteps      | 2273280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007734326 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.3        |\n",
      "|    n_updates            | 11090       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | 6.059573    |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 64.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1111        |\n",
      "|    time_elapsed         | 21044       |\n",
      "|    total_timesteps      | 2275328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019346885 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    reward               | 0.49352592  |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1112        |\n",
      "|    time_elapsed         | 21064       |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011519762 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 11110       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | 1.6927507   |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1113        |\n",
      "|    time_elapsed         | 21083       |\n",
      "|    total_timesteps      | 2279424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007529979 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 11120       |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | 2.0630243   |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1114        |\n",
      "|    time_elapsed         | 21102       |\n",
      "|    total_timesteps      | 2281472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010042675 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | -0.53420866 |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 21121       |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012382286 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.88        |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    reward               | -1.1004677  |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1116         |\n",
      "|    time_elapsed         | 21140        |\n",
      "|    total_timesteps      | 2285568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070922496 |\n",
      "|    clip_fraction        | 0.0497       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.6        |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 11150        |\n",
      "|    policy_gradient_loss | -0.00771     |\n",
      "|    reward               | 1.8776776    |\n",
      "|    std                  | 4.09         |\n",
      "|    value_loss           | 57.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 21160       |\n",
      "|    total_timesteps      | 2287616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006818075 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0723      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 11160       |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    reward               | 2.5074532   |\n",
      "|    std                  | 4.09        |\n",
      "|    value_loss           | 88.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1118       |\n",
      "|    time_elapsed         | 21179      |\n",
      "|    total_timesteps      | 2289664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01745667 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.7      |\n",
      "|    explained_variance   | 0.241      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.4       |\n",
      "|    n_updates            | 11170      |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    reward               | 0.22698621 |\n",
      "|    std                  | 4.1        |\n",
      "|    value_loss           | 32         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1119        |\n",
      "|    time_elapsed         | 21198       |\n",
      "|    total_timesteps      | 2291712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010127485 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 11180       |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | 0.36471358  |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 86.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1120         |\n",
      "|    time_elapsed         | 21217        |\n",
      "|    total_timesteps      | 2293760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068911407 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.8        |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 11190        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -0.4031656   |\n",
      "|    std                  | 4.11         |\n",
      "|    value_loss           | 51.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1121        |\n",
      "|    time_elapsed         | 21236       |\n",
      "|    total_timesteps      | 2295808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010225942 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 11200       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | -1.9832069  |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 21256       |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012340834 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.3         |\n",
      "|    n_updates            | 11210       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.5975301  |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1123        |\n",
      "|    time_elapsed         | 21275       |\n",
      "|    total_timesteps      | 2299904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009747453 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 11220       |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 5.3830214   |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3733474.30\n",
      "total_reward: 2733474.30\n",
      "total_cost: 109200.91\n",
      "total_trades: 56705\n",
      "Sharpe: 0.681\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1124         |\n",
      "|    time_elapsed         | 21294        |\n",
      "|    total_timesteps      | 2301952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074028904 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.9        |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 11230        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    reward               | -2.7112484   |\n",
      "|    std                  | 4.13         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1125        |\n",
      "|    time_elapsed         | 21313       |\n",
      "|    total_timesteps      | 2304000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017692551 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.0919      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 11240       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 1.0583993   |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1126        |\n",
      "|    time_elapsed         | 21331       |\n",
      "|    total_timesteps      | 2306048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011606996 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 11250       |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | 1.3231689   |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1127        |\n",
      "|    time_elapsed         | 21350       |\n",
      "|    total_timesteps      | 2308096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01035342  |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 11260       |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | -0.17158613 |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1128        |\n",
      "|    time_elapsed         | 21369       |\n",
      "|    total_timesteps      | 2310144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009000151 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | 2.0664854   |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1129        |\n",
      "|    time_elapsed         | 21388       |\n",
      "|    total_timesteps      | 2312192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011276726 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 11280       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -4.235327   |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1130         |\n",
      "|    time_elapsed         | 21407        |\n",
      "|    total_timesteps      | 2314240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046458934 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.2        |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 11290        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -1.1472479   |\n",
      "|    std                  | 4.17         |\n",
      "|    value_loss           | 51.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1131        |\n",
      "|    time_elapsed         | 21426       |\n",
      "|    total_timesteps      | 2316288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008152929 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 11300       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | 0.7035641   |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1132        |\n",
      "|    time_elapsed         | 21445       |\n",
      "|    total_timesteps      | 2318336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015662368 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 11310       |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    reward               | 1.705712    |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1133         |\n",
      "|    time_elapsed         | 21464        |\n",
      "|    total_timesteps      | 2320384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012101818  |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.3        |\n",
      "|    explained_variance   | 0.333        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.5         |\n",
      "|    n_updates            | 11320        |\n",
      "|    policy_gradient_loss | -0.00888     |\n",
      "|    reward               | -0.070129566 |\n",
      "|    std                  | 4.18         |\n",
      "|    value_loss           | 74.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1134        |\n",
      "|    time_elapsed         | 21483       |\n",
      "|    total_timesteps      | 2322432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009145761 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 11330       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | -1.0064828  |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 21502       |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012119457 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 11340       |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | -0.44184464 |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1136       |\n",
      "|    time_elapsed         | 21521      |\n",
      "|    total_timesteps      | 2326528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01367898 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.3      |\n",
      "|    explained_variance   | 0.246      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.3       |\n",
      "|    n_updates            | 11350      |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    reward               | 1.1940807  |\n",
      "|    std                  | 4.18       |\n",
      "|    value_loss           | 43.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1137        |\n",
      "|    time_elapsed         | 21539       |\n",
      "|    total_timesteps      | 2328576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007907895 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 11360       |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    reward               | -0.74269605 |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3904582.65\n",
      "total_reward: 2904582.65\n",
      "total_cost: 95183.63\n",
      "total_trades: 55437\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1138        |\n",
      "|    time_elapsed         | 21558       |\n",
      "|    total_timesteps      | 2330624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009800402 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 11370       |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    reward               | 2.6469889   |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1139         |\n",
      "|    time_elapsed         | 21577        |\n",
      "|    total_timesteps      | 2332672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084489975 |\n",
      "|    clip_fraction        | 0.0912       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.4        |\n",
      "|    explained_variance   | 0.325        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 11380        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | 0.08908186   |\n",
      "|    std                  | 4.2          |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 21596       |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011874663 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -2.7142386  |\n",
      "|    std                  | 4.22        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1141         |\n",
      "|    time_elapsed         | 21615        |\n",
      "|    total_timesteps      | 2336768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067162304 |\n",
      "|    clip_fraction        | 0.0506       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.5        |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 11400        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | 3.8595595    |\n",
      "|    std                  | 4.22         |\n",
      "|    value_loss           | 49.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 21634       |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010938904 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -2.4972687  |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1143         |\n",
      "|    time_elapsed         | 21653        |\n",
      "|    total_timesteps      | 2340864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120012835 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.6        |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.5         |\n",
      "|    n_updates            | 11420        |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    reward               | -1.009156    |\n",
      "|    std                  | 4.23         |\n",
      "|    value_loss           | 49.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 21673       |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008412009 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 11430       |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    reward               | -6.6465087  |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 65.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1145         |\n",
      "|    time_elapsed         | 21692        |\n",
      "|    total_timesteps      | 2344960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124903545 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.7        |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 11440        |\n",
      "|    policy_gradient_loss | -0.00768     |\n",
      "|    reward               | -1.5683781   |\n",
      "|    std                  | 4.24         |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1146        |\n",
      "|    time_elapsed         | 21711       |\n",
      "|    total_timesteps      | 2347008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011156372 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 11450       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 0.6233902   |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1147        |\n",
      "|    time_elapsed         | 21730       |\n",
      "|    total_timesteps      | 2349056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010555739 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 11460       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | 26.475945   |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1148         |\n",
      "|    time_elapsed         | 21749        |\n",
      "|    total_timesteps      | 2351104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086993305 |\n",
      "|    clip_fraction        | 0.0515       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.7        |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 11470        |\n",
      "|    policy_gradient_loss | -0.00793     |\n",
      "|    reward               | 1.9599285    |\n",
      "|    std                  | 4.25         |\n",
      "|    value_loss           | 86           |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 1149      |\n",
      "|    time_elapsed         | 21768     |\n",
      "|    total_timesteps      | 2353152   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.008869  |\n",
      "|    clip_fraction        | 0.064     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -82.7     |\n",
      "|    explained_variance   | 0.548     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 16.1      |\n",
      "|    n_updates            | 11480     |\n",
      "|    policy_gradient_loss | -0.00775  |\n",
      "|    reward               | 1.1088103 |\n",
      "|    std                  | 4.25      |\n",
      "|    value_loss           | 37.8      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1150       |\n",
      "|    time_elapsed         | 21787      |\n",
      "|    total_timesteps      | 2355200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01939702 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.8      |\n",
      "|    explained_variance   | 0.164      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.9       |\n",
      "|    n_updates            | 11490      |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    reward               | 0.54965305 |\n",
      "|    std                  | 4.27       |\n",
      "|    value_loss           | 42.8       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 1151      |\n",
      "|    time_elapsed         | 21806     |\n",
      "|    total_timesteps      | 2357248   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0101973 |\n",
      "|    clip_fraction        | 0.0882    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -82.9     |\n",
      "|    explained_variance   | 0.373     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 26.2      |\n",
      "|    n_updates            | 11500     |\n",
      "|    policy_gradient_loss | -0.00918  |\n",
      "|    reward               | 4.0371437 |\n",
      "|    std                  | 4.27      |\n",
      "|    value_loss           | 54.7      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4351856.59\n",
      "total_reward: 3351856.59\n",
      "total_cost: 94525.83\n",
      "total_trades: 55912\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 21826       |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009915156 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 11510       |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | 5.4997272   |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1153        |\n",
      "|    time_elapsed         | 21845       |\n",
      "|    total_timesteps      | 2361344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012804875 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 11520       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -6.559396   |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1154        |\n",
      "|    time_elapsed         | 21863       |\n",
      "|    total_timesteps      | 2363392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009133973 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 11530       |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | -2.793237   |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 62.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1155        |\n",
      "|    time_elapsed         | 21882       |\n",
      "|    total_timesteps      | 2365440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013124343 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 11540       |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | -1.1911886  |\n",
      "|    std                  | 4.29        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 21901       |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010862076 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -0.61837864 |\n",
      "|    std                  | 4.29        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1157        |\n",
      "|    time_elapsed         | 21920       |\n",
      "|    total_timesteps      | 2369536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010211764 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31          |\n",
      "|    n_updates            | 11560       |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | 1.2263838   |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 61.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1158        |\n",
      "|    time_elapsed         | 21939       |\n",
      "|    total_timesteps      | 2371584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008871568 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | 3.8149793   |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 21958       |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009948373 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 11580       |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | -0.77241975 |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 21977       |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008538243 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 11590       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | 0.54548556  |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1161        |\n",
      "|    time_elapsed         | 21997       |\n",
      "|    total_timesteps      | 2377728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012303952 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 11600       |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | -0.21655956 |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 22016       |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009700064 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | 4.2158256   |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1163        |\n",
      "|    time_elapsed         | 22035       |\n",
      "|    total_timesteps      | 2381824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013205467 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 11620       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -0.09849223 |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1164        |\n",
      "|    time_elapsed         | 22054       |\n",
      "|    total_timesteps      | 2383872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011856051 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 11630       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.3529132  |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1165        |\n",
      "|    time_elapsed         | 22073       |\n",
      "|    total_timesteps      | 2385920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007829107 |\n",
      "|    clip_fraction        | 0.0406      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 11640       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    reward               | 2.1128194   |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3724026.42\n",
      "total_reward: 2724026.42\n",
      "total_cost: 81340.24\n",
      "total_trades: 54645\n",
      "Sharpe: 0.680\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1166        |\n",
      "|    time_elapsed         | 22092       |\n",
      "|    total_timesteps      | 2387968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012123145 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.61        |\n",
      "|    n_updates            | 11650       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | -2.0363107  |\n",
      "|    std                  | 4.36        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1167        |\n",
      "|    time_elapsed         | 22111       |\n",
      "|    total_timesteps      | 2390016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013545509 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 11660       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.43716592 |\n",
      "|    std                  | 4.36        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1168        |\n",
      "|    time_elapsed         | 22130       |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010538546 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | 1.5518665   |\n",
      "|    std                  | 4.36        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1169         |\n",
      "|    time_elapsed         | 22149        |\n",
      "|    total_timesteps      | 2394112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098564625 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.5        |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 11680        |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    reward               | 1.5481203    |\n",
      "|    std                  | 4.37         |\n",
      "|    value_loss           | 40.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1170        |\n",
      "|    time_elapsed         | 22168       |\n",
      "|    total_timesteps      | 2396160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012341122 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 2.7764893   |\n",
      "|    std                  | 4.39        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 22187       |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011307776 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | -6.318036   |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1172        |\n",
      "|    time_elapsed         | 22205       |\n",
      "|    total_timesteps      | 2400256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009257256 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 11710       |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | 2.3611143   |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 22224       |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010667634 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 11720       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 2.7646046   |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1174        |\n",
      "|    time_elapsed         | 22243       |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011434312 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 11730       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.29881945 |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1175        |\n",
      "|    time_elapsed         | 22262       |\n",
      "|    total_timesteps      | 2406400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006139436 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 11740       |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | -5.675723   |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 66.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1176        |\n",
      "|    time_elapsed         | 22281       |\n",
      "|    total_timesteps      | 2408448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013803188 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 0.34136954  |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1177        |\n",
      "|    time_elapsed         | 22300       |\n",
      "|    total_timesteps      | 2410496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015316607 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 11760       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | 0.30177438  |\n",
      "|    std                  | 4.44        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1178        |\n",
      "|    time_elapsed         | 22318       |\n",
      "|    total_timesteps      | 2412544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013641886 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 11770       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | -5.6909823  |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 49.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1179        |\n",
      "|    time_elapsed         | 22337       |\n",
      "|    total_timesteps      | 2414592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014003582 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 11780       |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | 4.1519184   |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3924851.45\n",
      "total_reward: 2924851.45\n",
      "total_cost: 111164.46\n",
      "total_trades: 56290\n",
      "Sharpe: 0.716\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1180        |\n",
      "|    time_elapsed         | 22356       |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015933026 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.52406913  |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1181        |\n",
      "|    time_elapsed         | 22375       |\n",
      "|    total_timesteps      | 2418688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009389071 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 11800       |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | 0.3084403   |\n",
      "|    std                  | 4.47        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1182         |\n",
      "|    time_elapsed         | 22394        |\n",
      "|    total_timesteps      | 2420736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071689314 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.2        |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 11810        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | 1.7183965    |\n",
      "|    std                  | 4.47         |\n",
      "|    value_loss           | 57.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1183         |\n",
      "|    time_elapsed         | 22413        |\n",
      "|    total_timesteps      | 2422784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131171215 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.3        |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 11820        |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | -1.5926673   |\n",
      "|    std                  | 4.49         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1184        |\n",
      "|    time_elapsed         | 22432       |\n",
      "|    total_timesteps      | 2424832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010185402 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 11830       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | 0.48049608  |\n",
      "|    std                  | 4.5         |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1185         |\n",
      "|    time_elapsed         | 22450        |\n",
      "|    total_timesteps      | 2426880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058431625 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.3        |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 11840        |\n",
      "|    policy_gradient_loss | -0.00722     |\n",
      "|    reward               | 1.8709635    |\n",
      "|    std                  | 4.5          |\n",
      "|    value_loss           | 55.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1186       |\n",
      "|    time_elapsed         | 22469      |\n",
      "|    total_timesteps      | 2428928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00966874 |\n",
      "|    clip_fraction        | 0.0626     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.4      |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.2       |\n",
      "|    n_updates            | 11850      |\n",
      "|    policy_gradient_loss | -0.00472   |\n",
      "|    reward               | -0.5195165 |\n",
      "|    std                  | 4.5        |\n",
      "|    value_loss           | 53.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1187         |\n",
      "|    time_elapsed         | 22488        |\n",
      "|    total_timesteps      | 2430976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127992425 |\n",
      "|    clip_fraction        | 0.0737       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.4        |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 11860        |\n",
      "|    policy_gradient_loss | -0.00885     |\n",
      "|    reward               | -0.53673303  |\n",
      "|    std                  | 4.51         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 22506       |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010371668 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 11870       |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | -0.9195957  |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1189        |\n",
      "|    time_elapsed         | 22525       |\n",
      "|    total_timesteps      | 2435072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012373388 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 11880       |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    reward               | 0.18245049  |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 51.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 22544       |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011640044 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 11890       |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | 0.0326339   |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1191         |\n",
      "|    time_elapsed         | 22563        |\n",
      "|    total_timesteps      | 2439168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143858185 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.5        |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 11900        |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    reward               | -1.6454552   |\n",
      "|    std                  | 4.52         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1192        |\n",
      "|    time_elapsed         | 22581       |\n",
      "|    total_timesteps      | 2441216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004958967 |\n",
      "|    clip_fraction        | 0.0145      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 11910       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    reward               | -1.4639378  |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 68.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1193         |\n",
      "|    time_elapsed         | 22600        |\n",
      "|    total_timesteps      | 2443264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038816147 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.5        |\n",
      "|    explained_variance   | 0.254        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 11920        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 0.031650625  |\n",
      "|    std                  | 4.52         |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3857051.85\n",
      "total_reward: 2857051.85\n",
      "total_cost: 101026.39\n",
      "total_trades: 55429\n",
      "Sharpe: 0.698\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1194        |\n",
      "|    time_elapsed         | 22619       |\n",
      "|    total_timesteps      | 2445312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012583896 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 11930       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 1.56587     |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1195        |\n",
      "|    time_elapsed         | 22638       |\n",
      "|    total_timesteps      | 2447360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007350607 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 11940       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | -1.6026953  |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1196       |\n",
      "|    time_elapsed         | 22656      |\n",
      "|    total_timesteps      | 2449408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01185842 |\n",
      "|    clip_fraction        | 0.0949     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.7      |\n",
      "|    explained_variance   | 0.385      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.4       |\n",
      "|    n_updates            | 11950      |\n",
      "|    policy_gradient_loss | -0.00461   |\n",
      "|    reward               | 3.706485   |\n",
      "|    std                  | 4.56       |\n",
      "|    value_loss           | 54.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 22675       |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009584241 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    reward               | 0.45367807  |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1198        |\n",
      "|    time_elapsed         | 22694       |\n",
      "|    total_timesteps      | 2453504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014701815 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | -1.2801375  |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1199        |\n",
      "|    time_elapsed         | 22713       |\n",
      "|    total_timesteps      | 2455552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005868064 |\n",
      "|    clip_fraction        | 0.044       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 11980       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | -12.430011  |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 49.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1200        |\n",
      "|    time_elapsed         | 22732       |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011783358 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 11990       |\n",
      "|    policy_gradient_loss | -0.00889    |\n",
      "|    reward               | 0.91416883  |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1201        |\n",
      "|    time_elapsed         | 22751       |\n",
      "|    total_timesteps      | 2459648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016847188 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.79        |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.8924085   |\n",
      "|    std                  | 4.59        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1202        |\n",
      "|    time_elapsed         | 22769       |\n",
      "|    total_timesteps      | 2461696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009789868 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 12010       |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    reward               | 0.3115387   |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 22788       |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013038447 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | -0.00754    |\n",
      "|    reward               | 1.7863952   |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1204        |\n",
      "|    time_elapsed         | 22807       |\n",
      "|    total_timesteps      | 2465792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022316199 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 12030       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 0.34231618  |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1205         |\n",
      "|    time_elapsed         | 22825        |\n",
      "|    total_timesteps      | 2467840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074355425 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.1        |\n",
      "|    explained_variance   | 0.359        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.3         |\n",
      "|    n_updates            | 12040        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    reward               | 0.4755295    |\n",
      "|    std                  | 4.62         |\n",
      "|    value_loss           | 58.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1206        |\n",
      "|    time_elapsed         | 22844       |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007694155 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 1.3255615   |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 53.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1207        |\n",
      "|    time_elapsed         | 22863       |\n",
      "|    total_timesteps      | 2471936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014380868 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.81        |\n",
      "|    n_updates            | 12060       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 2.0276554   |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4120304.96\n",
      "total_reward: 3120304.96\n",
      "total_cost: 165186.09\n",
      "total_trades: 60207\n",
      "Sharpe: 0.756\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1208         |\n",
      "|    time_elapsed         | 22881        |\n",
      "|    total_timesteps      | 2473984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01304597   |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.2        |\n",
      "|    explained_variance   | 0.333        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 12070        |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    reward               | -0.021794667 |\n",
      "|    std                  | 4.64         |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1209        |\n",
      "|    time_elapsed         | 22900       |\n",
      "|    total_timesteps      | 2476032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009887059 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | -9.496135   |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1210        |\n",
      "|    time_elapsed         | 22918       |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017074566 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    reward               | -4.9180174  |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1211        |\n",
      "|    time_elapsed         | 22937       |\n",
      "|    total_timesteps      | 2480128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013449135 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | 1.2729896   |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1212       |\n",
      "|    time_elapsed         | 22956      |\n",
      "|    total_timesteps      | 2482176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01576285 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.3      |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.5       |\n",
      "|    n_updates            | 12110      |\n",
      "|    policy_gradient_loss | -0.00616   |\n",
      "|    reward               | -1.8569709 |\n",
      "|    std                  | 4.66       |\n",
      "|    value_loss           | 40.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1213        |\n",
      "|    time_elapsed         | 22974       |\n",
      "|    total_timesteps      | 2484224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011604746 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 12120       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.46733418 |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1214        |\n",
      "|    time_elapsed         | 22993       |\n",
      "|    total_timesteps      | 2486272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012763249 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.0748      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.29        |\n",
      "|    n_updates            | 12130       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 2.8717825   |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1215        |\n",
      "|    time_elapsed         | 23012       |\n",
      "|    total_timesteps      | 2488320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014929967 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 12140       |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | -0.5637461  |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1216        |\n",
      "|    time_elapsed         | 23032       |\n",
      "|    total_timesteps      | 2490368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011442263 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 12150       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | -3.5826879  |\n",
      "|    std                  | 4.71        |\n",
      "|    value_loss           | 72.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 1217      |\n",
      "|    time_elapsed         | 23053     |\n",
      "|    total_timesteps      | 2492416   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0193503 |\n",
      "|    clip_fraction        | 0.16      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -85.7     |\n",
      "|    explained_variance   | 0.405     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 18.6      |\n",
      "|    n_updates            | 12160     |\n",
      "|    policy_gradient_loss | -0.00562  |\n",
      "|    reward               | 2.3416944 |\n",
      "|    std                  | 4.72      |\n",
      "|    value_loss           | 41.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 23074       |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022588756 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 3.2615812   |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1219       |\n",
      "|    time_elapsed         | 23094      |\n",
      "|    total_timesteps      | 2496512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00937145 |\n",
      "|    clip_fraction        | 0.0833     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.8      |\n",
      "|    explained_variance   | 0.415      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26         |\n",
      "|    n_updates            | 12180      |\n",
      "|    policy_gradient_loss | -0.00571   |\n",
      "|    reward               | 0.32160592 |\n",
      "|    std                  | 4.72       |\n",
      "|    value_loss           | 55         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1220        |\n",
      "|    time_elapsed         | 23113       |\n",
      "|    total_timesteps      | 2498560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014764113 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 12190       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.11774215  |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1221        |\n",
      "|    time_elapsed         | 23131       |\n",
      "|    total_timesteps      | 2500608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010111347 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | 0.4168007   |\n",
      "|    std                  | 4.74        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3608790.53\n",
      "total_reward: 2608790.53\n",
      "total_cost: 114664.23\n",
      "total_trades: 56768\n",
      "Sharpe: 0.664\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1222         |\n",
      "|    time_elapsed         | 23150        |\n",
      "|    total_timesteps      | 2502656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010513698  |\n",
      "|    clip_fraction        | 0.0948       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.9        |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 12210        |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    reward               | -0.064708814 |\n",
      "|    std                  | 4.75         |\n",
      "|    value_loss           | 56.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1223        |\n",
      "|    time_elapsed         | 23169       |\n",
      "|    total_timesteps      | 2504704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007861376 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.0111      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 12220       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | -2.3293624  |\n",
      "|    std                  | 4.76        |\n",
      "|    value_loss           | 49.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1224        |\n",
      "|    time_elapsed         | 23188       |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014303729 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 12230       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -0.8666241  |\n",
      "|    std                  | 4.76        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1225        |\n",
      "|    time_elapsed         | 23207       |\n",
      "|    total_timesteps      | 2508800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011876743 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.58        |\n",
      "|    n_updates            | 12240       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | 0.65567267  |\n",
      "|    std                  | 4.77        |\n",
      "|    value_loss           | 44.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1226        |\n",
      "|    time_elapsed         | 23225       |\n",
      "|    total_timesteps      | 2510848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010277618 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 12250       |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | -0.98005384 |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1227        |\n",
      "|    time_elapsed         | 23245       |\n",
      "|    total_timesteps      | 2512896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013216946 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 12260       |\n",
      "|    policy_gradient_loss | -0.000988   |\n",
      "|    reward               | 1.7666206   |\n",
      "|    std                  | 4.79        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1228        |\n",
      "|    time_elapsed         | 23266       |\n",
      "|    total_timesteps      | 2514944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010930603 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.31        |\n",
      "|    n_updates            | 12270       |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    reward               | 2.4488165   |\n",
      "|    std                  | 4.8         |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1229        |\n",
      "|    time_elapsed         | 23287       |\n",
      "|    total_timesteps      | 2516992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012196595 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 12280       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | 0.17400093  |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1230        |\n",
      "|    time_elapsed         | 23307       |\n",
      "|    total_timesteps      | 2519040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009475043 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 12290       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 0.077688165 |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1231        |\n",
      "|    time_elapsed         | 23326       |\n",
      "|    total_timesteps      | 2521088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014855222 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.69        |\n",
      "|    n_updates            | 12300       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 2.786691    |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1232        |\n",
      "|    time_elapsed         | 23347       |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010222969 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 12310       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | 0.6222662   |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1233        |\n",
      "|    time_elapsed         | 23367       |\n",
      "|    total_timesteps      | 2525184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012619582 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 12320       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -2.549699   |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1234        |\n",
      "|    time_elapsed         | 23387       |\n",
      "|    total_timesteps      | 2527232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013170788 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 12330       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -0.20948522 |\n",
      "|    std                  | 4.84        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1235        |\n",
      "|    time_elapsed         | 23408       |\n",
      "|    total_timesteps      | 2529280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021446967 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.82        |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.34814578 |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1236        |\n",
      "|    time_elapsed         | 23427       |\n",
      "|    total_timesteps      | 2531328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009903716 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 12350       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | 3.7846441   |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 61.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4628129.72\n",
      "total_reward: 3628129.72\n",
      "total_cost: 314348.12\n",
      "total_trades: 67619\n",
      "Sharpe: 0.811\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1237       |\n",
      "|    time_elapsed         | 23447      |\n",
      "|    total_timesteps      | 2533376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01574255 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.6      |\n",
      "|    explained_variance   | -0.0349    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.5       |\n",
      "|    n_updates            | 12360      |\n",
      "|    policy_gradient_loss | -2.09e-05  |\n",
      "|    reward               | 0.41354477 |\n",
      "|    std                  | 4.86       |\n",
      "|    value_loss           | 52.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1238         |\n",
      "|    time_elapsed         | 23466        |\n",
      "|    total_timesteps      | 2535424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116691245 |\n",
      "|    clip_fraction        | 0.0964       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.6        |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.91         |\n",
      "|    n_updates            | 12370        |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    reward               | -0.5576004   |\n",
      "|    std                  | 4.87         |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1239        |\n",
      "|    time_elapsed         | 23487       |\n",
      "|    total_timesteps      | 2537472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015484909 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 12380       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -0.27759185 |\n",
      "|    std                  | 4.88        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1240        |\n",
      "|    time_elapsed         | 23507       |\n",
      "|    total_timesteps      | 2539520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010677535 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 12390       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -6.1258826  |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1241         |\n",
      "|    time_elapsed         | 23527        |\n",
      "|    total_timesteps      | 2541568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074676475 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.8        |\n",
      "|    explained_variance   | 0.172        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 12400        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    reward               | 4.512176     |\n",
      "|    std                  | 4.89         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1242         |\n",
      "|    time_elapsed         | 23548        |\n",
      "|    total_timesteps      | 2543616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120613035 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.8        |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 12410        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    reward               | 3.2513905    |\n",
      "|    std                  | 4.9          |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1243         |\n",
      "|    time_elapsed         | 23568        |\n",
      "|    total_timesteps      | 2545664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076562646 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.8        |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.37         |\n",
      "|    n_updates            | 12420        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | -1.8435962   |\n",
      "|    std                  | 4.9          |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1244         |\n",
      "|    time_elapsed         | 23588        |\n",
      "|    total_timesteps      | 2547712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119894035 |\n",
      "|    clip_fraction        | 0.0627       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.8        |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.87         |\n",
      "|    n_updates            | 12430        |\n",
      "|    policy_gradient_loss | -0.0077      |\n",
      "|    reward               | -2.5334933   |\n",
      "|    std                  | 4.9          |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1245        |\n",
      "|    time_elapsed         | 23608       |\n",
      "|    total_timesteps      | 2549760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02042209  |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 12440       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | -0.15686336 |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1246        |\n",
      "|    time_elapsed         | 23627       |\n",
      "|    total_timesteps      | 2551808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009987725 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 12450       |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    reward               | -1.3237091  |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 67          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1247        |\n",
      "|    time_elapsed         | 23646       |\n",
      "|    total_timesteps      | 2553856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005197946 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 12460       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | -0.12402828 |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1248       |\n",
      "|    time_elapsed         | 23665      |\n",
      "|    total_timesteps      | 2555904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01574549 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.9      |\n",
      "|    explained_variance   | 0.409      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.8        |\n",
      "|    n_updates            | 12470      |\n",
      "|    policy_gradient_loss | -0.00902   |\n",
      "|    reward               | -0.3256619 |\n",
      "|    std                  | 4.91       |\n",
      "|    value_loss           | 19         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1249        |\n",
      "|    time_elapsed         | 23685       |\n",
      "|    total_timesteps      | 2557952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009937774 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 12480       |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 0.08372763  |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1250        |\n",
      "|    time_elapsed         | 23705       |\n",
      "|    total_timesteps      | 2560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009269465 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 12490       |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    reward               | 1.4413235   |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4162714.75\n",
      "total_reward: 3162714.75\n",
      "total_cost: 115227.70\n",
      "total_trades: 56888\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1251        |\n",
      "|    time_elapsed         | 23725       |\n",
      "|    total_timesteps      | 2562048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014643831 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 12500       |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | 2.500537    |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1252        |\n",
      "|    time_elapsed         | 23744       |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014409111 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.51        |\n",
      "|    n_updates            | 12510       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 1.8228034   |\n",
      "|    std                  | 4.93        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1253        |\n",
      "|    time_elapsed         | 23763       |\n",
      "|    total_timesteps      | 2566144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012077784 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 12520       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | -0.3900668  |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1254        |\n",
      "|    time_elapsed         | 23783       |\n",
      "|    total_timesteps      | 2568192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008183625 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 12530       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | 0.88692605  |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1255        |\n",
      "|    time_elapsed         | 23803       |\n",
      "|    total_timesteps      | 2570240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015276397 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.3         |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | 0.8391363   |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1256        |\n",
      "|    time_elapsed         | 23824       |\n",
      "|    total_timesteps      | 2572288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011695912 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 12550       |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    reward               | 2.7054253   |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1257        |\n",
      "|    time_elapsed         | 23844       |\n",
      "|    total_timesteps      | 2574336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009277219 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 12560       |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | 7.293827    |\n",
      "|    std                  | 4.96        |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1258        |\n",
      "|    time_elapsed         | 23863       |\n",
      "|    total_timesteps      | 2576384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017348524 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.77        |\n",
      "|    n_updates            | 12570       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.9128256   |\n",
      "|    std                  | 4.96        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 23883       |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00976621  |\n",
      "|    clip_fraction        | 0.0601      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    reward               | -0.12737086 |\n",
      "|    std                  | 4.97        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1260        |\n",
      "|    time_elapsed         | 23903       |\n",
      "|    total_timesteps      | 2580480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010736406 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 12590       |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | 32.868427   |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 23923       |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013100729 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.98824257 |\n",
      "|    std                  | 4.99        |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 23943       |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017577332 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.0923      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 12610       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | 1.7656584   |\n",
      "|    std                  | 4.99        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1263        |\n",
      "|    time_elapsed         | 23963       |\n",
      "|    total_timesteps      | 2586624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014501557 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51          |\n",
      "|    n_updates            | 12620       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 0.48934954  |\n",
      "|    std                  | 5           |\n",
      "|    value_loss           | 64.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1264        |\n",
      "|    time_elapsed         | 23981       |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010809917 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 12630       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | -3.7607582  |\n",
      "|    std                  | 5           |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4155324.16\n",
      "total_reward: 3155324.16\n",
      "total_cost: 140477.19\n",
      "total_trades: 59885\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1265        |\n",
      "|    time_elapsed         | 24000       |\n",
      "|    total_timesteps      | 2590720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014575226 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 12640       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 1.4067907   |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1266       |\n",
      "|    time_elapsed         | 24019      |\n",
      "|    total_timesteps      | 2592768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01614171 |\n",
      "|    clip_fraction        | 0.0968     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.5      |\n",
      "|    explained_variance   | 0.124      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.7       |\n",
      "|    n_updates            | 12650      |\n",
      "|    policy_gradient_loss | -0.00912   |\n",
      "|    reward               | 2.4280455  |\n",
      "|    std                  | 5.01       |\n",
      "|    value_loss           | 40         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1267        |\n",
      "|    time_elapsed         | 24038       |\n",
      "|    total_timesteps      | 2594816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012923625 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | -0.0186     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 12660       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 5.5683036   |\n",
      "|    std                  | 5.03        |\n",
      "|    value_loss           | 54.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1268       |\n",
      "|    time_elapsed         | 24057      |\n",
      "|    total_timesteps      | 2596864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01626459 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.6      |\n",
      "|    explained_variance   | 0.308      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.4       |\n",
      "|    n_updates            | 12670      |\n",
      "|    policy_gradient_loss | -0.00596   |\n",
      "|    reward               | -5.879883  |\n",
      "|    std                  | 5.04       |\n",
      "|    value_loss           | 50.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1269        |\n",
      "|    time_elapsed         | 24076       |\n",
      "|    total_timesteps      | 2598912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015188944 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 12680       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -2.0336208  |\n",
      "|    std                  | 5.03        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1270         |\n",
      "|    time_elapsed         | 24094        |\n",
      "|    total_timesteps      | 2600960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104797855 |\n",
      "|    clip_fraction        | 0.0784       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.6        |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 12690        |\n",
      "|    policy_gradient_loss | -0.00746     |\n",
      "|    reward               | 2.4684799    |\n",
      "|    std                  | 5.03         |\n",
      "|    value_loss           | 44.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1271         |\n",
      "|    time_elapsed         | 24113        |\n",
      "|    total_timesteps      | 2603008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119108725 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.7        |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 12700        |\n",
      "|    policy_gradient_loss | -0.00818     |\n",
      "|    reward               | -2.661708    |\n",
      "|    std                  | 5.04         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1272        |\n",
      "|    time_elapsed         | 24132       |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018410608 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.35        |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    reward               | 0.5793026   |\n",
      "|    std                  | 5.05        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1273        |\n",
      "|    time_elapsed         | 24150       |\n",
      "|    total_timesteps      | 2607104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013745109 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 12720       |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | 1.2110031   |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 59.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1274        |\n",
      "|    time_elapsed         | 24169       |\n",
      "|    total_timesteps      | 2609152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010231819 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 12730       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | -0.2371638  |\n",
      "|    std                  | 5.07        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1275       |\n",
      "|    time_elapsed         | 24188      |\n",
      "|    total_timesteps      | 2611200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01647819 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.9      |\n",
      "|    explained_variance   | 0.227      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.2       |\n",
      "|    n_updates            | 12740      |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    reward               | 2.0903463  |\n",
      "|    std                  | 5.09       |\n",
      "|    value_loss           | 33.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1276        |\n",
      "|    time_elapsed         | 24208       |\n",
      "|    total_timesteps      | 2613248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020053579 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 12750       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 1.5218275   |\n",
      "|    std                  | 5.1         |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1277        |\n",
      "|    time_elapsed         | 24227       |\n",
      "|    total_timesteps      | 2615296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019173626 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.89        |\n",
      "|    n_updates            | 12760       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.6286398   |\n",
      "|    std                  | 5.1         |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1278        |\n",
      "|    time_elapsed         | 24245       |\n",
      "|    total_timesteps      | 2617344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005441456 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 12770       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | 1.5856707   |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3086899.01\n",
      "total_reward: 2086899.01\n",
      "total_cost: 109889.22\n",
      "total_trades: 57582\n",
      "Sharpe: 0.582\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1279        |\n",
      "|    time_elapsed         | 24264       |\n",
      "|    total_timesteps      | 2619392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017264992 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.91        |\n",
      "|    n_updates            | 12780       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 0.8380842   |\n",
      "|    std                  | 5.13        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1280         |\n",
      "|    time_elapsed         | 24283        |\n",
      "|    total_timesteps      | 2621440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016161919  |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.2        |\n",
      "|    explained_variance   | 0.325        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 12790        |\n",
      "|    policy_gradient_loss | -0.00875     |\n",
      "|    reward               | -0.118243344 |\n",
      "|    std                  | 5.13         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1281         |\n",
      "|    time_elapsed         | 24302        |\n",
      "|    total_timesteps      | 2623488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077581555 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.2        |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 12800        |\n",
      "|    policy_gradient_loss | -0.00901     |\n",
      "|    reward               | 4.1959486    |\n",
      "|    std                  | 5.14         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1282        |\n",
      "|    time_elapsed         | 24321       |\n",
      "|    total_timesteps      | 2625536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012836341 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 12810       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.99753684  |\n",
      "|    std                  | 5.14        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1283         |\n",
      "|    time_elapsed         | 24340        |\n",
      "|    total_timesteps      | 2627584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127143655 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.3        |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 12820        |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    reward               | -2.8794377   |\n",
      "|    std                  | 5.16         |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1284        |\n",
      "|    time_elapsed         | 24360       |\n",
      "|    total_timesteps      | 2629632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011627705 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 12830       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -5.772777   |\n",
      "|    std                  | 5.17        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1285        |\n",
      "|    time_elapsed         | 24379       |\n",
      "|    total_timesteps      | 2631680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017065141 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 12840       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.629177    |\n",
      "|    std                  | 5.18        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1286        |\n",
      "|    time_elapsed         | 24397       |\n",
      "|    total_timesteps      | 2633728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014171381 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.17        |\n",
      "|    n_updates            | 12850       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 1.1689255   |\n",
      "|    std                  | 5.19        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1287        |\n",
      "|    time_elapsed         | 24416       |\n",
      "|    total_timesteps      | 2635776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011290101 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 12860       |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | 1.3876967   |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1288        |\n",
      "|    time_elapsed         | 24435       |\n",
      "|    total_timesteps      | 2637824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011664527 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 12870       |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    reward               | 2.0449882   |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 24454       |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023248892 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.00871     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 12880       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | -4.072442   |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1290        |\n",
      "|    time_elapsed         | 24473       |\n",
      "|    total_timesteps      | 2641920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011176498 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 12890       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.6419699  |\n",
      "|    std                  | 5.23        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1291         |\n",
      "|    time_elapsed         | 24492        |\n",
      "|    total_timesteps      | 2643968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048970967 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.7        |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 12900        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | 1.3093828    |\n",
      "|    std                  | 5.23         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1292        |\n",
      "|    time_elapsed         | 24511       |\n",
      "|    total_timesteps      | 2646016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017638259 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.0879      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 12910       |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | -1.3147881  |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3520603.36\n",
      "total_reward: 2520603.36\n",
      "total_cost: 94335.83\n",
      "total_trades: 56977\n",
      "Sharpe: 0.653\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 24530       |\n",
      "|    total_timesteps      | 2648064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011442498 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 12920       |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    reward               | -3.2478652  |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1294        |\n",
      "|    time_elapsed         | 24565       |\n",
      "|    total_timesteps      | 2650112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009229249 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 12930       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | 0.20611656  |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1295       |\n",
      "|    time_elapsed         | 24584      |\n",
      "|    total_timesteps      | 2652160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01652707 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.9      |\n",
      "|    explained_variance   | 0.0659     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.7       |\n",
      "|    n_updates            | 12940      |\n",
      "|    policy_gradient_loss | -0.00905   |\n",
      "|    reward               | -1.0014325 |\n",
      "|    std                  | 5.27       |\n",
      "|    value_loss           | 69.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 24603       |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018349268 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.98        |\n",
      "|    n_updates            | 12950       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.27541625  |\n",
      "|    std                  | 5.28        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1297        |\n",
      "|    time_elapsed         | 24622       |\n",
      "|    total_timesteps      | 2656256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010777781 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 12960       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 2.611118    |\n",
      "|    std                  | 5.29        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1298        |\n",
      "|    time_elapsed         | 24640       |\n",
      "|    total_timesteps      | 2658304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016245592 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | -0.0393     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 12970       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 3.2318702   |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1299       |\n",
      "|    time_elapsed         | 24659      |\n",
      "|    total_timesteps      | 2660352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00896665 |\n",
      "|    clip_fraction        | 0.0965     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.1      |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.2       |\n",
      "|    n_updates            | 12980      |\n",
      "|    policy_gradient_loss | -0.00703   |\n",
      "|    reward               | -0.8380223 |\n",
      "|    std                  | 5.3        |\n",
      "|    value_loss           | 32.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1300        |\n",
      "|    time_elapsed         | 24678       |\n",
      "|    total_timesteps      | 2662400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013079026 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 12990       |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | -0.6700741  |\n",
      "|    std                  | 5.31        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 24696       |\n",
      "|    total_timesteps      | 2664448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009198954 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 13000       |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | -7.2448177  |\n",
      "|    std                  | 5.31        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1302        |\n",
      "|    time_elapsed         | 24715       |\n",
      "|    total_timesteps      | 2666496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014468726 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | -0.0667     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 13010       |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | 2.0013113   |\n",
      "|    std                  | 5.32        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1303        |\n",
      "|    time_elapsed         | 24734       |\n",
      "|    total_timesteps      | 2668544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013515563 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.98        |\n",
      "|    n_updates            | 13020       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -2.2687442  |\n",
      "|    std                  | 5.33        |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1304        |\n",
      "|    time_elapsed         | 24753       |\n",
      "|    total_timesteps      | 2670592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010976699 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.7         |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | -1.1211311  |\n",
      "|    std                  | 5.32        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1305         |\n",
      "|    time_elapsed         | 24772        |\n",
      "|    total_timesteps      | 2672640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102863815 |\n",
      "|    clip_fraction        | 0.0916       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.2        |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 13040        |\n",
      "|    policy_gradient_loss | -0.00961     |\n",
      "|    reward               | -0.3379177   |\n",
      "|    std                  | 5.33         |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1306         |\n",
      "|    time_elapsed         | 24792        |\n",
      "|    total_timesteps      | 2674688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122950375 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.3        |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 13050        |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    reward               | -1.4644877   |\n",
      "|    std                  | 5.34         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2349091.81\n",
      "total_reward: 1349091.81\n",
      "total_cost: 274108.13\n",
      "total_trades: 63990\n",
      "Sharpe: 0.504\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1307        |\n",
      "|    time_elapsed         | 24811       |\n",
      "|    total_timesteps      | 2676736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009334303 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 13060       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 5.3929      |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1308         |\n",
      "|    time_elapsed         | 24830        |\n",
      "|    total_timesteps      | 2678784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106397495 |\n",
      "|    clip_fraction        | 0.0904       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.3        |\n",
      "|    explained_variance   | 0.0565       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 13070        |\n",
      "|    policy_gradient_loss | -0.00834     |\n",
      "|    reward               | -0.40893108  |\n",
      "|    std                  | 5.34         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1309        |\n",
      "|    time_elapsed         | 24849       |\n",
      "|    total_timesteps      | 2680832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008964257 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | 2.58228     |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 24869       |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011261325 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 13090       |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    reward               | 0.67183816  |\n",
      "|    std                  | 5.35        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1311         |\n",
      "|    time_elapsed         | 24888        |\n",
      "|    total_timesteps      | 2684928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033306638 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.4        |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 13100        |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    reward               | -1.0840471   |\n",
      "|    std                  | 5.35         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1312        |\n",
      "|    time_elapsed         | 24907       |\n",
      "|    total_timesteps      | 2686976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011749669 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 13110       |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    reward               | 1.1782279   |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1313        |\n",
      "|    time_elapsed         | 24925       |\n",
      "|    total_timesteps      | 2689024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009825194 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.91        |\n",
      "|    n_updates            | 13120       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 1.100066    |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1314         |\n",
      "|    time_elapsed         | 24945        |\n",
      "|    total_timesteps      | 2691072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039678793 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.5        |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.2         |\n",
      "|    n_updates            | 13130        |\n",
      "|    policy_gradient_loss | -0.00815     |\n",
      "|    reward               | 0.94274217   |\n",
      "|    std                  | 5.36         |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1315        |\n",
      "|    time_elapsed         | 24964       |\n",
      "|    total_timesteps      | 2693120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010908376 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 13140       |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    reward               | 0.22385205  |\n",
      "|    std                  | 5.37        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1316        |\n",
      "|    time_elapsed         | 24982       |\n",
      "|    total_timesteps      | 2695168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011620898 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    reward               | 1.1756499   |\n",
      "|    std                  | 5.39        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1317        |\n",
      "|    time_elapsed         | 25001       |\n",
      "|    total_timesteps      | 2697216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015198771 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.4         |\n",
      "|    n_updates            | 13160       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.36404863 |\n",
      "|    std                  | 5.4         |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1318        |\n",
      "|    time_elapsed         | 25021       |\n",
      "|    total_timesteps      | 2699264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010945178 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 13170       |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -1.2238052  |\n",
      "|    std                  | 5.42        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1319       |\n",
      "|    time_elapsed         | 25040      |\n",
      "|    total_timesteps      | 2701312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01205955 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.8      |\n",
      "|    explained_variance   | -0.017     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.3       |\n",
      "|    n_updates            | 13180      |\n",
      "|    policy_gradient_loss | 0.00143    |\n",
      "|    reward               | -6.7259836 |\n",
      "|    std                  | 5.42       |\n",
      "|    value_loss           | 33.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1320        |\n",
      "|    time_elapsed         | 25059       |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017745366 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.9         |\n",
      "|    n_updates            | 13190       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    reward               | -1.5566064  |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4530092.94\n",
      "total_reward: 3530092.94\n",
      "total_cost: 261845.61\n",
      "total_trades: 64829\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1321         |\n",
      "|    time_elapsed         | 25078        |\n",
      "|    total_timesteps      | 2705408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071112476 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.9        |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.6         |\n",
      "|    n_updates            | 13200        |\n",
      "|    policy_gradient_loss | -0.00934     |\n",
      "|    reward               | 1.9770128    |\n",
      "|    std                  | 5.44         |\n",
      "|    value_loss           | 49.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1322        |\n",
      "|    time_elapsed         | 25097       |\n",
      "|    total_timesteps      | 2707456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014351011 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.0386      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 13210       |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | 0.13361448  |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1323        |\n",
      "|    time_elapsed         | 25116       |\n",
      "|    total_timesteps      | 2709504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010526001 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 13220       |\n",
      "|    policy_gradient_loss | 0.000207    |\n",
      "|    reward               | -1.6814312  |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1324         |\n",
      "|    time_elapsed         | 25135        |\n",
      "|    total_timesteps      | 2711552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066528125 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.9        |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 13230        |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    reward               | -0.97405136  |\n",
      "|    std                  | 5.44         |\n",
      "|    value_loss           | 35.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1325         |\n",
      "|    time_elapsed         | 25154        |\n",
      "|    total_timesteps      | 2713600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062380168 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.9        |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 13240        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | -6.818632    |\n",
      "|    std                  | 5.44         |\n",
      "|    value_loss           | 50.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1326         |\n",
      "|    time_elapsed         | 25173        |\n",
      "|    total_timesteps      | 2715648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102985315 |\n",
      "|    clip_fraction        | 0.0638       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.9        |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 13250        |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    reward               | 0.14681122   |\n",
      "|    std                  | 5.45         |\n",
      "|    value_loss           | 53.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 25191       |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011556686 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.78        |\n",
      "|    n_updates            | 13260       |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    reward               | 0.18122143  |\n",
      "|    std                  | 5.46        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1328        |\n",
      "|    time_elapsed         | 25210       |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015039837 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | 0.0157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 13270       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.317547    |\n",
      "|    std                  | 5.47        |\n",
      "|    value_loss           | 83.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1329        |\n",
      "|    time_elapsed         | 25230       |\n",
      "|    total_timesteps      | 2721792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007969813 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.0269      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 13280       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 7.2545533   |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 25248       |\n",
      "|    total_timesteps      | 2723840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010467587 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 13290       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | 3.122048    |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1331        |\n",
      "|    time_elapsed         | 25267       |\n",
      "|    total_timesteps      | 2725888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005181635 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 13300       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | -0.07649195 |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1332        |\n",
      "|    time_elapsed         | 25286       |\n",
      "|    total_timesteps      | 2727936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010621209 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.0583      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.2        |\n",
      "|    n_updates            | 13310       |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -2.936753   |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1333        |\n",
      "|    time_elapsed         | 25304       |\n",
      "|    total_timesteps      | 2729984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007140532 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 13320       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | 3.8488402   |\n",
      "|    std                  | 5.5         |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1334        |\n",
      "|    time_elapsed         | 25323       |\n",
      "|    total_timesteps      | 2732032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011363838 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 13330       |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | 1.8744104   |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4359952.30\n",
      "total_reward: 3359952.30\n",
      "total_cost: 116851.40\n",
      "total_trades: 57794\n",
      "Sharpe: 0.742\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1335        |\n",
      "|    time_elapsed         | 25342       |\n",
      "|    total_timesteps      | 2734080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01001949  |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 13340       |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | 0.085399754 |\n",
      "|    std                  | 5.52        |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1336        |\n",
      "|    time_elapsed         | 25361       |\n",
      "|    total_timesteps      | 2736128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013576967 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 13350       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | 2.2747474   |\n",
      "|    std                  | 5.53        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 25382       |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009956026 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.46        |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | -2.8051908  |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1338        |\n",
      "|    time_elapsed         | 25403       |\n",
      "|    total_timesteps      | 2740224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011269294 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 13370       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -1.6231344  |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1339        |\n",
      "|    time_elapsed         | 25421       |\n",
      "|    total_timesteps      | 2742272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008933499 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53          |\n",
      "|    n_updates            | 13380       |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | 1.5333003   |\n",
      "|    std                  | 5.55        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1340         |\n",
      "|    time_elapsed         | 25441        |\n",
      "|    total_timesteps      | 2744320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120802615 |\n",
      "|    clip_fraction        | 0.0916       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.4        |\n",
      "|    explained_variance   | 0.154        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 13390        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    reward               | 1.8194634    |\n",
      "|    std                  | 5.55         |\n",
      "|    value_loss           | 54           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1341        |\n",
      "|    time_elapsed         | 25461       |\n",
      "|    total_timesteps      | 2746368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013144357 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 13400       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 0.31789985  |\n",
      "|    std                  | 5.57        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1342         |\n",
      "|    time_elapsed         | 25481        |\n",
      "|    total_timesteps      | 2748416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011496231  |\n",
      "|    clip_fraction        | 0.0864       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.5        |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.7         |\n",
      "|    n_updates            | 13410        |\n",
      "|    policy_gradient_loss | -0.00787     |\n",
      "|    reward               | -0.002122617 |\n",
      "|    std                  | 5.57         |\n",
      "|    value_loss           | 52.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1343        |\n",
      "|    time_elapsed         | 25502       |\n",
      "|    total_timesteps      | 2750464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008640727 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.0735      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 13420       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | 0.33921334  |\n",
      "|    std                  | 5.58        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 25522       |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007584444 |\n",
      "|    clip_fraction        | 0.0628      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | -0.30972207 |\n",
      "|    std                  | 5.58        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1345         |\n",
      "|    time_elapsed         | 25542        |\n",
      "|    total_timesteps      | 2754560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040694894 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.6        |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.4         |\n",
      "|    n_updates            | 13440        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    reward               | -0.1413079   |\n",
      "|    std                  | 5.58         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1346        |\n",
      "|    time_elapsed         | 25563       |\n",
      "|    total_timesteps      | 2756608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010400312 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 13450       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -1.1142957  |\n",
      "|    std                  | 5.6         |\n",
      "|    value_loss           | 50.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1347        |\n",
      "|    time_elapsed         | 25582       |\n",
      "|    total_timesteps      | 2758656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011698282 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 13460       |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    reward               | 0.28099966  |\n",
      "|    std                  | 5.61        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1348        |\n",
      "|    time_elapsed         | 25601       |\n",
      "|    total_timesteps      | 2760704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009184192 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 13470       |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    reward               | 1.1245233   |\n",
      "|    std                  | 5.61        |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1349         |\n",
      "|    time_elapsed         | 25620        |\n",
      "|    total_timesteps      | 2762752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081967795 |\n",
      "|    clip_fraction        | 0.0497       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.8        |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.7         |\n",
      "|    n_updates            | 13480        |\n",
      "|    policy_gradient_loss | -0.00918     |\n",
      "|    reward               | 1.253988     |\n",
      "|    std                  | 5.62         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2900711.68\n",
      "total_reward: 1900711.68\n",
      "total_cost: 73748.17\n",
      "total_trades: 54909\n",
      "Sharpe: 0.571\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1350         |\n",
      "|    time_elapsed         | 25639        |\n",
      "|    total_timesteps      | 2764800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045418288 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.8        |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 13490        |\n",
      "|    policy_gradient_loss | -0.000116    |\n",
      "|    reward               | -1.3477137   |\n",
      "|    std                  | 5.62         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1351        |\n",
      "|    time_elapsed         | 25658       |\n",
      "|    total_timesteps      | 2766848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016002249 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.1         |\n",
      "|    n_updates            | 13500       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -1.4897491  |\n",
      "|    std                  | 5.63        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1352         |\n",
      "|    time_elapsed         | 25677        |\n",
      "|    total_timesteps      | 2768896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065217726 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.9        |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.9         |\n",
      "|    n_updates            | 13510        |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    reward               | -0.20213696  |\n",
      "|    std                  | 5.63         |\n",
      "|    value_loss           | 73.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1353        |\n",
      "|    time_elapsed         | 25695       |\n",
      "|    total_timesteps      | 2770944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006108497 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 13520       |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | 1.9426945   |\n",
      "|    std                  | 5.63        |\n",
      "|    value_loss           | 61.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1354        |\n",
      "|    time_elapsed         | 25714       |\n",
      "|    total_timesteps      | 2772992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006561947 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 13530       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | 0.9491857   |\n",
      "|    std                  | 5.64        |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1355        |\n",
      "|    time_elapsed         | 25733       |\n",
      "|    total_timesteps      | 2775040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011988356 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 13540       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -0.01195532 |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 25752       |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013091722 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 13550       |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | -0.66356695 |\n",
      "|    std                  | 5.66        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1357        |\n",
      "|    time_elapsed         | 25771       |\n",
      "|    total_timesteps      | 2779136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008802681 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 13560       |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | -5.400339   |\n",
      "|    std                  | 5.66        |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1358        |\n",
      "|    time_elapsed         | 25790       |\n",
      "|    total_timesteps      | 2781184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011161095 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.0292      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | 2.651175    |\n",
      "|    std                  | 5.67        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1359        |\n",
      "|    time_elapsed         | 25809       |\n",
      "|    total_timesteps      | 2783232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012894206 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 13580       |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | -0.4894223  |\n",
      "|    std                  | 5.67        |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1360        |\n",
      "|    time_elapsed         | 25828       |\n",
      "|    total_timesteps      | 2785280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012493296 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 13590       |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | 0.7639676   |\n",
      "|    std                  | 5.67        |\n",
      "|    value_loss           | 66.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1361         |\n",
      "|    time_elapsed         | 25847        |\n",
      "|    total_timesteps      | 2787328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125795305 |\n",
      "|    clip_fraction        | 0.0796       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.1        |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 13600        |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    reward               | -1.9529554   |\n",
      "|    std                  | 5.69         |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1362        |\n",
      "|    time_elapsed         | 25866       |\n",
      "|    total_timesteps      | 2789376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010234716 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 2.0012126   |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 50.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1363        |\n",
      "|    time_elapsed         | 25885       |\n",
      "|    total_timesteps      | 2791424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010836199 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 13620       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -0.35013926 |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 65.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3778922.71\n",
      "total_reward: 2778922.71\n",
      "total_cost: 69016.77\n",
      "total_trades: 55131\n",
      "Sharpe: 0.673\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1364        |\n",
      "|    time_elapsed         | 25905       |\n",
      "|    total_timesteps      | 2793472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007837199 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 13630       |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | -3.2221863  |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1365        |\n",
      "|    time_elapsed         | 25924       |\n",
      "|    total_timesteps      | 2795520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013826166 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 13640       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 3.2424374   |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 25942       |\n",
      "|    total_timesteps      | 2797568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011372641 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 13650       |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | 0.052881032 |\n",
      "|    std                  | 5.72        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1367        |\n",
      "|    time_elapsed         | 25961       |\n",
      "|    total_timesteps      | 2799616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011062607 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 13660       |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    reward               | 1.0743909   |\n",
      "|    std                  | 5.72        |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1368        |\n",
      "|    time_elapsed         | 25980       |\n",
      "|    total_timesteps      | 2801664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012567276 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 13670       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | -1.0533886  |\n",
      "|    std                  | 5.73        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1369        |\n",
      "|    time_elapsed         | 25999       |\n",
      "|    total_timesteps      | 2803712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011703264 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 13680       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | -0.2027343  |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1370         |\n",
      "|    time_elapsed         | 26018        |\n",
      "|    total_timesteps      | 2805760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104987025 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.5        |\n",
      "|    explained_variance   | 0.259        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 13690        |\n",
      "|    policy_gradient_loss | -0.00826     |\n",
      "|    reward               | 0.77281415   |\n",
      "|    std                  | 5.76         |\n",
      "|    value_loss           | 64.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1371        |\n",
      "|    time_elapsed         | 26036       |\n",
      "|    total_timesteps      | 2807808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010740785 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 13700       |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | -1.1578165  |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1372        |\n",
      "|    time_elapsed         | 26056       |\n",
      "|    total_timesteps      | 2809856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013715066 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 13710       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -0.9276305  |\n",
      "|    std                  | 5.77        |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1373        |\n",
      "|    time_elapsed         | 26074       |\n",
      "|    total_timesteps      | 2811904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009421186 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 13720       |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | 0.023273036 |\n",
      "|    std                  | 5.78        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1374        |\n",
      "|    time_elapsed         | 26093       |\n",
      "|    total_timesteps      | 2813952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013685156 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 13730       |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    reward               | -2.04891    |\n",
      "|    std                  | 5.78        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1375          |\n",
      "|    time_elapsed         | 26112         |\n",
      "|    total_timesteps      | 2816000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012509864   |\n",
      "|    clip_fraction        | 0.109         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -91.7         |\n",
      "|    explained_variance   | 0.283         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.6          |\n",
      "|    n_updates            | 13740         |\n",
      "|    policy_gradient_loss | -0.0106       |\n",
      "|    reward               | -0.0033019613 |\n",
      "|    std                  | 5.8           |\n",
      "|    value_loss           | 28.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1376        |\n",
      "|    time_elapsed         | 26131       |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009073431 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 13750       |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | 0.6622582   |\n",
      "|    std                  | 5.8         |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1377        |\n",
      "|    time_elapsed         | 26150       |\n",
      "|    total_timesteps      | 2820096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010536104 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 13760       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -2.2471735  |\n",
      "|    std                  | 5.8         |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4446319.40\n",
      "total_reward: 3446319.40\n",
      "total_cost: 84085.58\n",
      "total_trades: 55362\n",
      "Sharpe: 0.757\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 26168       |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011586348 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 13770       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.11646155  |\n",
      "|    std                  | 5.81        |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1379        |\n",
      "|    time_elapsed         | 26187       |\n",
      "|    total_timesteps      | 2824192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010623381 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.0987      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 13780       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -1.6955618  |\n",
      "|    std                  | 5.81        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1380        |\n",
      "|    time_elapsed         | 26207       |\n",
      "|    total_timesteps      | 2826240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006960376 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 13790       |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | 19.995234   |\n",
      "|    std                  | 5.82        |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1381         |\n",
      "|    time_elapsed         | 26226        |\n",
      "|    total_timesteps      | 2828288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062998915 |\n",
      "|    clip_fraction        | 0.048        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.8        |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 13800        |\n",
      "|    policy_gradient_loss | -0.0083      |\n",
      "|    reward               | -2.8162277   |\n",
      "|    std                  | 5.82         |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1382        |\n",
      "|    time_elapsed         | 26245       |\n",
      "|    total_timesteps      | 2830336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012208769 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 13810       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.43882942 |\n",
      "|    std                  | 5.85        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1383        |\n",
      "|    time_elapsed         | 26264       |\n",
      "|    total_timesteps      | 2832384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004386923 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.0953      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 13820       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    reward               | 0.8752416   |\n",
      "|    std                  | 5.85        |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1384         |\n",
      "|    time_elapsed         | 26283        |\n",
      "|    total_timesteps      | 2834432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068055065 |\n",
      "|    clip_fraction        | 0.0487       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92          |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.7         |\n",
      "|    n_updates            | 13830        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | 0.15968817   |\n",
      "|    std                  | 5.85         |\n",
      "|    value_loss           | 56.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1385        |\n",
      "|    time_elapsed         | 26302       |\n",
      "|    total_timesteps      | 2836480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013700927 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 13840       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -0.44574606 |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1386        |\n",
      "|    time_elapsed         | 26320       |\n",
      "|    total_timesteps      | 2838528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009553578 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 13850       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -2.199654   |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1387       |\n",
      "|    time_elapsed         | 26339      |\n",
      "|    total_timesteps      | 2840576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00959341 |\n",
      "|    clip_fraction        | 0.0814     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.1      |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.8       |\n",
      "|    n_updates            | 13860      |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    reward               | 2.0197747  |\n",
      "|    std                  | 5.88       |\n",
      "|    value_loss           | 71.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1388        |\n",
      "|    time_elapsed         | 26358       |\n",
      "|    total_timesteps      | 2842624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012925842 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 13870       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -1.5369129  |\n",
      "|    std                  | 5.89        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1389        |\n",
      "|    time_elapsed         | 26377       |\n",
      "|    total_timesteps      | 2844672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015318153 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 13880       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 0.49619296  |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1390        |\n",
      "|    time_elapsed         | 26396       |\n",
      "|    total_timesteps      | 2846720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008082806 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 13890       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | -0.3765363  |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1391        |\n",
      "|    time_elapsed         | 26414       |\n",
      "|    total_timesteps      | 2848768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008236598 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 13900       |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    reward               | -0.705663   |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 80.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4723478.96\n",
      "total_reward: 3723478.96\n",
      "total_cost: 100357.61\n",
      "total_trades: 56105\n",
      "Sharpe: 0.780\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1392        |\n",
      "|    time_elapsed         | 26433       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018142477 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 13910       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 0.8264622   |\n",
      "|    std                  | 5.93        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1393         |\n",
      "|    time_elapsed         | 26452        |\n",
      "|    total_timesteps      | 2852864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066023874 |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.4        |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 13920        |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    reward               | 0.64113724   |\n",
      "|    std                  | 5.94         |\n",
      "|    value_loss           | 63           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1394        |\n",
      "|    time_elapsed         | 26471       |\n",
      "|    total_timesteps      | 2854912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010397358 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.8        |\n",
      "|    n_updates            | 13930       |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | 0.19012584  |\n",
      "|    std                  | 5.95        |\n",
      "|    value_loss           | 74.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1395        |\n",
      "|    time_elapsed         | 26489       |\n",
      "|    total_timesteps      | 2856960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004534778 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | -0.155      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 13940       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | 3.1650279   |\n",
      "|    std                  | 5.95        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1396        |\n",
      "|    time_elapsed         | 26508       |\n",
      "|    total_timesteps      | 2859008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012656929 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 13950       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.21685131  |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1397        |\n",
      "|    time_elapsed         | 26527       |\n",
      "|    total_timesteps      | 2861056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006792533 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 13960       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | -1.7059838  |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 58.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1398        |\n",
      "|    time_elapsed         | 26546       |\n",
      "|    total_timesteps      | 2863104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015183365 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 13970       |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | 0.8073427   |\n",
      "|    std                  | 5.98        |\n",
      "|    value_loss           | 69.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1399        |\n",
      "|    time_elapsed         | 26565       |\n",
      "|    total_timesteps      | 2865152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013021979 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 13980       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | 2.970041    |\n",
      "|    std                  | 5.99        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1400        |\n",
      "|    time_elapsed         | 26584       |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008333039 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 13990       |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | 0.47521013  |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1401         |\n",
      "|    time_elapsed         | 26602        |\n",
      "|    total_timesteps      | 2869248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067149773 |\n",
      "|    clip_fraction        | 0.0474       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.7        |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 14000        |\n",
      "|    policy_gradient_loss | -0.0066      |\n",
      "|    reward               | -3.6728013   |\n",
      "|    std                  | 6            |\n",
      "|    value_loss           | 58.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1402        |\n",
      "|    time_elapsed         | 26621       |\n",
      "|    total_timesteps      | 2871296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014302375 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 14010       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | -2.3840928  |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1403        |\n",
      "|    time_elapsed         | 26640       |\n",
      "|    total_timesteps      | 2873344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010896249 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 14020       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -0.62288374 |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1404        |\n",
      "|    time_elapsed         | 26658       |\n",
      "|    total_timesteps      | 2875392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009264872 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 14030       |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | -1.9169503  |\n",
      "|    std                  | 6.01        |\n",
      "|    value_loss           | 88.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1405        |\n",
      "|    time_elapsed         | 26677       |\n",
      "|    total_timesteps      | 2877440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017336922 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 14040       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 5.098865    |\n",
      "|    std                  | 6.02        |\n",
      "|    value_loss           | 78.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4890840.25\n",
      "total_reward: 3890840.25\n",
      "total_cost: 106188.44\n",
      "total_trades: 57015\n",
      "Sharpe: 0.787\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1406        |\n",
      "|    time_elapsed         | 26696       |\n",
      "|    total_timesteps      | 2879488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014325546 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 14050       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 1.7161546   |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1407         |\n",
      "|    time_elapsed         | 26714        |\n",
      "|    total_timesteps      | 2881536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054495255 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.9        |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.2         |\n",
      "|    n_updates            | 14060        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    reward               | 0.3173994    |\n",
      "|    std                  | 6.05         |\n",
      "|    value_loss           | 79           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1408        |\n",
      "|    time_elapsed         | 26733       |\n",
      "|    total_timesteps      | 2883584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008752033 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.0993      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.2        |\n",
      "|    n_updates            | 14070       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | 4.3007765   |\n",
      "|    std                  | 6.06        |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1409        |\n",
      "|    time_elapsed         | 26752       |\n",
      "|    total_timesteps      | 2885632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018323807 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 14080       |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    reward               | 2.669956    |\n",
      "|    std                  | 6.08        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1410         |\n",
      "|    time_elapsed         | 26771        |\n",
      "|    total_timesteps      | 2887680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116857495 |\n",
      "|    clip_fraction        | 0.0943       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.1        |\n",
      "|    explained_variance   | 0.141        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.7         |\n",
      "|    n_updates            | 14090        |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | -0.66062903  |\n",
      "|    std                  | 6.1          |\n",
      "|    value_loss           | 92.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1411        |\n",
      "|    time_elapsed         | 26789       |\n",
      "|    total_timesteps      | 2889728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011649415 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 14100       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.91185516  |\n",
      "|    std                  | 6.11        |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1412        |\n",
      "|    time_elapsed         | 26808       |\n",
      "|    total_timesteps      | 2891776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011358609 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.0829      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 14110       |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | -1.9650325  |\n",
      "|    std                  | 6.12        |\n",
      "|    value_loss           | 62.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1413        |\n",
      "|    time_elapsed         | 26827       |\n",
      "|    total_timesteps      | 2893824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017142002 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 14120       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 2.1083357   |\n",
      "|    std                  | 6.13        |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1414         |\n",
      "|    time_elapsed         | 26846        |\n",
      "|    total_timesteps      | 2895872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076203872 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.3        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 14130        |\n",
      "|    policy_gradient_loss | -0.00735     |\n",
      "|    reward               | -0.07217029  |\n",
      "|    std                  | 6.15         |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1415        |\n",
      "|    time_elapsed         | 26866       |\n",
      "|    total_timesteps      | 2897920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013176631 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 14140       |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | -1.3874068  |\n",
      "|    std                  | 6.16        |\n",
      "|    value_loss           | 70.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 26884       |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022053521 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 14150       |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | 0.85072595  |\n",
      "|    std                  | 6.19        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1417        |\n",
      "|    time_elapsed         | 26904       |\n",
      "|    total_timesteps      | 2902016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008178253 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 14160       |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    reward               | -4.4436774  |\n",
      "|    std                  | 6.2         |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1418        |\n",
      "|    time_elapsed         | 26923       |\n",
      "|    total_timesteps      | 2904064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008410572 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 14170       |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    reward               | 3.2783434   |\n",
      "|    std                  | 6.2         |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1419        |\n",
      "|    time_elapsed         | 26943       |\n",
      "|    total_timesteps      | 2906112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012152497 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 14180       |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    reward               | -0.7437043  |\n",
      "|    std                  | 6.21        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4559464.38\n",
      "total_reward: 3559464.38\n",
      "total_cost: 143142.01\n",
      "total_trades: 59840\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1420        |\n",
      "|    time_elapsed         | 26962       |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014137635 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 14190       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.7086328   |\n",
      "|    std                  | 6.22        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1421        |\n",
      "|    time_elapsed         | 26981       |\n",
      "|    total_timesteps      | 2910208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008625563 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 14200       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -2.0575647  |\n",
      "|    std                  | 6.23        |\n",
      "|    value_loss           | 51.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1422        |\n",
      "|    time_elapsed         | 27000       |\n",
      "|    total_timesteps      | 2912256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010603424 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 14210       |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -0.6523163  |\n",
      "|    std                  | 6.24        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1423        |\n",
      "|    time_elapsed         | 27019       |\n",
      "|    total_timesteps      | 2914304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012290353 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 14220       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 0.12968369  |\n",
      "|    std                  | 6.27        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1424        |\n",
      "|    time_elapsed         | 27037       |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009360966 |\n",
      "|    clip_fraction        | 0.0749      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 14230       |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    reward               | 3.2661104   |\n",
      "|    std                  | 6.28        |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1425        |\n",
      "|    time_elapsed         | 27056       |\n",
      "|    total_timesteps      | 2918400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012324234 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.0806      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 14240       |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | 1.8597935   |\n",
      "|    std                  | 6.29        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1426        |\n",
      "|    time_elapsed         | 27075       |\n",
      "|    total_timesteps      | 2920448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015109892 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.3         |\n",
      "|    n_updates            | 14250       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -2.8982422  |\n",
      "|    std                  | 6.31        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1427        |\n",
      "|    time_elapsed         | 27094       |\n",
      "|    total_timesteps      | 2922496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009708119 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 14260       |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | 0.34727782  |\n",
      "|    std                  | 6.33        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1428        |\n",
      "|    time_elapsed         | 27112       |\n",
      "|    total_timesteps      | 2924544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010529895 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 14270       |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    reward               | -3.3148057  |\n",
      "|    std                  | 6.33        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1429        |\n",
      "|    time_elapsed         | 27131       |\n",
      "|    total_timesteps      | 2926592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011355728 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 14280       |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    reward               | -6.9678097  |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1430        |\n",
      "|    time_elapsed         | 27150       |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014143171 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 14290       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 1.4654349   |\n",
      "|    std                  | 6.35        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1431        |\n",
      "|    time_elapsed         | 27168       |\n",
      "|    total_timesteps      | 2930688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010563467 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 14300       |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    reward               | 0.40960783  |\n",
      "|    std                  | 6.36        |\n",
      "|    value_loss           | 76.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1432       |\n",
      "|    time_elapsed         | 27187      |\n",
      "|    total_timesteps      | 2932736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01069549 |\n",
      "|    clip_fraction        | 0.0772     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.3      |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.8       |\n",
      "|    n_updates            | 14310      |\n",
      "|    policy_gradient_loss | -0.00813   |\n",
      "|    reward               | -2.8327987 |\n",
      "|    std                  | 6.37       |\n",
      "|    value_loss           | 52.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1433         |\n",
      "|    time_elapsed         | 27206        |\n",
      "|    total_timesteps      | 2934784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014208651  |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.4        |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.54         |\n",
      "|    n_updates            | 14320        |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    reward               | -0.008485652 |\n",
      "|    std                  | 6.38         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3739380.82\n",
      "total_reward: 2739380.82\n",
      "total_cost: 83551.88\n",
      "total_trades: 56110\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1434        |\n",
      "|    time_elapsed         | 27225       |\n",
      "|    total_timesteps      | 2936832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013706862 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 14330       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | 0.28900215  |\n",
      "|    std                  | 6.4         |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1435         |\n",
      "|    time_elapsed         | 27244        |\n",
      "|    total_timesteps      | 2938880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067532184 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.5        |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 14340        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | -4.5530834   |\n",
      "|    std                  | 6.41         |\n",
      "|    value_loss           | 54.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1436        |\n",
      "|    time_elapsed         | 27262       |\n",
      "|    total_timesteps      | 2940928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010086441 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 14350       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | 1.7552143   |\n",
      "|    std                  | 6.43        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1437        |\n",
      "|    time_elapsed         | 27281       |\n",
      "|    total_timesteps      | 2942976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010653155 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 14360       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | -0.13519596 |\n",
      "|    std                  | 6.45        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1438       |\n",
      "|    time_elapsed         | 27299      |\n",
      "|    total_timesteps      | 2945024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00662922 |\n",
      "|    clip_fraction        | 0.0489     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.7      |\n",
      "|    explained_variance   | 0.502      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.4       |\n",
      "|    n_updates            | 14370      |\n",
      "|    policy_gradient_loss | -0.00647   |\n",
      "|    reward               | -2.2293632 |\n",
      "|    std                  | 6.45       |\n",
      "|    value_loss           | 45         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1439        |\n",
      "|    time_elapsed         | 27318       |\n",
      "|    total_timesteps      | 2947072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010745606 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 14380       |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | -0.6945     |\n",
      "|    std                  | 6.46        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 27337       |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013622092 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.0477      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.31        |\n",
      "|    n_updates            | 14390       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 1.4961085   |\n",
      "|    std                  | 6.47        |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1441        |\n",
      "|    time_elapsed         | 27356       |\n",
      "|    total_timesteps      | 2951168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008188497 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | 0.37368312  |\n",
      "|    std                  | 6.48        |\n",
      "|    value_loss           | 49.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1442        |\n",
      "|    time_elapsed         | 27375       |\n",
      "|    total_timesteps      | 2953216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007023946 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 14410       |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    reward               | 3.1188388   |\n",
      "|    std                  | 6.48        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1443        |\n",
      "|    time_elapsed         | 27394       |\n",
      "|    total_timesteps      | 2955264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010945544 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -1.0370126  |\n",
      "|    std                  | 6.51        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1444         |\n",
      "|    time_elapsed         | 27413        |\n",
      "|    total_timesteps      | 2957312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105709825 |\n",
      "|    clip_fraction        | 0.0982       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95          |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 14430        |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    reward               | 0.2907275    |\n",
      "|    std                  | 6.52         |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1445        |\n",
      "|    time_elapsed         | 27432       |\n",
      "|    total_timesteps      | 2959360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008061116 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 14440       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    reward               | 1.2010759   |\n",
      "|    std                  | 6.53        |\n",
      "|    value_loss           | 44.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1446         |\n",
      "|    time_elapsed         | 27451        |\n",
      "|    total_timesteps      | 2961408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008294817  |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.1        |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 14450        |\n",
      "|    policy_gradient_loss | -0.00791     |\n",
      "|    reward               | -0.014077644 |\n",
      "|    std                  | 6.54         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1447        |\n",
      "|    time_elapsed         | 27471       |\n",
      "|    total_timesteps      | 2963456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012472099 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 14460       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 0.36473826  |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3283738.98\n",
      "total_reward: 2283738.98\n",
      "total_cost: 82013.22\n",
      "total_trades: 56091\n",
      "Sharpe: 0.616\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1448        |\n",
      "|    time_elapsed         | 27489       |\n",
      "|    total_timesteps      | 2965504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007966771 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | 0.49608225  |\n",
      "|    std                  | 6.57        |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1449        |\n",
      "|    time_elapsed         | 27508       |\n",
      "|    total_timesteps      | 2967552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007660102 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 14480       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | -2.9933925  |\n",
      "|    std                  | 6.58        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1450        |\n",
      "|    time_elapsed         | 27527       |\n",
      "|    total_timesteps      | 2969600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010854131 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.15        |\n",
      "|    n_updates            | 14490       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | 0.7421671   |\n",
      "|    std                  | 6.6         |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1451        |\n",
      "|    time_elapsed         | 27545       |\n",
      "|    total_timesteps      | 2971648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009491324 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 14500       |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | 1.3381298   |\n",
      "|    std                  | 6.62        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1452        |\n",
      "|    time_elapsed         | 27564       |\n",
      "|    total_timesteps      | 2973696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008758188 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 14510       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | 3.3542922   |\n",
      "|    std                  | 6.62        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1453       |\n",
      "|    time_elapsed         | 27583      |\n",
      "|    total_timesteps      | 2975744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01049472 |\n",
      "|    clip_fraction        | 0.0794     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.5      |\n",
      "|    explained_variance   | 0.319      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.82       |\n",
      "|    n_updates            | 14520      |\n",
      "|    policy_gradient_loss | -0.00994   |\n",
      "|    reward               | 1.0979309  |\n",
      "|    std                  | 6.63       |\n",
      "|    value_loss           | 25.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1454        |\n",
      "|    time_elapsed         | 27602       |\n",
      "|    total_timesteps      | 2977792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011933247 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 14530       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -1.7530539  |\n",
      "|    std                  | 6.66        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1455        |\n",
      "|    time_elapsed         | 27621       |\n",
      "|    total_timesteps      | 2979840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007674988 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 14540       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | 0.7684551   |\n",
      "|    std                  | 6.67        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1456        |\n",
      "|    time_elapsed         | 27640       |\n",
      "|    total_timesteps      | 2981888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010620173 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 14550       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 1.4244372   |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1457        |\n",
      "|    time_elapsed         | 27658       |\n",
      "|    total_timesteps      | 2983936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013719958 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.4524039   |\n",
      "|    std                  | 6.7         |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1458       |\n",
      "|    time_elapsed         | 27677      |\n",
      "|    total_timesteps      | 2985984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01081102 |\n",
      "|    clip_fraction        | 0.0762     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.8      |\n",
      "|    explained_variance   | 0.295      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.2       |\n",
      "|    n_updates            | 14570      |\n",
      "|    policy_gradient_loss | -0.00549   |\n",
      "|    reward               | 1.2960305  |\n",
      "|    std                  | 6.72       |\n",
      "|    value_loss           | 28.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 27696       |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008516772 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 14580       |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | 0.38956523  |\n",
      "|    std                  | 6.74        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1460        |\n",
      "|    time_elapsed         | 27714       |\n",
      "|    total_timesteps      | 2990080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008815318 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 14590       |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    reward               | -1.4351515  |\n",
      "|    std                  | 6.76        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1461        |\n",
      "|    time_elapsed         | 27733       |\n",
      "|    total_timesteps      | 2992128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010206061 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 14600       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 1.6755385   |\n",
      "|    std                  | 6.76        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1462         |\n",
      "|    time_elapsed         | 27752        |\n",
      "|    total_timesteps      | 2994176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086152535 |\n",
      "|    clip_fraction        | 0.0617       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.1        |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 14610        |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    reward               | 8.24437      |\n",
      "|    std                  | 6.77         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3768474.03\n",
      "total_reward: 2768474.03\n",
      "total_cost: 103498.31\n",
      "total_trades: 58108\n",
      "Sharpe: 0.676\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1463         |\n",
      "|    time_elapsed         | 27771        |\n",
      "|    total_timesteps      | 2996224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072807414 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.1        |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 14620        |\n",
      "|    policy_gradient_loss | -0.00828     |\n",
      "|    reward               | 0.5510695    |\n",
      "|    std                  | 6.78         |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1464        |\n",
      "|    time_elapsed         | 27791       |\n",
      "|    total_timesteps      | 2998272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013129592 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.99        |\n",
      "|    n_updates            | 14630       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 2.000252    |\n",
      "|    std                  | 6.78        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1465        |\n",
      "|    time_elapsed         | 27811       |\n",
      "|    total_timesteps      | 3000320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008341359 |\n",
      "|    clip_fraction        | 0.0517      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.0249      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 14640       |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    reward               | 0.718792    |\n",
      "|    std                  | 6.79        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name=\"1\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [],
   "source": [
    "agent_con = DRLAgent(env = env_train_con)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo2 = agent_con.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [],
   "source": [
    "trained_ppo2 = agent_con.train_model(model=model_ppo2, \n",
    "                             tensorboard_log=\"2\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS,tensorboard_log='sac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23766/4244563930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_sac = agent.train_model(model=model_sac, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=60000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Select action according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mnext_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# Compute the next Q values: min over all critics targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnext_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/policies.py\u001b[0m in \u001b[0;36maction_log_prob\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_dist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# return action and associated log prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mlog_prob_from_params\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mactions_from_params\u001b[0;34m(self, mean_actions, log_std, deterministic)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Update the proba distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SquashedDiagGaussianDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSquashedDiagGaussianDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0maction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='1',\n",
    "                             total_timesteps=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<'2020-07-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       18.824245\n",
       "std         8.489311\n",
       "min         9.140000\n",
       "25%        13.330000\n",
       "50%        16.139999\n",
       "75%        21.309999\n",
       "max        82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.40400183105453"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       34.574233\n",
       "std        43.787150\n",
       "min         0.000000\n",
       "25%        14.966105\n",
       "50%        24.124290\n",
       "75%        39.162080\n",
       "max       652.505555\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)\n",
    "\n",
    "trained_ppo.save('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ERxw3KqLkcP4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>1.580755e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>1.583119e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>1.581918e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>1.563387e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1.577981e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "331  2021-10-22   1.580755e+06\n",
       "332  2021-10-25   1.583119e+06\n",
       "333  2021-10-26   1.581918e+06\n",
       "334  2021-10-27   1.563387e+06\n",
       "335  2021-10-28   1.577981e+06"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMGN</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BA</th>\n",
       "      <th>CAT</th>\n",
       "      <th>CRM</th>\n",
       "      <th>CSCO</th>\n",
       "      <th>CVX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>GS</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>V</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WMT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL  AMGN  AXP  BA  CAT  CRM  CSCO  CVX  DIS   GS  ...  MRK  \\\n",
       "date                                                            ...        \n",
       "2020-07-01     0     0    0  58    0   54     0   15    0  100  ...   33   \n",
       "2020-07-02     0     0    0  58    0   54     0   15    0  100  ...   33   \n",
       "2020-07-06     0     0    0  58    0   54     0   15    0  100  ...   33   \n",
       "2020-07-07     0     0    0  58    0   54     0   15    0  100  ...   33   \n",
       "2020-07-08     0     0    0  58    0   54     0   15    0  100  ...   33   \n",
       "\n",
       "            MSFT  NKE  PG  TRV  UNH  V  VZ  WBA  WMT  \n",
       "date                                                  \n",
       "2020-07-01     0  100   0   84    0  0   0  100    0  \n",
       "2020-07-02     0  100   0   84    0  0   0  100    0  \n",
       "2020-07-06     0  100   0   84    0  0   0  100    0  \n",
       "2020-07-07     0  100   0   84    0  0   0  100    0  \n",
       "2020-07-08     0  100   0   84    0  0   0  100    0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.407915\n",
      "Cumulative returns     0.577981\n",
      "Annual volatility      0.178183\n",
      "Sharpe ratio           2.015623\n",
      "Calmar ratio           4.439130\n",
      "Stability              0.932659\n",
      "Max drawdown          -0.091891\n",
      "Omega ratio            1.389657\n",
      "Sortino ratio          3.243073\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.392968\n",
      "Daily value at risk   -0.021024\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "Annual return          0.269722\n",
      "Cumulative returns     0.374922\n",
      "Annual volatility      0.139083\n",
      "Sharpe ratio           1.792302\n",
      "Calmar ratio           3.020136\n",
      "Stability              0.919220\n",
      "Max drawdown          -0.089308\n",
      "Omega ratio            1.347571\n",
      "Sortino ratio          2.655481\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.052781\n",
      "Daily value at risk   -0.016534\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "qg1kvfemrrQH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-07-01'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.loc[0,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-10-28'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-10-28</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>16</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>40.791%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>57.798%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>17.818%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-9.189%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-2.102%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.19</td>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.00</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.00</td>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>2021-09-21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.72</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.99</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.14%</td>\n",
       "      <td>-3.23%</td>\n",
       "      <td>4.67%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzBaE63H3RLc"
   },
   "outputs": [],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value2, df_actions2 = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo2, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYeOjax-7H_5"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value2)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'2.csv')\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value2.loc[0,'date'],\n",
    "        end = df_account_value2.loc[len(df_account_value2)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value2, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value2.loc[0,'date'],\n",
    "             baseline_end = df_account_value2.loc[len(df_account_value2)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
