{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)   \n",
    "* [RLlib Section](#7)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "ef0ba8d0-f57a-4c74-bb0b-46737762677d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-8i1_yu6g\n",
      "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-8i1_yu6g\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.19.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.1.5)\n",
      "Collecting stockstats\n",
      "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Collecting elegantrl\n",
      "  Downloading elegantrl-0.3.2-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.3.0-py3-none-any.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 65.2 MB/s \n",
      "\u001b[?25hCollecting ray[default]\n",
      "  Downloading ray-1.9.1-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 57.6 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 42.9 MB/s \n",
      "\u001b[?25hCollecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 71.5 MB/s \n",
      "\u001b[?25hCollecting gputil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "Collecting exchange_calendars\n",
      "  Downloading exchange_calendars-3.5.tar.gz (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 35.6 MB/s \n",
      "\u001b[?25hCollecting alpaca_trade_api\n",
      "  Downloading alpaca_trade_api-1.4.3-py3-none-any.whl (36 kB)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting jqdatasdk\n",
      "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting wrds\n",
      "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n",
      "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n",
      "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n",
      "Collecting pre-commit\n",
      "  Downloading pre_commit-2.16.0-py2.py3-none-any.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 55.1 MB/s \n",
      "\u001b[?25hCollecting pybullet\n",
      "  Downloading pybullet-3.2.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (90.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 90.8 MB 244 bytes/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n",
      "Collecting box2d-py\n",
      "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 50.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n",
      "Collecting websocket-client<2,>=0.56.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting PyYAML==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 52.7 MB/s \n",
      "\u001b[?25hCollecting msgpack==1.0.2\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 60.4 MB/s \n",
      "\u001b[?25hCollecting aiohttp==3.7.4\n",
      "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 55.5 MB/s \n",
      "\u001b[?25hCollecting websockets<10,>=8.0\n",
      "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 48.7 MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 56.6 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 57.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 68.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 28.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 21.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 70.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 14.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 65.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.85-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 59.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.84-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.83-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.82-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.81-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.80-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 35.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.79-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.78-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 20.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.77-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.76-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.75-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.74-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 34.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.73-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.72-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.71-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.70-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.69-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.68-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 60.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.67-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.66-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.65-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.64-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.63-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.62-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.61-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.60-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 57.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.59-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.58-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.57-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.56-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.55-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.54-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.53-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.52-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.51-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.6 MB/s \n",
      "\u001b[?25hCollecting aiodns>=1.1.1\n",
      "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 60.7 MB/s \n",
      "\u001b[?25hCollecting cryptography>=2.6.1\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 42.6 MB/s \n",
      "\u001b[?25hCollecting pycares>=4.0.0\n",
      "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 44.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n",
      "Collecting pyluach\n",
      "  Downloading pyluach-1.3.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.11.2)\n",
      "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.2.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.27)\n",
      "Collecting thriftpy2>=0.3.9\n",
      "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
      "\u001b[K     |████████████████████████████████| 361 kB 50.4 MB/s \n",
      "\u001b[?25hCollecting pymysql>=0.7.6\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n",
      "Collecting ply<4.0,>=3.4\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n",
      "Collecting cfgv>=2.0.0\n",
      "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n",
      "Collecting identify>=1.0.0\n",
      "  Downloading identify-2.4.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting virtualenv>=20.0.8\n",
      "  Downloading virtualenv-20.11.0-py2.py3-none-any.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 39.6 MB/s \n",
      "\u001b[?25hCollecting nodeenv>=0.11.1\n",
      "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.4.0)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "\u001b[K     |████████████████████████████████| 461 kB 32.3 MB/s \n",
      "\u001b[?25hCollecting platformdirs<3,>=2\n",
      "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.12.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.0-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 57.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n",
      "Collecting aioredis<2\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 50.8 MB/s \n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 70.8 MB/s \n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (5.2.1)\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
      "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 213 kB/s \n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 53.5 MB/s \n",
      "\u001b[?25hCollecting hiredis\n",
      "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n",
      "Collecting blessed>=1.17.1\n",
      "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n",
      "Collecting int-date>=0.1.7\n",
      "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting mock\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 45.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.10)\n",
      "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat\n",
      "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for finrl: filename=finrl-0.3.3-py3-none-any.whl size=3885640 sha256=1667a85b9c8c0a7a8efbf04d5ebf154d5d1ea119a32e922d094820030ce0e7e4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/17/ff/bd/1bc602a0352762b0b24041b88536d803ae343ed0a711fcf55e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for elegantrl: filename=elegantrl-0.3.2-py3-none-any.whl size=168744 sha256=7773813204e1a2954730bd149444640d5155458fc82b6910ec4e661879797016\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75775 sha256=e3753b24d032afc5ef0b133c50557002ca9fed8416e2205e1547fc81af5c124a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39777 sha256=6cc78a6b3f88187e2798221487acba0361bb1d094b6c82496348fb4c85f7686b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
      "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for exchange-calendars: filename=exchange_calendars-3.5-py3-none-any.whl size=179487 sha256=3d877d78e29a28c4b098f4a0b1d0106458d7f73b52f6c7a43d0757d55c11d44b\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/21/43/b6ae2605dd767f6cd5a5b0b70c93a9a75823e44b3ccb92bce7\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=33dcd980f1b32f0582d029fcef126ae53327fb90724eee8c33bc3b4dbebda4b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
      "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940507 sha256=429244bf5fd89014c79f01bf0e4a59477258cd2b88978e3125b54f4bd62a88f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=b831a9dba6682b3e0a7ae05d7c2ba465918426c72474917e56e0850ac8c73263\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
      "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat\n",
      "Installing collected packages: multidict, yarl, lxml, deprecated, async-timeout, redis, PyYAML, pycares, ply, platformdirs, opencensus-context, msgpack, hiredis, frozenlist, distlib, blessed, aiohttp, websockets, websocket-client, virtualenv, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, opencensus, nodeenv, mock, int-date, identify, gpustat, empyrical, cryptography, colorful, cfgv, box2d-py, aiosignal, aioredis, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "Successfully installed PyYAML-5.4.1 aiodns-3.0.0 aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 alpaca-trade-api-1.4.3 async-timeout-3.0.1 blessed-1.19.0 box2d-py-2.3.8 ccxt-1.61.51 cfgv-3.3.1 colorful-0.5.4 cryptography-36.0.1 deprecated-1.2.13 distlib-0.3.4 elegantrl-0.3.2 empyrical-0.5.5 exchange-calendars-3.5 finrl-0.3.3 frozenlist-1.2.0 gpustat-1.0.0b1 gputil-1.4.0 hiredis-2.0.0 identify-2.4.1 int-date-0.1.8 jqdatasdk-1.8.10 lxml-4.7.1 lz4-3.1.10 mock-4.0.3 msgpack-1.0.2 multidict-5.2.0 nodeenv-1.6.0 opencensus-0.8.0 opencensus-context-0.1.2 platformdirs-2.4.1 ply-3.11 pre-commit-2.16.0 psycopg2-binary-2.9.2 py-spy-0.3.11 pybullet-3.2.1 pycares-4.1.2 pyfolio-0.9.2+75.g4b901f6 pyluach-1.3.0 pymysql-1.0.2 ray-1.9.1 redis-4.1.0 stable-baselines3-1.3.0 stockstats-0.3.2 tensorboardX-2.4.1 thriftpy2-0.4.14 virtualenv-20.11.0 websocket-client-1.2.3 websockets-9.1 wrds-3.1.1 yarl-1.6.3 yfinance-0.1.67\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.tusharedownloader import TushareDownloader\n",
    "from finrl.finrl_meta.data_processors.processor_alpaca import AlpacaProcessor\n",
    "from finrl.finrl_meta.data_processors.processor_wrds import WrdsProcessor\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading_conservative import StockTradingEnvCon\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot2 import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "5302d7c0-1c68-4c6e-b30e-b1395bdc109e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-01'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "config.TRAIN_START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FUnY8WEfLq3C",
    "outputId": "35dd8c5b-d58f-49b8-e4df-ae7e122448cd"
   },
   "outputs": [],
   "source": [
    "# from config.py TRAIN_END_DATE is a string\n",
    "# config.TRAIN_END_DATE\n",
    "# df2=TushareDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83c7f894-3757-473b-8afb-a904e6caabda",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "7a991dfe-f39c-40db-ec44-7c416cdce7dc"
   },
   "outputs": [],
   "source": [
    "# print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94360, 9)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "210fade5-e912-40df-be99-4ad00bdb9d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date       open       high        low      close  \\\n",
       "0           0  2008-12-31   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31  43.700001  45.099998  43.700001  30.628819   \n",
       "\n",
       "      volume   tic  day  \n",
       "0  607541200  AAPL    2  \n",
       "1    6287200  AMGN    2  \n",
       "2    9625600   AXP    2  \n",
       "3    5443100    BA    2  \n",
       "4    6277400   CAT    2  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fe = FeatureEngineer(\n",
    "#                     use_technical_indicator=True,\n",
    "#                     tech_indicator_list = config.INDICATORS,\n",
    "#                     use_vix=True,\n",
    "#                     use_turbulence=True,\n",
    "#                     user_defined_feature = False)\n",
    "\n",
    "# processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "# list_ticker = processed[\"tic\"].unique().tolist()\n",
    "# list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "# combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "# processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "# processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "grvhGJJII3Xn",
    "outputId": "733758c3-3552-4aa5-e1f9-789bd4ce0c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CRM</td>\n",
       "      <td>7.712500</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>5367600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.180000</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.120001</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>37513700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>74.629997</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>9964300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>DIS</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>22.520000</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>9012100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>GS</td>\n",
       "      <td>82.239998</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>81.120003</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>14894100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic       open       high        low      close  \\\n",
       "0           0  2008-12-31  AAPL   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  AMGN  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31   AXP  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31    BA  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31   CAT  43.700001  45.099998  43.700001  30.628819   \n",
       "5           5  2008-12-31   CRM   7.712500   8.130000   7.707500   8.002500   \n",
       "6           6  2008-12-31  CSCO  16.180000  16.549999  16.120001  11.787783   \n",
       "7           7  2008-12-31   CVX  72.900002  74.629997  72.900002  43.314438   \n",
       "8           8  2008-12-31   DIS  22.570000  22.950001  22.520000  19.538342   \n",
       "9           9  2008-12-31    GS  82.239998  86.150002  81.120003  69.224182   \n",
       "\n",
       "        volume  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  607541200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "1    6287200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "2    9625600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "3    5443100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "4    6277400.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "5    5367600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "6   37513700.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "7    9964300.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "8    9012100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "9   14894100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma   vix  turbulence  \n",
       "0      2.606277      2.606277  40.0         0.0  \n",
       "1     43.924454     43.924454  40.0         0.0  \n",
       "2     14.908465     14.908465  40.0         0.0  \n",
       "3     32.005894     32.005894  40.0         0.0  \n",
       "4     30.628819     30.628819  40.0         0.0  \n",
       "5      8.002500      8.002500  40.0         0.0  \n",
       "6     11.787783     11.787783  40.0         0.0  \n",
       "7     43.314438     43.314438  40.0         0.0  \n",
       "8     19.538342     19.538342  40.0         0.0  \n",
       "9     69.224182     69.224182  40.0         0.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full=pd.read_csv('./2.csv')\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01\n",
    "## Trade data split: 2020-07-01 to 2021-10-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "9744\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121795</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>288.570007</td>\n",
       "      <td>296.450012</td>\n",
       "      <td>287.660004</td>\n",
       "      <td>287.776794</td>\n",
       "      <td>2932900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>303.925869</td>\n",
       "      <td>271.251255</td>\n",
       "      <td>52.413046</td>\n",
       "      <td>-25.838431</td>\n",
       "      <td>1.846804</td>\n",
       "      <td>288.020689</td>\n",
       "      <td>281.001438</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121796</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>193.750000</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>190.737244</td>\n",
       "      <td>9040100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048786</td>\n",
       "      <td>198.750528</td>\n",
       "      <td>185.041391</td>\n",
       "      <td>53.021033</td>\n",
       "      <td>-51.550760</td>\n",
       "      <td>2.013358</td>\n",
       "      <td>191.485037</td>\n",
       "      <td>181.677683</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121797</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.919998</td>\n",
       "      <td>55.290001</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>50.376743</td>\n",
       "      <td>17414800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.437111</td>\n",
       "      <td>53.918425</td>\n",
       "      <td>48.729324</td>\n",
       "      <td>48.097044</td>\n",
       "      <td>-51.018262</td>\n",
       "      <td>8.508886</td>\n",
       "      <td>51.012123</td>\n",
       "      <td>51.464679</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121798</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>42.580002</td>\n",
       "      <td>41.759998</td>\n",
       "      <td>39.035732</td>\n",
       "      <td>4782100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083986</td>\n",
       "      <td>42.609305</td>\n",
       "      <td>36.487095</td>\n",
       "      <td>48.830181</td>\n",
       "      <td>-14.508130</td>\n",
       "      <td>1.500723</td>\n",
       "      <td>39.135190</td>\n",
       "      <td>38.935129</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121799</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>119.220001</td>\n",
       "      <td>120.129997</td>\n",
       "      <td>118.540001</td>\n",
       "      <td>116.121765</td>\n",
       "      <td>6836400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.886569</td>\n",
       "      <td>119.473758</td>\n",
       "      <td>113.510454</td>\n",
       "      <td>48.159665</td>\n",
       "      <td>-69.938795</td>\n",
       "      <td>3.847271</td>\n",
       "      <td>117.787627</td>\n",
       "      <td>119.723273</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date  tic        open        high         low  \\\n",
       "2892      121795  2020-06-30  UNH  288.570007  296.450012  287.660004   \n",
       "2892      121796  2020-06-30    V  191.490005  193.750000  190.160004   \n",
       "2892      121797  2020-06-30   VZ   54.919998   55.290001   54.360001   \n",
       "2892      121798  2020-06-30  WBA   42.119999   42.580002   41.759998   \n",
       "2892      121799  2020-06-30  WMT  119.220001  120.129997  118.540001   \n",
       "\n",
       "           close      volume  day      macd     boll_ub     boll_lb  \\\n",
       "2892  287.776794   2932900.0  1.0 -0.019475  303.925869  271.251255   \n",
       "2892  190.737244   9040100.0  1.0  1.048786  198.750528  185.041391   \n",
       "2892   50.376743  17414800.0  1.0 -0.437111   53.918425   48.729324   \n",
       "2892   39.035732   4782100.0  1.0 -0.083986   42.609305   36.487095   \n",
       "2892  116.121765   6836400.0  1.0 -0.886569  119.473758  113.510454   \n",
       "\n",
       "         rsi_30     cci_30     dx_30  close_30_sma  close_60_sma    vix  \\\n",
       "2892  52.413046 -25.838431  1.846804    288.020689    281.001438  30.43   \n",
       "2892  53.021033 -51.550760  2.013358    191.485037    181.677683  30.43   \n",
       "2892  48.097044 -51.018262  8.508886     51.012123     51.464679  30.43   \n",
       "2892  48.830181 -14.508130  1.500723     39.135190     38.935129  30.43   \n",
       "2892  48.159665 -69.938795  3.847271    117.787627    119.723273  30.43   \n",
       "\n",
       "      turbulence  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "e_train_gym_conservative = StockTradingEnvCon(df = train, **env_kwargs)\n",
    "e_train_gym_conservative.value_history.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "env_train_con, _ = e_train_gym_conservative.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "agent_con = DRLAgent(env = env_train_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50015/153760662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDRLAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_a2c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a2c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(self, model_name, policy, policy_kwargs, model_kwargs, verbose, seed, tensorboard_log)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/a2c/a2c.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, rms_prop_eps, use_rms_prop, use_sde, sde_sample_freq, normalize_advantage, tensorboard_log, create_eval_env, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDiscrete\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiBinary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             ),\n\u001b[1;32m    104\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, policy_base, tensorboard_log, create_eval_env, monitor_wrapper, policy_kwargs, verbose, seed, device, _init_setup_model, supported_action_spaces)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtensorboard_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensorboard_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0msupported_action_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupported_action_spaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         )\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, policy_base, learning_rate, policy_kwargs, tensorboard_log, verbose, device, support_multi_env, create_eval_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Using {self.device} device\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/utils.py\u001b[0m in \u001b[0;36mget_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# Cuda not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# This function never throws and returns 0 if driver is missing or can't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# be initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDeviceCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_bf16_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ppo/1_1\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 124       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.5073655 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3946387.70\n",
      "total_reward: 2946387.70\n",
      "total_cost: 357438.48\n",
      "total_trades: 81024\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015788507 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00723     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | 0.3435485   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012375185 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -1.1157341  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016662188 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00193    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.2809894   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017038994 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00886    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    reward               | 3.2505164   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01701039 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.4      |\n",
      "|    explained_variance   | 0.0063     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17         |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    reward               | 1.8685282  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 32.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02486872 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0142    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    reward               | 0.39857626 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020911664 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0215     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 1.3883617   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7870/2360990771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_ppo = agent.train_model(model=model_ppo, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=3000000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    321\u001b[0m             )\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_total_asset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_total_asset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_total_asset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36m_get_date\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m         \"\"\"\n\u001b[0;32m-> 2039\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_hashtable_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_hashtable_algo\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_object_for_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mhtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hashtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_check_object_for_strings\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# including nulls because that is the only difference between\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# StringHashTable and ObjectHashtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mndtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name=\"1\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent_con = DRLAgent(env = env_train_con)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo2 = agent_con.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "Logging to ppo/7_6\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 112        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 18         |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.34528866 |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011976912 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.0235      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.18        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    reward               | 0.8717839   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012296513 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.00114    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    reward               | -1.6236689  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015781278 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00212     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 4.1609073   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011733886 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00161    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    reward               | 2.9029012   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013525588 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00478    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    reward               | 1.903915    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 132        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01527894 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.3      |\n",
      "|    explained_variance   | -0.00212   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 59.8       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    reward               | 2.4900546  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 148        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017276555 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.0201     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    reward               | -1.3389828  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024856843 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00251    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | 0.073213845 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020815587 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00124    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.1        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 0.9549495   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011760997 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00489    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 0.015047797 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 223         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018881794 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00268    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.21985316  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5079946.36\n",
      "total_reward: 4079946.36\n",
      "total_cost: 334610.25\n",
      "total_trades: 79408\n",
      "Sharpe: 0.870\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020979285 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.00731    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | 0.19074394  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021442452 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.05804967  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 243         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024998931 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0221     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 4.5841074   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015441887 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.00964    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 0.063334666 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019195262 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.0022     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.1        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.503461    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019585978 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | -0.0559     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.1        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -1.4682422  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 95.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019835886 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | -0.0267     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -0.5846788  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 377         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015316779 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | -0.0257     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.1        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | 0.55794096  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024741955 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.0209      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -14.2525    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 75.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017376442 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.0175      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 2.63466     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018932046 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.016       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    reward               | 0.41901106  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 97.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020434733 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | -0.00244    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    reward               | 3.0234337   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 97.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019444788 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | -0.024      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -0.793974   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 489         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040541895 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | -4.43e-05   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.6083637  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4416376.17\n",
      "total_reward: 3416376.17\n",
      "total_cost: 297051.43\n",
      "total_trades: 76542\n",
      "Sharpe: 0.843\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 508         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028539734 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.00219     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | -1.0323929  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 68.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 526         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022856805 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | -0.0195     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | -1.0057505  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 76.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 545         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022446405 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.0245      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | -0.39981744 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 564         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028286923 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 1.8898252   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 83          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021338787 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.024       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 2.0239441   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023171712 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.00492     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 0.19132055  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 54.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 621          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.052563325  |\n",
      "|    clip_fraction        | 0.288        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.3        |\n",
      "|    explained_variance   | -0.00951     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    reward               | -0.047201224 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 639         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029799096 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.016       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.5494655   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 658         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025781136 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.00615     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | 0.4673843   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 677        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0310794  |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.5      |\n",
      "|    explained_variance   | -0.00661   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.03       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    reward               | -6.3783083 |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 21.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 696         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019482508 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | -0.00296    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.1        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | -0.56475776 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 715         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032450095 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00183    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.3        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | -12.129939  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 89.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 733         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028704492 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0249     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    reward               | -2.2877207  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 752         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041718177 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0781      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | -0.9185785  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4049121.43\n",
      "total_reward: 3049121.43\n",
      "total_cost: 275123.95\n",
      "total_trades: 76154\n",
      "Sharpe: 0.864\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 771         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032813102 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0951      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | 0.32844082  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 790         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021502744 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0279      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    reward               | 0.39835757  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 809         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021277677 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0808      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.48        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | -1.6899797  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036559507 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0548      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    reward               | 0.27166808  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 847           |\n",
      "|    total_timesteps      | 92160         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.053470083   |\n",
      "|    clip_fraction        | 0.24          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -43.1         |\n",
      "|    explained_variance   | -0.0208       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.8          |\n",
      "|    n_updates            | 440           |\n",
      "|    policy_gradient_loss | -0.00171      |\n",
      "|    reward               | -0.0033681702 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 54.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 865         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043553177 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.029       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    reward               | -3.185715   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 884         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027731901 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | -0.0484     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 1.4394855   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 904         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034132123 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0138      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | 3.968282    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 922         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021507464 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0451      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    reward               | -1.0570002  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 941         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035226077 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.83        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | 0.16500548  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 959         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02438518  |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.21934654 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 978         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033833615 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0297      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | 0.00119     |\n",
      "|    reward               | -4.975218   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 997         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028201573 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.00966     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | 2.7587104   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1016        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032743998 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0349      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | 0.6424643   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1035        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029216014 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0754      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    reward               | 1.7326418   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3896794.02\n",
      "total_reward: 2896794.02\n",
      "total_cost: 229783.67\n",
      "total_trades: 72611\n",
      "Sharpe: 0.794\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1054        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022701731 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0318      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | 1.7559187   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1073        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028481226 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0905      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    reward               | -0.32280523 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1092        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018335516 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.7971901   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1110        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030700047 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.00146     |\n",
      "|    reward               | 0.013960611 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1129        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03613994  |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0671      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.47        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    reward               | -0.42557678 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1148        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033748776 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.0199     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -9.91e-05   |\n",
      "|    reward               | 0.943725    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1167        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038821533 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0118      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.00397     |\n",
      "|    reward               | 2.6262228   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1186        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027175771 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | -0.00694    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 3.1120346   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1204        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026038049 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | -0.00434    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | -0.9932122  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 92.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 1223       |\n",
      "|    total_timesteps      | 133120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03206998 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.00483    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 83         |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.00581   |\n",
      "|    reward               | -1.0692474 |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 128        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 1243       |\n",
      "|    total_timesteps      | 135168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02351452 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.00706    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 200        |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | -0.00352   |\n",
      "|    reward               | 2.5817215  |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 206        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1261        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038026534 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0713      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.24        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    reward               | -2.3108482  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 1280       |\n",
      "|    total_timesteps      | 139264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03721745 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.00584    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 108        |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.00278   |\n",
      "|    reward               | -0.4106404 |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 126        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 1299       |\n",
      "|    total_timesteps      | 141312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03985774 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0143     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 86.5       |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.00606   |\n",
      "|    reward               | -1.1163088 |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 131        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5614417.47\n",
      "total_reward: 4614417.47\n",
      "total_cost: 291691.19\n",
      "total_trades: 74901\n",
      "Sharpe: 0.897\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1317        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036470972 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | -0.0125     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | 0.54372084  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 1336       |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02353516 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.000704   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 51         |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.00407   |\n",
      "|    reward               | 0.73441416 |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1355        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022447813 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0162      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.4        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    reward               | -32.370094  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1374        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027973045 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | -0.00118    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46          |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    reward               | -0.7864212  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 1393       |\n",
      "|    total_timesteps      | 151552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04654534 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.014      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.4       |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    reward               | -2.987311  |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 90.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1412        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043206707 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.00982     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 1.277808    |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 1431       |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03367657 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0231     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 91.7       |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.00563   |\n",
      "|    reward               | -2.237736  |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 182        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1449        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038401823 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0981      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.48        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | -0.27505538 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1468        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031872705 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | -0.00593    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | 1.7547429   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1487        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024523979 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0171      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.2        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    reward               | -2.1445785  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1506        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032079186 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | -0.0656     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | 4.34e-05    |\n",
      "|    reward               | 0.29950914  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1525        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035160072 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | -0.0181     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | -0.5204797  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1544        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022878919 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.00842     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -0.41385123 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1562        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036899563 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | -0.00104    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    reward               | -1.2816633  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8233829.56\n",
      "total_reward: 7233829.56\n",
      "total_cost: 291632.56\n",
      "total_trades: 74764\n",
      "Sharpe: 1.050\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1581        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041286953 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0713      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | 0.86584485  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1600        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022034727 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.00648     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 235         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    reward               | 0.010613131 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 237         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1619        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03826391  |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0136      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98          |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | 0.00128     |\n",
      "|    reward               | -0.18338549 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 1638       |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02496088 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | 0.0448     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19         |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.00708   |\n",
      "|    reward               | 2.692416   |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 45.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1656        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034096867 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0225      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -2.6479697  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1675        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032064512 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | -0.000212   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.6        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -0.3148124  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1694        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034170058 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | -0.00347    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.1        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | -2.2246819  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1712        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020328745 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0168      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | -0.7466851  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 1731       |\n",
      "|    total_timesteps      | 188416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03327501 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.6      |\n",
      "|    explained_variance   | -0.0116    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 81.1       |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.00241   |\n",
      "|    reward               | -1.9355103 |\n",
      "|    std                  | 1.17       |\n",
      "|    value_loss           | 147        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1750        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018106211 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.00834     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.2        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    reward               | -1.7835941  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1768        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044556756 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0491      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | 0.00995     |\n",
      "|    reward               | 1.3435966   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 1787       |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02799996 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.7      |\n",
      "|    explained_variance   | -0.0435    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.8       |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.00864   |\n",
      "|    reward               | -0.3078732 |\n",
      "|    std                  | 1.17       |\n",
      "|    value_loss           | 69.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1805        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033388074 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.0051      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | 1.4970739   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 95.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1824        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025335766 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.0676      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 0.83968204  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3874134.76\n",
      "total_reward: 2874134.76\n",
      "total_cost: 289680.82\n",
      "total_trades: 74318\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1843        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023374628 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.0435      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | 0.17841047  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 91.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1862        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025050398 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.6        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | -2.399547   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1881        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032578696 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | -0.000371   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.7        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    reward               | -1.2483108  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 1899        |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042576514 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | -0.0438     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | 0.00487     |\n",
      "|    reward               | -1.5444105  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1918        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049330335 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.035       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | -1.9726336  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 66.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 1937        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037231043 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.0411      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.9        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 7.4935727   |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 89          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 1955         |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.033143666  |\n",
      "|    clip_fraction        | 0.228        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.1        |\n",
      "|    explained_variance   | 0.017        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.3         |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    reward               | -0.109561294 |\n",
      "|    std                  | 1.19         |\n",
      "|    value_loss           | 64.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 1974        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.064456135 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    reward               | -3.9007695  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1993        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033958986 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | -0.00132    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53          |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | -1.2621773  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 2011        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025847198 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.3       |\n",
      "|    explained_variance   | -0.00168    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    reward               | 0.21723619  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 2030       |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03315825 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.4      |\n",
      "|    explained_variance   | 0.0126     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    reward               | -0.7292153 |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 26.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 2049        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027617402 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | -0.00491    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.17589809  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 2068        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042883582 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | -0.00253    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.9        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | 1.617787    |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 2087        |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038697552 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.5       |\n",
      "|    explained_variance   | -0.0383     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    reward               | 6.2294164   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5319540.86\n",
      "total_reward: 4319540.86\n",
      "total_cost: 267199.62\n",
      "total_trades: 71192\n",
      "Sharpe: 0.844\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 2106        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024499629 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.00876     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75          |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -1.3410271  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 2124        |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051171497 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.0256      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    reward               | 0.43333623  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 2144        |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021139499 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.00894     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -3.061542   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 2163        |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044708055 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.041       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    reward               | -2.0864782  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 2181        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040467314 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.011       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | -1.8927261  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 2200        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041485682 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | -0.0109     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 1.3715258   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 2219        |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052634798 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | -0.0459     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.94        |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | 0.00402     |\n",
      "|    reward               | 0.41043347  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 2238        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059668943 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.00555     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.3233437   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 120        |\n",
      "|    time_elapsed         | 2256       |\n",
      "|    total_timesteps      | 245760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0501253  |\n",
      "|    clip_fraction        | 0.399      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47        |\n",
      "|    explained_variance   | 0.00998    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.5       |\n",
      "|    n_updates            | 1190       |\n",
      "|    policy_gradient_loss | -0.00736   |\n",
      "|    reward               | -3.2297435 |\n",
      "|    std                  | 1.23       |\n",
      "|    value_loss           | 87.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 2275        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046233926 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | -0.0035     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | 0.00305     |\n",
      "|    reward               | -1.9565353  |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 2295        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044485092 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.00885     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | 0.1264349   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 81          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 2313        |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039158724 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | -0.0235     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 2.350543    |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 77.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 2333         |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.029466394  |\n",
      "|    clip_fraction        | 0.306        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.3        |\n",
      "|    explained_variance   | 0.00836      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.8         |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    reward               | -0.098979115 |\n",
      "|    std                  | 1.24         |\n",
      "|    value_loss           | 84.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 2352        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024423968 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.77        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | 0.74249196  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3810882.37\n",
      "total_reward: 2810882.37\n",
      "total_cost: 300086.96\n",
      "total_trades: 73673\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 2372        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028784797 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.00268     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 0.08089204  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 2391        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047292285 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | -0.000686   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | 0.00569     |\n",
      "|    reward               | -7.432667   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 85          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 2409        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027657595 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | -0.0799     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    reward               | 1.4028522   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 2429        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030663315 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | -0.000697   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -0.7647111  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 2447        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025721747 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | -0.0234     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 0.033263955 |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 84.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 2466        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035504483 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.0136      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.6        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.39580104  |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 132        |\n",
      "|    time_elapsed         | 2485       |\n",
      "|    total_timesteps      | 270336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04329545 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.9      |\n",
      "|    explained_variance   | 0.046      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.98       |\n",
      "|    n_updates            | 1310       |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    reward               | 0.21224125 |\n",
      "|    std                  | 1.27       |\n",
      "|    value_loss           | 13.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 2504       |\n",
      "|    total_timesteps      | 272384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03284278 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48        |\n",
      "|    explained_variance   | 0.0161     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.6       |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | -0.00368   |\n",
      "|    reward               | 2.341572   |\n",
      "|    std                  | 1.27       |\n",
      "|    value_loss           | 63.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 2523        |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025509752 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 1.9256895   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 91.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 2542        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022879526 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | -0.00588    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -1.6579462  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 91          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 2561        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028992008 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.016       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.37298205  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 304         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 2580        |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021922085 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | -0.000306   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    reward               | -4.4998813  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 2599        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038791806 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.046       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.8        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | 0.000788    |\n",
      "|    reward               | 1.400745    |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 2617        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022251373 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | -0.0319     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | -1.1367843  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5756302.04\n",
      "total_reward: 4756302.04\n",
      "total_cost: 305837.77\n",
      "total_trades: 73537\n",
      "Sharpe: 0.899\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 2636        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023802232 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.00483     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | 0.6120528   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 2655        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030879412 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.0566      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    reward               | 3.0279753   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 251         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 2673        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031456165 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | -0.0793     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -1.4980985  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 2692        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017966935 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.0518      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.5        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 0.95674366  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 2710        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030170908 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.0361      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -1.2573614  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 2729        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034622468 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | -0.0907     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | -0.92667747 |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 2748       |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03255713 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.5      |\n",
      "|    explained_variance   | 0.0742     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 57.2       |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    reward               | 1.6636523  |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 90.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 2766        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03260268  |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.0621      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.7        |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | -0.42564452 |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 2785       |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02869552 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.6      |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 154        |\n",
      "|    n_updates            | 1470       |\n",
      "|    policy_gradient_loss | -0.00633   |\n",
      "|    reward               | 0.51777846 |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 160        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 149        |\n",
      "|    time_elapsed         | 2804       |\n",
      "|    total_timesteps      | 305152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04210795 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.7      |\n",
      "|    explained_variance   | 0.0952     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.4       |\n",
      "|    n_updates            | 1480       |\n",
      "|    policy_gradient_loss | 0.00023    |\n",
      "|    reward               | 1.2523887  |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 20.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 2823        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027685594 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    reward               | 0.7350989   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 2841        |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023122374 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | -0.000164   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.6        |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | 3.8959703   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 2860        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032924388 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | -0.0841     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.000426   |\n",
      "|    reward               | -2.1959875  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 2879        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020030439 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | -1.0753963  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 83.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5447167.63\n",
      "total_reward: 4447167.63\n",
      "total_cost: 327049.27\n",
      "total_trades: 73929\n",
      "Sharpe: 0.872\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 2897        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034136124 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | -0.00587    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.8        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.5739441  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 2916         |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.02793077   |\n",
      "|    clip_fraction        | 0.208        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.9        |\n",
      "|    explained_variance   | 0.00976      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 167          |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.00938     |\n",
      "|    reward               | -0.044686183 |\n",
      "|    std                  | 1.31         |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 2935        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043836012 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.058       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -2.35445    |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 2953        |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028738119 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.0411      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -1.8568949  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 2972        |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027739707 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.0487      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | -6.5172286  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 2991        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028489543 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.0566      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.000679   |\n",
      "|    reward               | 0.21398579  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 3009       |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02668409 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.2      |\n",
      "|    explained_variance   | 0.00603    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 80.5       |\n",
      "|    n_updates            | 1590       |\n",
      "|    policy_gradient_loss | -0.00867   |\n",
      "|    reward               | 1.0800127  |\n",
      "|    std                  | 1.32       |\n",
      "|    value_loss           | 175        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 3029        |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021703452 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.0589      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.3        |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | 25.856554   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 3048        |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033363655 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | -0.0185     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    reward               | -1.2411642  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 3067        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031729102 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.0466      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | -2.0859342  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 3085        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022508804 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.3        |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | 0.49830112  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 3104        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018334854 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.0269      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    reward               | 7.7953386   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 3123        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026553012 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.0179      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    reward               | 0.70997876  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 3141        |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026518049 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.00623     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 247         |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    reward               | -1.4406053  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 3160        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020637529 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | -0.00426    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    reward               | 4.5434422   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7974778.66\n",
      "total_reward: 6974778.66\n",
      "total_cost: 296107.91\n",
      "total_trades: 71148\n",
      "Sharpe: 0.968\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 3179        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025605094 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.0451      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.2        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    reward               | -5.395204   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 170        |\n",
      "|    time_elapsed         | 3198       |\n",
      "|    total_timesteps      | 348160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02925369 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.6      |\n",
      "|    explained_variance   | 0.00309    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 182        |\n",
      "|    n_updates            | 1690       |\n",
      "|    policy_gradient_loss | -0.00396   |\n",
      "|    reward               | -1.2438498 |\n",
      "|    std                  | 1.34       |\n",
      "|    value_loss           | 298        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 3217        |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040917505 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.00257     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.00044    |\n",
      "|    reward               | -0.7393989  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 286         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 3235        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035065174 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.00551     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | 0.8538932   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 323         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 3254        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026157036 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.0316      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | -2.3318954  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 3273        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030087225 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.0274      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    reward               | 1.3753104   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 399         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 175        |\n",
      "|    time_elapsed         | 3292       |\n",
      "|    total_timesteps      | 358400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03756424 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.8      |\n",
      "|    explained_variance   | 0.00379    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 370        |\n",
      "|    n_updates            | 1740       |\n",
      "|    policy_gradient_loss | 0.00256    |\n",
      "|    reward               | -1.9983339 |\n",
      "|    std                  | 1.35       |\n",
      "|    value_loss           | 684        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 3311        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022152293 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | -0.0337     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    reward               | -2.000335   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 3329        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023161367 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.00191     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | 0.6948094   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 374         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 3349        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027945386 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.0225      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -0.60492754 |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 3368       |\n",
      "|    total_timesteps      | 366592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02278879 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50        |\n",
      "|    explained_variance   | -0.0215    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 234        |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | -0.00575   |\n",
      "|    reward               | 0.8996364  |\n",
      "|    std                  | 1.36       |\n",
      "|    value_loss           | 428        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 3387        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026059598 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.0135      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | -5.9216213  |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 62          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 3405        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022679038 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.00586     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 224         |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.6622208   |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 423         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 3424        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017370392 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | -4.577925   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 335         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5410776.57\n",
      "total_reward: 4410776.57\n",
      "total_cost: 303012.22\n",
      "total_trades: 72796\n",
      "Sharpe: 0.852\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 3443        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041068777 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | -0.158      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | 0.00344     |\n",
      "|    reward               | 1.4665184   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 3480        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025355326 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.00843     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | -3.877163   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 3499        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034341253 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 251         |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | 0.000968    |\n",
      "|    reward               | 12.346748   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 300         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 3517        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035293046 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | -0.0109     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | 0.00393     |\n",
      "|    reward               | -5.3975477  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 3536        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021054607 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.3        |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 2.4379022   |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 3554        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031891488 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.0463      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.3        |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 1.2187543   |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 244         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 3573        |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018199703 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | -0.00211    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | -5.2528315  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 350         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 190        |\n",
      "|    time_elapsed         | 3592       |\n",
      "|    total_timesteps      | 389120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04496161 |\n",
      "|    clip_fraction        | 0.395      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.6      |\n",
      "|    explained_variance   | -0.0892    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15         |\n",
      "|    n_updates            | 1890       |\n",
      "|    policy_gradient_loss | -0.00758   |\n",
      "|    reward               | 6.0506964  |\n",
      "|    std                  | 1.39       |\n",
      "|    value_loss           | 34.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 3611        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023164518 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.00488     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | 1.3445199   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 3629        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023890898 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.1        |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | -7.3574524  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 3648        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020599741 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.0163      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    reward               | 0.8721445   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 87.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 194        |\n",
      "|    time_elapsed         | 3667       |\n",
      "|    total_timesteps      | 397312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02536136 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.8      |\n",
      "|    explained_variance   | 0.042      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 83         |\n",
      "|    n_updates            | 1930       |\n",
      "|    policy_gradient_loss | -0.00987   |\n",
      "|    reward               | 0.13565685 |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 150        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 195        |\n",
      "|    time_elapsed         | 3686       |\n",
      "|    total_timesteps      | 399360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02256991 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.9      |\n",
      "|    explained_variance   | 0.0368     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 133        |\n",
      "|    n_updates            | 1940       |\n",
      "|    policy_gradient_loss | -0.00714   |\n",
      "|    reward               | 0.1129462  |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 256        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 3705        |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031085042 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.0175      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    reward               | 3.913193    |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4388699.20\n",
      "total_reward: 3388699.20\n",
      "total_cost: 287542.00\n",
      "total_trades: 72559\n",
      "Sharpe: 0.737\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 3724        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041322067 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | 2.9871898   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 3742        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023757527 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | -0.00437    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.000354   |\n",
      "|    reward               | 0.4993634   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 3761        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015830599 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.0499      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 5.5849547   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 3780        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032554008 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.0756      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | 0.00137     |\n",
      "|    reward               | 1.8176268   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 77.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 3799        |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034154296 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.0484      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | -1.0600374  |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 3818        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032261774 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.0438      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.9        |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | 0.00223     |\n",
      "|    reward               | -16.247347  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 3836        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019405436 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.0459      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 214         |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | 0.00205     |\n",
      "|    reward               | -0.7873033  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 3855        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049307007 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.0422      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | 0.00811     |\n",
      "|    reward               | -0.31303963 |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 3873        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020171497 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.0506      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | 3.2094195   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 3892        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03113972  |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.0803      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.2        |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -0.23913884 |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 207        |\n",
      "|    time_elapsed         | 3911       |\n",
      "|    total_timesteps      | 423936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04156998 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.4      |\n",
      "|    explained_variance   | 0.0277     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.8       |\n",
      "|    n_updates            | 2060       |\n",
      "|    policy_gradient_loss | 0.00441    |\n",
      "|    reward               | -2.4504817 |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 55.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 208        |\n",
      "|    time_elapsed         | 3930       |\n",
      "|    total_timesteps      | 425984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03006445 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.5      |\n",
      "|    explained_variance   | 0.0115     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 137        |\n",
      "|    n_updates            | 2070       |\n",
      "|    policy_gradient_loss | -0.00549   |\n",
      "|    reward               | -5.085765  |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 205        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 3949        |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027946403 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.00252     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.8        |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | 0.69329923  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 3968        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047358826 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | -0.11       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | 0.00614     |\n",
      "|    reward               | -0.2931561  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 76.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4928580.10\n",
      "total_reward: 3928580.10\n",
      "total_cost: 268806.14\n",
      "total_trades: 70572\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 3987        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025634134 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.0691      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 1.1635668   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 224         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 4006        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02944604  |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.046       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 209         |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | -0.23749915 |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 4024        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031032424 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.0772      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.3        |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    reward               | -4.5472803  |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 4043        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03868907  |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.0557      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | 0.00632     |\n",
      "|    reward               | -0.01755897 |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 215          |\n",
      "|    time_elapsed         | 4062         |\n",
      "|    total_timesteps      | 440320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.048519693  |\n",
      "|    clip_fraction        | 0.221        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -51.8        |\n",
      "|    explained_variance   | 0.0126       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 2140         |\n",
      "|    policy_gradient_loss | 0.000568     |\n",
      "|    reward               | -0.004101107 |\n",
      "|    std                  | 1.45         |\n",
      "|    value_loss           | 274          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 4081       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03661153 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.8      |\n",
      "|    explained_variance   | 0.0311     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 121        |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | -0.0067    |\n",
      "|    reward               | -2.049669  |\n",
      "|    std                  | 1.45       |\n",
      "|    value_loss           | 369        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 4100        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028376535 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.9        |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | 0.1101789   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 218        |\n",
      "|    time_elapsed         | 4119       |\n",
      "|    total_timesteps      | 446464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03292701 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52        |\n",
      "|    explained_variance   | 0.101      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 112        |\n",
      "|    n_updates            | 2170       |\n",
      "|    policy_gradient_loss | -0.00863   |\n",
      "|    reward               | 1.4369805  |\n",
      "|    std                  | 1.46       |\n",
      "|    value_loss           | 309        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 4138        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02653417  |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.6        |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | 7.42e-05    |\n",
      "|    reward               | -0.24748944 |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 4157        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0526333   |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.7        |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | 0.00832     |\n",
      "|    reward               | 0.121742934 |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 4175        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045593664 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    reward               | 1.0090175   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 4195        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039265454 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.9        |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | 0.09672117  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 223        |\n",
      "|    time_elapsed         | 4214       |\n",
      "|    total_timesteps      | 456704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03961069 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.3      |\n",
      "|    explained_variance   | 0.098      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 77.7       |\n",
      "|    n_updates            | 2220       |\n",
      "|    policy_gradient_loss | 0.00278    |\n",
      "|    reward               | 4.0268893  |\n",
      "|    std                  | 1.47       |\n",
      "|    value_loss           | 219        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 4232        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031091426 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.0953      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    reward               | 0.7758764   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3342392.07\n",
      "total_reward: 2342392.07\n",
      "total_cost: 285279.68\n",
      "total_trades: 70442\n",
      "Sharpe: 0.589\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 225        |\n",
      "|    time_elapsed         | 4252       |\n",
      "|    total_timesteps      | 460800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03311811 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.4      |\n",
      "|    explained_variance   | 0.173      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 68.2       |\n",
      "|    n_updates            | 2240       |\n",
      "|    policy_gradient_loss | -0.00329   |\n",
      "|    reward               | 2.532463   |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 170        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 4270        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017292392 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.3        |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | 0.6734313   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 4289        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028739188 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.5        |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | -1.5656823  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 4308        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020397864 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | 0.11166482  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 4327        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031624813 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | -0.82653105 |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 90.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 4347        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034000702 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.1        |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 0.6573938   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 231        |\n",
      "|    time_elapsed         | 4367       |\n",
      "|    total_timesteps      | 473088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03587835 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.6      |\n",
      "|    explained_variance   | 0.11       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.1       |\n",
      "|    n_updates            | 2300       |\n",
      "|    policy_gradient_loss | 0.000539   |\n",
      "|    reward               | -4.8155055 |\n",
      "|    std                  | 1.49       |\n",
      "|    value_loss           | 33.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 4386        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03985005  |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    reward               | -0.49090016 |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 233        |\n",
      "|    time_elapsed         | 4405       |\n",
      "|    total_timesteps      | 477184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03429509 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.8      |\n",
      "|    explained_variance   | 0.166      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 120        |\n",
      "|    n_updates            | 2320       |\n",
      "|    policy_gradient_loss | -0.000498  |\n",
      "|    reward               | 0.97576827 |\n",
      "|    std                  | 1.5        |\n",
      "|    value_loss           | 208        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 234        |\n",
      "|    time_elapsed         | 4424       |\n",
      "|    total_timesteps      | 479232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03652985 |\n",
      "|    clip_fraction        | 0.35       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.8      |\n",
      "|    explained_variance   | -0.029     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.7       |\n",
      "|    n_updates            | 2330       |\n",
      "|    policy_gradient_loss | 0.00262    |\n",
      "|    reward               | 0.14706598 |\n",
      "|    std                  | 1.5        |\n",
      "|    value_loss           | 35.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 4443        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032372482 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.5        |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    reward               | -4.6081657  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 99.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 4462        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033091296 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | -0.00831    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.5        |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    reward               | 1.5584403   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 237        |\n",
      "|    time_elapsed         | 4480       |\n",
      "|    total_timesteps      | 485376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03496676 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53        |\n",
      "|    explained_variance   | 0.0599     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 199        |\n",
      "|    n_updates            | 2360       |\n",
      "|    policy_gradient_loss | -0.00243   |\n",
      "|    reward               | -2.0685039 |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 197        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 238        |\n",
      "|    time_elapsed         | 4499       |\n",
      "|    total_timesteps      | 487424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05102829 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53        |\n",
      "|    explained_variance   | 0.0051     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14         |\n",
      "|    n_updates            | 2370       |\n",
      "|    policy_gradient_loss | 0.000812   |\n",
      "|    reward               | -0.5700166 |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 32         |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3631929.49\n",
      "total_reward: 2631929.49\n",
      "total_cost: 279782.12\n",
      "total_trades: 72034\n",
      "Sharpe: 0.646\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 4518        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032599315 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.2        |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 2.0724795   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 240        |\n",
      "|    time_elapsed         | 4536       |\n",
      "|    total_timesteps      | 491520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02712119 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.1      |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 56         |\n",
      "|    n_updates            | 2390       |\n",
      "|    policy_gradient_loss | -0.00462   |\n",
      "|    reward               | -1.5508196 |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 145        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 4555        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029977884 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | -0.0374     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | -0.7679071  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 71.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 242        |\n",
      "|    time_elapsed         | 4573       |\n",
      "|    total_timesteps      | 495616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02473622 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.2      |\n",
      "|    explained_variance   | 0.166      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 90.5       |\n",
      "|    n_updates            | 2410       |\n",
      "|    policy_gradient_loss | -0.00633   |\n",
      "|    reward               | 1.0851558  |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 152        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 4592        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021781232 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.3       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.5        |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.033095956 |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 244        |\n",
      "|    time_elapsed         | 4611       |\n",
      "|    total_timesteps      | 499712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03327313 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.3      |\n",
      "|    explained_variance   | 0.147      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 69         |\n",
      "|    n_updates            | 2430       |\n",
      "|    policy_gradient_loss | 0.00366    |\n",
      "|    reward               | -2.0418205 |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 172        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 245        |\n",
      "|    time_elapsed         | 4630       |\n",
      "|    total_timesteps      | 501760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03192702 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.3      |\n",
      "|    explained_variance   | 0.0372     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.16       |\n",
      "|    n_updates            | 2440       |\n",
      "|    policy_gradient_loss | -0.00723   |\n",
      "|    reward               | -0.8018264 |\n",
      "|    std                  | 1.53       |\n",
      "|    value_loss           | 20.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 4649        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022215625 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | 0.96504444  |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 247        |\n",
      "|    time_elapsed         | 4668       |\n",
      "|    total_timesteps      | 505856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01497755 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.5      |\n",
      "|    explained_variance   | 0.122      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.5       |\n",
      "|    n_updates            | 2460       |\n",
      "|    policy_gradient_loss | -0.00278   |\n",
      "|    reward               | 6.611339   |\n",
      "|    std                  | 1.54       |\n",
      "|    value_loss           | 177        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 4687        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038087063 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | 0.00175     |\n",
      "|    reward               | -2.312313   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 249        |\n",
      "|    time_elapsed         | 4706       |\n",
      "|    total_timesteps      | 509952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02585238 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.7      |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 60.5       |\n",
      "|    n_updates            | 2480       |\n",
      "|    policy_gradient_loss | -0.0171    |\n",
      "|    reward               | 1.8858926  |\n",
      "|    std                  | 1.55       |\n",
      "|    value_loss           | 142        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 4724        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022845848 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.0946      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    reward               | -9.817925   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 4743        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034200404 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | -0.025      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.000528   |\n",
      "|    reward               | 1.4371303   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 252        |\n",
      "|    time_elapsed         | 4762       |\n",
      "|    total_timesteps      | 516096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03305272 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.8      |\n",
      "|    explained_variance   | 0.21       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.3       |\n",
      "|    n_updates            | 2510       |\n",
      "|    policy_gradient_loss | -0.00875   |\n",
      "|    reward               | 1.210551   |\n",
      "|    std                  | 1.56       |\n",
      "|    value_loss           | 39.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2887196.68\n",
      "total_reward: 1887196.68\n",
      "total_cost: 315389.47\n",
      "total_trades: 72444\n",
      "Sharpe: 0.546\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 4780        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027497403 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.0476      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 0.30807862  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 4799        |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020195173 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.6        |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | -2.3230255  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 255       |\n",
      "|    time_elapsed         | 4818      |\n",
      "|    total_timesteps      | 522240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0460025 |\n",
      "|    clip_fraction        | 0.255     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -54       |\n",
      "|    explained_variance   | 0.00657   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 13.6      |\n",
      "|    n_updates            | 2540      |\n",
      "|    policy_gradient_loss | -0.00401  |\n",
      "|    reward               | 3.1411653 |\n",
      "|    std                  | 1.56      |\n",
      "|    value_loss           | 30.5      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 4837        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029046055 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | 5.3383193   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 4857        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019336965 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    reward               | -0.19614045 |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 4877        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040431675 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 1.1635983   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 4895        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025335966 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 0.14240122  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 4914        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028756887 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.8        |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.31603315 |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 4933        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016035572 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.0891      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.3291523   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 262        |\n",
      "|    time_elapsed         | 4951       |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03259542 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.4      |\n",
      "|    explained_variance   | 0.123      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.42       |\n",
      "|    n_updates            | 2610       |\n",
      "|    policy_gradient_loss | -0.00603   |\n",
      "|    reward               | -0.3207658 |\n",
      "|    std                  | 1.58       |\n",
      "|    value_loss           | 20.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 4970        |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018819077 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.0959      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | -0.34072888 |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 85.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 264         |\n",
      "|    time_elapsed         | 4989        |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021088053 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.0543      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.9        |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | -1.372762   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 5008        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031876553 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | -0.0282     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | -1.5842388  |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 5027        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028161075 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | -2.3006463  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4871851.93\n",
      "total_reward: 3871851.93\n",
      "total_cost: 304560.53\n",
      "total_trades: 71834\n",
      "Sharpe: 0.831\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 5046        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018667638 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.0121      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -0.5274544  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 268        |\n",
      "|    time_elapsed         | 5064       |\n",
      "|    total_timesteps      | 548864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03795746 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.7      |\n",
      "|    explained_variance   | -0.0048    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 180        |\n",
      "|    n_updates            | 2670       |\n",
      "|    policy_gradient_loss | -0.00924   |\n",
      "|    reward               | -1.2174889 |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 200        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 5083        |\n",
      "|    total_timesteps      | 550912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03986621  |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 0.084       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 2680        |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | -0.28904152 |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 5102        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023205854 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.0389      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 1.7628233   |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 271        |\n",
      "|    time_elapsed         | 5120       |\n",
      "|    total_timesteps      | 555008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01676146 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55        |\n",
      "|    explained_variance   | 0.046      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 111        |\n",
      "|    n_updates            | 2700       |\n",
      "|    policy_gradient_loss | -0.00857   |\n",
      "|    reward               | 1.501735   |\n",
      "|    std                  | 1.61       |\n",
      "|    value_loss           | 137        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 272        |\n",
      "|    time_elapsed         | 5139       |\n",
      "|    total_timesteps      | 557056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03563013 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55        |\n",
      "|    explained_variance   | -0.0371    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.1       |\n",
      "|    n_updates            | 2710       |\n",
      "|    policy_gradient_loss | -0.00984   |\n",
      "|    reward               | 2.1662436  |\n",
      "|    std                  | 1.62       |\n",
      "|    value_loss           | 35.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 5158        |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023052063 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | 0.0038      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    reward               | -0.84995854 |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 5177        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020999404 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.0199      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.1        |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -11.848608  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 275        |\n",
      "|    time_elapsed         | 5197       |\n",
      "|    total_timesteps      | 563200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03474172 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.2      |\n",
      "|    explained_variance   | -0.0144    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.6       |\n",
      "|    n_updates            | 2740       |\n",
      "|    policy_gradient_loss | -0.00433   |\n",
      "|    reward               | 0.4445469  |\n",
      "|    std                  | 1.63       |\n",
      "|    value_loss           | 38.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 276        |\n",
      "|    time_elapsed         | 5216       |\n",
      "|    total_timesteps      | 565248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03697889 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.2      |\n",
      "|    explained_variance   | 0.0536     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.4       |\n",
      "|    n_updates            | 2750       |\n",
      "|    policy_gradient_loss | -0.00833   |\n",
      "|    reward               | 1.3377545  |\n",
      "|    std                  | 1.63       |\n",
      "|    value_loss           | 41.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 5234        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023928702 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.0452      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.6        |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | -0.000292   |\n",
      "|    reward               | 0.8800601   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 278        |\n",
      "|    time_elapsed         | 5254       |\n",
      "|    total_timesteps      | 569344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03532023 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.3      |\n",
      "|    explained_variance   | -0.00716   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 159        |\n",
      "|    n_updates            | 2770       |\n",
      "|    policy_gradient_loss | -0.00794   |\n",
      "|    reward               | 1.5541068  |\n",
      "|    std                  | 1.63       |\n",
      "|    value_loss           | 138        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 279        |\n",
      "|    time_elapsed         | 5273       |\n",
      "|    total_timesteps      | 571392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03453505 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.3      |\n",
      "|    explained_variance   | -0.0521    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 2780       |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    reward               | 2.04215    |\n",
      "|    std                  | 1.64       |\n",
      "|    value_loss           | 26.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 5292        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020246651 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.0558      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 1.4520615   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 5313        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018373884 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.0626      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.3        |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 2.5622432   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3831150.38\n",
      "total_reward: 2831150.38\n",
      "total_cost: 302401.21\n",
      "total_trades: 70575\n",
      "Sharpe: 0.699\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 5332        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037174877 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -0.3771052  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 283       |\n",
      "|    time_elapsed         | 5352      |\n",
      "|    total_timesteps      | 579584    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0296062 |\n",
      "|    clip_fraction        | 0.293     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -55.7     |\n",
      "|    explained_variance   | -0.00242  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 103       |\n",
      "|    n_updates            | 2820      |\n",
      "|    policy_gradient_loss | -0.0136   |\n",
      "|    reward               | 0.5452871 |\n",
      "|    std                  | 1.66      |\n",
      "|    value_loss           | 129       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 5371        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032573454 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | -0.00991    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.6268961   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 5390        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028457103 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | 3.5442686   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 98.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 5409        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031337533 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.4         |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    reward               | -0.3702459  |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 5428        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022359818 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.0341      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 0.51004803  |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 5447        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027357468 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.00651     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 2.9334037   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 5465        |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036410496 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | -0.07       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.00094    |\n",
      "|    reward               | 3.1185145   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 5484        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024817746 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.0206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 0.05166667  |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 5503        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017805241 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | 0.02150787  |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 5522        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021964226 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.0575      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.9        |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | -0.42943832 |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 5540        |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030449852 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.00227     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.94        |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -0.04150466 |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 5559        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027495202 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.0301      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | 0.00267     |\n",
      "|    reward               | -0.09890212 |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 5578        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019890703 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | -0.00404    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.9        |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    reward               | 0.12989807  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5058351.61\n",
      "total_reward: 4058351.61\n",
      "total_cost: 275537.48\n",
      "total_trades: 70012\n",
      "Sharpe: 0.858\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 5597        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028509876 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | -0.174      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.03        |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | -2.078792   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 5617        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014542939 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | -1.9005655  |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 5635        |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021139044 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -0.84601295 |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 5655        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0330163   |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | -0.147      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | 0.00404     |\n",
      "|    reward               | -0.72344416 |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 5674        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019624706 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | -0.0313     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 0.120305434 |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 5693        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022058183 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.0455      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    reward               | 0.88361543  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 5712        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017200906 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.6        |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | -8.15209    |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 303        |\n",
      "|    time_elapsed         | 5730       |\n",
      "|    total_timesteps      | 620544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03329776 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.8      |\n",
      "|    explained_variance   | -0.168     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 3020       |\n",
      "|    policy_gradient_loss | -0.00941   |\n",
      "|    reward               | -4.1749206 |\n",
      "|    std                  | 1.72       |\n",
      "|    value_loss           | 21.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 5749        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017439492 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | 0.64715385  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 305        |\n",
      "|    time_elapsed         | 5768       |\n",
      "|    total_timesteps      | 624640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02391392 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.9      |\n",
      "|    explained_variance   | 0.0453     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 57.1       |\n",
      "|    n_updates            | 3040       |\n",
      "|    policy_gradient_loss | -0.00597   |\n",
      "|    reward               | 0.25143635 |\n",
      "|    std                  | 1.73       |\n",
      "|    value_loss           | 186        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 5787        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029602304 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.0141      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -2.8386507  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 5806        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021668762 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.3        |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 1.0876038   |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 5824        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028083201 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | -0.36635575 |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 5844        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023100242 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.0202      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.1        |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    reward               | 1.4506208   |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 213         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5324908.70\n",
      "total_reward: 4324908.70\n",
      "total_cost: 215821.81\n",
      "total_trades: 65516\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 5863        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030541185 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.4       |\n",
      "|    explained_variance   | 0.0548      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.2         |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | 1.0081518   |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 5881        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021049611 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.5        |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | 0.51088095  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 5900        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030223217 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.0171      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | 1.7298117   |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 5919        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019233827 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.0291      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | -10.6168995 |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 314        |\n",
      "|    time_elapsed         | 5938       |\n",
      "|    total_timesteps      | 643072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02174842 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.6      |\n",
      "|    explained_variance   | 0.0235     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 100        |\n",
      "|    n_updates            | 3130       |\n",
      "|    policy_gradient_loss | -0.00851   |\n",
      "|    reward               | -1.0114576 |\n",
      "|    std                  | 1.77       |\n",
      "|    value_loss           | 138        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 5957        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020218503 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.0441      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.6        |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | -7.819657   |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 5976        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023342248 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.00819     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80          |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | 1.2651532   |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 317        |\n",
      "|    time_elapsed         | 5996       |\n",
      "|    total_timesteps      | 649216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03005822 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.8      |\n",
      "|    explained_variance   | 0.133      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.1       |\n",
      "|    n_updates            | 3160       |\n",
      "|    policy_gradient_loss | 0.0032     |\n",
      "|    reward               | 0.5397285  |\n",
      "|    std                  | 1.79       |\n",
      "|    value_loss           | 23.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 318         |\n",
      "|    time_elapsed         | 6015        |\n",
      "|    total_timesteps      | 651264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021039803 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | -0.00476    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | 4.416819    |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 6034        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024560211 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.00809     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.000877   |\n",
      "|    reward               | -4.9808755  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 6053        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016316175 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.0179      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | -0.97333336 |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 6072        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020401273 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.019       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.5629907  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 322        |\n",
      "|    time_elapsed         | 6090       |\n",
      "|    total_timesteps      | 659456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03186138 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.2      |\n",
      "|    explained_variance   | 0.0418     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 84.3       |\n",
      "|    n_updates            | 3210       |\n",
      "|    policy_gradient_loss | -0.00327   |\n",
      "|    reward               | 2.907804   |\n",
      "|    std                  | 1.81       |\n",
      "|    value_loss           | 245        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 6109        |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025371753 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | -1.7041739  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5451748.85\n",
      "total_reward: 4451748.85\n",
      "total_cost: 199403.82\n",
      "total_trades: 63559\n",
      "Sharpe: 0.871\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 6128        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017915748 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | 1.4594812   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 6147        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021231677 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.3        |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    reward               | 1.3222861   |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 6166        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017708529 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.0163      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | -0.4039571  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 327        |\n",
      "|    time_elapsed         | 6184       |\n",
      "|    total_timesteps      | 669696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03254271 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.5      |\n",
      "|    explained_variance   | -0.154     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.95       |\n",
      "|    n_updates            | 3260       |\n",
      "|    policy_gradient_loss | -0.00171   |\n",
      "|    reward               | 1.0298625  |\n",
      "|    std                  | 1.83       |\n",
      "|    value_loss           | 21.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 6203        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013926293 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.8        |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | -0.12647735 |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 6222        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022829026 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    reward               | -1.2327878  |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 6240        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020245377 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.00389     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 3290        |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    reward               | -6.3782263  |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 6259        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016602762 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.00424     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    reward               | -0.22971265 |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 6278        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026013914 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    reward               | -0.2609371  |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 333        |\n",
      "|    time_elapsed         | 6297       |\n",
      "|    total_timesteps      | 681984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01893648 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.9      |\n",
      "|    explained_variance   | 0.00884    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 65.1       |\n",
      "|    n_updates            | 3320       |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    reward               | 3.536773   |\n",
      "|    std                  | 1.85       |\n",
      "|    value_loss           | 195        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 334          |\n",
      "|    time_elapsed         | 6316         |\n",
      "|    total_timesteps      | 684032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.031472005  |\n",
      "|    clip_fraction        | 0.338        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -58.9        |\n",
      "|    explained_variance   | 0.0588       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 3330         |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    reward               | -0.039081644 |\n",
      "|    std                  | 1.86         |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 6335        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015758226 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.0181      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    reward               | -0.5396002  |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 6354        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014090469 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -3.0602396  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 6373        |\n",
      "|    total_timesteps      | 690176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019266473 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | -0.0034     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    reward               | 2.2346647   |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4504576.60\n",
      "total_reward: 3504576.60\n",
      "total_cost: 255263.88\n",
      "total_trades: 67357\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 6391        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024465306 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.0153      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | 0.12968802  |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 6410        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014875432 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.034       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | 0.46769238  |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 6428        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023310281 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | -0.00677    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73          |\n",
      "|    n_updates            | 3390        |\n",
      "|    policy_gradient_loss | 0.00108     |\n",
      "|    reward               | -2.186942   |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 6448        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026293308 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.0195      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -1.9067538  |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 6469        |\n",
      "|    total_timesteps      | 700416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016048629 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.00644     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    reward               | 0.04062053  |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 6487        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018240876 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.0459      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    reward               | 0.7377973   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 6506        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015333016 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 1.5815037   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 6525        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017705083 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.000873    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 214         |\n",
      "|    n_updates            | 3440        |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    reward               | 1.3883595   |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 6543        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015472695 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.0316      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.9        |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 2.0119128   |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 282         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 6562        |\n",
      "|    total_timesteps      | 710656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020803593 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | -0.0395     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | -1.4525566  |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 75.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 6581        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015792854 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.9       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | -0.09044128 |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 6600        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023254089 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.036       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.6        |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    reward               | 1.334983    |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 6618        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017770402 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.0998      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.4        |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | -2.4845202  |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 6637        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024757717 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | -0.0309     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | 0.3151518   |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2952630.86\n",
      "total_reward: 1952630.86\n",
      "total_cost: 295427.25\n",
      "total_trades: 68094\n",
      "Sharpe: 0.547\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 352        |\n",
      "|    time_elapsed         | 6656       |\n",
      "|    total_timesteps      | 720896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02821625 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.1      |\n",
      "|    explained_variance   | 3.29e-05   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 255        |\n",
      "|    n_updates            | 3510       |\n",
      "|    policy_gradient_loss | -0.00868   |\n",
      "|    reward               | -0.8892708 |\n",
      "|    std                  | 1.93       |\n",
      "|    value_loss           | 226        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 6674        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017099984 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.0654      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    reward               | -5.237297   |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 354        |\n",
      "|    time_elapsed         | 6693       |\n",
      "|    total_timesteps      | 724992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02306794 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.2      |\n",
      "|    explained_variance   | 0.0447     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.7       |\n",
      "|    n_updates            | 3530       |\n",
      "|    policy_gradient_loss | -0.00752   |\n",
      "|    reward               | -3.180422  |\n",
      "|    std                  | 1.93       |\n",
      "|    value_loss           | 87.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 6712        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015324296 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.0429      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.9        |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.00987    |\n",
      "|    reward               | 0.6692408   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 270         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 6731        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017177027 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.0255      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    reward               | -1.5501063  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 6749        |\n",
      "|    total_timesteps      | 731136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016304776 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.0221      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | 0.04643628  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 6768        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0388628   |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.0777      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -0.23444878 |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 6787        |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018325832 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | -1.9700539  |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 6806        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021060836 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | -0.0166     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 1.2792054   |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 6825        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033632927 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.5       |\n",
      "|    explained_variance   | -0.0296     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | -0.18747005 |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 362        |\n",
      "|    time_elapsed         | 6844       |\n",
      "|    total_timesteps      | 741376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01619699 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.6      |\n",
      "|    explained_variance   | 0.0979     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 124        |\n",
      "|    n_updates            | 3610       |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    reward               | 0.8918226  |\n",
      "|    std                  | 1.97       |\n",
      "|    value_loss           | 122        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 6863        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023114342 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.5        |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | -25.858168  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 94.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 6882        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018466108 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.0117      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | 0.62028307  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 6900        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024299998 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.0218      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8           |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 2.3273778   |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3024403.49\n",
      "total_reward: 2024403.49\n",
      "total_cost: 288845.30\n",
      "total_trades: 67998\n",
      "Sharpe: 0.554\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 366        |\n",
      "|    time_elapsed         | 6919       |\n",
      "|    total_timesteps      | 749568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02514613 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.7      |\n",
      "|    explained_variance   | 0.115      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.5       |\n",
      "|    n_updates            | 3650       |\n",
      "|    policy_gradient_loss | 9.41e-05   |\n",
      "|    reward               | 2.1345391  |\n",
      "|    std                  | 1.98       |\n",
      "|    value_loss           | 102        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 367         |\n",
      "|    time_elapsed         | 6938        |\n",
      "|    total_timesteps      | 751616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021910101 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.9        |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | 3.9600763   |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 6957        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022009233 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | -0.027      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 0.7934206   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 6975        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021670463 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.0018      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -0.6371809  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 6994        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022411719 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.0314      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.2        |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | 0.7305459   |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 7013        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026419505 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | -0.0678     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | -1.7639929  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 372        |\n",
      "|    time_elapsed         | 7032       |\n",
      "|    total_timesteps      | 761856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02305965 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.1      |\n",
      "|    explained_variance   | 0.00243    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 80.5       |\n",
      "|    n_updates            | 3710       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | 1.130414   |\n",
      "|    std                  | 2          |\n",
      "|    value_loss           | 141        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 7051        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022493511 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.0173      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -1.5106963  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 7069        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022778396 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.0146      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.7        |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | 0.50817734  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 375        |\n",
      "|    time_elapsed         | 7089       |\n",
      "|    total_timesteps      | 768000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02230272 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.3      |\n",
      "|    explained_variance   | 0.0103     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.5       |\n",
      "|    n_updates            | 3740       |\n",
      "|    policy_gradient_loss | -0.00977   |\n",
      "|    reward               | 0.8655114  |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 29.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 376        |\n",
      "|    time_elapsed         | 7107       |\n",
      "|    total_timesteps      | 770048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01818637 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.3      |\n",
      "|    explained_variance   | 0.0115     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 187        |\n",
      "|    n_updates            | 3750       |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    reward               | 0.20123611 |\n",
      "|    std                  | 2.02       |\n",
      "|    value_loss           | 199        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 7126        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017873336 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.025       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82          |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | 0.24118733  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 7145        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023161106 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | -0.012      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | 3.076598    |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 7163        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016747309 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.0309      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.4        |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 0.039901022 |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3087245.02\n",
      "total_reward: 2087245.02\n",
      "total_cost: 315846.81\n",
      "total_trades: 69384\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 7182        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038041793 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.00675     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.9        |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | 0.21838032  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 94.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 381         |\n",
      "|    time_elapsed         | 7201        |\n",
      "|    total_timesteps      | 780288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027948275 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.0351      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.7        |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    reward               | -0.36566427 |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 7219        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026974216 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 1.1600329   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 7238        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022289582 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.0382      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 0.78978956  |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 384        |\n",
      "|    time_elapsed         | 7257       |\n",
      "|    total_timesteps      | 786432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01413933 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.7      |\n",
      "|    explained_variance   | 0.0871     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.9       |\n",
      "|    n_updates            | 3830       |\n",
      "|    policy_gradient_loss | -0.00874   |\n",
      "|    reward               | 4.379089   |\n",
      "|    std                  | 2.05       |\n",
      "|    value_loss           | 127        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 7276        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037941866 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | -0.103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | -2.0263302  |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 7294        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018070182 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | -0.00245    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 171         |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 1.296403    |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 7313        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022470932 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.00737     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 2.3819811   |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 388        |\n",
      "|    time_elapsed         | 7333       |\n",
      "|    total_timesteps      | 794624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0284182  |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62        |\n",
      "|    explained_variance   | -0.0543    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.9       |\n",
      "|    n_updates            | 3870       |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    reward               | 0.48889545 |\n",
      "|    std                  | 2.06       |\n",
      "|    value_loss           | 33.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 389        |\n",
      "|    time_elapsed         | 7352       |\n",
      "|    total_timesteps      | 796672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01691376 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.1      |\n",
      "|    explained_variance   | 0.00113    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47.1       |\n",
      "|    n_updates            | 3880       |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    reward               | 2.3893993  |\n",
      "|    std                  | 2.07       |\n",
      "|    value_loss           | 78.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 7371        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029919416 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.0213      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.6280906   |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 7390        |\n",
      "|    total_timesteps      | 800768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026117578 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | -0.0707     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 0.13085729  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 7410        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0328981   |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.4       |\n",
      "|    explained_variance   | -0.0188     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | -0.56017286 |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 7428        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025802862 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.4       |\n",
      "|    explained_variance   | -0.00577    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.7015691  |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 7448        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023313623 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.0467      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57          |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 1.2875407   |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3971003.69\n",
      "total_reward: 2971003.69\n",
      "total_cost: 352283.97\n",
      "total_trades: 73777\n",
      "Sharpe: 0.701\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 7467        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021966945 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | -0.0183     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 1.5577546   |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 59.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 7485        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020513155 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.0332      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.9        |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | 1.4550214   |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 397        |\n",
      "|    time_elapsed         | 7504       |\n",
      "|    total_timesteps      | 813056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01797086 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.7      |\n",
      "|    explained_variance   | 0.0634     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 58.1       |\n",
      "|    n_updates            | 3960       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | -1.2300727 |\n",
      "|    std                  | 2.11       |\n",
      "|    value_loss           | 166        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 7523        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020145752 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.3        |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -4.3084674  |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 7542        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031480145 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | -0.0601     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -5.40769    |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 400        |\n",
      "|    time_elapsed         | 7560       |\n",
      "|    total_timesteps      | 819200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01997289 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.9      |\n",
      "|    explained_variance   | 0.0607     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.5       |\n",
      "|    n_updates            | 3990       |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    reward               | -0.8687677 |\n",
      "|    std                  | 2.13       |\n",
      "|    value_loss           | 112        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 401        |\n",
      "|    time_elapsed         | 7579       |\n",
      "|    total_timesteps      | 821248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02212307 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.9      |\n",
      "|    explained_variance   | -0.00263   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.5       |\n",
      "|    n_updates            | 4000       |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    reward               | -3.9355993 |\n",
      "|    std                  | 2.13       |\n",
      "|    value_loss           | 164        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 7597        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033208806 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | -0.0256     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.65962577  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 7616        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018739626 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.6        |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -0.58625096 |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 7635        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022904087 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.0386      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.5        |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 5.3224053   |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 7654        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022837108 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | -0.00258    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | 2.6119504   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 406         |\n",
      "|    time_elapsed         | 7672        |\n",
      "|    total_timesteps      | 831488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034544766 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | -0.0479     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 4050        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 1.1579037   |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 7691        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021567889 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.0016      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.1        |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | 2.0850441   |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 7710        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019165136 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.0252      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | 1.0316133   |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3178920.08\n",
      "total_reward: 2178920.08\n",
      "total_cost: 320209.71\n",
      "total_trades: 69397\n",
      "Sharpe: 0.697\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 7728        |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023931883 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | -0.137      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.48        |\n",
      "|    n_updates            | 4080        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -5.13022    |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 7748        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020769473 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.00038     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    reward               | 1.3793564   |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 7768        |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01878766  |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.00042     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.116190456 |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 7787        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03060722  |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | -0.012      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    reward               | -0.15844512 |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 7805        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016538294 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.00764     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -3.1001923  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 414        |\n",
      "|    time_elapsed         | 7824       |\n",
      "|    total_timesteps      | 847872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01846359 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.8      |\n",
      "|    explained_variance   | -0.00224   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.3       |\n",
      "|    n_updates            | 4130       |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    reward               | -0.8188069 |\n",
      "|    std                  | 2.19       |\n",
      "|    value_loss           | 111        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 7843        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014093328 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | -0.00666    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.2        |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 0.42250285  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 7863        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025814563 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | -0.0547     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | 0.044944    |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 7882        |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017748427 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.00278     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.1        |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    reward               | -0.10562966 |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 7902        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022597333 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.00419     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.6697694   |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 7921        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030780084 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | 0.0023      |\n",
      "|    reward               | -0.04209296 |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 7941        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014960563 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.00568     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.3        |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | -0.15233603 |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 7960        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021344053 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.0193      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.3        |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -0.46108848 |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 7978        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025893793 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.0062      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.3        |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | 0.000245    |\n",
      "|    reward               | 1.7965183   |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 257         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5577826.92\n",
      "total_reward: 4577826.92\n",
      "total_cost: 244089.21\n",
      "total_trades: 64434\n",
      "Sharpe: 0.917\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 7997        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029225007 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.0974      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.83        |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    reward               | 0.36373994  |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 8017        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025422424 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.00241     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.8        |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    reward               | -1.2386936  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 8036        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026679574 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.00222     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | -9.762568   |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 8056        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028624494 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | -0.0043     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | -2.8306522  |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 8075        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019989995 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.0038      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.6        |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | -0.15978895 |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 8094        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027966445 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.00598     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56          |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | -9.642491   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 8112        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025966763 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.0663      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | -0.23241794 |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 430        |\n",
      "|    time_elapsed         | 8131       |\n",
      "|    total_timesteps      | 880640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02142366 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.8      |\n",
      "|    explained_variance   | -0.0873    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.56       |\n",
      "|    n_updates            | 4290       |\n",
      "|    policy_gradient_loss | -0.00915   |\n",
      "|    reward               | 0.35449308 |\n",
      "|    std                  | 2.27       |\n",
      "|    value_loss           | 19.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 8149        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026464125 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | -0.00299    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69          |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -1.6279109  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 96.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 8168        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023945741 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.0464      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.5040143  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 65.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 8187        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030022569 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | -0.0466     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.01        |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | -4.9079995  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 434        |\n",
      "|    time_elapsed         | 8206       |\n",
      "|    total_timesteps      | 888832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01562883 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65        |\n",
      "|    explained_variance   | 0.165      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.2       |\n",
      "|    n_updates            | 4330       |\n",
      "|    policy_gradient_loss | -0.00748   |\n",
      "|    reward               | 2.4143531  |\n",
      "|    std                  | 2.29       |\n",
      "|    value_loss           | 53         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 8224        |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030407509 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.00542     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.29399645  |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 71.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 8243        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024610339 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | -0.0178     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    reward               | 2.8091488   |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1934913.12\n",
      "total_reward: 934913.12\n",
      "total_cost: 288736.32\n",
      "total_trades: 68125\n",
      "Sharpe: 0.405\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 8262        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017939672 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | -1.6067309  |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 72          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 8281        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025078304 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.0461      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | 1.422667    |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 8299        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011494542 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.0189      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    reward               | 1.0256027   |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 8318        |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016475137 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.65        |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | -0.3229573  |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 8336        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017587876 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.0474      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -1.0476487  |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 8356        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016234905 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.0014     |\n",
      "|    reward               | 1.1054587   |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 8375        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020862633 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.0608      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | 0.00365     |\n",
      "|    reward               | 2.3760834   |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 8395        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012922779 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.0372      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | -0.39020705 |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 8414        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008712758 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | -1.9615067  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 8433        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013860293 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.0545      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    reward               | 0.6601351   |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 8452        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017424008 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | 0.70537984  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 8471        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020700075 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.23380597  |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 8490        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012967701 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 0.43832946  |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 8509        |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018522087 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -1.7703214  |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2350459.00\n",
      "total_reward: 1350459.00\n",
      "total_cost: 284072.32\n",
      "total_trades: 67381\n",
      "Sharpe: 0.486\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 451       |\n",
      "|    time_elapsed         | 8528      |\n",
      "|    total_timesteps      | 923648    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0191328 |\n",
      "|    clip_fraction        | 0.18      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -65.5     |\n",
      "|    explained_variance   | 0.21      |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 10.2      |\n",
      "|    n_updates            | 4500      |\n",
      "|    policy_gradient_loss | -0.00494  |\n",
      "|    reward               | 0.4301813 |\n",
      "|    std                  | 2.33      |\n",
      "|    value_loss           | 35.1      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 8548        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025339955 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | -4.9024944  |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 8566        |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019503696 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.0674      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -1.1351203  |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 8585        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030798297 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.8         |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | 0.000287    |\n",
      "|    reward               | 1.2433314   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 455        |\n",
      "|    time_elapsed         | 8605       |\n",
      "|    total_timesteps      | 931840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0140129  |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.7      |\n",
      "|    explained_variance   | 0.0169     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 4540       |\n",
      "|    policy_gradient_loss | -0.00896   |\n",
      "|    reward               | 0.74488133 |\n",
      "|    std                  | 2.34       |\n",
      "|    value_loss           | 38.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 8625        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014684238 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | -0.633253   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 8645        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024274394 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | 0.00684     |\n",
      "|    reward               | -6.531354   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 8664        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023204695 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.75        |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | -6.710693   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 8683        |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027465507 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.0749      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | 1.2803351   |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 78.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 8702        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020890472 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -1.9310919  |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 8721        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027830033 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | -0.0052     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    reward               | -0.08509375 |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 8740        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040018555 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | -0.73713845 |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 8759        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027132632 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.0568      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.3        |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | -1.6735246  |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 51.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 464        |\n",
      "|    time_elapsed         | 8779       |\n",
      "|    total_timesteps      | 950272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03008471 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.1      |\n",
      "|    explained_variance   | -0.0192    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 4630       |\n",
      "|    policy_gradient_loss | -0.00782   |\n",
      "|    reward               | -2.0378685 |\n",
      "|    std                  | 2.38       |\n",
      "|    value_loss           | 23.4       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4069340.72\n",
      "total_reward: 3069340.72\n",
      "total_cost: 318361.49\n",
      "total_trades: 70273\n",
      "Sharpe: 0.727\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 8798        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014098196 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.0337      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | 1.3528491   |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 8817        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024618931 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.0419      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | -7.8222365  |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 8835        |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023405515 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | -0.000643   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    reward               | 1.1314025   |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 468        |\n",
      "|    time_elapsed         | 8855       |\n",
      "|    total_timesteps      | 958464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03687822 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.5      |\n",
      "|    explained_variance   | 0.00598    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.5       |\n",
      "|    n_updates            | 4670       |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    reward               | 0.9965286  |\n",
      "|    std                  | 2.42       |\n",
      "|    value_loss           | 96.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 8874        |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029752303 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.00446     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.3        |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | -0.3973988  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 8893        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026550835 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | -0.00169    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -2.2866092  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 8912        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033117987 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | -0.0109     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 0.07694388  |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 8931        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027818378 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.00487     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.6        |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | -0.66765314 |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 8950        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027694054 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | -0.000127   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | -0.32619786 |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 474       |\n",
      "|    time_elapsed         | 8969      |\n",
      "|    total_timesteps      | 970752    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.027463  |\n",
      "|    clip_fraction        | 0.282     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -67.1     |\n",
      "|    explained_variance   | 0.0277    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 13.3      |\n",
      "|    n_updates            | 4730      |\n",
      "|    policy_gradient_loss | -0.0139   |\n",
      "|    reward               | 4.0521035 |\n",
      "|    std                  | 2.46      |\n",
      "|    value_loss           | 22.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 8989        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023163563 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.0382      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | -0.23695375 |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 87.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 9008        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023197943 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.00314     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.72527134  |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 80.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 9027        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032943077 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | -0.00174    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    reward               | -1.0125109  |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 9046        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025105156 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | -0.0238     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.36        |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 1.3304462   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3908711.09\n",
      "total_reward: 2908711.09\n",
      "total_cost: 329560.94\n",
      "total_trades: 69784\n",
      "Sharpe: 0.766\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 9065        |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018791636 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -2.1520963  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 9083        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037173066 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | -0.00475    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.9        |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | -2.0712311  |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 98.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 9102        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035270922 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | -0.0593     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 2.1210747   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 9121        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023299035 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.00901     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.1        |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -0.43828452 |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 71          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 9140        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025112139 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | -0.0126     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.1        |\n",
      "|    n_updates            | 4820        |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    reward               | -10.435973  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 99.2        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 484       |\n",
      "|    time_elapsed         | 9158      |\n",
      "|    total_timesteps      | 991232    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.021354  |\n",
      "|    clip_fraction        | 0.25      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -68       |\n",
      "|    explained_variance   | -0.0371   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 11.6      |\n",
      "|    n_updates            | 4830      |\n",
      "|    policy_gradient_loss | -0.00867  |\n",
      "|    reward               | 2.1595123 |\n",
      "|    std                  | 2.54      |\n",
      "|    value_loss           | 29.5      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 9177        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019748375 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.0144      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    reward               | -0.66071427 |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 9195        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025589846 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | -0.00277    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.8152508   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 70.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 9214        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019550987 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | -0.0166     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 0.5152719   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 9233        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020774886 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.0277      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.33        |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | 0.42179435  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 489         |\n",
      "|    time_elapsed         | 9252        |\n",
      "|    total_timesteps      | 1001472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023687234 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.00335     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.2        |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | -0.0932781  |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 90.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 9271        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025182262 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | -0.0017     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | 0.29161772  |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 9289        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022008039 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.0163      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | 3.3018053   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 9308        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014473364 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.0354      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 2.2716284   |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5954812.29\n",
      "total_reward: 4954812.29\n",
      "total_cost: 322233.70\n",
      "total_trades: 69872\n",
      "Sharpe: 0.917\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 9327        |\n",
      "|    total_timesteps      | 1009664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022445384 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | -0.00305    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 4920        |\n",
      "|    policy_gradient_loss | 0.00284     |\n",
      "|    reward               | 0.017398978 |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 494          |\n",
      "|    time_elapsed         | 9346         |\n",
      "|    total_timesteps      | 1011712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143886255 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.5        |\n",
      "|    explained_variance   | 0.0266       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 4930         |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    reward               | 0.8032201    |\n",
      "|    std                  | 2.58         |\n",
      "|    value_loss           | 229          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 9364        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029615346 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | -0.0449     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    reward               | -0.9202921  |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 496          |\n",
      "|    time_elapsed         | 9383         |\n",
      "|    total_timesteps      | 1015808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136273075 |\n",
      "|    clip_fraction        | 0.0998       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.6        |\n",
      "|    explained_variance   | 0.0626       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 4950         |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    reward               | -0.42202672  |\n",
      "|    std                  | 2.59         |\n",
      "|    value_loss           | 289          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 497          |\n",
      "|    time_elapsed         | 9402         |\n",
      "|    total_timesteps      | 1017856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132023655 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.6        |\n",
      "|    explained_variance   | 0.0227       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.8         |\n",
      "|    n_updates            | 4960         |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | 2.7439013    |\n",
      "|    std                  | 2.59         |\n",
      "|    value_loss           | 400          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 9420        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025713153 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.0556      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -0.23822294 |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 9439        |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014794237 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.0352      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    reward               | -0.9585422  |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 9458        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013812341 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.0587      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73          |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | -1.6560067  |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 251         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 501         |\n",
      "|    time_elapsed         | 9477        |\n",
      "|    total_timesteps      | 1026048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027017495 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.0233      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 5000        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.49283415  |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 64.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 502        |\n",
      "|    time_elapsed         | 9496       |\n",
      "|    total_timesteps      | 1028096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02329624 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.8      |\n",
      "|    explained_variance   | 0.0395     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 117        |\n",
      "|    n_updates            | 5010       |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    reward               | -0.178321  |\n",
      "|    std                  | 2.61       |\n",
      "|    value_loss           | 172        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 503         |\n",
      "|    time_elapsed         | 9515        |\n",
      "|    total_timesteps      | 1030144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012835124 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.0409      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 5020        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.74946314  |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 9534        |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017186686 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.0265      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 244         |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | -6.4204607  |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 324         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 9554        |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023794973 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | -0.0308     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -1.7847124  |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 9573        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015151989 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.00416     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | 1.0005097   |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 9592        |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016605847 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.0427      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 201         |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 5.395656    |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6642862.77\n",
      "total_reward: 5642862.77\n",
      "total_cost: 307095.09\n",
      "total_trades: 68267\n",
      "Sharpe: 0.944\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 508         |\n",
      "|    time_elapsed         | 9611        |\n",
      "|    total_timesteps      | 1040384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019994635 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | -0.00567    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | -0.85184854 |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 509        |\n",
      "|    time_elapsed         | 9630       |\n",
      "|    total_timesteps      | 1042432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01575968 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.2      |\n",
      "|    explained_variance   | 0.025      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 235        |\n",
      "|    n_updates            | 5080       |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    reward               | 0.43780968 |\n",
      "|    std                  | 2.65       |\n",
      "|    value_loss           | 229        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 9649        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019194663 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.0634      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.1        |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | 0.1378245   |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 9669        |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015620059 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.0544      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72          |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 1.6872913   |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 512        |\n",
      "|    time_elapsed         | 9687       |\n",
      "|    total_timesteps      | 1048576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03428732 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.4      |\n",
      "|    explained_variance   | -0.108     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.56       |\n",
      "|    n_updates            | 5110       |\n",
      "|    policy_gradient_loss | -0.00768   |\n",
      "|    reward               | -1.9333843 |\n",
      "|    std                  | 2.66       |\n",
      "|    value_loss           | 23.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 513        |\n",
      "|    time_elapsed         | 9706       |\n",
      "|    total_timesteps      | 1050624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01372542 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.4      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47.6       |\n",
      "|    n_updates            | 5120       |\n",
      "|    policy_gradient_loss | -0.00518   |\n",
      "|    reward               | 0.30445707 |\n",
      "|    std                  | 2.67       |\n",
      "|    value_loss           | 149        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 9725        |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026234929 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.0265      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 5130        |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    reward               | 5.247774    |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 9743        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022410408 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.00438     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | -2.0846286  |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 9762        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017461278 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | -2.9039252  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 9781        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019743444 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.0305      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.6        |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | -0.2499832  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 9799        |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022862505 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.0141      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 1.6841843   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 9818        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03149136  |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | -0.42100528 |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 9837        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021373492 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -0.52413815 |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 521         |\n",
      "|    time_elapsed         | 9855        |\n",
      "|    total_timesteps      | 1067008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016162142 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.0637      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.1        |\n",
      "|    n_updates            | 5200        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 1.1150069   |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2736016.65\n",
      "total_reward: 1736016.65\n",
      "total_cost: 349142.45\n",
      "total_trades: 69226\n",
      "Sharpe: 0.560\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 9874        |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028467271 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | -0.266      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.36        |\n",
      "|    n_updates            | 5210        |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    reward               | 0.16497122  |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 9893        |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020399299 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.0173      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    reward               | 1.4805559   |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 9912        |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023649247 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.00118     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 0.025199851 |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 9932        |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023635581 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | -0.024      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 5240        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -0.10397662 |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 9951        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01815661  |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.0268      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    reward               | 0.069787435 |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 89.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 9969        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017464753 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.7        |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -0.7731255  |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 528         |\n",
      "|    time_elapsed         | 9988        |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017598871 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.0844      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 0.5537414   |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 97.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 10007       |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014503628 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 0.081283316 |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 10025       |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020297147 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    reward               | -0.7784241  |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 66.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 10044       |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017411908 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | -1.8589449  |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 68.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 10063       |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025475748 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | 0.4748754   |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 533        |\n",
      "|    time_elapsed         | 10081      |\n",
      "|    total_timesteps      | 1091584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02022488 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.5      |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.3       |\n",
      "|    n_updates            | 5320       |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    reward               | -1.6685121 |\n",
      "|    std                  | 2.77       |\n",
      "|    value_loss           | 59.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 10101       |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022481607 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -0.40374038 |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 535           |\n",
      "|    time_elapsed         | 10120         |\n",
      "|    total_timesteps      | 1095680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.020851832   |\n",
      "|    clip_fraction        | 0.245         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -70.7         |\n",
      "|    explained_variance   | 0.0449        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15            |\n",
      "|    n_updates            | 5340          |\n",
      "|    policy_gradient_loss | -0.0124       |\n",
      "|    reward               | -0.0062495023 |\n",
      "|    std                  | 2.79          |\n",
      "|    value_loss           | 48.3          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3272698.71\n",
      "total_reward: 2272698.71\n",
      "total_cost: 277882.60\n",
      "total_trades: 65124\n",
      "Sharpe: 0.626\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 10139       |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014061676 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.39        |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    reward               | 1.1035093   |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 10158       |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014035432 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.0891      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.6        |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | -0.2010285  |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 86.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 538         |\n",
      "|    time_elapsed         | 10178       |\n",
      "|    total_timesteps      | 1101824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013121926 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | -0.47726455 |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 86.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 539         |\n",
      "|    time_elapsed         | 10197       |\n",
      "|    total_timesteps      | 1103872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017116705 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 5380        |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | 0.938614    |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 540         |\n",
      "|    time_elapsed         | 10216       |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018117458 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.0805      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    reward               | 0.554944    |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 84.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 10236       |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016378548 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.0324      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.9        |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | -11.723829  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 542        |\n",
      "|    time_elapsed         | 10255      |\n",
      "|    total_timesteps      | 1110016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02203055 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71        |\n",
      "|    explained_variance   | 0.0174     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 222        |\n",
      "|    n_updates            | 5410       |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    reward               | 4.2842474  |\n",
      "|    std                  | 2.81       |\n",
      "|    value_loss           | 176        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 10273       |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017781401 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | -0.00556    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 1.9148076   |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 10292       |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018975161 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.0349      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | -1.0278661  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 545        |\n",
      "|    time_elapsed         | 10311      |\n",
      "|    total_timesteps      | 1116160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02165728 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.2      |\n",
      "|    explained_variance   | 0.0112     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40         |\n",
      "|    n_updates            | 5440       |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    reward               | 0.80720186 |\n",
      "|    std                  | 2.84       |\n",
      "|    value_loss           | 176        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 10330       |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020989545 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | 0.796315    |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 547          |\n",
      "|    time_elapsed         | 10349        |\n",
      "|    total_timesteps      | 1120256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0141033735 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.4        |\n",
      "|    explained_variance   | 0.0622       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38           |\n",
      "|    n_updates            | 5460         |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    reward               | 5.1748104    |\n",
      "|    std                  | 2.85         |\n",
      "|    value_loss           | 214          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 10368       |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007213315 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | -0.0132     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 262         |\n",
      "|    n_updates            | 5470        |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | -2.5930793  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 598         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 10386       |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014336955 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | -0.0255     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.9        |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 2.4594567   |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3857633.03\n",
      "total_reward: 2857633.03\n",
      "total_cost: 311781.85\n",
      "total_trades: 65897\n",
      "Sharpe: 0.717\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 10405       |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005732446 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | -0.0587     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 500         |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | -0.96053565 |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 537         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 551        |\n",
      "|    time_elapsed         | 10424      |\n",
      "|    total_timesteps      | 1128448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02393939 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.5      |\n",
      "|    explained_variance   | -0.0648    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42         |\n",
      "|    n_updates            | 5500       |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    reward               | 0.29866967 |\n",
      "|    std                  | 2.87       |\n",
      "|    value_loss           | 155        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 552        |\n",
      "|    time_elapsed         | 10442      |\n",
      "|    total_timesteps      | 1130496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01918323 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.6      |\n",
      "|    explained_variance   | -0.0122    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 126        |\n",
      "|    n_updates            | 5510       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | -1.3963896 |\n",
      "|    std                  | 2.88       |\n",
      "|    value_loss           | 180        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 10462       |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035233434 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.97        |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.66075665 |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 10480       |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017865453 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.00175     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.6        |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 0.5762993   |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 10499       |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019153306 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | -0.00205    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.81811845  |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 10518       |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020353585 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.0359      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -1.2455028  |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 10536       |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024453074 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.0339      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | -2.190174   |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 558        |\n",
      "|    time_elapsed         | 10555      |\n",
      "|    total_timesteps      | 1142784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01562855 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72        |\n",
      "|    explained_variance   | 0.021      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.7       |\n",
      "|    n_updates            | 5570       |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    reward               | 0.11712872 |\n",
      "|    std                  | 2.91       |\n",
      "|    value_loss           | 147        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 10573       |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010786067 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.0119      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -0.33038187 |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 84.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 10592       |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012555847 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 1.1728103   |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 10611       |\n",
      "|    total_timesteps      | 1148928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012836811 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | -0.0361     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -0.1328936  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 562         |\n",
      "|    time_elapsed         | 10630       |\n",
      "|    total_timesteps      | 1150976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012573689 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.0617      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.8        |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 8.990063    |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 10649       |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009530798 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | -0.0188     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.4        |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -0.6562196  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3035416.33\n",
      "total_reward: 2035416.33\n",
      "total_cost: 335251.77\n",
      "total_trades: 67916\n",
      "Sharpe: 0.567\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 564          |\n",
      "|    time_elapsed         | 10668        |\n",
      "|    total_timesteps      | 1155072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074311374 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.2        |\n",
      "|    explained_variance   | -0.0209      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 529          |\n",
      "|    n_updates            | 5630         |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | 0.92555165   |\n",
      "|    std                  | 2.93         |\n",
      "|    value_loss           | 815          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 565        |\n",
      "|    time_elapsed         | 10687      |\n",
      "|    total_timesteps      | 1157120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01531635 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.2      |\n",
      "|    explained_variance   | -0.0953    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 77.6       |\n",
      "|    n_updates            | 5640       |\n",
      "|    policy_gradient_loss | -0.00906   |\n",
      "|    reward               | -54.659386 |\n",
      "|    std                  | 2.94       |\n",
      "|    value_loss           | 229        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 566        |\n",
      "|    time_elapsed         | 10705      |\n",
      "|    total_timesteps      | 1159168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01612246 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.3      |\n",
      "|    explained_variance   | 0.0167     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 122        |\n",
      "|    n_updates            | 5650       |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    reward               | 3.3391554  |\n",
      "|    std                  | 2.94       |\n",
      "|    value_loss           | 232        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 567         |\n",
      "|    time_elapsed         | 10724       |\n",
      "|    total_timesteps      | 1161216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022815978 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | -0.052      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | -5.2774415  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 65.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 10743       |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015431097 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.0625      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    reward               | -0.27697757 |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 10763       |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018398393 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | -0.0283     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    reward               | -5.74309    |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 570          |\n",
      "|    time_elapsed         | 10782        |\n",
      "|    total_timesteps      | 1167360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020077817  |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.4        |\n",
      "|    explained_variance   | -0.132       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 5690         |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    reward               | -0.036875367 |\n",
      "|    std                  | 2.96         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 10802       |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015883164 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.0741      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 0.40329957  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 572         |\n",
      "|    time_elapsed         | 10822       |\n",
      "|    total_timesteps      | 1171456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016100012 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.8        |\n",
      "|    n_updates            | 5710        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -3.2848046  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 10840       |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025099792 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | -0.0197     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 5720        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -1.1360146  |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 10859       |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014766768 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | -0.0535     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 5730        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -1.2856553  |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 67          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 10878       |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015881967 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | -0.00644    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | -1.7337298  |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 287         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 10897       |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009653244 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.0467      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.1        |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | -3.7110732  |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 10916       |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023429744 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.07        |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | 0.19183257  |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3588556.79\n",
      "total_reward: 2588556.79\n",
      "total_cost: 332467.15\n",
      "total_trades: 68199\n",
      "Sharpe: 0.661\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 10935       |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010472934 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.6246996   |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 579         |\n",
      "|    time_elapsed         | 10954       |\n",
      "|    total_timesteps      | 1185792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01592179  |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.5        |\n",
      "|    n_updates            | 5780        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.25011024 |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 10973       |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017628621 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -0.4120853  |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 581        |\n",
      "|    time_elapsed         | 10992      |\n",
      "|    total_timesteps      | 1189888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01871882 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73        |\n",
      "|    explained_variance   | 0.225      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44.3       |\n",
      "|    n_updates            | 5800       |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    reward               | 0.66863376 |\n",
      "|    std                  | 3.02       |\n",
      "|    value_loss           | 90.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 582         |\n",
      "|    time_elapsed         | 11011       |\n",
      "|    total_timesteps      | 1191936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025342377 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.0334      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -0.350947   |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 583        |\n",
      "|    time_elapsed         | 11031      |\n",
      "|    total_timesteps      | 1193984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02222533 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.2      |\n",
      "|    explained_variance   | 0.00617    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 79.5       |\n",
      "|    n_updates            | 5820       |\n",
      "|    policy_gradient_loss | -0.00871   |\n",
      "|    reward               | 0.5360918  |\n",
      "|    std                  | 3.04       |\n",
      "|    value_loss           | 203        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 11050       |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023143772 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 5830        |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    reward               | 0.27826384  |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 11070       |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020004878 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.0459      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.5        |\n",
      "|    n_updates            | 5840        |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 0.5187882   |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 586         |\n",
      "|    time_elapsed         | 11088       |\n",
      "|    total_timesteps      | 1200128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018002551 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.0345      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 5850        |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | 1.3008479   |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 587           |\n",
      "|    time_elapsed         | 11107         |\n",
      "|    total_timesteps      | 1202176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.028404895   |\n",
      "|    clip_fraction        | 0.31          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -73.4         |\n",
      "|    explained_variance   | -0.0301       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.4          |\n",
      "|    n_updates            | 5860          |\n",
      "|    policy_gradient_loss | -0.00214      |\n",
      "|    reward               | -0.0026192968 |\n",
      "|    std                  | 3.06          |\n",
      "|    value_loss           | 23.6          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 588        |\n",
      "|    time_elapsed         | 11126      |\n",
      "|    total_timesteps      | 1204224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01652644 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.4      |\n",
      "|    explained_variance   | 0.0288     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.1       |\n",
      "|    n_updates            | 5870       |\n",
      "|    policy_gradient_loss | -0.00993   |\n",
      "|    reward               | 0.25788587 |\n",
      "|    std                  | 3.06       |\n",
      "|    value_loss           | 137        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 589        |\n",
      "|    time_elapsed         | 11144      |\n",
      "|    total_timesteps      | 1206272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02143098 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.5      |\n",
      "|    explained_variance   | 0.0449     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 85.8       |\n",
      "|    n_updates            | 5880       |\n",
      "|    policy_gradient_loss | -0.0084    |\n",
      "|    reward               | -9.086459  |\n",
      "|    std                  | 3.07       |\n",
      "|    value_loss           | 193        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 590        |\n",
      "|    time_elapsed         | 11163      |\n",
      "|    total_timesteps      | 1208320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03059506 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.6      |\n",
      "|    explained_variance   | 0.0346     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.9       |\n",
      "|    n_updates            | 5890       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    reward               | 2.3885007  |\n",
      "|    std                  | 3.08       |\n",
      "|    value_loss           | 52.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 591         |\n",
      "|    time_elapsed         | 11182       |\n",
      "|    total_timesteps      | 1210368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011765888 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.0653      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.3        |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | -0.54628694 |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5296336.27\n",
      "total_reward: 4296336.27\n",
      "total_cost: 289538.82\n",
      "total_trades: 65059\n",
      "Sharpe: 0.847\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 11201       |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012946386 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.0868      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.1        |\n",
      "|    n_updates            | 5910        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 0.13173923  |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 11220       |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014144246 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.071       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 1.3880584   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 11240       |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023729984 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | -0.00252    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    reward               | -5.138241   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 11259       |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017390294 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 205         |\n",
      "|    n_updates            | 5940        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -2.5419207  |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 596         |\n",
      "|    time_elapsed         | 11277       |\n",
      "|    total_timesteps      | 1220608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018943118 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.0028      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 209         |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.8038234   |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 11296       |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01733192  |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.0383      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    reward               | -0.44995964 |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 11315       |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018133236 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.0652      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | 2.6060796   |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 599         |\n",
      "|    time_elapsed         | 11334       |\n",
      "|    total_timesteps      | 1226752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021298468 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 5980        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | 1.821052    |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 11352       |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016216379 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.0396      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.1        |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 3.5664275   |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 601         |\n",
      "|    time_elapsed         | 11371       |\n",
      "|    total_timesteps      | 1230848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020643007 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.73        |\n",
      "|    n_updates            | 6000        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.8305418  |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 602        |\n",
      "|    time_elapsed         | 11390      |\n",
      "|    total_timesteps      | 1232896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01538366 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.2      |\n",
      "|    explained_variance   | 0.0467     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 95.6       |\n",
      "|    n_updates            | 6010       |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    reward               | 1.4442331  |\n",
      "|    std                  | 3.15       |\n",
      "|    value_loss           | 272        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 11409       |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014909323 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.052       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    reward               | -1.1494907  |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 604        |\n",
      "|    time_elapsed         | 11428      |\n",
      "|    total_timesteps      | 1236992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01943798 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.3      |\n",
      "|    explained_variance   | 0.161      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.5       |\n",
      "|    n_updates            | 6030       |\n",
      "|    policy_gradient_loss | -0.00946   |\n",
      "|    reward               | 5.100671   |\n",
      "|    std                  | 3.16       |\n",
      "|    value_loss           | 42.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 605        |\n",
      "|    time_elapsed         | 11447      |\n",
      "|    total_timesteps      | 1239040    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01218001 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.4      |\n",
      "|    explained_variance   | 0.208      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 88.6       |\n",
      "|    n_updates            | 6040       |\n",
      "|    policy_gradient_loss | -0.0058    |\n",
      "|    reward               | -1.3880717 |\n",
      "|    std                  | 3.16       |\n",
      "|    value_loss           | 147        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 606         |\n",
      "|    time_elapsed         | 11466       |\n",
      "|    total_timesteps      | 1241088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014870666 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.00748     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.3        |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | -0.18197426 |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4480760.09\n",
      "total_reward: 3480760.09\n",
      "total_cost: 320167.19\n",
      "total_trades: 67158\n",
      "Sharpe: 0.782\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 11485       |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017883955 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.0649      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.2        |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | -1.0140159  |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 11505       |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023980534 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.44        |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 1.2512211   |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 11523       |\n",
      "|    total_timesteps      | 1247232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023575965 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.0796      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.9        |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.0099     |\n",
      "|    reward               | -1.1460469  |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 93.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 610         |\n",
      "|    time_elapsed         | 11542       |\n",
      "|    total_timesteps      | 1249280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018261265 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.045       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 6090        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 2.8517053   |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 611         |\n",
      "|    time_elapsed         | 11561       |\n",
      "|    total_timesteps      | 1251328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017636959 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    reward               | 0.91465884  |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 11579       |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018313905 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 6110        |\n",
      "|    policy_gradient_loss | -0.00948    |\n",
      "|    reward               | 3.7362142   |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 613         |\n",
      "|    time_elapsed         | 11599       |\n",
      "|    total_timesteps      | 1255424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014540622 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.0535      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 6120        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 6.2603726   |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 11618       |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016271083 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.087       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.2        |\n",
      "|    n_updates            | 6130        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 0.94577044  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 79.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 11637       |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011331854 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.0953      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90          |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.00987    |\n",
      "|    reward               | 1.2996889   |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 616        |\n",
      "|    time_elapsed         | 11657      |\n",
      "|    total_timesteps      | 1261568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01883189 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.9      |\n",
      "|    explained_variance   | 0.0439     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 146        |\n",
      "|    n_updates            | 6150       |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    reward               | 1.2300607  |\n",
      "|    std                  | 3.22       |\n",
      "|    value_loss           | 217        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 11675       |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026483854 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.0168      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    reward               | 4.9182043   |\n",
      "|    std                  | 3.23        |\n",
      "|    value_loss           | 71.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 618         |\n",
      "|    time_elapsed         | 11720       |\n",
      "|    total_timesteps      | 1265664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018481033 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9           |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.9075798  |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 11739       |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018505739 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.0419      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.6        |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | 0.8804603   |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 11758       |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013018221 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    reward               | -0.29875714 |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 88.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2796804.65\n",
      "total_reward: 1796804.65\n",
      "total_cost: 358232.78\n",
      "total_trades: 68358\n",
      "Sharpe: 0.597\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 621         |\n",
      "|    time_elapsed         | 11777       |\n",
      "|    total_timesteps      | 1271808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02625934  |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.0972      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | -0.11342693 |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 622        |\n",
      "|    time_elapsed         | 11795      |\n",
      "|    total_timesteps      | 1273856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01910025 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.3      |\n",
      "|    explained_variance   | 0.186      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.5       |\n",
      "|    n_updates            | 6210       |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    reward               | 0.09182918 |\n",
      "|    std                  | 3.26       |\n",
      "|    value_loss           | 46.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 11814       |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016999997 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    reward               | -0.40473735 |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 92.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 11833       |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019653603 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.00379     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | 1.5931829   |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 625          |\n",
      "|    time_elapsed         | 11852        |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.023657817  |\n",
      "|    clip_fraction        | 0.255        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.4        |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.57         |\n",
      "|    n_updates            | 6240         |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    reward               | -0.091291204 |\n",
      "|    std                  | 3.28         |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 11871       |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022177206 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 0.45025307  |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 11890       |\n",
      "|    total_timesteps      | 1284096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015645122 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.000321    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 6260        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 1.1506759   |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 11909       |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020793771 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.031       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.59        |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 1.9472471   |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 11928       |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016110668 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.24        |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.1452736  |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 630         |\n",
      "|    time_elapsed         | 11946       |\n",
      "|    total_timesteps      | 1290240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014409978 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 1.1221362   |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 56.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 631        |\n",
      "|    time_elapsed         | 11965      |\n",
      "|    total_timesteps      | 1292288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01764124 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.8      |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 6300       |\n",
      "|    policy_gradient_loss | -0.00834   |\n",
      "|    reward               | 0.12027704 |\n",
      "|    std                  | 3.32       |\n",
      "|    value_loss           | 48.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 11984       |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019108202 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | -0.0321     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.68        |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | -0.7188027  |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 633         |\n",
      "|    time_elapsed         | 12003       |\n",
      "|    total_timesteps      | 1296384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019517941 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | -0.00171    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 0.66614294  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 77.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 12022       |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012364228 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.0485      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | -3.3933482  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2920100.25\n",
      "total_reward: 1920100.25\n",
      "total_cost: 366184.89\n",
      "total_trades: 68877\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 635         |\n",
      "|    time_elapsed         | 12041       |\n",
      "|    total_timesteps      | 1300480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020898044 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.0223      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.97        |\n",
      "|    n_updates            | 6340        |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 4.077913    |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 12059       |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014058545 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    reward               | 0.60155356  |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 12078       |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016764347 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.0604      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | -0.29536948 |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 77.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 638        |\n",
      "|    time_elapsed         | 12097      |\n",
      "|    total_timesteps      | 1306624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02156201 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.2      |\n",
      "|    explained_variance   | -0.0218    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.1       |\n",
      "|    n_updates            | 6370       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | 3.4781485  |\n",
      "|    std                  | 3.36       |\n",
      "|    value_loss           | 24.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 12116       |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016924364 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | 0.13720593  |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 640         |\n",
      "|    time_elapsed         | 12135       |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008949216 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.0783      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | 1.2342035   |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 641          |\n",
      "|    time_elapsed         | 12154        |\n",
      "|    total_timesteps      | 1312768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081623625 |\n",
      "|    clip_fraction        | 0.0663       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.2        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 6400         |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | -1.5789924   |\n",
      "|    std                  | 3.37         |\n",
      "|    value_loss           | 96.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 12172       |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016117038 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | -0.0237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.2         |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 2.1061075   |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 12191       |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011420099 |\n",
      "|    clip_fraction        | 0.0972      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.1        |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | 0.5171835   |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 76.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 12210       |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009060446 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.8        |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    reward               | 3.4384027   |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 12229       |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010954012 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.0444      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | -4.133857   |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 12247       |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012327502 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.0459      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.7        |\n",
      "|    n_updates            | 6450        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.30893505  |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 95.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 12266       |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009727731 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.0784      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | 1.7309473   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 12285       |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009601435 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | -0.012      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 1.7717421   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4501566.38\n",
      "total_reward: 3501566.38\n",
      "total_cost: 332385.02\n",
      "total_trades: 65816\n",
      "Sharpe: 0.844\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 12304       |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019656908 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | -0.0537     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -2.8317666  |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 650         |\n",
      "|    time_elapsed         | 12322       |\n",
      "|    total_timesteps      | 1331200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02109585  |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.0601      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 0.013352581 |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 12341       |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011057575 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.6        |\n",
      "|    n_updates            | 6500        |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    reward               | -1.8098547  |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 12360       |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014420802 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.0612      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.58        |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | 1.6695976   |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 12378       |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014417442 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.0422      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75          |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | 1.6194366   |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 12397       |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011287099 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.3        |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | 22.01218    |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 655        |\n",
      "|    time_elapsed         | 12416      |\n",
      "|    total_timesteps      | 1341440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01026993 |\n",
      "|    clip_fraction        | 0.0849     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.6      |\n",
      "|    explained_variance   | 0.0564     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.3       |\n",
      "|    n_updates            | 6540       |\n",
      "|    policy_gradient_loss | -0.00864   |\n",
      "|    reward               | -4.197269  |\n",
      "|    std                  | 3.41       |\n",
      "|    value_loss           | 188        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 12435       |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011825264 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | -0.118      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    reward               | -0.40744624 |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 12454       |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014118586 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.0786      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.4        |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | -0.17074944 |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 12473       |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008794053 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | -0.9016132  |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 12493       |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011120563 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | -0.0102     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    reward               | -1.5801753  |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 12511       |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011338187 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.0418      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.5        |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | -0.40319788 |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 661          |\n",
      "|    time_elapsed         | 12530        |\n",
      "|    total_timesteps      | 1353728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058443714 |\n",
      "|    clip_fraction        | 0.0559       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.9        |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.4         |\n",
      "|    n_updates            | 6600         |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | -1.961171    |\n",
      "|    std                  | 3.44         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 12549       |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013885239 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | 1.4899215   |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3347037.99\n",
      "total_reward: 2347037.99\n",
      "total_cost: 285629.08\n",
      "total_trades: 63816\n",
      "Sharpe: 0.642\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 12567       |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011398682 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | 0.49559295  |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 664          |\n",
      "|    time_elapsed         | 12586        |\n",
      "|    total_timesteps      | 1359872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065079755 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.9        |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 6630         |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    reward               | 0.071223     |\n",
      "|    std                  | 3.45         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 665         |\n",
      "|    time_elapsed         | 12605       |\n",
      "|    total_timesteps      | 1361920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005263161 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    reward               | 0.48494422  |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 12624       |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016131727 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | 0.38177082  |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 12642       |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006480539 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.1        |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -0.15394986 |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 83          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 12661       |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010462968 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 6670        |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | -5.105781   |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 669         |\n",
      "|    time_elapsed         | 12680       |\n",
      "|    total_timesteps      | 1370112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015775852 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | -0.5068226  |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 12699       |\n",
      "|    total_timesteps      | 1372160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013313059 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.3        |\n",
      "|    n_updates            | 6690        |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    reward               | 1.3202208   |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 671          |\n",
      "|    time_elapsed         | 12718        |\n",
      "|    total_timesteps      | 1374208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053263255 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.1        |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.7         |\n",
      "|    n_updates            | 6700         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | -0.4615222   |\n",
      "|    std                  | 3.47         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 12737       |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007757358 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | 1.79997     |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 12756       |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016555846 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -0.35165608 |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 674         |\n",
      "|    time_elapsed         | 12775       |\n",
      "|    total_timesteps      | 1380352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017782405 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.1024215   |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 12794       |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013981114 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | 1.0053148   |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 12813       |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017396003 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -1.3396827  |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3231654.32\n",
      "total_reward: 2231654.32\n",
      "total_cost: 324448.28\n",
      "total_trades: 65112\n",
      "Sharpe: 0.651\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 677        |\n",
      "|    time_elapsed         | 12832      |\n",
      "|    total_timesteps      | 1386496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02350819 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.5      |\n",
      "|    explained_variance   | 0.173      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.6       |\n",
      "|    n_updates            | 6760       |\n",
      "|    policy_gradient_loss | -0.00669   |\n",
      "|    reward               | -1.7937609 |\n",
      "|    std                  | 3.51       |\n",
      "|    value_loss           | 61.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 678          |\n",
      "|    time_elapsed         | 12852        |\n",
      "|    total_timesteps      | 1388544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108218705 |\n",
      "|    clip_fraction        | 0.0867       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.5        |\n",
      "|    explained_variance   | 0.0281       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 6770         |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    reward               | 1.1485215    |\n",
      "|    std                  | 3.52         |\n",
      "|    value_loss           | 80.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 12871       |\n",
      "|    total_timesteps      | 1390592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009115478 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | -1.986766   |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 12891       |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014668179 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -0.87657326 |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 78.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 12911       |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019379245 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.2        |\n",
      "|    n_updates            | 6800        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 1.6723734   |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 682         |\n",
      "|    time_elapsed         | 12930       |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018150426 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 3.0464764   |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 66          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 683        |\n",
      "|    time_elapsed         | 12948      |\n",
      "|    total_timesteps      | 1398784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01678502 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.6      |\n",
      "|    explained_variance   | 0.0956     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.4       |\n",
      "|    n_updates            | 6820       |\n",
      "|    policy_gradient_loss | -0.00784   |\n",
      "|    reward               | 2.995399   |\n",
      "|    std                  | 3.54       |\n",
      "|    value_loss           | 32.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 684         |\n",
      "|    time_elapsed         | 12967       |\n",
      "|    total_timesteps      | 1400832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016847268 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | 1.4745176   |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 685        |\n",
      "|    time_elapsed         | 12986      |\n",
      "|    total_timesteps      | 1402880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01574849 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.8      |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 62.7       |\n",
      "|    n_updates            | 6840       |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    reward               | 0.19336487 |\n",
      "|    std                  | 3.57       |\n",
      "|    value_loss           | 85.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 13005       |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012171683 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 2.784905    |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 61.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 13023       |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01432034  |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.054416977 |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 13042       |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016945265 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 2.7354705   |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 689        |\n",
      "|    time_elapsed         | 13061      |\n",
      "|    total_timesteps      | 1411072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02165433 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.1      |\n",
      "|    explained_variance   | 0.152      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.8       |\n",
      "|    n_updates            | 6880       |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    reward               | 0.4458051  |\n",
      "|    std                  | 3.59       |\n",
      "|    value_loss           | 78.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 13080       |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023211868 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | -0.0492     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.06        |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | -1.8061414  |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2983816.94\n",
      "total_reward: 1983816.94\n",
      "total_cost: 323345.13\n",
      "total_trades: 63978\n",
      "Sharpe: 0.607\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 13099       |\n",
      "|    total_timesteps      | 1415168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022915326 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | -0.0031     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 6900        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 1.066103    |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 99.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 692        |\n",
      "|    time_elapsed         | 13119      |\n",
      "|    total_timesteps      | 1417216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01045427 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.2      |\n",
      "|    explained_variance   | 0.113      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.8       |\n",
      "|    n_updates            | 6910       |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    reward               | 0.631293   |\n",
      "|    std                  | 3.62       |\n",
      "|    value_loss           | 73.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 13138       |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024080759 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    reward               | 2.410691    |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 694         |\n",
      "|    time_elapsed         | 13157       |\n",
      "|    total_timesteps      | 1421312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017533783 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.0411      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    reward               | -0.51726204 |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 13176       |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012798194 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.00194     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.9        |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | 0.016725857 |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 13195       |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011557607 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.0842      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | 0.34754562  |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 13214       |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019980572 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | -0.000167   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | 0.7605441   |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 13232       |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016795972 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | 0.27700606  |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 699        |\n",
      "|    time_elapsed         | 13251      |\n",
      "|    total_timesteps      | 1431552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01712313 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.6      |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 51.3       |\n",
      "|    n_updates            | 6980       |\n",
      "|    policy_gradient_loss | -0.00475   |\n",
      "|    reward               | 0.9077197  |\n",
      "|    std                  | 3.67       |\n",
      "|    value_loss           | 104        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 13271       |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022834472 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | -0.00139    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | -1.3225619  |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 13290       |\n",
      "|    total_timesteps      | 1435648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013815327 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -5.4460883  |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 97.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 702        |\n",
      "|    time_elapsed         | 13310      |\n",
      "|    total_timesteps      | 1437696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01163758 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.8      |\n",
      "|    explained_variance   | 0.235      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 105        |\n",
      "|    n_updates            | 7010       |\n",
      "|    policy_gradient_loss | -0.00415   |\n",
      "|    reward               | 8.196672   |\n",
      "|    std                  | 3.69       |\n",
      "|    value_loss           | 218        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 703        |\n",
      "|    time_elapsed         | 13328      |\n",
      "|    total_timesteps      | 1439744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01387205 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.9      |\n",
      "|    explained_variance   | -0.0723    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.6       |\n",
      "|    n_updates            | 7020       |\n",
      "|    policy_gradient_loss | -0.00528   |\n",
      "|    reward               | -0.2457154 |\n",
      "|    std                  | 3.7        |\n",
      "|    value_loss           | 77.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 704         |\n",
      "|    time_elapsed         | 13347       |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019601783 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.0913      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 7030        |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | -3.0892189  |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5225959.11\n",
      "total_reward: 4225959.11\n",
      "total_cost: 263695.32\n",
      "total_trades: 61881\n",
      "Sharpe: 0.852\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 13366       |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013082514 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 258         |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | 0.124987826 |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 274         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 13385       |\n",
      "|    total_timesteps      | 1445888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009805213 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.5        |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    reward               | 1.3747321   |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 13404       |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015168982 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 7060        |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | -0.8158947  |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 708        |\n",
      "|    time_elapsed         | 13424      |\n",
      "|    total_timesteps      | 1449984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01599574 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.2      |\n",
      "|    explained_variance   | 0.292      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 67.2       |\n",
      "|    n_updates            | 7070       |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    reward               | 0.45941418 |\n",
      "|    std                  | 3.75       |\n",
      "|    value_loss           | 171        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 13444       |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019917097 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | -0.000332   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | 6.124107    |\n",
      "|    std                  | 3.75        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 13464       |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018539932 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | -0.00693    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | 0.88607866  |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 88.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 13484       |\n",
      "|    total_timesteps      | 1456128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009154901 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54          |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | -1.1314583  |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 13504       |\n",
      "|    total_timesteps      | 1458176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009208685 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.1        |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | -0.5432882  |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 713        |\n",
      "|    time_elapsed         | 13523      |\n",
      "|    total_timesteps      | 1460224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01308883 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.4      |\n",
      "|    explained_variance   | 0.159      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 170        |\n",
      "|    n_updates            | 7120       |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    reward               | 2.7978618  |\n",
      "|    std                  | 3.77       |\n",
      "|    value_loss           | 268        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 13543       |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024431758 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.0059      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | -0.50690764 |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 715        |\n",
      "|    time_elapsed         | 13563      |\n",
      "|    total_timesteps      | 1464320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01022849 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.6      |\n",
      "|    explained_variance   | 0.0591     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47.8       |\n",
      "|    n_updates            | 7140       |\n",
      "|    policy_gradient_loss | -0.00951   |\n",
      "|    reward               | 0.5118982  |\n",
      "|    std                  | 3.8        |\n",
      "|    value_loss           | 199        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 13583       |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014757466 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.0791      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | -8.805603   |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 13602       |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013873847 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | 1.2088795   |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 59.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 718          |\n",
      "|    time_elapsed         | 13622        |\n",
      "|    total_timesteps      | 1470464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124189835 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.9        |\n",
      "|    explained_variance   | 0.312        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.6         |\n",
      "|    n_updates            | 7170         |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    reward               | -1.9794396   |\n",
      "|    std                  | 3.83         |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 13641       |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013673419 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | -0.00455    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 1.4027973   |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5001118.04\n",
      "total_reward: 4001118.04\n",
      "total_cost: 253334.52\n",
      "total_trades: 61453\n",
      "Sharpe: 0.889\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 13660       |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008726433 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.5        |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    reward               | 1.078455    |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 13680       |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011835573 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.0911      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | 2.1625822   |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 13699       |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012867898 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.0387      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.4        |\n",
      "|    n_updates            | 7210        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -2.837198   |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 723          |\n",
      "|    time_elapsed         | 13718        |\n",
      "|    total_timesteps      | 1480704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051777675 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80          |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 7220         |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | 1.1506627    |\n",
      "|    std                  | 3.85         |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 13737       |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014673217 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    reward               | 0.94227165  |\n",
      "|    std                  | 3.86        |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 725          |\n",
      "|    time_elapsed         | 13756        |\n",
      "|    total_timesteps      | 1484800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151875755 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.2        |\n",
      "|    explained_variance   | 0.0993       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70           |\n",
      "|    n_updates            | 7240         |\n",
      "|    policy_gradient_loss | -0.00983     |\n",
      "|    reward               | 2.0267951    |\n",
      "|    std                  | 3.87         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 726         |\n",
      "|    time_elapsed         | 13775       |\n",
      "|    total_timesteps      | 1486848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016068712 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.00263     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63          |\n",
      "|    n_updates            | 7250        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    reward               | 1.149052    |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 13794       |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016732756 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | 0.107260056 |\n",
      "|    std                  | 3.9         |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 13813       |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012271637 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 1.246836    |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 58.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 13832       |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009418487 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.5        |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | -1.9972793  |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 13850       |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010227964 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.6        |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | 2.5940776   |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 731        |\n",
      "|    time_elapsed         | 13869      |\n",
      "|    total_timesteps      | 1497088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00950536 |\n",
      "|    clip_fraction        | 0.0633     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.5      |\n",
      "|    explained_variance   | 0.447      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.8       |\n",
      "|    n_updates            | 7300       |\n",
      "|    policy_gradient_loss | -0.00593   |\n",
      "|    reward               | 0.6209176  |\n",
      "|    std                  | 3.92       |\n",
      "|    value_loss           | 28.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 13888       |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013059717 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.3        |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | -0.45862782 |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 733         |\n",
      "|    time_elapsed         | 13907       |\n",
      "|    total_timesteps      | 1501184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011310251 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.8        |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | -1.8261632  |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4824551.44\n",
      "total_reward: 3824551.44\n",
      "total_cost: 299365.29\n",
      "total_trades: 63357\n",
      "Sharpe: 0.816\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 13926       |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008083196 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | -5.1311603  |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 13945       |\n",
      "|    total_timesteps      | 1505280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009801192 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | -1.3106635  |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 13964       |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015596164 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43          |\n",
      "|    n_updates            | 7350        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.7125645  |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 91.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 737         |\n",
      "|    time_elapsed         | 13983       |\n",
      "|    total_timesteps      | 1509376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019899314 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 7360        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 1.6371398   |\n",
      "|    std                  | 3.95        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 14002       |\n",
      "|    total_timesteps      | 1511424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016613442 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | -1.7752289  |\n",
      "|    std                  | 3.95        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 14021       |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0194498   |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.9        |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.073171556 |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 81.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 740         |\n",
      "|    time_elapsed         | 14040       |\n",
      "|    total_timesteps      | 1515520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012351973 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 7390        |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | 0.5138208   |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 50.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 14059       |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012176518 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 7400        |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | -0.6652869  |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 14078       |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012280714 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.57        |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.9814546   |\n",
      "|    std                  | 3.98        |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 743         |\n",
      "|    time_elapsed         | 14097       |\n",
      "|    total_timesteps      | 1521664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008752018 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.4        |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | 0.093467884 |\n",
      "|    std                  | 3.98        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 14116       |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015193464 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.0468      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | 1.0678592   |\n",
      "|    std                  | 3.99        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 14135       |\n",
      "|    total_timesteps      | 1525760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016609654 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.81        |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -0.2660644  |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 14154       |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01464829  |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 7450        |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | -0.69304657 |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 78.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 14173       |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011047592 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -2.128342   |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 71.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3560583.80\n",
      "total_reward: 2560583.80\n",
      "total_cost: 305004.64\n",
      "total_trades: 64933\n",
      "Sharpe: 0.740\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 748         |\n",
      "|    time_elapsed         | 14192       |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008838771 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    reward               | 0.3786232   |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 749        |\n",
      "|    time_elapsed         | 14211      |\n",
      "|    total_timesteps      | 1533952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01946793 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.3      |\n",
      "|    explained_variance   | 0.388      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.1       |\n",
      "|    n_updates            | 7480       |\n",
      "|    policy_gradient_loss | -0.00682   |\n",
      "|    reward               | -6.555245  |\n",
      "|    std                  | 4.03       |\n",
      "|    value_loss           | 64.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 14230       |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009547351 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | -2.84064    |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 73.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 14249       |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016845591 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.35073614  |\n",
      "|    std                  | 4.04        |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 752         |\n",
      "|    time_elapsed         | 14268       |\n",
      "|    total_timesteps      | 1540096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014494993 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.0874      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 7510        |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | 1.7105136   |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 89.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 14287       |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012163926 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.9        |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | 0.5420867   |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 14306       |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010285357 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -0.5988546  |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 755         |\n",
      "|    time_elapsed         | 14325       |\n",
      "|    total_timesteps      | 1546240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014436528 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | -0.0788     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 7540        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.99587363  |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 14344       |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013802889 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.0865      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.9        |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.07641723  |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 97          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 757         |\n",
      "|    time_elapsed         | 14364       |\n",
      "|    total_timesteps      | 1550336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013919814 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.0797      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 7560        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 1.7838507   |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 90.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 758          |\n",
      "|    time_elapsed         | 14383        |\n",
      "|    total_timesteps      | 1552384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134116765 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.9        |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 7570         |\n",
      "|    policy_gradient_loss | -0.00988     |\n",
      "|    reward               | 0.3656416    |\n",
      "|    std                  | 4.11         |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 14402       |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013703945 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.7        |\n",
      "|    n_updates            | 7580        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.7087018   |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 74.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 14421       |\n",
      "|    total_timesteps      | 1556480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012541754 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.0807      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.3        |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.29493773  |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 93.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 14440       |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015105984 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.00855     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.5        |\n",
      "|    n_updates            | 7600        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -1.0368644  |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5313057.17\n",
      "total_reward: 4313057.17\n",
      "total_cost: 287255.63\n",
      "total_trades: 63811\n",
      "Sharpe: 0.904\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 762         |\n",
      "|    time_elapsed         | 14459       |\n",
      "|    total_timesteps      | 1560576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016294735 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | -0.049      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 4.91742     |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 763        |\n",
      "|    time_elapsed         | 14478      |\n",
      "|    total_timesteps      | 1562624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01488656 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.1      |\n",
      "|    explained_variance   | 0.0095     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 91.5       |\n",
      "|    n_updates            | 7620       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    reward               | -3.0844631 |\n",
      "|    std                  | 4.14       |\n",
      "|    value_loss           | 176        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 14497       |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009179746 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.4        |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    reward               | -0.330006   |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 765         |\n",
      "|    time_elapsed         | 14516       |\n",
      "|    total_timesteps      | 1566720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009062083 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | -0.34675738 |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 14535       |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010585654 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    reward               | -0.19259778 |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 767         |\n",
      "|    time_elapsed         | 14554       |\n",
      "|    total_timesteps      | 1570816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013194906 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 7660        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 21.313942   |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 94.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 14573       |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016409326 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | -1.5868903  |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 14592       |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012435788 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.78        |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | 1.3052689   |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 770         |\n",
      "|    time_elapsed         | 14611       |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010804923 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | 0.29354826  |\n",
      "|    std                  | 4.2         |\n",
      "|    value_loss           | 96.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 14629       |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020772552 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 7700        |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    reward               | -2.5047843  |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 58.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 14648       |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016332854 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | 0.00339     |\n",
      "|    reward               | 0.37058276  |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 14668       |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013670281 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.5638072  |\n",
      "|    std                  | 4.22        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 774         |\n",
      "|    time_elapsed         | 14687       |\n",
      "|    total_timesteps      | 1585152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012468768 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 2.2790437   |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 14706       |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012283608 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 7740        |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    reward               | 1.7962439   |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2722480.85\n",
      "total_reward: 1722480.85\n",
      "total_cost: 286554.34\n",
      "total_trades: 63062\n",
      "Sharpe: 0.586\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 14725       |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011328242 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | 0.6381999   |\n",
      "|    std                  | 4.25        |\n",
      "|    value_loss           | 55.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 777         |\n",
      "|    time_elapsed         | 14744       |\n",
      "|    total_timesteps      | 1591296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011989107 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 7760        |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | 1.8119173   |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 14763       |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011827087 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | -2.9658718  |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 14782       |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017212521 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    reward               | -2.3885264  |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 14801       |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009868145 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 1.0878885   |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 67.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 14820       |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012042807 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.2        |\n",
      "|    n_updates            | 7800        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 1.0961456   |\n",
      "|    std                  | 4.29        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 782         |\n",
      "|    time_elapsed         | 14839       |\n",
      "|    total_timesteps      | 1601536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015037249 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.0636      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 7810        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -1.9891047  |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 14858       |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013140783 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 0.32816195  |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 784        |\n",
      "|    time_elapsed         | 14877      |\n",
      "|    total_timesteps      | 1605632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00812722 |\n",
      "|    clip_fraction        | 0.0747     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.3      |\n",
      "|    explained_variance   | 0.372      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.8       |\n",
      "|    n_updates            | 7830       |\n",
      "|    policy_gradient_loss | -0.00197   |\n",
      "|    reward               | 0.92085016 |\n",
      "|    std                  | 4.31       |\n",
      "|    value_loss           | 100        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 14896       |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010278563 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | -0.0291     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.8        |\n",
      "|    n_updates            | 7840        |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | -0.4509743  |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 14915       |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017951313 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | -0.0892     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.8688908   |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 787         |\n",
      "|    time_elapsed         | 14935       |\n",
      "|    total_timesteps      | 1611776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009036476 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | -1.2456708  |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 14954       |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013237395 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | 2.3897045   |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 789          |\n",
      "|    time_elapsed         | 14973        |\n",
      "|    total_timesteps      | 1615872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116343405 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.5        |\n",
      "|    explained_variance   | -0.00578     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 7880         |\n",
      "|    policy_gradient_loss | -0.0089      |\n",
      "|    reward               | -2.654875    |\n",
      "|    std                  | 4.34         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4353156.33\n",
      "total_reward: 3353156.33\n",
      "total_cost: 313778.32\n",
      "total_trades: 64770\n",
      "Sharpe: 0.834\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 14992       |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009358515 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.7        |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    reward               | -0.5060415  |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 15011       |\n",
      "|    total_timesteps      | 1619968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011970673 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.4        |\n",
      "|    n_updates            | 7900        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -2.8530107  |\n",
      "|    std                  | 4.36        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 792         |\n",
      "|    time_elapsed         | 15030       |\n",
      "|    total_timesteps      | 1622016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012061536 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 7910        |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    reward               | 2.9163742   |\n",
      "|    std                  | 4.36        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 15049       |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013710859 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.6        |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.48050246 |\n",
      "|    std                  | 4.36        |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 794        |\n",
      "|    time_elapsed         | 15068      |\n",
      "|    total_timesteps      | 1626112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01231012 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.6      |\n",
      "|    explained_variance   | 0.155      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.8       |\n",
      "|    n_updates            | 7930       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    reward               | 0.16062139 |\n",
      "|    std                  | 4.36       |\n",
      "|    value_loss           | 82.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 15088       |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009108992 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.8        |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | 0.50787085  |\n",
      "|    std                  | 4.37        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 796          |\n",
      "|    time_elapsed         | 15107        |\n",
      "|    total_timesteps      | 1630208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016595013  |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.7        |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 7950         |\n",
      "|    policy_gradient_loss | -0.00957     |\n",
      "|    reward               | -0.066956185 |\n",
      "|    std                  | 4.37         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 15126       |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012762316 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 7960        |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | 0.36081526  |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 58          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 15145       |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010459619 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 7970        |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | -0.3052295  |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 68.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 15164       |\n",
      "|    total_timesteps      | 1636352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009958046 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | 0.4879735   |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 15184       |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011914177 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | 0.9141159   |\n",
      "|    std                  | 4.39        |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 801         |\n",
      "|    time_elapsed         | 15203       |\n",
      "|    total_timesteps      | 1640448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013104364 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -2.1898954  |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 65.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 802          |\n",
      "|    time_elapsed         | 15223        |\n",
      "|    total_timesteps      | 1642496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057714833 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.9        |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 8010         |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | 0.6823552    |\n",
      "|    std                  | 4.4          |\n",
      "|    value_loss           | 84.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 15242       |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022784697 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | -0.062      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 1.4864318   |\n",
      "|    std                  | 4.39        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3365521.68\n",
      "total_reward: 2365521.68\n",
      "total_cost: 324381.30\n",
      "total_trades: 66668\n",
      "Sharpe: 0.655\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 804         |\n",
      "|    time_elapsed         | 15261       |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009595702 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 8030        |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | 0.7113255   |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 15280       |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010375984 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.4        |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | -1.084145   |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 93          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 806         |\n",
      "|    time_elapsed         | 15299       |\n",
      "|    total_timesteps      | 1650688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013319083 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 8050        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 2.4364643   |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 15318       |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010425187 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | 0.86547136  |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 15337       |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014412891 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 8070        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.3478169   |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 809         |\n",
      "|    time_elapsed         | 15356       |\n",
      "|    total_timesteps      | 1656832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008688043 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 8080        |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 0.11442217  |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 15375       |\n",
      "|    total_timesteps      | 1658880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017583411 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | -0.00991    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 8090        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.73397565  |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 811         |\n",
      "|    time_elapsed         | 15394       |\n",
      "|    total_timesteps      | 1660928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012595324 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.2       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -1.8157493  |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 15413       |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010595143 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 8110        |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | 7.4112525   |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 15432       |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016096301 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.0854      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | 0.21095677  |\n",
      "|    std                  | 4.47        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 15452       |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009421875 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -0.9028025  |\n",
      "|    std                  | 4.47        |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 815          |\n",
      "|    time_elapsed         | 15471        |\n",
      "|    total_timesteps      | 1669120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097312825 |\n",
      "|    clip_fraction        | 0.0798       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.3        |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 8140         |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | 0.36384678   |\n",
      "|    std                  | 4.48         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 816         |\n",
      "|    time_elapsed         | 15490       |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016238455 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 8150        |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    reward               | -0.3842993  |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 15509       |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012457335 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 8160        |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | -1.1565171  |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4085849.46\n",
      "total_reward: 3085849.46\n",
      "total_cost: 307645.34\n",
      "total_trades: 66341\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 818          |\n",
      "|    time_elapsed         | 15529        |\n",
      "|    total_timesteps      | 1675264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076134517 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.4        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 8170         |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 0.18581301   |\n",
      "|    std                  | 4.49         |\n",
      "|    value_loss           | 65.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 819         |\n",
      "|    time_elapsed         | 15548       |\n",
      "|    total_timesteps      | 1677312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012828214 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.5        |\n",
      "|    n_updates            | 8180        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.33576456  |\n",
      "|    std                  | 4.5         |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 820        |\n",
      "|    time_elapsed         | 15567      |\n",
      "|    total_timesteps      | 1679360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01698025 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.6      |\n",
      "|    explained_variance   | -0.607     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12         |\n",
      "|    n_updates            | 8190       |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    reward               | 0.88516724 |\n",
      "|    std                  | 4.52       |\n",
      "|    value_loss           | 25.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 821         |\n",
      "|    time_elapsed         | 15586       |\n",
      "|    total_timesteps      | 1681408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009488634 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 8200        |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    reward               | 0.38569474  |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 90.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 822          |\n",
      "|    time_elapsed         | 15605        |\n",
      "|    total_timesteps      | 1683456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061012497 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.7        |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.4         |\n",
      "|    n_updates            | 8210         |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 3.261134     |\n",
      "|    std                  | 4.53         |\n",
      "|    value_loss           | 90.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 823          |\n",
      "|    time_elapsed         | 15624        |\n",
      "|    total_timesteps      | 1685504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075713587 |\n",
      "|    clip_fraction        | 0.0651       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.7        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 8220         |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -2.4449306   |\n",
      "|    std                  | 4.54         |\n",
      "|    value_loss           | 75.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 15643       |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012570543 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 8230        |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    reward               | 0.9119623   |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 93.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 15663       |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012680623 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52          |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -1.3916508  |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 826         |\n",
      "|    time_elapsed         | 15682       |\n",
      "|    total_timesteps      | 1691648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011916267 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 8250        |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | 3.6520066   |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 15701       |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015087094 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | -0.0458     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 8260        |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | 1.4840596   |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 828          |\n",
      "|    time_elapsed         | 15720        |\n",
      "|    total_timesteps      | 1695744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063097863 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.9        |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.5         |\n",
      "|    n_updates            | 8270         |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    reward               | -0.05301695  |\n",
      "|    std                  | 4.56         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 829        |\n",
      "|    time_elapsed         | 15740      |\n",
      "|    total_timesteps      | 1697792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01154476 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.9      |\n",
      "|    explained_variance   | 0.178      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 52.6       |\n",
      "|    n_updates            | 8280       |\n",
      "|    policy_gradient_loss | -0.00724   |\n",
      "|    reward               | 11.789018  |\n",
      "|    std                  | 4.56       |\n",
      "|    value_loss           | 140        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 15759       |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015415472 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.0297      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.37012792 |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 831         |\n",
      "|    time_elapsed         | 15779       |\n",
      "|    total_timesteps      | 1701888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009473922 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 8300        |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    reward               | 2.9604275   |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 89.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 832          |\n",
      "|    time_elapsed         | 15798        |\n",
      "|    total_timesteps      | 1703936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063869776 |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85          |\n",
      "|    explained_variance   | 0.265        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 8310         |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    reward               | -1.0830815   |\n",
      "|    std                  | 4.58         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3705359.76\n",
      "total_reward: 2705359.76\n",
      "total_cost: 312292.02\n",
      "total_trades: 65994\n",
      "Sharpe: 0.708\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 833         |\n",
      "|    time_elapsed         | 15817       |\n",
      "|    total_timesteps      | 1705984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009062964 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.2        |\n",
      "|    n_updates            | 8320        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | -0.42161936 |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 95.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 15836       |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014920728 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | -0.0951     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -2.7973464  |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 835        |\n",
      "|    time_elapsed         | 15855      |\n",
      "|    total_timesteps      | 1710080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01461295 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.1      |\n",
      "|    explained_variance   | -0.00458   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 160        |\n",
      "|    n_updates            | 8340       |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    reward               | -0.3221223 |\n",
      "|    std                  | 4.58       |\n",
      "|    value_loss           | 229        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 15874       |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013518411 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | -0.000443   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.4        |\n",
      "|    n_updates            | 8350        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -1.1475574  |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 15893       |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015273627 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.00613     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 2.5326338   |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 15912       |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010126509 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 8370        |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    reward               | 3.197718    |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 85.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 839          |\n",
      "|    time_elapsed         | 15931        |\n",
      "|    total_timesteps      | 1718272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035911372 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.2        |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 8380         |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | 1.6514412    |\n",
      "|    std                  | 4.61         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 840         |\n",
      "|    time_elapsed         | 15950       |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013012759 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.00518     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 1.9438875   |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 67.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 15969       |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011468229 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.0694      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.5        |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    reward               | -1.0668172  |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 842          |\n",
      "|    time_elapsed         | 15989        |\n",
      "|    total_timesteps      | 1724416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066279415 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.3        |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.5         |\n",
      "|    n_updates            | 8410         |\n",
      "|    policy_gradient_loss | -0.00883     |\n",
      "|    reward               | -2.5197244   |\n",
      "|    std                  | 4.63         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 843         |\n",
      "|    time_elapsed         | 16008       |\n",
      "|    total_timesteps      | 1726464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011247469 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.0735      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 8420        |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | 1.8065419   |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 16028       |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009805819 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 8430        |\n",
      "|    policy_gradient_loss | 0.000627    |\n",
      "|    reward               | -0.49510685 |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 845         |\n",
      "|    time_elapsed         | 16047       |\n",
      "|    total_timesteps      | 1730560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013968414 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -1.5303596  |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 89.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 846          |\n",
      "|    time_elapsed         | 16066        |\n",
      "|    total_timesteps      | 1732608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061633717 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.5        |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 123          |\n",
      "|    n_updates            | 8450         |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    reward               | -3.6181636   |\n",
      "|    std                  | 4.65         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3997434.42\n",
      "total_reward: 2997434.42\n",
      "total_cost: 331803.49\n",
      "total_trades: 67650\n",
      "Sharpe: 0.744\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 16085       |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013522949 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | -0.0362     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 2.5153692   |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 848         |\n",
      "|    time_elapsed         | 16104       |\n",
      "|    total_timesteps      | 1736704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012837453 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 8470        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 3.4271731   |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 72.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 849         |\n",
      "|    time_elapsed         | 16123       |\n",
      "|    total_timesteps      | 1738752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009691741 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.6        |\n",
      "|    n_updates            | 8480        |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -1.1580626  |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 850          |\n",
      "|    time_elapsed         | 16142        |\n",
      "|    total_timesteps      | 1740800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047760457 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.6        |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.7         |\n",
      "|    n_updates            | 8490         |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    reward               | -3.7378812   |\n",
      "|    std                  | 4.67         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 16161       |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012462276 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | -1.3590394  |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 16180       |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009718159 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 8510        |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    reward               | -1.77865    |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 85.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 853         |\n",
      "|    time_elapsed         | 16199       |\n",
      "|    total_timesteps      | 1746944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013596735 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 8520        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -1.4729834  |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 84.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 16218       |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017340627 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | -0.00892    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 8530        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.11535622 |\n",
      "|    std                  | 4.71        |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 855         |\n",
      "|    time_elapsed         | 16237       |\n",
      "|    total_timesteps      | 1751040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009022228 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.9       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.7        |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    reward               | -0.7851203  |\n",
      "|    std                  | 4.71        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 856         |\n",
      "|    time_elapsed         | 16257       |\n",
      "|    total_timesteps      | 1753088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011431118 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.9       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.6        |\n",
      "|    n_updates            | 8550        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | -14.270785  |\n",
      "|    std                  | 4.71        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 16275       |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008448908 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.9       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.2        |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 7.054911    |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 16295       |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013850377 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | -0.21       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 1.5151252   |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 859        |\n",
      "|    time_elapsed         | 16314      |\n",
      "|    total_timesteps      | 1759232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00834652 |\n",
      "|    clip_fraction        | 0.0494     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86        |\n",
      "|    explained_variance   | 0.444      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.7       |\n",
      "|    n_updates            | 8580       |\n",
      "|    policy_gradient_loss | -0.00637   |\n",
      "|    reward               | -0.4545069 |\n",
      "|    std                  | 4.74       |\n",
      "|    value_loss           | 98.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 860          |\n",
      "|    time_elapsed         | 16333        |\n",
      "|    total_timesteps      | 1761280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070899045 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.1        |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.1         |\n",
      "|    n_updates            | 8590         |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    reward               | 2.5303295    |\n",
      "|    std                  | 4.74         |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3197504.17\n",
      "total_reward: 2197504.17\n",
      "total_cost: 311607.71\n",
      "total_trades: 66749\n",
      "Sharpe: 0.628\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 16353       |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01751107  |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.38        |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.09824986 |\n",
      "|    std                  | 4.76        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 16372       |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010723002 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    reward               | -4.5517197  |\n",
      "|    std                  | 4.77        |\n",
      "|    value_loss           | 58.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 863        |\n",
      "|    time_elapsed         | 16391      |\n",
      "|    total_timesteps      | 1767424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01026389 |\n",
      "|    clip_fraction        | 0.0873     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.3      |\n",
      "|    explained_variance   | 0.353      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.9       |\n",
      "|    n_updates            | 8620       |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    reward               | 0.1721032  |\n",
      "|    std                  | 4.78       |\n",
      "|    value_loss           | 78.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 864         |\n",
      "|    time_elapsed         | 16411       |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010987654 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.00117     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 8630        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.4750241  |\n",
      "|    std                  | 4.79        |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 865         |\n",
      "|    time_elapsed         | 16430       |\n",
      "|    total_timesteps      | 1771520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010058943 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -1.9854218  |\n",
      "|    std                  | 4.8         |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 16449       |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012036178 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.0239      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 8650        |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | 0.59511554  |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 867         |\n",
      "|    time_elapsed         | 16468       |\n",
      "|    total_timesteps      | 1775616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012654312 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | 0.0279      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.2        |\n",
      "|    n_updates            | 8660        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -1.5308168  |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 868          |\n",
      "|    time_elapsed         | 16487        |\n",
      "|    total_timesteps      | 1777664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0138859525 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.6        |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 8670         |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    reward               | -0.6329291   |\n",
      "|    std                  | 4.83         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 16506       |\n",
      "|    total_timesteps      | 1779712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008272421 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 8680        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | -0.40749297 |\n",
      "|    std                  | 4.84        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 870         |\n",
      "|    time_elapsed         | 16525       |\n",
      "|    total_timesteps      | 1781760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007767517 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.6        |\n",
      "|    n_updates            | 8690        |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | 3.0913231   |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 16544       |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014989033 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.00521     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 8700        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 0.30938512  |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 16563       |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009996522 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.9        |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | 1.0765785   |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 16583       |\n",
      "|    total_timesteps      | 1787904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008639665 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 8720        |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    reward               | -1.0580043  |\n",
      "|    std                  | 4.88        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 16602       |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012921542 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | -0.15207298 |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4367813.86\n",
      "total_reward: 3367813.86\n",
      "total_cost: 315128.19\n",
      "total_trades: 66698\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 875         |\n",
      "|    time_elapsed         | 16621       |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016567659 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.92        |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    reward               | 1.4593089   |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 16640       |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008834995 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.4        |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | 0.6323485   |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 877         |\n",
      "|    time_elapsed         | 16659       |\n",
      "|    total_timesteps      | 1796096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010712905 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 8760        |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    reward               | 1.6589383   |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 16678       |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007986876 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | -2.738903   |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 879         |\n",
      "|    time_elapsed         | 16698       |\n",
      "|    total_timesteps      | 1800192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011216093 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 8780        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -1.4008113  |\n",
      "|    std                  | 4.93        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 16717       |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010287629 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.1        |\n",
      "|    n_updates            | 8790        |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    reward               | 2.7359686   |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 99.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 881          |\n",
      "|    time_elapsed         | 16736        |\n",
      "|    total_timesteps      | 1804288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137161985 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.2        |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.7         |\n",
      "|    n_updates            | 8800         |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    reward               | -2.4675019   |\n",
      "|    std                  | 4.94         |\n",
      "|    value_loss           | 87.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 16755       |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013335127 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -1.9116468  |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 74.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 16774       |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010149779 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.3        |\n",
      "|    n_updates            | 8820        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.1922373   |\n",
      "|    std                  | 4.95        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 884        |\n",
      "|    time_elapsed         | 16793      |\n",
      "|    total_timesteps      | 1810432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01291563 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.3      |\n",
      "|    explained_variance   | 0.0437     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.6       |\n",
      "|    n_updates            | 8830       |\n",
      "|    policy_gradient_loss | -0.00833   |\n",
      "|    reward               | 4.8200555  |\n",
      "|    std                  | 4.96       |\n",
      "|    value_loss           | 172        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 16812       |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012003318 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | -0.0256     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 5.978606    |\n",
      "|    std                  | 4.97        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 16831       |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012196157 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.0641      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 8850        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -3.6292112  |\n",
      "|    std                  | 4.99        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 887        |\n",
      "|    time_elapsed         | 16850      |\n",
      "|    total_timesteps      | 1816576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01035358 |\n",
      "|    clip_fraction        | 0.0905     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.5      |\n",
      "|    explained_variance   | 0.244      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 66.5       |\n",
      "|    n_updates            | 8860       |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    reward               | 4.358648   |\n",
      "|    std                  | 4.99       |\n",
      "|    value_loss           | 155        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 888         |\n",
      "|    time_elapsed         | 16869       |\n",
      "|    total_timesteps      | 1818624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018849816 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.0821      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.8        |\n",
      "|    n_updates            | 8870        |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    reward               | 1.4753839   |\n",
      "|    std                  | 5           |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4131411.80\n",
      "total_reward: 3131411.80\n",
      "total_cost: 276795.94\n",
      "total_trades: 64692\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 889         |\n",
      "|    time_elapsed         | 16888       |\n",
      "|    total_timesteps      | 1820672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012010232 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.5        |\n",
      "|    n_updates            | 8880        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.14749065  |\n",
      "|    std                  | 5           |\n",
      "|    value_loss           | 89.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 890          |\n",
      "|    time_elapsed         | 16908        |\n",
      "|    total_timesteps      | 1822720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077803526 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.6        |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 8890         |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | -0.70828384  |\n",
      "|    std                  | 5.01         |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 891          |\n",
      "|    time_elapsed         | 16926        |\n",
      "|    total_timesteps      | 1824768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013905875  |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.6        |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 8900         |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    reward               | -0.003382235 |\n",
      "|    std                  | 5.01         |\n",
      "|    value_loss           | 201          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 892         |\n",
      "|    time_elapsed         | 16946       |\n",
      "|    total_timesteps      | 1826816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006291923 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 8910        |\n",
      "|    policy_gradient_loss | 0.000832    |\n",
      "|    reward               | 1.347055    |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 16965       |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005259098 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 8920        |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    reward               | 0.05138945  |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 894         |\n",
      "|    time_elapsed         | 16984       |\n",
      "|    total_timesteps      | 1830912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003855493 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83          |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | 1.365452    |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 17003       |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013311154 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 8940        |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    reward               | -1.8646877  |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 75.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 896         |\n",
      "|    time_elapsed         | 17023       |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009120863 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 8950        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -0.6323212  |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 17042       |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012537252 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 8960        |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    reward               | -15.167031  |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 17061       |\n",
      "|    total_timesteps      | 1839104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009426288 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    reward               | -2.1988122  |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 899         |\n",
      "|    time_elapsed         | 17080       |\n",
      "|    total_timesteps      | 1841152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016315542 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 8980        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | -2.5122964  |\n",
      "|    std                  | 5.04        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 17099       |\n",
      "|    total_timesteps      | 1843200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013533831 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 8990        |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | 1.7360059   |\n",
      "|    std                  | 5.05        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 901         |\n",
      "|    time_elapsed         | 17118       |\n",
      "|    total_timesteps      | 1845248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012527296 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 3.5726717   |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 902         |\n",
      "|    time_elapsed         | 17138       |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012946693 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 9010        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -1.3583306  |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2803506.04\n",
      "total_reward: 1803506.04\n",
      "total_cost: 298036.01\n",
      "total_trades: 66207\n",
      "Sharpe: 0.584\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 903         |\n",
      "|    time_elapsed         | 17157       |\n",
      "|    total_timesteps      | 1849344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015600545 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -0.5935484  |\n",
      "|    std                  | 5.09        |\n",
      "|    value_loss           | 83.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 904         |\n",
      "|    time_elapsed         | 17176       |\n",
      "|    total_timesteps      | 1851392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014980226 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    reward               | 0.92233634  |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 17195       |\n",
      "|    total_timesteps      | 1853440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012144672 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 9040        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.94911915 |\n",
      "|    std                  | 5.12        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 17214       |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012863466 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    reward               | -1.1676747  |\n",
      "|    std                  | 5.12        |\n",
      "|    value_loss           | 68.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 17233       |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010902599 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.4        |\n",
      "|    n_updates            | 9060        |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    reward               | 1.3748956   |\n",
      "|    std                  | 5.13        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 908         |\n",
      "|    time_elapsed         | 17252       |\n",
      "|    total_timesteps      | 1859584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007175062 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62          |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | 2.1735656   |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 909          |\n",
      "|    time_elapsed         | 17271        |\n",
      "|    total_timesteps      | 1861632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034301989 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.4        |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 9080         |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    reward               | -1.4306043   |\n",
      "|    std                  | 5.15         |\n",
      "|    value_loss           | 62.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 17291       |\n",
      "|    total_timesteps      | 1863680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011437269 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.6        |\n",
      "|    n_updates            | 9090        |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    reward               | -1.0841041  |\n",
      "|    std                  | 5.16        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 911          |\n",
      "|    time_elapsed         | 17310        |\n",
      "|    total_timesteps      | 1865728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067581907 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.5        |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 9100         |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    reward               | -3.4711602   |\n",
      "|    std                  | 5.16         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 17329       |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009354739 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | 3.1490054   |\n",
      "|    std                  | 5.16        |\n",
      "|    value_loss           | 72.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 913          |\n",
      "|    time_elapsed         | 17348        |\n",
      "|    total_timesteps      | 1869824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062196236 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.5        |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.7         |\n",
      "|    n_updates            | 9120         |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | -0.4050948   |\n",
      "|    std                  | 5.17         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 914        |\n",
      "|    time_elapsed         | 17367      |\n",
      "|    total_timesteps      | 1871872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01063578 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.5      |\n",
      "|    explained_variance   | 0.464      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.5       |\n",
      "|    n_updates            | 9130       |\n",
      "|    policy_gradient_loss | -0.0095    |\n",
      "|    reward               | 1.195476   |\n",
      "|    std                  | 5.18       |\n",
      "|    value_loss           | 112        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 915         |\n",
      "|    time_elapsed         | 17387       |\n",
      "|    total_timesteps      | 1873920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013070928 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.2        |\n",
      "|    n_updates            | 9140        |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | -0.9988581  |\n",
      "|    std                  | 5.18        |\n",
      "|    value_loss           | 75.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 17406       |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014011913 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.0906      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | 0.64558685  |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4042637.73\n",
      "total_reward: 3042637.73\n",
      "total_cost: 269357.11\n",
      "total_trades: 65172\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 917          |\n",
      "|    time_elapsed         | 17425        |\n",
      "|    total_timesteps      | 1878016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073368596 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.7        |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.3         |\n",
      "|    n_updates            | 9160         |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    reward               | -0.8296677   |\n",
      "|    std                  | 5.21         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 918          |\n",
      "|    time_elapsed         | 17445        |\n",
      "|    total_timesteps      | 1880064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067063896 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.7        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.3         |\n",
      "|    n_updates            | 9170         |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    reward               | 1.1786212    |\n",
      "|    std                  | 5.21         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 17464       |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018215936 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.00422     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 9180        |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | -4.202428   |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 70.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 17484       |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011464052 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 0.59474796  |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 84.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 921         |\n",
      "|    time_elapsed         | 17503       |\n",
      "|    total_timesteps      | 1886208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009043239 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 9200        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | -6.659184   |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 17523       |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015816702 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 1.5179131   |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 923         |\n",
      "|    time_elapsed         | 17542       |\n",
      "|    total_timesteps      | 1890304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012119378 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | -0.00313    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 9220        |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | 0.7546834   |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 17561       |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009736491 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 9230        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | -3.2617757  |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 17580       |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008768428 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | -1.3609957  |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 926          |\n",
      "|    time_elapsed         | 17599        |\n",
      "|    total_timesteps      | 1896448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115212565 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89          |\n",
      "|    explained_variance   | 0.0248       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 9250         |\n",
      "|    policy_gradient_loss | -0.00949     |\n",
      "|    reward               | 2.774768     |\n",
      "|    std                  | 5.25         |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 927         |\n",
      "|    time_elapsed         | 17618       |\n",
      "|    total_timesteps      | 1898496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017704131 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 3.449431    |\n",
      "|    std                  | 5.26        |\n",
      "|    value_loss           | 81.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 928          |\n",
      "|    time_elapsed         | 17638        |\n",
      "|    total_timesteps      | 1900544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061914115 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89          |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.2         |\n",
      "|    n_updates            | 9270         |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | -1.0795896   |\n",
      "|    std                  | 5.26         |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 929          |\n",
      "|    time_elapsed         | 17657        |\n",
      "|    total_timesteps      | 1902592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075187176 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89          |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 9280         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 4.0850534    |\n",
      "|    std                  | 5.27         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 17676       |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015177942 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 0.5246056   |\n",
      "|    std                  | 5.28        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4201315.26\n",
      "total_reward: 3201315.26\n",
      "total_cost: 327840.59\n",
      "total_trades: 68784\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 931         |\n",
      "|    time_elapsed         | 17695       |\n",
      "|    total_timesteps      | 1906688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007296709 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 9300        |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | -0.07740442 |\n",
      "|    std                  | 5.28        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 932         |\n",
      "|    time_elapsed         | 17714       |\n",
      "|    total_timesteps      | 1908736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009113024 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.6        |\n",
      "|    n_updates            | 9310        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | 2.4508767   |\n",
      "|    std                  | 5.29        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 933         |\n",
      "|    time_elapsed         | 17734       |\n",
      "|    total_timesteps      | 1910784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016748728 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | -0.211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 9320        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | 1.4149963   |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 17753       |\n",
      "|    total_timesteps      | 1912832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012783318 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 9330        |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | 0.36831993  |\n",
      "|    std                  | 5.32        |\n",
      "|    value_loss           | 62.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 17772       |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015278765 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.0624      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 9340        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 5.4157286   |\n",
      "|    std                  | 5.33        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 936         |\n",
      "|    time_elapsed         | 17791       |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015610352 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | -0.0237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 9350        |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | -3.6184855  |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 17810       |\n",
      "|    total_timesteps      | 1918976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010651236 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -1.1729163  |\n",
      "|    std                  | 5.35        |\n",
      "|    value_loss           | 97.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 938         |\n",
      "|    time_elapsed         | 17829       |\n",
      "|    total_timesteps      | 1921024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011188872 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.00209     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 9370        |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | -0.18411297 |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 17848       |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009930616 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.2        |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -1.960991   |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 17868       |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013066474 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.0286      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 2.1334898   |\n",
      "|    std                  | 5.39        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 941          |\n",
      "|    time_elapsed         | 17887        |\n",
      "|    total_timesteps      | 1927168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087658735 |\n",
      "|    clip_fraction        | 0.0779       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.8        |\n",
      "|    explained_variance   | 0.117        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 9400         |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    reward               | 0.9099436    |\n",
      "|    std                  | 5.4          |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 17906       |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010407784 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | 1.2936634   |\n",
      "|    std                  | 5.41        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 943          |\n",
      "|    time_elapsed         | 17925        |\n",
      "|    total_timesteps      | 1931264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101084225 |\n",
      "|    clip_fraction        | 0.0979       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.9        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 9420         |\n",
      "|    policy_gradient_loss | -0.00987     |\n",
      "|    reward               | -0.4274489   |\n",
      "|    std                  | 5.43         |\n",
      "|    value_loss           | 64.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 944        |\n",
      "|    time_elapsed         | 17944      |\n",
      "|    total_timesteps      | 1933312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01071926 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.9      |\n",
      "|    explained_variance   | 0.415      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.8       |\n",
      "|    n_updates            | 9430       |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    reward               | 0.28778377 |\n",
      "|    std                  | 5.43       |\n",
      "|    value_loss           | 79.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 945         |\n",
      "|    time_elapsed         | 17963       |\n",
      "|    total_timesteps      | 1935360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008516092 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.2        |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | -4.797345   |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4324768.31\n",
      "total_reward: 3324768.31\n",
      "total_cost: 278006.12\n",
      "total_trades: 64746\n",
      "Sharpe: 0.707\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 17982       |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008676356 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.9        |\n",
      "|    n_updates            | 9450        |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    reward               | -1.4391046  |\n",
      "|    std                  | 5.45        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 18002       |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012661377 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.0378      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | -2.802304   |\n",
      "|    std                  | 5.46        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 948         |\n",
      "|    time_elapsed         | 18021       |\n",
      "|    total_timesteps      | 1941504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008799636 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.1        |\n",
      "|    n_updates            | 9470        |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | 0.19018821  |\n",
      "|    std                  | 5.47        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 18040       |\n",
      "|    total_timesteps      | 1943552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011355211 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | 1.1075039   |\n",
      "|    std                  | 5.47        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 950         |\n",
      "|    time_elapsed         | 18060       |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012430305 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | 1.3954142   |\n",
      "|    std                  | 5.48        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 951          |\n",
      "|    time_elapsed         | 18079        |\n",
      "|    total_timesteps      | 1947648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099828765 |\n",
      "|    clip_fraction        | 0.0914       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.3        |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 9500         |\n",
      "|    policy_gradient_loss | -0.00995     |\n",
      "|    reward               | 2.2812328    |\n",
      "|    std                  | 5.49         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 18098       |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009364402 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 9510        |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    reward               | 3.6972556   |\n",
      "|    std                  | 5.5         |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 953          |\n",
      "|    time_elapsed         | 18117        |\n",
      "|    total_timesteps      | 1951744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049035633 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.3        |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.6         |\n",
      "|    n_updates            | 9520         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | -0.83196306  |\n",
      "|    std                  | 5.5          |\n",
      "|    value_loss           | 88.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 18137       |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011292798 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.38112605  |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 955         |\n",
      "|    time_elapsed         | 18156       |\n",
      "|    total_timesteps      | 1955840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012765778 |\n",
      "|    clip_fraction        | 0.0972      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 9540        |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | 0.4825085   |\n",
      "|    std                  | 5.53        |\n",
      "|    value_loss           | 87.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 107       |\n",
      "|    iterations           | 956       |\n",
      "|    time_elapsed         | 18175     |\n",
      "|    total_timesteps      | 1957888   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.013674  |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -90.5     |\n",
      "|    explained_variance   | 0.249     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 62        |\n",
      "|    n_updates            | 9550      |\n",
      "|    policy_gradient_loss | -0.00536  |\n",
      "|    reward               | 0.5728126 |\n",
      "|    std                  | 5.54      |\n",
      "|    value_loss           | 101       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 957         |\n",
      "|    time_elapsed         | 18195       |\n",
      "|    total_timesteps      | 1959936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011078544 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.0449      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.04        |\n",
      "|    n_updates            | 9560        |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    reward               | 1.1413894   |\n",
      "|    std                  | 5.55        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 958          |\n",
      "|    time_elapsed         | 18215        |\n",
      "|    total_timesteps      | 1961984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130088795 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.6        |\n",
      "|    explained_variance   | 0.097        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 9570         |\n",
      "|    policy_gradient_loss | -0.00782     |\n",
      "|    reward               | -0.8783825   |\n",
      "|    std                  | 5.57         |\n",
      "|    value_loss           | 59.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 959         |\n",
      "|    time_elapsed         | 18235       |\n",
      "|    total_timesteps      | 1964032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012893515 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.3        |\n",
      "|    n_updates            | 9580        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    reward               | -1.0391431  |\n",
      "|    std                  | 5.58        |\n",
      "|    value_loss           | 96.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4713371.15\n",
      "total_reward: 3713371.15\n",
      "total_cost: 253092.52\n",
      "total_trades: 62967\n",
      "Sharpe: 0.837\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 960          |\n",
      "|    time_elapsed         | 18254        |\n",
      "|    total_timesteps      | 1966080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061541754 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.8        |\n",
      "|    explained_variance   | -0.0797      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 9590         |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    reward               | -0.9523301   |\n",
      "|    std                  | 5.59         |\n",
      "|    value_loss           | 51.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 18274       |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009150903 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 1.0591053   |\n",
      "|    std                  | 5.6         |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 962         |\n",
      "|    time_elapsed         | 18293       |\n",
      "|    total_timesteps      | 1970176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008968722 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.0605      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 9610        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | -0.11048617 |\n",
      "|    std                  | 5.6         |\n",
      "|    value_loss           | 83.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 18312       |\n",
      "|    total_timesteps      | 1972224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011518382 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | -0.0711     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 9620        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 4.705643    |\n",
      "|    std                  | 5.61        |\n",
      "|    value_loss           | 77.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 18331       |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016148638 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.0474      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.96        |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 1.4597789   |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 965          |\n",
      "|    time_elapsed         | 18351        |\n",
      "|    total_timesteps      | 1976320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076120514 |\n",
      "|    clip_fraction        | 0.052        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.1        |\n",
      "|    explained_variance   | 0.14         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 9640         |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    reward               | -0.026396189 |\n",
      "|    std                  | 5.65         |\n",
      "|    value_loss           | 64.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 18370       |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009058558 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | 0.23572691  |\n",
      "|    std                  | 5.66        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 967         |\n",
      "|    time_elapsed         | 18390       |\n",
      "|    total_timesteps      | 1980416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012631481 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | -0.103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 9660        |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | -6.6640215  |\n",
      "|    std                  | 5.68        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 18409       |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009742811 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.24661754 |\n",
      "|    std                  | 5.69        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 969          |\n",
      "|    time_elapsed         | 18428        |\n",
      "|    total_timesteps      | 1984512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053265593 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.3        |\n",
      "|    explained_variance   | -0.0098      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 9680         |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    reward               | -5.115215    |\n",
      "|    std                  | 5.69         |\n",
      "|    value_loss           | 60.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 970         |\n",
      "|    time_elapsed         | 18447       |\n",
      "|    total_timesteps      | 1986560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008934242 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.5        |\n",
      "|    n_updates            | 9690        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | 1.3593743   |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 18467       |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012087483 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | -1.5437609  |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 972         |\n",
      "|    time_elapsed         | 18486       |\n",
      "|    total_timesteps      | 1990656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010437159 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | 1.1248813   |\n",
      "|    std                  | 5.72        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 18505       |\n",
      "|    total_timesteps      | 1992704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009209766 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 9720        |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | -6.941557   |\n",
      "|    std                  | 5.73        |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4809278.20\n",
      "total_reward: 3809278.20\n",
      "total_cost: 280685.84\n",
      "total_trades: 65639\n",
      "Sharpe: 0.878\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 18524       |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010640378 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.0828      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | -0.4472436  |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 975         |\n",
      "|    time_elapsed         | 18543       |\n",
      "|    total_timesteps      | 1996800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009153355 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 9740        |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    reward               | -0.1514671  |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 976          |\n",
      "|    time_elapsed         | 18562        |\n",
      "|    total_timesteps      | 1998848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056396876 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.6        |\n",
      "|    explained_variance   | 0.133        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 9750         |\n",
      "|    policy_gradient_loss | -0.00766     |\n",
      "|    reward               | -8.594861    |\n",
      "|    std                  | 5.75         |\n",
      "|    value_loss           | 68.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 977         |\n",
      "|    time_elapsed         | 18581       |\n",
      "|    total_timesteps      | 2000896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010859959 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.0588      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 9760        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.5349159   |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 68.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 978          |\n",
      "|    time_elapsed         | 18600        |\n",
      "|    total_timesteps      | 2002944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067090522 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.7        |\n",
      "|    explained_variance   | 0.0439       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39           |\n",
      "|    n_updates            | 9770         |\n",
      "|    policy_gradient_loss | -0.00923     |\n",
      "|    reward               | 1.2634324    |\n",
      "|    std                  | 5.76         |\n",
      "|    value_loss           | 68.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 18619       |\n",
      "|    total_timesteps      | 2004992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011641669 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 9780        |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    reward               | -0.26788044 |\n",
      "|    std                  | 5.77        |\n",
      "|    value_loss           | 68.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 980         |\n",
      "|    time_elapsed         | 18638       |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009634832 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | 1.846995    |\n",
      "|    std                  | 5.78        |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 981        |\n",
      "|    time_elapsed         | 18657      |\n",
      "|    total_timesteps      | 2009088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01618917 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.8      |\n",
      "|    explained_variance   | 0.115      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.47       |\n",
      "|    n_updates            | 9800       |\n",
      "|    policy_gradient_loss | -0.00811   |\n",
      "|    reward               | 1.4240252  |\n",
      "|    std                  | 5.79       |\n",
      "|    value_loss           | 22.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 982        |\n",
      "|    time_elapsed         | 18676      |\n",
      "|    total_timesteps      | 2011136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01503753 |\n",
      "|    clip_fraction        | 0.0959     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.8      |\n",
      "|    explained_variance   | 0.253      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.1       |\n",
      "|    n_updates            | 9810       |\n",
      "|    policy_gradient_loss | -0.000415  |\n",
      "|    reward               | 0.12976296 |\n",
      "|    std                  | 5.8        |\n",
      "|    value_loss           | 49.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 983        |\n",
      "|    time_elapsed         | 18695      |\n",
      "|    total_timesteps      | 2013184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01311194 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.9      |\n",
      "|    explained_variance   | 0.113      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 58.5       |\n",
      "|    n_updates            | 9820       |\n",
      "|    policy_gradient_loss | -0.00632   |\n",
      "|    reward               | -3.175879  |\n",
      "|    std                  | 5.8        |\n",
      "|    value_loss           | 83.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 984         |\n",
      "|    time_elapsed         | 18714       |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014574889 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 9830        |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    reward               | -0.8477861  |\n",
      "|    std                  | 5.82        |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 985          |\n",
      "|    time_elapsed         | 18733        |\n",
      "|    total_timesteps      | 2017280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143878795 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92          |\n",
      "|    explained_variance   | 0.202        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 9840         |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    reward               | -2.0585608   |\n",
      "|    std                  | 5.83         |\n",
      "|    value_loss           | 52.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 986         |\n",
      "|    time_elapsed         | 18752       |\n",
      "|    total_timesteps      | 2019328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009303989 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.0913      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.4        |\n",
      "|    n_updates            | 9850        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -0.18328892 |\n",
      "|    std                  | 5.84        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 987         |\n",
      "|    time_elapsed         | 18772       |\n",
      "|    total_timesteps      | 2021376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008381749 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.0268      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.4        |\n",
      "|    n_updates            | 9860        |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | 0.25392333  |\n",
      "|    std                  | 5.84        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6225763.85\n",
      "total_reward: 5225763.85\n",
      "total_cost: 282129.94\n",
      "total_trades: 66131\n",
      "Sharpe: 0.947\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 18792       |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012960355 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.0361      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.23        |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    reward               | -1.3472749  |\n",
      "|    std                  | 5.84        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 989          |\n",
      "|    time_elapsed         | 18811        |\n",
      "|    total_timesteps      | 2025472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074383635 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.1        |\n",
      "|    explained_variance   | 0.0836       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.2         |\n",
      "|    n_updates            | 9880         |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | -0.06274055  |\n",
      "|    std                  | 5.84         |\n",
      "|    value_loss           | 215          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 18831       |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009737123 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.0729      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | 0.51346326  |\n",
      "|    std                  | 5.85        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 18850       |\n",
      "|    total_timesteps      | 2029568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014687142 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.0824      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    reward               | 1.6748384   |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 992         |\n",
      "|    time_elapsed         | 18869       |\n",
      "|    total_timesteps      | 2031616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014220408 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.4        |\n",
      "|    n_updates            | 9910        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | -3.0706449  |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 993         |\n",
      "|    time_elapsed         | 18889       |\n",
      "|    total_timesteps      | 2033664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009537632 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.0843      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    reward               | 6.965685    |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 994        |\n",
      "|    time_elapsed         | 18908      |\n",
      "|    total_timesteps      | 2035712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01395809 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.2      |\n",
      "|    explained_variance   | -0.021     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.6       |\n",
      "|    n_updates            | 9930       |\n",
      "|    policy_gradient_loss | -0.00845   |\n",
      "|    reward               | -1.6157597 |\n",
      "|    std                  | 5.88       |\n",
      "|    value_loss           | 82.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 18927       |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014160268 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.0784      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | -2.481044   |\n",
      "|    std                  | 5.88        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 18947       |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008982863 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.084       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.4        |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    reward               | 0.14432485  |\n",
      "|    std                  | 5.89        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 997         |\n",
      "|    time_elapsed         | 18966       |\n",
      "|    total_timesteps      | 2041856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007872649 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.0328      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 9960        |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    reward               | -19.118343  |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 18985       |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015743218 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | -0.00365    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -2.795308   |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 19004       |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010131694 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    reward               | -2.3283036  |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 77.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1000        |\n",
      "|    time_elapsed         | 19023       |\n",
      "|    total_timesteps      | 2048000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003918059 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.0426      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | 1.3672171   |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1001        |\n",
      "|    time_elapsed         | 19042       |\n",
      "|    total_timesteps      | 2050048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009489047 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.0231      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | -0.5130976  |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 96.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5947852.22\n",
      "total_reward: 4947852.22\n",
      "total_cost: 269541.84\n",
      "total_trades: 65095\n",
      "Sharpe: 0.934\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1002       |\n",
      "|    time_elapsed         | 19061      |\n",
      "|    total_timesteps      | 2052096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01276993 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.5      |\n",
      "|    explained_variance   | 0.0223     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 67.3       |\n",
      "|    n_updates            | 10010      |\n",
      "|    policy_gradient_loss | -0.00835   |\n",
      "|    reward               | 0.60892504 |\n",
      "|    std                  | 5.93       |\n",
      "|    value_loss           | 152        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1003        |\n",
      "|    time_elapsed         | 19080       |\n",
      "|    total_timesteps      | 2054144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015769582 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.0311      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 10020       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | -0.17815052 |\n",
      "|    std                  | 5.94        |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1004       |\n",
      "|    time_elapsed         | 19099      |\n",
      "|    total_timesteps      | 2056192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01885032 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.6      |\n",
      "|    explained_variance   | 0.00308    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 62         |\n",
      "|    n_updates            | 10030      |\n",
      "|    policy_gradient_loss | -0.00604   |\n",
      "|    reward               | 1.7851279  |\n",
      "|    std                  | 5.96       |\n",
      "|    value_loss           | 190        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 19119       |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012661813 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | 0.45825538  |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1006        |\n",
      "|    time_elapsed         | 19139       |\n",
      "|    total_timesteps      | 2060288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009636231 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | -1.8345698  |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1007        |\n",
      "|    time_elapsed         | 19157       |\n",
      "|    total_timesteps      | 2062336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006491345 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 10060       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | 2.2782133   |\n",
      "|    std                  | 5.98        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1008        |\n",
      "|    time_elapsed         | 19177       |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011619931 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 10070       |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | -1.4212847  |\n",
      "|    std                  | 5.98        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1009        |\n",
      "|    time_elapsed         | 19196       |\n",
      "|    total_timesteps      | 2066432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009708449 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 10080       |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | -1.553208   |\n",
      "|    std                  | 6.01        |\n",
      "|    value_loss           | 70.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 19217       |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012600806 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.2        |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -1.8946908  |\n",
      "|    std                  | 6.03        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1011         |\n",
      "|    time_elapsed         | 19237        |\n",
      "|    total_timesteps      | 2070528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036154005 |\n",
      "|    clip_fraction        | 0.00747      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.9        |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 10100        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    reward               | -0.02428814  |\n",
      "|    std                  | 6.03         |\n",
      "|    value_loss           | 57.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 19258       |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010626643 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.15        |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.40705442  |\n",
      "|    std                  | 6.04        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1013       |\n",
      "|    time_elapsed         | 19278      |\n",
      "|    total_timesteps      | 2074624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0066316  |\n",
      "|    clip_fraction        | 0.0429     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93        |\n",
      "|    explained_variance   | 0.33       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.6       |\n",
      "|    n_updates            | 10120      |\n",
      "|    policy_gradient_loss | -0.0049    |\n",
      "|    reward               | -2.9895043 |\n",
      "|    std                  | 6.05       |\n",
      "|    value_loss           | 55         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1014        |\n",
      "|    time_elapsed         | 19298       |\n",
      "|    total_timesteps      | 2076672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005033978 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 10130       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | -0.9983197  |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 19317       |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011887588 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | -0.95307505 |\n",
      "|    std                  | 6.08        |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3574813.80\n",
      "total_reward: 2574813.80\n",
      "total_cost: 206458.51\n",
      "total_trades: 62200\n",
      "Sharpe: 0.690\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1016        |\n",
      "|    time_elapsed         | 19337       |\n",
      "|    total_timesteps      | 2080768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012022639 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 10150       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -0.19589192 |\n",
      "|    std                  | 6.1         |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1017         |\n",
      "|    time_elapsed         | 19356        |\n",
      "|    total_timesteps      | 2082816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068638646 |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.3        |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 10160        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    reward               | 0.124897175  |\n",
      "|    std                  | 6.11         |\n",
      "|    value_loss           | 52.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1018        |\n",
      "|    time_elapsed         | 19376       |\n",
      "|    total_timesteps      | 2084864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009794595 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 10170       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | -0.39856118 |\n",
      "|    std                  | 6.12        |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 19396       |\n",
      "|    total_timesteps      | 2086912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010870966 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.31663385 |\n",
      "|    std                  | 6.13        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1020        |\n",
      "|    time_elapsed         | 19415       |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008595252 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.36898488  |\n",
      "|    std                  | 6.14        |\n",
      "|    value_loss           | 62          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1021       |\n",
      "|    time_elapsed         | 19434      |\n",
      "|    total_timesteps      | 2091008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00812827 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.5      |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.9       |\n",
      "|    n_updates            | 10200      |\n",
      "|    policy_gradient_loss | -0.00635   |\n",
      "|    reward               | 0.30778196 |\n",
      "|    std                  | 6.14       |\n",
      "|    value_loss           | 50.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1022         |\n",
      "|    time_elapsed         | 19453        |\n",
      "|    total_timesteps      | 2093056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088822115 |\n",
      "|    clip_fraction        | 0.0636       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.16         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 10210        |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    reward               | 0.28645316   |\n",
      "|    std                  | 6.14         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 19472       |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009445686 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 0.16134481  |\n",
      "|    std                  | 6.15        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1024        |\n",
      "|    time_elapsed         | 19491       |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012462647 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 10230       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    reward               | 0.9383028   |\n",
      "|    std                  | 6.16        |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 19511       |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019162562 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.00569     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 3.34034     |\n",
      "|    std                  | 6.18        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1026        |\n",
      "|    time_elapsed         | 19530       |\n",
      "|    total_timesteps      | 2101248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013900507 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.0699      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 10250       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.73840666  |\n",
      "|    std                  | 6.2         |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1027       |\n",
      "|    time_elapsed         | 19549      |\n",
      "|    total_timesteps      | 2103296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00941395 |\n",
      "|    clip_fraction        | 0.0888     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.8      |\n",
      "|    explained_variance   | 0.165      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 58.2       |\n",
      "|    n_updates            | 10260      |\n",
      "|    policy_gradient_loss | -0.0082    |\n",
      "|    reward               | 0.6075044  |\n",
      "|    std                  | 6.22       |\n",
      "|    value_loss           | 74.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1028       |\n",
      "|    time_elapsed         | 19568      |\n",
      "|    total_timesteps      | 2105344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0095699  |\n",
      "|    clip_fraction        | 0.0956     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.8      |\n",
      "|    explained_variance   | 0.296      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42.9       |\n",
      "|    n_updates            | 10270      |\n",
      "|    policy_gradient_loss | -0.0048    |\n",
      "|    reward               | -7.5650125 |\n",
      "|    std                  | 6.22       |\n",
      "|    value_loss           | 70         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 19587       |\n",
      "|    total_timesteps      | 2107392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013674993 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 10280       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 1.0316484   |\n",
      "|    std                  | 6.23        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5826653.33\n",
      "total_reward: 4826653.33\n",
      "total_cost: 283094.73\n",
      "total_trades: 65902\n",
      "Sharpe: 0.930\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1030         |\n",
      "|    time_elapsed         | 19607        |\n",
      "|    total_timesteps      | 2109440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061322274 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.9        |\n",
      "|    explained_variance   | 0.0441       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.6         |\n",
      "|    n_updates            | 10290        |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    reward               | 0.25818595   |\n",
      "|    std                  | 6.24         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1031         |\n",
      "|    time_elapsed         | 19627        |\n",
      "|    total_timesteps      | 2111488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105200205 |\n",
      "|    clip_fraction        | 0.0796       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.9        |\n",
      "|    explained_variance   | 0.0167       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.7         |\n",
      "|    n_updates            | 10300        |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    reward               | 0.34780794   |\n",
      "|    std                  | 6.24         |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1032        |\n",
      "|    time_elapsed         | 19646       |\n",
      "|    total_timesteps      | 2113536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010045669 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    reward               | -1.6024536  |\n",
      "|    std                  | 6.25        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 19665       |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010556966 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 1.8816509   |\n",
      "|    std                  | 6.25        |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1034       |\n",
      "|    time_elapsed         | 19684      |\n",
      "|    total_timesteps      | 2117632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01211055 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94        |\n",
      "|    explained_variance   | 0.033      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 76.4       |\n",
      "|    n_updates            | 10330      |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    reward               | 1.9782121  |\n",
      "|    std                  | 6.27       |\n",
      "|    value_loss           | 151        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 19703       |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011528349 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.0352      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -2.4610918  |\n",
      "|    std                  | 6.27        |\n",
      "|    value_loss           | 84          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1036        |\n",
      "|    time_elapsed         | 19723       |\n",
      "|    total_timesteps      | 2121728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017772786 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 10350       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 1.233589    |\n",
      "|    std                  | 6.29        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 19742       |\n",
      "|    total_timesteps      | 2123776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011377762 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | 0.6246216   |\n",
      "|    std                  | 6.3         |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1038         |\n",
      "|    time_elapsed         | 19762        |\n",
      "|    total_timesteps      | 2125824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077595906 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.2        |\n",
      "|    explained_variance   | 0.0688       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.6         |\n",
      "|    n_updates            | 10370        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    reward               | -5.682524    |\n",
      "|    std                  | 6.31         |\n",
      "|    value_loss           | 212          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1039       |\n",
      "|    time_elapsed         | 19781      |\n",
      "|    total_timesteps      | 2127872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01263221 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.3      |\n",
      "|    explained_variance   | -0.0208    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 10380      |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | -1.6796398 |\n",
      "|    std                  | 6.33       |\n",
      "|    value_loss           | 35.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1040        |\n",
      "|    time_elapsed         | 19800       |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010972497 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47          |\n",
      "|    n_updates            | 10390       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | -2.9873421  |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1041        |\n",
      "|    time_elapsed         | 19820       |\n",
      "|    total_timesteps      | 2131968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009121193 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.0619      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.5        |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | 1.8441639   |\n",
      "|    std                  | 6.35        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 19839       |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010004911 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | 1.422577    |\n",
      "|    std                  | 6.36        |\n",
      "|    value_loss           | 74.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 19858       |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011636384 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | -0.28272966 |\n",
      "|    std                  | 6.38        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3465808.91\n",
      "total_reward: 2465808.91\n",
      "total_cost: 303764.50\n",
      "total_trades: 67644\n",
      "Sharpe: 0.622\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1044       |\n",
      "|    time_elapsed         | 19877      |\n",
      "|    total_timesteps      | 2138112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01329507 |\n",
      "|    clip_fraction        | 0.087      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.6      |\n",
      "|    explained_variance   | -0.0135    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 94.7       |\n",
      "|    n_updates            | 10430      |\n",
      "|    policy_gradient_loss | -0.00997   |\n",
      "|    reward               | 0.14093587 |\n",
      "|    std                  | 6.4        |\n",
      "|    value_loss           | 208        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1045        |\n",
      "|    time_elapsed         | 19896       |\n",
      "|    total_timesteps      | 2140160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004984052 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.6        |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | 4.2699156   |\n",
      "|    std                  | 6.4         |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 19916       |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015468124 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | -0.00717    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | -2.7214453  |\n",
      "|    std                  | 6.42        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1047       |\n",
      "|    time_elapsed         | 19935      |\n",
      "|    total_timesteps      | 2144256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01098953 |\n",
      "|    clip_fraction        | 0.0867     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.8      |\n",
      "|    explained_variance   | 0.0133     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 93.1       |\n",
      "|    n_updates            | 10460      |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    reward               | -3.1870098 |\n",
      "|    std                  | 6.44       |\n",
      "|    value_loss           | 209        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 19954       |\n",
      "|    total_timesteps      | 2146304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009784259 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.0432      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.7        |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -2.5276678  |\n",
      "|    std                  | 6.44        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1049        |\n",
      "|    time_elapsed         | 19973       |\n",
      "|    total_timesteps      | 2148352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008275164 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.0165      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.00754    |\n",
      "|    reward               | -1.1049944  |\n",
      "|    std                  | 6.45        |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1050         |\n",
      "|    time_elapsed         | 19992        |\n",
      "|    total_timesteps      | 2150400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116365235 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.9        |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 10490        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | -2.630292    |\n",
      "|    std                  | 6.47         |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1051        |\n",
      "|    time_elapsed         | 20011       |\n",
      "|    total_timesteps      | 2152448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007002972 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 10500       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | 0.31396908  |\n",
      "|    std                  | 6.47        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 20030       |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008820674 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | -1.47e-05   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.7        |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.2546679  |\n",
      "|    std                  | 6.48        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 20050       |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014488732 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.0737      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.36        |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.1384333   |\n",
      "|    std                  | 6.51        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1054        |\n",
      "|    time_elapsed         | 20069       |\n",
      "|    total_timesteps      | 2158592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010669428 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 0.17450275  |\n",
      "|    std                  | 6.51        |\n",
      "|    value_loss           | 65.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1055        |\n",
      "|    time_elapsed         | 20088       |\n",
      "|    total_timesteps      | 2160640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008033463 |\n",
      "|    clip_fraction        | 0.0481      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | 2.4876645   |\n",
      "|    std                  | 6.52        |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 20107       |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011741484 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | -0.0291     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 10550       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -1.9270364  |\n",
      "|    std                  | 6.53        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1057        |\n",
      "|    time_elapsed         | 20126       |\n",
      "|    total_timesteps      | 2164736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009418614 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.0496      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 10560       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.32168764  |\n",
      "|    std                  | 6.54        |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1058        |\n",
      "|    time_elapsed         | 20146       |\n",
      "|    total_timesteps      | 2166784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010232354 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.0178      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 10570       |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -9.838766   |\n",
      "|    std                  | 6.54        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3509994.02\n",
      "total_reward: 2509994.02\n",
      "total_cost: 330641.35\n",
      "total_trades: 67932\n",
      "Sharpe: 0.727\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1059       |\n",
      "|    time_elapsed         | 20165      |\n",
      "|    total_timesteps      | 2168832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00851782 |\n",
      "|    clip_fraction        | 0.0627     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.3      |\n",
      "|    explained_variance   | 0.022      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 60.1       |\n",
      "|    n_updates            | 10580      |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    reward               | 0.79716384 |\n",
      "|    std                  | 6.55       |\n",
      "|    value_loss           | 72.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1060        |\n",
      "|    time_elapsed         | 20184       |\n",
      "|    total_timesteps      | 2170880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013582623 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.0515      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.06        |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | 0.1462002   |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 20204       |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005142167 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.0456      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.5        |\n",
      "|    n_updates            | 10600       |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | -0.48330522 |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 20223       |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009748049 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.0479      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -1.9898566  |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 94.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1063        |\n",
      "|    time_elapsed         | 20242       |\n",
      "|    total_timesteps      | 2177024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012875069 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.0312      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 10620       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | -2.1178513  |\n",
      "|    std                  | 6.57        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 20261       |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006287962 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.0698      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | -2.4877415  |\n",
      "|    std                  | 6.58        |\n",
      "|    value_loss           | 92.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1065         |\n",
      "|    time_elapsed         | 20281        |\n",
      "|    total_timesteps      | 2181120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048914477 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.5        |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.9         |\n",
      "|    n_updates            | 10640        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | 1.6622661    |\n",
      "|    std                  | 6.59         |\n",
      "|    value_loss           | 83.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1066         |\n",
      "|    time_elapsed         | 20300        |\n",
      "|    total_timesteps      | 2183168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077959257 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.5        |\n",
      "|    explained_variance   | 0.0466       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 10650        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    reward               | -0.8036609   |\n",
      "|    std                  | 6.59         |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1067        |\n",
      "|    time_elapsed         | 20320       |\n",
      "|    total_timesteps      | 2185216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012724456 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.8        |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -0.32063502 |\n",
      "|    std                  | 6.6         |\n",
      "|    value_loss           | 97.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1068         |\n",
      "|    time_elapsed         | 20339        |\n",
      "|    total_timesteps      | 2187264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048495946 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.5        |\n",
      "|    explained_variance   | 0.061        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.7         |\n",
      "|    n_updates            | 10670        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | -1.6744076   |\n",
      "|    std                  | 6.61         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1069         |\n",
      "|    time_elapsed         | 20358        |\n",
      "|    total_timesteps      | 2189312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100770965 |\n",
      "|    clip_fraction        | 0.0707       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.6        |\n",
      "|    explained_variance   | 0.0427       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.5         |\n",
      "|    n_updates            | 10680        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    reward               | 1.6314346    |\n",
      "|    std                  | 6.61         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1070       |\n",
      "|    time_elapsed         | 20377      |\n",
      "|    total_timesteps      | 2191360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01231266 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.7      |\n",
      "|    explained_variance   | 0.0236     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.42       |\n",
      "|    n_updates            | 10690      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    reward               | 0.8922726  |\n",
      "|    std                  | 6.64       |\n",
      "|    value_loss           | 25.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1071        |\n",
      "|    time_elapsed         | 20397       |\n",
      "|    total_timesteps      | 2193408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009874508 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.0913      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 10700       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 1.3466454   |\n",
      "|    std                  | 6.65        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1072         |\n",
      "|    time_elapsed         | 20418        |\n",
      "|    total_timesteps      | 2195456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005538192 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.8        |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 10710        |\n",
      "|    policy_gradient_loss | -0.000687    |\n",
      "|    reward               | 3.4924939    |\n",
      "|    std                  | 6.65         |\n",
      "|    value_loss           | 298          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4855707.50\n",
      "total_reward: 3855707.50\n",
      "total_cost: 353157.36\n",
      "total_trades: 69103\n",
      "Sharpe: 0.818\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 20438       |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013093677 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | 0.0573      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | -0.06489877 |\n",
      "|    std                  | 6.66        |\n",
      "|    value_loss           | 74.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1074        |\n",
      "|    time_elapsed         | 20459       |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010056075 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | -0.00753    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 10730       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | 0.8854866   |\n",
      "|    std                  | 6.67        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1075        |\n",
      "|    time_elapsed         | 20479       |\n",
      "|    total_timesteps      | 2201600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004212481 |\n",
      "|    clip_fraction        | 0.0213      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 10740       |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    reward               | 0.16730078  |\n",
      "|    std                  | 6.67        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1076        |\n",
      "|    time_elapsed         | 20499       |\n",
      "|    total_timesteps      | 2203648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007064663 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.9        |\n",
      "|    n_updates            | 10750       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    reward               | -0.41940352 |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 20519       |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011556978 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | -0.158      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.44        |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -1.4668382  |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1078        |\n",
      "|    time_elapsed         | 20538       |\n",
      "|    total_timesteps      | 2207744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006793812 |\n",
      "|    clip_fraction        | 0.0327      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.0437      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 10770       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | -0.10949068 |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1079         |\n",
      "|    time_elapsed         | 20557        |\n",
      "|    total_timesteps      | 2209792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015508048  |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.9        |\n",
      "|    explained_variance   | 0.0417       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.8         |\n",
      "|    n_updates            | 10780        |\n",
      "|    policy_gradient_loss | -0.00925     |\n",
      "|    reward               | -0.058635607 |\n",
      "|    std                  | 6.7          |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1080        |\n",
      "|    time_elapsed         | 20576       |\n",
      "|    total_timesteps      | 2211840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014187231 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | -0.0219     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 10790       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -1.3775493  |\n",
      "|    std                  | 6.72        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1081        |\n",
      "|    time_elapsed         | 20596       |\n",
      "|    total_timesteps      | 2213888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011307182 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 10800       |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    reward               | -1.6689334  |\n",
      "|    std                  | 6.73        |\n",
      "|    value_loss           | 66.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1082        |\n",
      "|    time_elapsed         | 20615       |\n",
      "|    total_timesteps      | 2215936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008032924 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | 4.3997116   |\n",
      "|    std                  | 6.74        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 20634       |\n",
      "|    total_timesteps      | 2217984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010303154 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | -0.0626     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 10820       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | -3.7163336  |\n",
      "|    std                  | 6.75        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1084        |\n",
      "|    time_elapsed         | 20655       |\n",
      "|    total_timesteps      | 2220032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011898476 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 0.36950207  |\n",
      "|    std                  | 6.77        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 20674       |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011530796 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.0297      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.9        |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 0.39411774  |\n",
      "|    std                  | 6.78        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 20693       |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008501602 |\n",
      "|    clip_fraction        | 0.0848      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 10850       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -9.666693   |\n",
      "|    std                  | 6.79        |\n",
      "|    value_loss           | 91.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4344075.32\n",
      "total_reward: 3344075.32\n",
      "total_cost: 300765.07\n",
      "total_trades: 66112\n",
      "Sharpe: 0.797\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 20712       |\n",
      "|    total_timesteps      | 2226176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011048876 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.0696      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 1.5865495   |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1088        |\n",
      "|    time_elapsed         | 20732       |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011543738 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.0612      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.5        |\n",
      "|    n_updates            | 10870       |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | -2.991593   |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1089        |\n",
      "|    time_elapsed         | 20751       |\n",
      "|    total_timesteps      | 2230272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007817141 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.0878      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | -5.9546556  |\n",
      "|    std                  | 6.81        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1090        |\n",
      "|    time_elapsed         | 20770       |\n",
      "|    total_timesteps      | 2232320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011245949 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | -0.00168    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 10890       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -3.297043   |\n",
      "|    std                  | 6.82        |\n",
      "|    value_loss           | 93.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 20789       |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011556959 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.034       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.9        |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 0.24533936  |\n",
      "|    std                  | 6.83        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 20808       |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005900586 |\n",
      "|    clip_fraction        | 0.0364      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.0566      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.7        |\n",
      "|    n_updates            | 10910       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.80563897 |\n",
      "|    std                  | 6.84        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1093         |\n",
      "|    time_elapsed         | 20828        |\n",
      "|    total_timesteps      | 2238464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062222914 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.6        |\n",
      "|    explained_variance   | 0.055        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82           |\n",
      "|    n_updates            | 10920        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | -2.2983282   |\n",
      "|    std                  | 6.84         |\n",
      "|    value_loss           | 186          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1094        |\n",
      "|    time_elapsed         | 20848       |\n",
      "|    total_timesteps      | 2240512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013936004 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.0516      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 10930       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 1.7302291   |\n",
      "|    std                  | 6.85        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1095         |\n",
      "|    time_elapsed         | 20867        |\n",
      "|    total_timesteps      | 2242560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019410468 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.6        |\n",
      "|    explained_variance   | 0.0702       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 132          |\n",
      "|    n_updates            | 10940        |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    reward               | -0.30574042  |\n",
      "|    std                  | 6.85         |\n",
      "|    value_loss           | 191          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1096        |\n",
      "|    time_elapsed         | 20887       |\n",
      "|    total_timesteps      | 2244608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009498566 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.0421      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.2        |\n",
      "|    n_updates            | 10950       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | -2.2948582  |\n",
      "|    std                  | 6.85        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1097         |\n",
      "|    time_elapsed         | 20906        |\n",
      "|    total_timesteps      | 2246656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050709457 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.0333       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.8         |\n",
      "|    n_updates            | 10960        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | -0.93862396  |\n",
      "|    std                  | 6.85         |\n",
      "|    value_loss           | 96.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1098         |\n",
      "|    time_elapsed         | 20926        |\n",
      "|    total_timesteps      | 2248704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068076993 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.0242       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.2         |\n",
      "|    n_updates            | 10970        |\n",
      "|    policy_gradient_loss | -0.00811     |\n",
      "|    reward               | -2.6772954   |\n",
      "|    std                  | 6.86         |\n",
      "|    value_loss           | 215          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1099        |\n",
      "|    time_elapsed         | 20945       |\n",
      "|    total_timesteps      | 2250752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001934906 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.0528      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.6        |\n",
      "|    n_updates            | 10980       |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    reward               | 12.014766   |\n",
      "|    std                  | 6.86        |\n",
      "|    value_loss           | 270         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1100         |\n",
      "|    time_elapsed         | 20965        |\n",
      "|    total_timesteps      | 2252800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010055203 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 169          |\n",
      "|    n_updates            | 10990        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 3.419009     |\n",
      "|    std                  | 6.86         |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6324425.91\n",
      "total_reward: 5324425.91\n",
      "total_cost: 256351.42\n",
      "total_trades: 64788\n",
      "Sharpe: 0.910\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 20985       |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010951664 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.0623      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    reward               | 4.21761     |\n",
      "|    std                  | 6.88        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1102        |\n",
      "|    time_elapsed         | 21005       |\n",
      "|    total_timesteps      | 2256896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008105254 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.076       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | 0.39917332  |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1103        |\n",
      "|    time_elapsed         | 21024       |\n",
      "|    total_timesteps      | 2258944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006144292 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.0639      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -0.8003936  |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 316         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1104        |\n",
      "|    time_elapsed         | 21043       |\n",
      "|    total_timesteps      | 2260992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010233823 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.0878      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | 4.528377    |\n",
      "|    std                  | 6.9         |\n",
      "|    value_loss           | 65          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1105         |\n",
      "|    time_elapsed         | 21063        |\n",
      "|    total_timesteps      | 2263040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037267706 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.0879       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 163          |\n",
      "|    n_updates            | 11040        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | -3.6232033   |\n",
      "|    std                  | 6.91         |\n",
      "|    value_loss           | 229          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1106        |\n",
      "|    time_elapsed         | 21083       |\n",
      "|    total_timesteps      | 2265088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006782463 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.0932      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.6        |\n",
      "|    n_updates            | 11050       |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    reward               | -6.2373843  |\n",
      "|    std                  | 6.92        |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1107        |\n",
      "|    time_elapsed         | 21102       |\n",
      "|    total_timesteps      | 2267136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006890022 |\n",
      "|    clip_fraction        | 0.0372      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 11060       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | 0.6085853   |\n",
      "|    std                  | 6.93        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1108         |\n",
      "|    time_elapsed         | 21122        |\n",
      "|    total_timesteps      | 2269184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030531427 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97          |\n",
      "|    explained_variance   | 0.0965       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 11070        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | 0.22007848   |\n",
      "|    std                  | 6.93         |\n",
      "|    value_loss           | 251          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1109         |\n",
      "|    time_elapsed         | 21142        |\n",
      "|    total_timesteps      | 2271232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023873877 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97          |\n",
      "|    explained_variance   | 0.103        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 143          |\n",
      "|    n_updates            | 11080        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | 0.34713197   |\n",
      "|    std                  | 6.93         |\n",
      "|    value_loss           | 360          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1110        |\n",
      "|    time_elapsed         | 21161       |\n",
      "|    total_timesteps      | 2273280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001659737 |\n",
      "|    clip_fraction        | 0.00801     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.0705      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 11090       |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    reward               | 6.7297573   |\n",
      "|    std                  | 6.94        |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1111        |\n",
      "|    time_elapsed         | 21180       |\n",
      "|    total_timesteps      | 2275328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011756589 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | -0.0389     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | -3.850262   |\n",
      "|    std                  | 6.94        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1112         |\n",
      "|    time_elapsed         | 21199        |\n",
      "|    total_timesteps      | 2277376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036711416 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97          |\n",
      "|    explained_variance   | 0.0064       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.5         |\n",
      "|    n_updates            | 11110        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    reward               | 0.9086122    |\n",
      "|    std                  | 6.94         |\n",
      "|    value_loss           | 249          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1113          |\n",
      "|    time_elapsed         | 21219         |\n",
      "|    total_timesteps      | 2279424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067041744 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -97.1         |\n",
      "|    explained_variance   | 0.152         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 58.2          |\n",
      "|    n_updates            | 11120         |\n",
      "|    policy_gradient_loss | -0.00204      |\n",
      "|    reward               | 6.732916      |\n",
      "|    std                  | 6.95          |\n",
      "|    value_loss           | 186           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1114        |\n",
      "|    time_elapsed         | 21238       |\n",
      "|    total_timesteps      | 2281472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008194933 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    reward               | 0.95289284  |\n",
      "|    std                  | 6.96        |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6363431.90\n",
      "total_reward: 5363431.90\n",
      "total_cost: 278621.14\n",
      "total_trades: 65730\n",
      "Sharpe: 0.919\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 21257       |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009859061 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    reward               | -0.5338809  |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1116         |\n",
      "|    time_elapsed         | 21276        |\n",
      "|    total_timesteps      | 2285568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084491465 |\n",
      "|    clip_fraction        | 0.045        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.2        |\n",
      "|    explained_variance   | 0.0456       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 227          |\n",
      "|    n_updates            | 11150        |\n",
      "|    policy_gradient_loss | -0.00748     |\n",
      "|    reward               | 1.3892026    |\n",
      "|    std                  | 6.98         |\n",
      "|    value_loss           | 299          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 21295       |\n",
      "|    total_timesteps      | 2287616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008528583 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 11160       |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | 0.6874729   |\n",
      "|    std                  | 7           |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1118        |\n",
      "|    time_elapsed         | 21314       |\n",
      "|    total_timesteps      | 2289664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014432558 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.056       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 11170       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.6097926  |\n",
      "|    std                  | 7.02        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1119        |\n",
      "|    time_elapsed         | 21333       |\n",
      "|    total_timesteps      | 2291712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010413913 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.0335      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 11180       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 0.63850796  |\n",
      "|    std                  | 7.03        |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 21353       |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012896214 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.7        |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    reward               | 1.6961123   |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1121        |\n",
      "|    time_elapsed         | 21372       |\n",
      "|    total_timesteps      | 2295808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010739914 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 11200       |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    reward               | -3.8025894  |\n",
      "|    std                  | 7.06        |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1122       |\n",
      "|    time_elapsed         | 21392      |\n",
      "|    total_timesteps      | 2297856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00900415 |\n",
      "|    clip_fraction        | 0.0481     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.6      |\n",
      "|    explained_variance   | 0.061      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 58.3       |\n",
      "|    n_updates            | 11210      |\n",
      "|    policy_gradient_loss | -0.00922   |\n",
      "|    reward               | -0.857107  |\n",
      "|    std                  | 7.07       |\n",
      "|    value_loss           | 162        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1123        |\n",
      "|    time_elapsed         | 21411       |\n",
      "|    total_timesteps      | 2299904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007267912 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 234         |\n",
      "|    n_updates            | 11220       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | 13.092249   |\n",
      "|    std                  | 7.07        |\n",
      "|    value_loss           | 308         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1124         |\n",
      "|    time_elapsed         | 21430        |\n",
      "|    total_timesteps      | 2301952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008256376  |\n",
      "|    clip_fraction        | 0.0738       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.6        |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.4         |\n",
      "|    n_updates            | 11230        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | -0.114775755 |\n",
      "|    std                  | 7.07         |\n",
      "|    value_loss           | 184          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1125         |\n",
      "|    time_elapsed         | 21449        |\n",
      "|    total_timesteps      | 2304000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011273096  |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.6        |\n",
      "|    explained_variance   | 0.0195       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 11240        |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    reward               | -0.039806303 |\n",
      "|    std                  | 7.09         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1126         |\n",
      "|    time_elapsed         | 21468        |\n",
      "|    total_timesteps      | 2306048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056789066 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.7        |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 11250        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | 0.43950292   |\n",
      "|    std                  | 7.1          |\n",
      "|    value_loss           | 245          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1127        |\n",
      "|    time_elapsed         | 21487       |\n",
      "|    total_timesteps      | 2308096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016024606 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 11260       |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | 0.9381236   |\n",
      "|    std                  | 7.12        |\n",
      "|    value_loss           | 320         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1128        |\n",
      "|    time_elapsed         | 21507       |\n",
      "|    total_timesteps      | 2310144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010672725 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | -0.00442    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | 0.6856664   |\n",
      "|    std                  | 7.15        |\n",
      "|    value_loss           | 76          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6027885.37\n",
      "total_reward: 5027885.37\n",
      "total_cost: 249901.01\n",
      "total_trades: 63205\n",
      "Sharpe: 0.981\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1129        |\n",
      "|    time_elapsed         | 21526       |\n",
      "|    total_timesteps      | 2312192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003057268 |\n",
      "|    clip_fraction        | 0.00845     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 11280       |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | -4.5041327  |\n",
      "|    std                  | 7.16        |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1130         |\n",
      "|    time_elapsed         | 21545        |\n",
      "|    total_timesteps      | 2314240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041861413 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.9         |\n",
      "|    n_updates            | 11290        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | -2.8433003   |\n",
      "|    std                  | 7.17         |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1131         |\n",
      "|    time_elapsed         | 21564        |\n",
      "|    total_timesteps      | 2316288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041102055 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | -0.00732     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.6         |\n",
      "|    n_updates            | 11300        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | -0.40617058  |\n",
      "|    std                  | 7.17         |\n",
      "|    value_loss           | 89.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1132         |\n",
      "|    time_elapsed         | 21584        |\n",
      "|    total_timesteps      | 2318336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114488285 |\n",
      "|    clip_fraction        | 0.0915       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 11310        |\n",
      "|    policy_gradient_loss | -0.00979     |\n",
      "|    reward               | 4.289052     |\n",
      "|    std                  | 7.17         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1133        |\n",
      "|    time_elapsed         | 21603       |\n",
      "|    total_timesteps      | 2320384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009376558 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 11320       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 0.3136939   |\n",
      "|    std                  | 7.18        |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1134         |\n",
      "|    time_elapsed         | 21622        |\n",
      "|    total_timesteps      | 2322432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098429285 |\n",
      "|    clip_fraction        | 0.0779       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.1        |\n",
      "|    explained_variance   | 0.0353       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 11330        |\n",
      "|    policy_gradient_loss | -0.00873     |\n",
      "|    reward               | 7.942593     |\n",
      "|    std                  | 7.2          |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1135         |\n",
      "|    time_elapsed         | 21641        |\n",
      "|    total_timesteps      | 2324480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127254985 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.2        |\n",
      "|    explained_variance   | -0.0226      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 11340        |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | -0.32852748  |\n",
      "|    std                  | 7.23         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1136        |\n",
      "|    time_elapsed         | 21661       |\n",
      "|    total_timesteps      | 2326528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00791738  |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.0814      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.2        |\n",
      "|    n_updates            | 11350       |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | -0.28321302 |\n",
      "|    std                  | 7.25        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1137         |\n",
      "|    time_elapsed         | 21680        |\n",
      "|    total_timesteps      | 2328576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045854514 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.3        |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 11360        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | -1.1971592   |\n",
      "|    std                  | 7.25         |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1138         |\n",
      "|    time_elapsed         | 21700        |\n",
      "|    total_timesteps      | 2330624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014549359 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.3        |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 11370        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | 2.4754608    |\n",
      "|    std                  | 7.25         |\n",
      "|    value_loss           | 59           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1139         |\n",
      "|    time_elapsed         | 21719        |\n",
      "|    total_timesteps      | 2332672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052427882 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.3        |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.6         |\n",
      "|    n_updates            | 11380        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | 1.1577711    |\n",
      "|    std                  | 7.27         |\n",
      "|    value_loss           | 78.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 21738       |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006054452 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68          |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | -1.0672446  |\n",
      "|    std                  | 7.28        |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1141        |\n",
      "|    time_elapsed         | 21757       |\n",
      "|    total_timesteps      | 2336768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002992016 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 11400       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | 4.312136    |\n",
      "|    std                  | 7.28        |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 21776       |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012261941 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.0672      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -1.309937   |\n",
      "|    std                  | 7.3         |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4685753.41\n",
      "total_reward: 3685753.41\n",
      "total_cost: 295683.54\n",
      "total_trades: 66741\n",
      "Sharpe: 0.800\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1143       |\n",
      "|    time_elapsed         | 21795      |\n",
      "|    total_timesteps      | 2340864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00918485 |\n",
      "|    clip_fraction        | 0.0787     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.5      |\n",
      "|    explained_variance   | 0.194      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 188        |\n",
      "|    n_updates            | 11420      |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    reward               | 0.02033701 |\n",
      "|    std                  | 7.32       |\n",
      "|    value_loss           | 234        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 21814       |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005692389 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.0756      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 11430       |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    reward               | -1.9124148  |\n",
      "|    std                  | 7.32        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1145        |\n",
      "|    time_elapsed         | 21833       |\n",
      "|    total_timesteps      | 2344960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006629315 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | -0.058      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 11440       |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | -1.2132256  |\n",
      "|    std                  | 7.34        |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1146        |\n",
      "|    time_elapsed         | 21852       |\n",
      "|    total_timesteps      | 2347008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010465955 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.1        |\n",
      "|    n_updates            | 11450       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | 0.45884714  |\n",
      "|    std                  | 7.35        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1147         |\n",
      "|    time_elapsed         | 21872        |\n",
      "|    total_timesteps      | 2349056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017902631 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 139          |\n",
      "|    n_updates            | 11460        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    reward               | 33.077946    |\n",
      "|    std                  | 7.35         |\n",
      "|    value_loss           | 186          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1148        |\n",
      "|    time_elapsed         | 21891       |\n",
      "|    total_timesteps      | 2351104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004518302 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.0525      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 11470       |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    reward               | 1.205379    |\n",
      "|    std                  | 7.35        |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1149         |\n",
      "|    time_elapsed         | 21910        |\n",
      "|    total_timesteps      | 2353152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01107888   |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | -0.0753      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 11480        |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    reward               | -0.043672584 |\n",
      "|    std                  | 7.35         |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1150        |\n",
      "|    time_elapsed         | 21930       |\n",
      "|    total_timesteps      | 2355200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010073436 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 11490       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.5515909   |\n",
      "|    std                  | 7.36        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1151        |\n",
      "|    time_elapsed         | 21949       |\n",
      "|    total_timesteps      | 2357248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004861856 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.0887      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 11500       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | -1.5368651  |\n",
      "|    std                  | 7.37        |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 21969       |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008081019 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | -0.0165     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 11510       |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | 4.973952    |\n",
      "|    std                  | 7.37        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1153        |\n",
      "|    time_elapsed         | 21988       |\n",
      "|    total_timesteps      | 2361344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004322975 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 11520       |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | -7.9968257  |\n",
      "|    std                  | 7.38        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1154         |\n",
      "|    time_elapsed         | 22007        |\n",
      "|    total_timesteps      | 2363392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014314798 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.8        |\n",
      "|    explained_variance   | 0.0995       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 11530        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | -6.518169    |\n",
      "|    std                  | 7.38         |\n",
      "|    value_loss           | 176          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1155        |\n",
      "|    time_elapsed         | 22026       |\n",
      "|    total_timesteps      | 2365440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006502117 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.0406      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.4        |\n",
      "|    n_updates            | 11540       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | -1.285633   |\n",
      "|    std                  | 7.38        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 22045       |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007490436 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.4        |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | -0.20011687 |\n",
      "|    std                  | 7.39        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5185082.71\n",
      "total_reward: 4185082.71\n",
      "total_cost: 325655.56\n",
      "total_trades: 68250\n",
      "Sharpe: 0.834\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1157         |\n",
      "|    time_elapsed         | 22064        |\n",
      "|    total_timesteps      | 2369536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024366523 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.8        |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.2         |\n",
      "|    n_updates            | 11560        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | 0.5994333    |\n",
      "|    std                  | 7.39         |\n",
      "|    value_loss           | 212          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1158        |\n",
      "|    time_elapsed         | 22084       |\n",
      "|    total_timesteps      | 2371584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011122595 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.0735      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    reward               | 2.6002274   |\n",
      "|    std                  | 7.41        |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 22103       |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013487866 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | -0.0289     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 11580       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 1.6819123   |\n",
      "|    std                  | 7.44        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 22167       |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006060115 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.0354      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 11590       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | 0.70089006  |\n",
      "|    std                  | 7.46        |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1161        |\n",
      "|    time_elapsed         | 22187       |\n",
      "|    total_timesteps      | 2377728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007014481 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.0533      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.4        |\n",
      "|    n_updates            | 11600       |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    reward               | 2.0559947   |\n",
      "|    std                  | 7.46        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 22206       |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011186065 |\n",
      "|    clip_fraction        | 0.0714      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.7        |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 2.8419466   |\n",
      "|    std                  | 7.48        |\n",
      "|    value_loss           | 93.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1163         |\n",
      "|    time_elapsed         | 22225        |\n",
      "|    total_timesteps      | 2381824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078021893 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.2        |\n",
      "|    explained_variance   | 0.179        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 11620        |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    reward               | -0.30883908  |\n",
      "|    std                  | 7.49         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1164         |\n",
      "|    time_elapsed         | 22245        |\n",
      "|    total_timesteps      | 2383872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051589515 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.3        |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 11630        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    reward               | -0.2463787   |\n",
      "|    std                  | 7.5          |\n",
      "|    value_loss           | 219          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1165         |\n",
      "|    time_elapsed         | 22264        |\n",
      "|    total_timesteps      | 2385920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029401095 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.3        |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 175          |\n",
      "|    n_updates            | 11640        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | 2.991473     |\n",
      "|    std                  | 7.51         |\n",
      "|    value_loss           | 227          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1166        |\n",
      "|    time_elapsed         | 22283       |\n",
      "|    total_timesteps      | 2387968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019282427 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | -0.163      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 11650       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -1.7855614  |\n",
      "|    std                  | 7.51        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1167         |\n",
      "|    time_elapsed         | 22302        |\n",
      "|    total_timesteps      | 2390016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048043923 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.3        |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 11660        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | -0.74937737  |\n",
      "|    std                  | 7.52         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1168        |\n",
      "|    time_elapsed         | 22321       |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005092818 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.0857      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -0.31105268 |\n",
      "|    std                  | 7.52        |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 22341       |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011278795 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.0257      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 1.8702095   |\n",
      "|    std                  | 7.53        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1170        |\n",
      "|    time_elapsed         | 22360       |\n",
      "|    total_timesteps      | 2396160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007893549 |\n",
      "|    clip_fraction        | 0.0517      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | 2.7272396   |\n",
      "|    std                  | 7.55        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 22379       |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006909575 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.0575      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.1        |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | -10.078655  |\n",
      "|    std                  | 7.55        |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4839188.13\n",
      "total_reward: 3839188.13\n",
      "total_cost: 345375.83\n",
      "total_trades: 69744\n",
      "Sharpe: 0.827\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1172        |\n",
      "|    time_elapsed         | 22399       |\n",
      "|    total_timesteps      | 2400256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014550436 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.0476      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.3        |\n",
      "|    n_updates            | 11710       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -1.3450081  |\n",
      "|    std                  | 7.59        |\n",
      "|    value_loss           | 82.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 22418       |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009244442 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | -0.0358     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 11720       |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    reward               | 2.475125    |\n",
      "|    std                  | 7.62        |\n",
      "|    value_loss           | 92.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1174        |\n",
      "|    time_elapsed         | 22437       |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006554011 |\n",
      "|    clip_fraction        | 0.0303      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.0357      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.3        |\n",
      "|    n_updates            | 11730       |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | -0.9168223  |\n",
      "|    std                  | 7.62        |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1175         |\n",
      "|    time_elapsed         | 22457        |\n",
      "|    total_timesteps      | 2406400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060821543 |\n",
      "|    clip_fraction        | 0.0487       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.2         |\n",
      "|    n_updates            | 11740        |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    reward               | -7.15538     |\n",
      "|    std                  | 7.63         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1176         |\n",
      "|    time_elapsed         | 22476        |\n",
      "|    total_timesteps      | 2408448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130207045 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | -0.0104      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 11750        |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    reward               | 3.353115     |\n",
      "|    std                  | 7.65         |\n",
      "|    value_loss           | 52.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1177        |\n",
      "|    time_elapsed         | 22495       |\n",
      "|    total_timesteps      | 2410496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005079862 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 11760       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | 0.43815807  |\n",
      "|    std                  | 7.65        |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1178         |\n",
      "|    time_elapsed         | 22514        |\n",
      "|    total_timesteps      | 2412544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019036132 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 100          |\n",
      "|    n_updates            | 11770        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | 13.262447    |\n",
      "|    std                  | 7.66         |\n",
      "|    value_loss           | 226          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1179        |\n",
      "|    time_elapsed         | 22533       |\n",
      "|    total_timesteps      | 2414592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008066986 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.0542      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.2        |\n",
      "|    n_updates            | 11780       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | 3.5661595   |\n",
      "|    std                  | 7.67        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1180        |\n",
      "|    time_elapsed         | 22552       |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007919783 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.086       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.3        |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | 0.021484155 |\n",
      "|    std                  | 7.68        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1181         |\n",
      "|    time_elapsed         | 22571        |\n",
      "|    total_timesteps      | 2418688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020322804 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.9        |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.1         |\n",
      "|    n_updates            | 11800        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | 1.0140872    |\n",
      "|    std                  | 7.69         |\n",
      "|    value_loss           | 196          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1182         |\n",
      "|    time_elapsed         | 22590        |\n",
      "|    total_timesteps      | 2420736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038310841 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41           |\n",
      "|    n_updates            | 11810        |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | 3.2856464    |\n",
      "|    std                  | 7.69         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 22609       |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011038034 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0995      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    reward               | -2.9475343  |\n",
      "|    std                  | 7.71        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1184         |\n",
      "|    time_elapsed         | 22628        |\n",
      "|    total_timesteps      | 2424832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061600786 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.00633      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.2         |\n",
      "|    n_updates            | 11830        |\n",
      "|    policy_gradient_loss | -0.00988     |\n",
      "|    reward               | -0.107863255 |\n",
      "|    std                  | 7.71         |\n",
      "|    value_loss           | 300          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1185        |\n",
      "|    time_elapsed         | 22648       |\n",
      "|    total_timesteps      | 2426880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004314931 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 11840       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | -2.0829935  |\n",
      "|    std                  | 7.72        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6557770.62\n",
      "total_reward: 5557770.62\n",
      "total_cost: 315498.96\n",
      "total_trades: 68335\n",
      "Sharpe: 0.932\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1186        |\n",
      "|    time_elapsed         | 22667       |\n",
      "|    total_timesteps      | 2428928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009378586 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0292      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.5        |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | 0.17606406  |\n",
      "|    std                  | 7.74        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1187         |\n",
      "|    time_elapsed         | 22686        |\n",
      "|    total_timesteps      | 2430976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061681587 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 11860        |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    reward               | -1.5100884   |\n",
      "|    std                  | 7.76         |\n",
      "|    value_loss           | 194          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1188         |\n",
      "|    time_elapsed         | 22705        |\n",
      "|    total_timesteps      | 2433024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047134347 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.6         |\n",
      "|    n_updates            | 11870        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | -0.85384965  |\n",
      "|    std                  | 7.77         |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1189         |\n",
      "|    time_elapsed         | 22725        |\n",
      "|    total_timesteps      | 2435072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054822974 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.7         |\n",
      "|    n_updates            | 11880        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -1.4107666   |\n",
      "|    std                  | 7.78         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1190       |\n",
      "|    time_elapsed         | 22744      |\n",
      "|    total_timesteps      | 2437120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01441681 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -100       |\n",
      "|    explained_variance   | 0.09       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.41       |\n",
      "|    n_updates            | 11890      |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | 1.5379853  |\n",
      "|    std                  | 7.81       |\n",
      "|    value_loss           | 22.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1191         |\n",
      "|    time_elapsed         | 22764        |\n",
      "|    total_timesteps      | 2439168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051911455 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.144        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.5         |\n",
      "|    n_updates            | 11900        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -2.5448275   |\n",
      "|    std                  | 7.81         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1192         |\n",
      "|    time_elapsed         | 22784        |\n",
      "|    total_timesteps      | 2441216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044007795 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78           |\n",
      "|    n_updates            | 11910        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | -2.181484    |\n",
      "|    std                  | 7.82         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1193        |\n",
      "|    time_elapsed         | 22803       |\n",
      "|    total_timesteps      | 2443264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010362846 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 11920       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | 2.1907887   |\n",
      "|    std                  | 7.83        |\n",
      "|    value_loss           | 54.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1194         |\n",
      "|    time_elapsed         | 22822        |\n",
      "|    total_timesteps      | 2445312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077616586 |\n",
      "|    clip_fraction        | 0.0552       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.7         |\n",
      "|    n_updates            | 11930        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    reward               | -0.667558    |\n",
      "|    std                  | 7.84         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1195        |\n",
      "|    time_elapsed         | 22841       |\n",
      "|    total_timesteps      | 2447360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007719295 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.8        |\n",
      "|    n_updates            | 11940       |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    reward               | -1.1098047  |\n",
      "|    std                  | 7.85        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1196         |\n",
      "|    time_elapsed         | 22860        |\n",
      "|    total_timesteps      | 2449408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065295063 |\n",
      "|    clip_fraction        | 0.0389       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 11950        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | -0.35630345  |\n",
      "|    std                  | 7.86         |\n",
      "|    value_loss           | 76.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 22879       |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010416955 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.9        |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.06651165  |\n",
      "|    std                  | 7.87        |\n",
      "|    value_loss           | 98.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1198        |\n",
      "|    time_elapsed         | 22898       |\n",
      "|    total_timesteps      | 2453504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005613571 |\n",
      "|    clip_fraction        | 0.0349      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.6        |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | -0.6068714  |\n",
      "|    std                  | 7.89        |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1199         |\n",
      "|    time_elapsed         | 22917        |\n",
      "|    total_timesteps      | 2455552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010260553 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.7         |\n",
      "|    n_updates            | 11980        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -32.665413   |\n",
      "|    std                  | 7.89         |\n",
      "|    value_loss           | 274          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6768353.62\n",
      "total_reward: 5768353.62\n",
      "total_cost: 279814.83\n",
      "total_trades: 66759\n",
      "Sharpe: 0.906\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1200       |\n",
      "|    time_elapsed         | 22937      |\n",
      "|    total_timesteps      | 2457600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01172767 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.0566     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.5       |\n",
      "|    n_updates            | 11990      |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | 2.1968527  |\n",
      "|    std                  | 7.92       |\n",
      "|    value_loss           | 67.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1201        |\n",
      "|    time_elapsed         | 22956       |\n",
      "|    total_timesteps      | 2459648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004383245 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.2        |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | 1.4469063   |\n",
      "|    std                  | 7.93        |\n",
      "|    value_loss           | 275         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1202        |\n",
      "|    time_elapsed         | 22976       |\n",
      "|    total_timesteps      | 2461696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006960529 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 12010       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | -2.9220011  |\n",
      "|    std                  | 7.94        |\n",
      "|    value_loss           | 223         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 22996       |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007696595 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    reward               | 4.817376    |\n",
      "|    std                  | 7.96        |\n",
      "|    value_loss           | 83.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1204         |\n",
      "|    time_elapsed         | 23015        |\n",
      "|    total_timesteps      | 2465792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064102267 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.9         |\n",
      "|    n_updates            | 12030        |\n",
      "|    policy_gradient_loss | -0.0086      |\n",
      "|    reward               | 2.0312526    |\n",
      "|    std                  | 7.98         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1205        |\n",
      "|    time_elapsed         | 23035       |\n",
      "|    total_timesteps      | 2467840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005944862 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0463      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.3        |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -0.12045045 |\n",
      "|    std                  | 8           |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1206        |\n",
      "|    time_elapsed         | 23054       |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008659581 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.4        |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | 0.123653725 |\n",
      "|    std                  | 8.01        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1207        |\n",
      "|    time_elapsed         | 23074       |\n",
      "|    total_timesteps      | 2471936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011174906 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 12060       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 1.3042678   |\n",
      "|    std                  | 8.03        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1208         |\n",
      "|    time_elapsed         | 23094        |\n",
      "|    total_timesteps      | 2473984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057074623 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.7         |\n",
      "|    n_updates            | 12070        |\n",
      "|    policy_gradient_loss | -0.0092      |\n",
      "|    reward               | 0.045979656  |\n",
      "|    std                  | 8.03         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1209        |\n",
      "|    time_elapsed         | 23113       |\n",
      "|    total_timesteps      | 2476032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010079777 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.2        |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    reward               | -10.148709  |\n",
      "|    std                  | 8.04        |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1210        |\n",
      "|    time_elapsed         | 23132       |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013325968 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.1        |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -3.9158964  |\n",
      "|    std                  | 8.06        |\n",
      "|    value_loss           | 92          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1211        |\n",
      "|    time_elapsed         | 23151       |\n",
      "|    total_timesteps      | 2480128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008561749 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | 1.4026912   |\n",
      "|    std                  | 8.07        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1212       |\n",
      "|    time_elapsed         | 23171      |\n",
      "|    total_timesteps      | 2482176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00963624 |\n",
      "|    clip_fraction        | 0.0583     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.397      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.9       |\n",
      "|    n_updates            | 12110      |\n",
      "|    policy_gradient_loss | -0.00824   |\n",
      "|    reward               | 8.702727   |\n",
      "|    std                  | 8.08       |\n",
      "|    value_loss           | 136        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1213        |\n",
      "|    time_elapsed         | 23190       |\n",
      "|    total_timesteps      | 2484224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006271882 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.9        |\n",
      "|    n_updates            | 12120       |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | 1.1278185   |\n",
      "|    std                  | 8.1         |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6089045.75\n",
      "total_reward: 5089045.75\n",
      "total_cost: 289861.51\n",
      "total_trades: 66617\n",
      "Sharpe: 0.935\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1214        |\n",
      "|    time_elapsed         | 23209       |\n",
      "|    total_timesteps      | 2486272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015110612 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | -0.0921     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 12130       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 2.1865644   |\n",
      "|    std                  | 8.12        |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1215        |\n",
      "|    time_elapsed         | 23228       |\n",
      "|    total_timesteps      | 2488320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009404566 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 12140       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | -0.545493   |\n",
      "|    std                  | 8.14        |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1216        |\n",
      "|    time_elapsed         | 23247       |\n",
      "|    total_timesteps      | 2490368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006494753 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.6        |\n",
      "|    n_updates            | 12150       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | 0.22328939  |\n",
      "|    std                  | 8.16        |\n",
      "|    value_loss           | 85.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 23266       |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013515511 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | -0.0286     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 2.1339798   |\n",
      "|    std                  | 8.19        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 23284       |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009462299 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.0713      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 4.762827    |\n",
      "|    std                  | 8.2         |\n",
      "|    value_loss           | 85.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1219        |\n",
      "|    time_elapsed         | 23303       |\n",
      "|    total_timesteps      | 2496512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009212287 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.032       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 12180       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -2.5267575  |\n",
      "|    std                  | 8.21        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1220        |\n",
      "|    time_elapsed         | 23322       |\n",
      "|    total_timesteps      | 2498560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007206601 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.0801      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 12190       |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    reward               | 0.5403538   |\n",
      "|    std                  | 8.22        |\n",
      "|    value_loss           | 58          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1221        |\n",
      "|    time_elapsed         | 23341       |\n",
      "|    total_timesteps      | 2500608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011026299 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -1.1658149  |\n",
      "|    std                  | 8.22        |\n",
      "|    value_loss           | 63.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1222         |\n",
      "|    time_elapsed         | 23359        |\n",
      "|    total_timesteps      | 2502656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049283914 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.3         |\n",
      "|    n_updates            | 12210        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    reward               | 0.20800754   |\n",
      "|    std                  | 8.22         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1223         |\n",
      "|    time_elapsed         | 23378        |\n",
      "|    total_timesteps      | 2504704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034009905 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.6         |\n",
      "|    n_updates            | 12220        |\n",
      "|    policy_gradient_loss | -0.000268    |\n",
      "|    reward               | 1.8656163    |\n",
      "|    std                  | 8.22         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1224        |\n",
      "|    time_elapsed         | 23397       |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008972105 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | -0.445      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 12230       |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | -0.44810885 |\n",
      "|    std                  | 8.24        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1225         |\n",
      "|    time_elapsed         | 23416        |\n",
      "|    total_timesteps      | 2508800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065052067 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.7         |\n",
      "|    n_updates            | 12240        |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | -0.9327628   |\n",
      "|    std                  | 8.25         |\n",
      "|    value_loss           | 99.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1226        |\n",
      "|    time_elapsed         | 23435       |\n",
      "|    total_timesteps      | 2510848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006070382 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.7        |\n",
      "|    n_updates            | 12250       |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    reward               | -3.9537137  |\n",
      "|    std                  | 8.26        |\n",
      "|    value_loss           | 94.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1227       |\n",
      "|    time_elapsed         | 23453      |\n",
      "|    total_timesteps      | 2512896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00615244 |\n",
      "|    clip_fraction        | 0.0262     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -102       |\n",
      "|    explained_variance   | 0.264      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.9       |\n",
      "|    n_updates            | 12260      |\n",
      "|    policy_gradient_loss | -0.00507   |\n",
      "|    reward               | 1.1518052  |\n",
      "|    std                  | 8.26       |\n",
      "|    value_loss           | 59.1       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6185990.47\n",
      "total_reward: 5185990.47\n",
      "total_cost: 273980.87\n",
      "total_trades: 66761\n",
      "Sharpe: 0.935\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1228       |\n",
      "|    time_elapsed         | 23472      |\n",
      "|    total_timesteps      | 2514944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00999747 |\n",
      "|    clip_fraction        | 0.0782     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -102       |\n",
      "|    explained_variance   | 0.322      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 67.6       |\n",
      "|    n_updates            | 12270      |\n",
      "|    policy_gradient_loss | -0.0071    |\n",
      "|    reward               | 3.2101684  |\n",
      "|    std                  | 8.26       |\n",
      "|    value_loss           | 102        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1229       |\n",
      "|    time_elapsed         | 23491      |\n",
      "|    total_timesteps      | 2516992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00984659 |\n",
      "|    clip_fraction        | 0.0853     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -102       |\n",
      "|    explained_variance   | 0.00629    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.3       |\n",
      "|    n_updates            | 12280      |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    reward               | 0.32112855 |\n",
      "|    std                  | 8.29       |\n",
      "|    value_loss           | 186        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1230        |\n",
      "|    time_elapsed         | 23509       |\n",
      "|    total_timesteps      | 2519040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007328484 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 12290       |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | -2.412195   |\n",
      "|    std                  | 8.29        |\n",
      "|    value_loss           | 223         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1231        |\n",
      "|    time_elapsed         | 23528       |\n",
      "|    total_timesteps      | 2521088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012104405 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 12300       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 1.7201147   |\n",
      "|    std                  | 8.32        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1232         |\n",
      "|    time_elapsed         | 23547        |\n",
      "|    total_timesteps      | 2523136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022945509 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.0428       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.5         |\n",
      "|    n_updates            | 12310        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 0.18626586   |\n",
      "|    std                  | 8.32         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1233         |\n",
      "|    time_elapsed         | 23565        |\n",
      "|    total_timesteps      | 2525184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013200267 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.9         |\n",
      "|    n_updates            | 12320        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | -9.781154    |\n",
      "|    std                  | 8.33         |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1234        |\n",
      "|    time_elapsed         | 23584       |\n",
      "|    total_timesteps      | 2527232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01023267  |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 12330       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -0.17090103 |\n",
      "|    std                  | 8.35        |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1235        |\n",
      "|    time_elapsed         | 23603       |\n",
      "|    total_timesteps      | 2529280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006053681 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | -2.0956588  |\n",
      "|    std                  | 8.35        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1236         |\n",
      "|    time_elapsed         | 23621        |\n",
      "|    total_timesteps      | 2531328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016707827 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 12350        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | 14.965966    |\n",
      "|    std                  | 8.36         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1237         |\n",
      "|    time_elapsed         | 23640        |\n",
      "|    total_timesteps      | 2533376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032038987 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85.4         |\n",
      "|    n_updates            | 12360        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | 2.5793371    |\n",
      "|    std                  | 8.36         |\n",
      "|    value_loss           | 205          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1238        |\n",
      "|    time_elapsed         | 23659       |\n",
      "|    total_timesteps      | 2535424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013764081 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | -0.149      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 12370       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.5463555  |\n",
      "|    std                  | 8.38        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1239         |\n",
      "|    time_elapsed         | 23678        |\n",
      "|    total_timesteps      | 2537472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006529157  |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | -0.00623     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 12380        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    reward               | -0.008522151 |\n",
      "|    std                  | 8.39         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1240         |\n",
      "|    time_elapsed         | 23697        |\n",
      "|    total_timesteps      | 2539520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068513253 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.7         |\n",
      "|    n_updates            | 12390        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | -0.56920356  |\n",
      "|    std                  | 8.4          |\n",
      "|    value_loss           | 79           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1241        |\n",
      "|    time_elapsed         | 23716       |\n",
      "|    total_timesteps      | 2541568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012154039 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.0961      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 12400       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 3.1236293   |\n",
      "|    std                  | 8.43        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3491805.48\n",
      "total_reward: 2491805.48\n",
      "total_cost: 292930.24\n",
      "total_trades: 66699\n",
      "Sharpe: 0.638\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1242       |\n",
      "|    time_elapsed         | 23735      |\n",
      "|    total_timesteps      | 2543616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01079847 |\n",
      "|    clip_fraction        | 0.0724     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.596      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.3       |\n",
      "|    n_updates            | 12410      |\n",
      "|    policy_gradient_loss | -0.00846   |\n",
      "|    reward               | 3.3313344  |\n",
      "|    std                  | 8.45       |\n",
      "|    value_loss           | 56.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1243        |\n",
      "|    time_elapsed         | 23754       |\n",
      "|    total_timesteps      | 2545664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006451524 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.0828      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.3        |\n",
      "|    n_updates            | 12420       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | -13.626575  |\n",
      "|    std                  | 8.45        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1244         |\n",
      "|    time_elapsed         | 23773        |\n",
      "|    total_timesteps      | 2547712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096008815 |\n",
      "|    clip_fraction        | 0.0677       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 12430        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    reward               | -1.4616449   |\n",
      "|    std                  | 8.46         |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1245         |\n",
      "|    time_elapsed         | 23793        |\n",
      "|    total_timesteps      | 2549760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129433945 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.8         |\n",
      "|    n_updates            | 12440        |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    reward               | 1.4948415    |\n",
      "|    std                  | 8.48         |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1246       |\n",
      "|    time_elapsed         | 23813      |\n",
      "|    total_timesteps      | 2551808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00970301 |\n",
      "|    clip_fraction        | 0.0887     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.411      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.3       |\n",
      "|    n_updates            | 12450      |\n",
      "|    policy_gradient_loss | -0.00621   |\n",
      "|    reward               | -1.1534818 |\n",
      "|    std                  | 8.49       |\n",
      "|    value_loss           | 88.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1247         |\n",
      "|    time_elapsed         | 23833        |\n",
      "|    total_timesteps      | 2553856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068175355 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.298        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.9         |\n",
      "|    n_updates            | 12460        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | -3.2154112   |\n",
      "|    std                  | 8.5          |\n",
      "|    value_loss           | 68.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1248        |\n",
      "|    time_elapsed         | 23853       |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015204111 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | -0.0204     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 12470       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.74521244 |\n",
      "|    std                  | 8.51        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1249        |\n",
      "|    time_elapsed         | 23872       |\n",
      "|    total_timesteps      | 2557952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004877531 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 12480       |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | 0.103395484 |\n",
      "|    std                  | 8.52        |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1250         |\n",
      "|    time_elapsed         | 23891        |\n",
      "|    total_timesteps      | 2560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046555935 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 12490        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    reward               | 3.5867236    |\n",
      "|    std                  | 8.52         |\n",
      "|    value_loss           | 73.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1251       |\n",
      "|    time_elapsed         | 23910      |\n",
      "|    total_timesteps      | 2562048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01385284 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.438      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.3       |\n",
      "|    n_updates            | 12500      |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    reward               | 3.8078144  |\n",
      "|    std                  | 8.54       |\n",
      "|    value_loss           | 48         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1252        |\n",
      "|    time_elapsed         | 23930       |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010222359 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 12510       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 2.5816002   |\n",
      "|    std                  | 8.56        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1253       |\n",
      "|    time_elapsed         | 23950      |\n",
      "|    total_timesteps      | 2566144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00953971 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.737      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.3       |\n",
      "|    n_updates            | 12520      |\n",
      "|    policy_gradient_loss | 0.00156    |\n",
      "|    reward               | -0.62344   |\n",
      "|    std                  | 8.56       |\n",
      "|    value_loss           | 74.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1254        |\n",
      "|    time_elapsed         | 23970       |\n",
      "|    total_timesteps      | 2568192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008336394 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 12530       |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    reward               | -0.0546076  |\n",
      "|    std                  | 8.57        |\n",
      "|    value_loss           | 81.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1255        |\n",
      "|    time_elapsed         | 23990       |\n",
      "|    total_timesteps      | 2570240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014292097 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.1949754   |\n",
      "|    std                  | 8.57        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4233623.05\n",
      "total_reward: 3233623.05\n",
      "total_cost: 259379.50\n",
      "total_trades: 64874\n",
      "Sharpe: 0.819\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1256        |\n",
      "|    time_elapsed         | 24009       |\n",
      "|    total_timesteps      | 2572288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008241242 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 12550       |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    reward               | -0.8743617  |\n",
      "|    std                  | 8.57        |\n",
      "|    value_loss           | 77.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1257        |\n",
      "|    time_elapsed         | 24028       |\n",
      "|    total_timesteps      | 2574336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008103659 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.8        |\n",
      "|    n_updates            | 12560       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | -1.5368927  |\n",
      "|    std                  | 8.58        |\n",
      "|    value_loss           | 95          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1258        |\n",
      "|    time_elapsed         | 24047       |\n",
      "|    total_timesteps      | 2576384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013310829 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 12570       |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | 0.32631475  |\n",
      "|    std                  | 8.59        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 24066       |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01024938  |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    reward               | -0.48970857 |\n",
      "|    std                  | 8.59        |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1260         |\n",
      "|    time_elapsed         | 24084        |\n",
      "|    total_timesteps      | 2580480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068377815 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.8         |\n",
      "|    n_updates            | 12590        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    reward               | 20.95747     |\n",
      "|    std                  | 8.6          |\n",
      "|    value_loss           | 71.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 24103       |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010021346 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | -3.047357   |\n",
      "|    std                  | 8.61        |\n",
      "|    value_loss           | 58          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 24121       |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013245929 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 12610       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 1.1635283   |\n",
      "|    std                  | 8.62        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1263         |\n",
      "|    time_elapsed         | 24140        |\n",
      "|    total_timesteps      | 2586624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053903325 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.7         |\n",
      "|    n_updates            | 12620        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    reward               | 0.70218307   |\n",
      "|    std                  | 8.63         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1264        |\n",
      "|    time_elapsed         | 24159       |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002959882 |\n",
      "|    clip_fraction        | 0.00894     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 12630       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | -14.410578  |\n",
      "|    std                  | 8.63        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1265         |\n",
      "|    time_elapsed         | 24178        |\n",
      "|    total_timesteps      | 2590720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059386254 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 12640        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | -0.8021465   |\n",
      "|    std                  | 8.64         |\n",
      "|    value_loss           | 56.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1266         |\n",
      "|    time_elapsed         | 24197        |\n",
      "|    total_timesteps      | 2592768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016534347 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.6         |\n",
      "|    n_updates            | 12650        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | 1.3874657    |\n",
      "|    std                  | 8.64         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1267        |\n",
      "|    time_elapsed         | 24215       |\n",
      "|    total_timesteps      | 2594816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007404921 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 12660       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -0.4305219  |\n",
      "|    std                  | 8.64        |\n",
      "|    value_loss           | 86.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1268        |\n",
      "|    time_elapsed         | 24234       |\n",
      "|    total_timesteps      | 2596864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009638072 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 12670       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -1.6531457  |\n",
      "|    std                  | 8.66        |\n",
      "|    value_loss           | 58.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1269       |\n",
      "|    time_elapsed         | 24253      |\n",
      "|    total_timesteps      | 2598912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0086358  |\n",
      "|    clip_fraction        | 0.0501     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.539      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.1       |\n",
      "|    n_updates            | 12680      |\n",
      "|    policy_gradient_loss | -0.00744   |\n",
      "|    reward               | -1.1627061 |\n",
      "|    std                  | 8.68       |\n",
      "|    value_loss           | 56.7       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3564469.70\n",
      "total_reward: 2564469.70\n",
      "total_cost: 238844.58\n",
      "total_trades: 63908\n",
      "Sharpe: 0.629\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1270         |\n",
      "|    time_elapsed         | 24271        |\n",
      "|    total_timesteps      | 2600960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062347474 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.8         |\n",
      "|    n_updates            | 12690        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | 1.5425085    |\n",
      "|    std                  | 8.69         |\n",
      "|    value_loss           | 97.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1271         |\n",
      "|    time_elapsed         | 24291        |\n",
      "|    total_timesteps      | 2603008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027482086 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.1         |\n",
      "|    n_updates            | 12700        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -0.924166    |\n",
      "|    std                  | 8.69         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1272         |\n",
      "|    time_elapsed         | 24310        |\n",
      "|    total_timesteps      | 2605056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042851088 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 12710        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | 0.83390033   |\n",
      "|    std                  | 8.69         |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1273         |\n",
      "|    time_elapsed         | 24329        |\n",
      "|    total_timesteps      | 2607104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050698267 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 12720        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    reward               | -0.06577169  |\n",
      "|    std                  | 8.69         |\n",
      "|    value_loss           | 86.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1274        |\n",
      "|    time_elapsed         | 24348       |\n",
      "|    total_timesteps      | 2609152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007524512 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49          |\n",
      "|    n_updates            | 12730       |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | -5.6193924  |\n",
      "|    std                  | 8.71        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1275       |\n",
      "|    time_elapsed         | 24367      |\n",
      "|    total_timesteps      | 2611200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01252668 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | 0.28       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.3       |\n",
      "|    n_updates            | 12740      |\n",
      "|    policy_gradient_loss | -0.00918   |\n",
      "|    reward               | 1.941028   |\n",
      "|    std                  | 8.73       |\n",
      "|    value_loss           | 74.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1276         |\n",
      "|    time_elapsed         | 24385        |\n",
      "|    total_timesteps      | 2613248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041259364 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.3         |\n",
      "|    n_updates            | 12750        |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    reward               | 1.9975122    |\n",
      "|    std                  | 8.74         |\n",
      "|    value_loss           | 98.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1277         |\n",
      "|    time_elapsed         | 24404        |\n",
      "|    total_timesteps      | 2615296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014156897 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.6         |\n",
      "|    n_updates            | 12760        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | 0.896786     |\n",
      "|    std                  | 8.75         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1278          |\n",
      "|    time_elapsed         | 24423         |\n",
      "|    total_timesteps      | 2617344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00097299414 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -104          |\n",
      "|    explained_variance   | 0.635         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 45.6          |\n",
      "|    n_updates            | 12770         |\n",
      "|    policy_gradient_loss | -0.00252      |\n",
      "|    reward               | 2.4442847     |\n",
      "|    std                  | 8.75          |\n",
      "|    value_loss           | 101           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1279       |\n",
      "|    time_elapsed         | 24441      |\n",
      "|    total_timesteps      | 2619392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01568621 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | -0.106     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 12780      |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    reward               | 0.5390061  |\n",
      "|    std                  | 8.77       |\n",
      "|    value_loss           | 30.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1280         |\n",
      "|    time_elapsed         | 24460        |\n",
      "|    total_timesteps      | 2621440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032207568 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.1         |\n",
      "|    n_updates            | 12790        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -0.4661976   |\n",
      "|    std                  | 8.78         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1281         |\n",
      "|    time_elapsed         | 24478        |\n",
      "|    total_timesteps      | 2623488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036823284 |\n",
      "|    clip_fraction        | 0.00864      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 12800        |\n",
      "|    policy_gradient_loss | -0.00724     |\n",
      "|    reward               | -0.50481755  |\n",
      "|    std                  | 8.79         |\n",
      "|    value_loss           | 92.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1282        |\n",
      "|    time_elapsed         | 24497       |\n",
      "|    total_timesteps      | 2625536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011199091 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 12810       |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | 1.0696362   |\n",
      "|    std                  | 8.8         |\n",
      "|    value_loss           | 51.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1283         |\n",
      "|    time_elapsed         | 24516        |\n",
      "|    total_timesteps      | 2627584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066469973 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 12820        |\n",
      "|    policy_gradient_loss | -0.00754     |\n",
      "|    reward               | -3.1358385   |\n",
      "|    std                  | 8.81         |\n",
      "|    value_loss           | 60.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1284        |\n",
      "|    time_elapsed         | 24536       |\n",
      "|    total_timesteps      | 2629632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003067933 |\n",
      "|    clip_fraction        | 0.00283     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 12830       |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | -9.062661   |\n",
      "|    std                  | 8.82        |\n",
      "|    value_loss           | 66.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3358938.78\n",
      "total_reward: 2358938.78\n",
      "total_cost: 257617.32\n",
      "total_trades: 65163\n",
      "Sharpe: 0.657\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1285         |\n",
      "|    time_elapsed         | 24556        |\n",
      "|    total_timesteps      | 2631680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021623936 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.5         |\n",
      "|    n_updates            | 12840        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | 2.9522579    |\n",
      "|    std                  | 8.82         |\n",
      "|    value_loss           | 63.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1286         |\n",
      "|    time_elapsed         | 24576        |\n",
      "|    total_timesteps      | 2633728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072814636 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 12850        |\n",
      "|    policy_gradient_loss | -0.00744     |\n",
      "|    reward               | 0.3098243    |\n",
      "|    std                  | 8.83         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1287         |\n",
      "|    time_elapsed         | 24594        |\n",
      "|    total_timesteps      | 2635776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043078572 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.7         |\n",
      "|    n_updates            | 12860        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | -0.20913506  |\n",
      "|    std                  | 8.83         |\n",
      "|    value_loss           | 85.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1288        |\n",
      "|    time_elapsed         | 24614       |\n",
      "|    total_timesteps      | 2637824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008166252 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.5        |\n",
      "|    n_updates            | 12870       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | 7.1317863   |\n",
      "|    std                  | 8.84        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 24634       |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011297034 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 12880       |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | -4.778241   |\n",
      "|    std                  | 8.86        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1290        |\n",
      "|    time_elapsed         | 24653       |\n",
      "|    total_timesteps      | 2641920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006054937 |\n",
      "|    clip_fraction        | 0.0213      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.9        |\n",
      "|    n_updates            | 12890       |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | -0.27828485 |\n",
      "|    std                  | 8.87        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1291        |\n",
      "|    time_elapsed         | 24672       |\n",
      "|    total_timesteps      | 2643968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006849148 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.3        |\n",
      "|    n_updates            | 12900       |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | 3.28632     |\n",
      "|    std                  | 8.87        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1292        |\n",
      "|    time_elapsed         | 24691       |\n",
      "|    total_timesteps      | 2646016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005287133 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 12910       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | -0.22776073 |\n",
      "|    std                  | 8.88        |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 24709       |\n",
      "|    total_timesteps      | 2648064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008758975 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 12920       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -4.3873925  |\n",
      "|    std                  | 8.9         |\n",
      "|    value_loss           | 77.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1294        |\n",
      "|    time_elapsed         | 24728       |\n",
      "|    total_timesteps      | 2650112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004965299 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 12930       |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | 0.5682545   |\n",
      "|    std                  | 8.91        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1295         |\n",
      "|    time_elapsed         | 24747        |\n",
      "|    total_timesteps      | 2652160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053279977 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.3         |\n",
      "|    n_updates            | 12940        |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    reward               | -0.5263068   |\n",
      "|    std                  | 8.92         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 24766       |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018929763 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0373      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.64        |\n",
      "|    n_updates            | 12950       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | -2.1836765  |\n",
      "|    std                  | 8.96        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1297        |\n",
      "|    time_elapsed         | 24786       |\n",
      "|    total_timesteps      | 2656256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005743024 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 12960       |\n",
      "|    policy_gradient_loss | -0.00948    |\n",
      "|    reward               | 3.5013287   |\n",
      "|    std                  | 8.96        |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1298         |\n",
      "|    time_elapsed         | 24805        |\n",
      "|    total_timesteps      | 2658304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077526295 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.0693       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.9         |\n",
      "|    n_updates            | 12970        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    reward               | -0.38132536  |\n",
      "|    std                  | 8.96         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3697931.22\n",
      "total_reward: 2697931.22\n",
      "total_cost: 278308.26\n",
      "total_trades: 65989\n",
      "Sharpe: 0.646\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1299        |\n",
      "|    time_elapsed         | 24825       |\n",
      "|    total_timesteps      | 2660352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008001143 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 12980       |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | -1.2076538  |\n",
      "|    std                  | 8.97        |\n",
      "|    value_loss           | 72.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1300         |\n",
      "|    time_elapsed         | 24844        |\n",
      "|    total_timesteps      | 2662400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063742986 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.3         |\n",
      "|    n_updates            | 12990        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | -1.8557444   |\n",
      "|    std                  | 8.98         |\n",
      "|    value_loss           | 72.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 24862       |\n",
      "|    total_timesteps      | 2664448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005034408 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65          |\n",
      "|    n_updates            | 13000       |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | -15.045016  |\n",
      "|    std                  | 8.99        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1302        |\n",
      "|    time_elapsed         | 24881       |\n",
      "|    total_timesteps      | 2666496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010419115 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | -0.0034     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 13010       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | 0.51065177  |\n",
      "|    std                  | 9.03        |\n",
      "|    value_loss           | 272         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1303         |\n",
      "|    time_elapsed         | 24900        |\n",
      "|    total_timesteps      | 2668544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114763845 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.0595       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 13020        |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    reward               | -2.311183    |\n",
      "|    std                  | 9.05         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1304        |\n",
      "|    time_elapsed         | 24920       |\n",
      "|    total_timesteps      | 2670592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005024484 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | -1.7121931  |\n",
      "|    std                  | 9.06        |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1305        |\n",
      "|    time_elapsed         | 24939       |\n",
      "|    total_timesteps      | 2672640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006213751 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.1        |\n",
      "|    n_updates            | 13040       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | 1.8625422   |\n",
      "|    std                  | 9.07        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 24959       |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012233408 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 13050       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -1.1501536  |\n",
      "|    std                  | 9.09        |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1307        |\n",
      "|    time_elapsed         | 24979       |\n",
      "|    total_timesteps      | 2676736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006630405 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 13060       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 3.9783337   |\n",
      "|    std                  | 9.13        |\n",
      "|    value_loss           | 69.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1308        |\n",
      "|    time_elapsed         | 24998       |\n",
      "|    total_timesteps      | 2678784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007466092 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 13070       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -2.313251   |\n",
      "|    std                  | 9.14        |\n",
      "|    value_loss           | 84.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1309        |\n",
      "|    time_elapsed         | 25017       |\n",
      "|    total_timesteps      | 2680832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007015895 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | -0.000496   |\n",
      "|    reward               | 0.9468293   |\n",
      "|    std                  | 9.15        |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 25036       |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009646641 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 13090       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | 0.792687    |\n",
      "|    std                  | 9.14        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1311        |\n",
      "|    time_elapsed         | 25055       |\n",
      "|    total_timesteps      | 2684928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004035688 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 13100       |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    reward               | -0.2799645  |\n",
      "|    std                  | 9.15        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1312        |\n",
      "|    time_elapsed         | 25074       |\n",
      "|    total_timesteps      | 2686976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009250682 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 13110       |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | 5.648472    |\n",
      "|    std                  | 9.17        |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3927099.32\n",
      "total_reward: 2927099.32\n",
      "total_cost: 255886.21\n",
      "total_trades: 64871\n",
      "Sharpe: 0.707\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1313        |\n",
      "|    time_elapsed         | 25093       |\n",
      "|    total_timesteps      | 2689024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009368859 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | -0.0784     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 13120       |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    reward               | 0.58867395  |\n",
      "|    std                  | 9.2         |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1314         |\n",
      "|    time_elapsed         | 25112        |\n",
      "|    total_timesteps      | 2691072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046267575 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 13130        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    reward               | 2.6806324    |\n",
      "|    std                  | 9.2          |\n",
      "|    value_loss           | 81.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1315         |\n",
      "|    time_elapsed         | 25131        |\n",
      "|    total_timesteps      | 2693120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082775485 |\n",
      "|    clip_fraction        | 0.0463       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.6         |\n",
      "|    n_updates            | 13140        |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    reward               | -0.717199    |\n",
      "|    std                  | 9.2          |\n",
      "|    value_loss           | 61.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1316        |\n",
      "|    time_elapsed         | 25151       |\n",
      "|    total_timesteps      | 2695168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013840906 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    reward               | -3.23545    |\n",
      "|    std                  | 9.2         |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1317         |\n",
      "|    time_elapsed         | 25169        |\n",
      "|    total_timesteps      | 2697216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055129156 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 13160        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -2.8680654   |\n",
      "|    std                  | 9.21         |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1318         |\n",
      "|    time_elapsed         | 25188        |\n",
      "|    total_timesteps      | 2699264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068723992 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 13170        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    reward               | -0.59853154  |\n",
      "|    std                  | 9.23         |\n",
      "|    value_loss           | 56.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1319         |\n",
      "|    time_elapsed         | 25207        |\n",
      "|    total_timesteps      | 2701312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038998306 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.2         |\n",
      "|    n_updates            | 13180        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -0.38325205  |\n",
      "|    std                  | 9.24         |\n",
      "|    value_loss           | 56.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1320         |\n",
      "|    time_elapsed         | 25226        |\n",
      "|    total_timesteps      | 2703360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098778885 |\n",
      "|    clip_fraction        | 0.0977       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 13190        |\n",
      "|    policy_gradient_loss | -0.00976     |\n",
      "|    reward               | -1.6798365   |\n",
      "|    std                  | 9.26         |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1321        |\n",
      "|    time_elapsed         | 25244       |\n",
      "|    total_timesteps      | 2705408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008583855 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 13200       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | 1.9773796   |\n",
      "|    std                  | 9.28        |\n",
      "|    value_loss           | 67.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1322        |\n",
      "|    time_elapsed         | 25263       |\n",
      "|    total_timesteps      | 2707456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007849198 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 13210       |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    reward               | -0.326103   |\n",
      "|    std                  | 9.28        |\n",
      "|    value_loss           | 71.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1323       |\n",
      "|    time_elapsed         | 25282      |\n",
      "|    total_timesteps      | 2709504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01230594 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.489      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.8       |\n",
      "|    n_updates            | 13220      |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | -1.1038679 |\n",
      "|    std                  | 9.3        |\n",
      "|    value_loss           | 40.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1324        |\n",
      "|    time_elapsed         | 25300       |\n",
      "|    total_timesteps      | 2711552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010080598 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 13230       |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    reward               | -1.8018502  |\n",
      "|    std                  | 9.31        |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1325         |\n",
      "|    time_elapsed         | 25319        |\n",
      "|    total_timesteps      | 2713600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063699554 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 13240        |\n",
      "|    policy_gradient_loss | -0.00902     |\n",
      "|    reward               | -0.19822629  |\n",
      "|    std                  | 9.31         |\n",
      "|    value_loss           | 61.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1326         |\n",
      "|    time_elapsed         | 25338        |\n",
      "|    total_timesteps      | 2715648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032778098 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 13250        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    reward               | 1.7574444    |\n",
      "|    std                  | 9.31         |\n",
      "|    value_loss           | 64.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3026701.98\n",
      "total_reward: 2026701.98\n",
      "total_cost: 237220.63\n",
      "total_trades: 63333\n",
      "Sharpe: 0.618\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1327       |\n",
      "|    time_elapsed         | 25356      |\n",
      "|    total_timesteps      | 2717696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01174638 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.325      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.89       |\n",
      "|    n_updates            | 13260      |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    reward               | -0.9003768 |\n",
      "|    std                  | 9.32       |\n",
      "|    value_loss           | 20.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1328        |\n",
      "|    time_elapsed         | 25376       |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004283853 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 13270       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | 0.9681203   |\n",
      "|    std                  | 9.33        |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1329        |\n",
      "|    time_elapsed         | 25396       |\n",
      "|    total_timesteps      | 2721792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004877202 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 13280       |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | 3.5433545   |\n",
      "|    std                  | 9.33        |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 25415       |\n",
      "|    total_timesteps      | 2723840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010781901 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 13290       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -1.6452972  |\n",
      "|    std                  | 9.34        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1331        |\n",
      "|    time_elapsed         | 25433       |\n",
      "|    total_timesteps      | 2725888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005098454 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 13300       |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | -0.147725   |\n",
      "|    std                  | 9.35        |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1332        |\n",
      "|    time_elapsed         | 25452       |\n",
      "|    total_timesteps      | 2727936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004755845 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55          |\n",
      "|    n_updates            | 13310       |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    reward               | 1.9611082   |\n",
      "|    std                  | 9.36        |\n",
      "|    value_loss           | 83.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1333         |\n",
      "|    time_elapsed         | 25471        |\n",
      "|    total_timesteps      | 2729984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063426755 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 13320        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | 1.701332     |\n",
      "|    std                  | 9.37         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1334        |\n",
      "|    time_elapsed         | 25490       |\n",
      "|    total_timesteps      | 2732032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007866713 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 13330       |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | -2.5216267  |\n",
      "|    std                  | 9.39        |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1335         |\n",
      "|    time_elapsed         | 25509        |\n",
      "|    total_timesteps      | 2734080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017261996 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.9         |\n",
      "|    n_updates            | 13340        |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    reward               | 0.40245414   |\n",
      "|    std                  | 9.39         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1336         |\n",
      "|    time_elapsed         | 25528        |\n",
      "|    total_timesteps      | 2736128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021447903 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.5         |\n",
      "|    n_updates            | 13350        |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    reward               | 0.42306393   |\n",
      "|    std                  | 9.39         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 25547       |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013232196 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.0515      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | -2.351998   |\n",
      "|    std                  | 9.43        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1338         |\n",
      "|    time_elapsed         | 25566        |\n",
      "|    total_timesteps      | 2740224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069380687 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.4         |\n",
      "|    n_updates            | 13370        |\n",
      "|    policy_gradient_loss | -0.00759     |\n",
      "|    reward               | -2.1733813   |\n",
      "|    std                  | 9.45         |\n",
      "|    value_loss           | 90.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1339         |\n",
      "|    time_elapsed         | 25586        |\n",
      "|    total_timesteps      | 2742272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074417237 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.9         |\n",
      "|    n_updates            | 13380        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    reward               | -3.5862625   |\n",
      "|    std                  | 9.47         |\n",
      "|    value_loss           | 94.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1340        |\n",
      "|    time_elapsed         | 25605       |\n",
      "|    total_timesteps      | 2744320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010938624 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 13390       |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | 2.5770895   |\n",
      "|    std                  | 9.5         |\n",
      "|    value_loss           | 66.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4724059.63\n",
      "total_reward: 3724059.63\n",
      "total_cost: 245848.67\n",
      "total_trades: 64148\n",
      "Sharpe: 0.826\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1341         |\n",
      "|    time_elapsed         | 25624        |\n",
      "|    total_timesteps      | 2746368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064653894 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.7         |\n",
      "|    n_updates            | 13400        |\n",
      "|    policy_gradient_loss | -0.00822     |\n",
      "|    reward               | 1.2774622    |\n",
      "|    std                  | 9.49         |\n",
      "|    value_loss           | 75.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1342         |\n",
      "|    time_elapsed         | 25643        |\n",
      "|    total_timesteps      | 2748416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029355057 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.3         |\n",
      "|    n_updates            | 13410        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | 0.60795575   |\n",
      "|    std                  | 9.48         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1343         |\n",
      "|    time_elapsed         | 25661        |\n",
      "|    total_timesteps      | 2750464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022088815 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.8         |\n",
      "|    n_updates            | 13420        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | -2.0500975   |\n",
      "|    std                  | 9.49         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 25680       |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014150349 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | -0.0184     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 0.08341787  |\n",
      "|    std                  | 9.55        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1345         |\n",
      "|    time_elapsed         | 25699        |\n",
      "|    total_timesteps      | 2754560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058878576 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 13440        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    reward               | 0.31079045   |\n",
      "|    std                  | 9.56         |\n",
      "|    value_loss           | 87           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1346        |\n",
      "|    time_elapsed         | 25718       |\n",
      "|    total_timesteps      | 2756608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003410746 |\n",
      "|    clip_fraction        | 0.0111      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 13450       |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | -11.325986  |\n",
      "|    std                  | 9.57        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1347        |\n",
      "|    time_elapsed         | 25737       |\n",
      "|    total_timesteps      | 2758656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009930445 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 13460       |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | 1.6582904   |\n",
      "|    std                  | 9.61        |\n",
      "|    value_loss           | 60.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1348        |\n",
      "|    time_elapsed         | 25755       |\n",
      "|    total_timesteps      | 2760704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004941958 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 13470       |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    reward               | -1.1006887  |\n",
      "|    std                  | 9.61        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1349        |\n",
      "|    time_elapsed         | 25774       |\n",
      "|    total_timesteps      | 2762752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004033665 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.7        |\n",
      "|    n_updates            | 13480       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | -26.124655  |\n",
      "|    std                  | 9.61        |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1350         |\n",
      "|    time_elapsed         | 25794        |\n",
      "|    total_timesteps      | 2764800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068439604 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.00704      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 296          |\n",
      "|    n_updates            | 13490        |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    reward               | -1.6511848   |\n",
      "|    std                  | 9.63         |\n",
      "|    value_loss           | 374          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1351       |\n",
      "|    time_elapsed         | 25814      |\n",
      "|    total_timesteps      | 2766848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01235    |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -106       |\n",
      "|    explained_variance   | 0.0541     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.7       |\n",
      "|    n_updates            | 13500      |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    reward               | 0.07547034 |\n",
      "|    std                  | 9.63       |\n",
      "|    value_loss           | 47.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1352         |\n",
      "|    time_elapsed         | 25834        |\n",
      "|    total_timesteps      | 2768896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063709086 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 13510        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | -0.18578318  |\n",
      "|    std                  | 9.63         |\n",
      "|    value_loss           | 203          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1353        |\n",
      "|    time_elapsed         | 25853       |\n",
      "|    total_timesteps      | 2770944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010018465 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.5        |\n",
      "|    n_updates            | 13520       |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    reward               | 2.5960085   |\n",
      "|    std                  | 9.63        |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1354        |\n",
      "|    time_elapsed         | 25873       |\n",
      "|    total_timesteps      | 2772992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015574666 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 13530       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | -0.8907018  |\n",
      "|    std                  | 9.66        |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5185695.12\n",
      "total_reward: 4185695.12\n",
      "total_cost: 259331.68\n",
      "total_trades: 65027\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1355       |\n",
      "|    time_elapsed         | 25893      |\n",
      "|    total_timesteps      | 2775040    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00210782 |\n",
      "|    clip_fraction        | 0.00859    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -106       |\n",
      "|    explained_variance   | 0.541      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 94         |\n",
      "|    n_updates            | 13540      |\n",
      "|    policy_gradient_loss | -0.00178   |\n",
      "|    reward               | 0.9765182  |\n",
      "|    std                  | 9.67       |\n",
      "|    value_loss           | 203        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1356         |\n",
      "|    time_elapsed         | 25913        |\n",
      "|    total_timesteps      | 2777088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022789268 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 13550        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | 1.4893094    |\n",
      "|    std                  | 9.67         |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1357         |\n",
      "|    time_elapsed         | 25932        |\n",
      "|    total_timesteps      | 2779136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024302602 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.1         |\n",
      "|    n_updates            | 13560        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | -1.1250702   |\n",
      "|    std                  | 9.68         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1358        |\n",
      "|    time_elapsed         | 25951       |\n",
      "|    total_timesteps      | 2781184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007586758 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.3        |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    reward               | 0.4840162   |\n",
      "|    std                  | 9.7         |\n",
      "|    value_loss           | 90.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1359         |\n",
      "|    time_elapsed         | 25971        |\n",
      "|    total_timesteps      | 2783232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004200487  |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 13580        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    reward               | -0.033150494 |\n",
      "|    std                  | 9.7          |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1360        |\n",
      "|    time_elapsed         | 25989       |\n",
      "|    total_timesteps      | 2785280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004205822 |\n",
      "|    clip_fraction        | 0.0084      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 13590       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 0.8082326   |\n",
      "|    std                  | 9.71        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 26008       |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011917242 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.0358      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 13600       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -4.0776925  |\n",
      "|    std                  | 9.73        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1362        |\n",
      "|    time_elapsed         | 26027       |\n",
      "|    total_timesteps      | 2789376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006779437 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.9        |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | 1.9573872   |\n",
      "|    std                  | 9.74        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1363         |\n",
      "|    time_elapsed         | 26046        |\n",
      "|    total_timesteps      | 2791424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030841525 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.9         |\n",
      "|    n_updates            | 13620        |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    reward               | 3.2221112    |\n",
      "|    std                  | 9.75         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1364        |\n",
      "|    time_elapsed         | 26065       |\n",
      "|    total_timesteps      | 2793472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009065536 |\n",
      "|    clip_fraction        | 0.044       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.1        |\n",
      "|    n_updates            | 13630       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | -1.929674   |\n",
      "|    std                  | 9.76        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1365        |\n",
      "|    time_elapsed         | 26084       |\n",
      "|    total_timesteps      | 2795520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006727893 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 13640       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 1.097993    |\n",
      "|    std                  | 9.77        |\n",
      "|    value_loss           | 93.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 26102       |\n",
      "|    total_timesteps      | 2797568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008202007 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 13650       |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | -0.6664875  |\n",
      "|    std                  | 9.8         |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1367         |\n",
      "|    time_elapsed         | 26121        |\n",
      "|    total_timesteps      | 2799616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015147161 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.6         |\n",
      "|    n_updates            | 13660        |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    reward               | 2.966842     |\n",
      "|    std                  | 9.81         |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1368        |\n",
      "|    time_elapsed         | 26140       |\n",
      "|    total_timesteps      | 2801664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012061057 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.0557      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 13670       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.40687686  |\n",
      "|    std                  | 9.85        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3914678.89\n",
      "total_reward: 2914678.89\n",
      "total_cost: 254270.04\n",
      "total_trades: 64003\n",
      "Sharpe: 0.668\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1369        |\n",
      "|    time_elapsed         | 26159       |\n",
      "|    total_timesteps      | 2803712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002996831 |\n",
      "|    clip_fraction        | 0.00562     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.2        |\n",
      "|    n_updates            | 13680       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | -0.5137004  |\n",
      "|    std                  | 9.86        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1370         |\n",
      "|    time_elapsed         | 26179        |\n",
      "|    total_timesteps      | 2805760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022806653 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57           |\n",
      "|    n_updates            | 13690        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | 0.621667     |\n",
      "|    std                  | 9.86         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1371        |\n",
      "|    time_elapsed         | 26199       |\n",
      "|    total_timesteps      | 2807808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009972576 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 13700       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.80083054  |\n",
      "|    std                  | 9.88        |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1372         |\n",
      "|    time_elapsed         | 26219        |\n",
      "|    total_timesteps      | 2809856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049432376 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.6         |\n",
      "|    n_updates            | 13710        |\n",
      "|    policy_gradient_loss | -0.0069      |\n",
      "|    reward               | -2.619672    |\n",
      "|    std                  | 9.91         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1373         |\n",
      "|    time_elapsed         | 26238        |\n",
      "|    total_timesteps      | 2811904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019401258 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.1         |\n",
      "|    n_updates            | 13720        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | 2.8518422    |\n",
      "|    std                  | 9.92         |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1374        |\n",
      "|    time_elapsed         | 26257       |\n",
      "|    total_timesteps      | 2813952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008264177 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 13730       |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | -1.4722097  |\n",
      "|    std                  | 9.93        |\n",
      "|    value_loss           | 87.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1375        |\n",
      "|    time_elapsed         | 26277       |\n",
      "|    total_timesteps      | 2816000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009713208 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -1.8935021  |\n",
      "|    std                  | 9.96        |\n",
      "|    value_loss           | 68.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1376        |\n",
      "|    time_elapsed         | 26297       |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005269831 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 13750       |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | 0.17588492  |\n",
      "|    std                  | 9.98        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1377        |\n",
      "|    time_elapsed         | 26316       |\n",
      "|    total_timesteps      | 2820096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004685782 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.7        |\n",
      "|    n_updates            | 13760       |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    reward               | -3.407838   |\n",
      "|    std                  | 9.98        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 26335       |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013465498 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 13770       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -2.989969   |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1379        |\n",
      "|    time_elapsed         | 26354       |\n",
      "|    total_timesteps      | 2824192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007838206 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 13780       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | -1.4816569  |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1380         |\n",
      "|    time_elapsed         | 26373        |\n",
      "|    total_timesteps      | 2826240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070585622 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.5         |\n",
      "|    n_updates            | 13790        |\n",
      "|    policy_gradient_loss | -0.00708     |\n",
      "|    reward               | 1.9967312    |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1381         |\n",
      "|    time_elapsed         | 26392        |\n",
      "|    total_timesteps      | 2828288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070447274 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.2         |\n",
      "|    n_updates            | 13800        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | -2.7921798   |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 85.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1382       |\n",
      "|    time_elapsed         | 26412      |\n",
      "|    total_timesteps      | 2830336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01016474 |\n",
      "|    clip_fraction        | 0.0958     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.5       |\n",
      "|    n_updates            | 13810      |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    reward               | -1.0739737 |\n",
      "|    std                  | 10         |\n",
      "|    value_loss           | 81.3       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4484146.93\n",
      "total_reward: 3484146.93\n",
      "total_cost: 272029.15\n",
      "total_trades: 65305\n",
      "Sharpe: 0.791\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1383         |\n",
      "|    time_elapsed         | 26431        |\n",
      "|    total_timesteps      | 2832384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042050146 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.4         |\n",
      "|    n_updates            | 13820        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | 0.59969187   |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1384        |\n",
      "|    time_elapsed         | 26451       |\n",
      "|    total_timesteps      | 2834432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003910467 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.6        |\n",
      "|    n_updates            | 13830       |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | 2.1777267   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1385        |\n",
      "|    time_elapsed         | 26470       |\n",
      "|    total_timesteps      | 2836480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017226364 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 13840       |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | -0.47192597 |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1386        |\n",
      "|    time_elapsed         | 26489       |\n",
      "|    total_timesteps      | 2838528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003833924 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 13850       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 0.20466687  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1387       |\n",
      "|    time_elapsed         | 26507      |\n",
      "|    total_timesteps      | 2840576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00251038 |\n",
      "|    clip_fraction        | 0.00527    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.602      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 64.8       |\n",
      "|    n_updates            | 13860      |\n",
      "|    policy_gradient_loss | -0.0046    |\n",
      "|    reward               | -2.2398572 |\n",
      "|    std                  | 10.1       |\n",
      "|    value_loss           | 129        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1388         |\n",
      "|    time_elapsed         | 26526        |\n",
      "|    total_timesteps      | 2842624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066371034 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.7         |\n",
      "|    n_updates            | 13870        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | 1.1629425    |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 92.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1389        |\n",
      "|    time_elapsed         | 26545       |\n",
      "|    total_timesteps      | 2844672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007679425 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 13880       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.39063102  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1390         |\n",
      "|    time_elapsed         | 26564        |\n",
      "|    total_timesteps      | 2846720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050807837 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.3         |\n",
      "|    n_updates            | 13890        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    reward               | -0.48511785  |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1391        |\n",
      "|    time_elapsed         | 26583       |\n",
      "|    total_timesteps      | 2848768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01024583  |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.1        |\n",
      "|    n_updates            | 13900       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | -0.63695335 |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1392        |\n",
      "|    time_elapsed         | 26602       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011480167 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 13910       |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    reward               | 2.2782168   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1393        |\n",
      "|    time_elapsed         | 26621       |\n",
      "|    total_timesteps      | 2852864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004334874 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 13920       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    reward               | 0.37036842  |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1394         |\n",
      "|    time_elapsed         | 26639        |\n",
      "|    total_timesteps      | 2854912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012340522 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.6         |\n",
      "|    n_updates            | 13930        |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    reward               | 0.55915236   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 107       |\n",
      "|    iterations           | 1395      |\n",
      "|    time_elapsed         | 26659     |\n",
      "|    total_timesteps      | 2856960   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0085389 |\n",
      "|    clip_fraction        | 0.0813    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -108      |\n",
      "|    explained_variance   | 0.408     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 30        |\n",
      "|    n_updates            | 13940     |\n",
      "|    policy_gradient_loss | -0.00487  |\n",
      "|    reward               | 2.9726458 |\n",
      "|    std                  | 10.2      |\n",
      "|    value_loss           | 52.9      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1396       |\n",
      "|    time_elapsed         | 26678      |\n",
      "|    total_timesteps      | 2859008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00487791 |\n",
      "|    clip_fraction        | 0.0117     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.612      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44.9       |\n",
      "|    n_updates            | 13950      |\n",
      "|    policy_gradient_loss | -0.00411   |\n",
      "|    reward               | 0.12883222 |\n",
      "|    std                  | 10.2       |\n",
      "|    value_loss           | 96.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1397         |\n",
      "|    time_elapsed         | 26697        |\n",
      "|    total_timesteps      | 2861056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058538956 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.6         |\n",
      "|    n_updates            | 13960        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    reward               | 2.899578     |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4386488.27\n",
      "total_reward: 3386488.27\n",
      "total_cost: 218028.06\n",
      "total_trades: 62600\n",
      "Sharpe: 0.748\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1398        |\n",
      "|    time_elapsed         | 26715       |\n",
      "|    total_timesteps      | 2863104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008858828 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 13970       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | 1.177365    |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 78.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1399         |\n",
      "|    time_elapsed         | 26734        |\n",
      "|    total_timesteps      | 2865152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051654186 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 13980        |\n",
      "|    policy_gradient_loss | -0.00801     |\n",
      "|    reward               | 1.417621     |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1400         |\n",
      "|    time_elapsed         | 26753        |\n",
      "|    total_timesteps      | 2867200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025035897 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.5         |\n",
      "|    n_updates            | 13990        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | 0.8338764    |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1401        |\n",
      "|    time_elapsed         | 26771       |\n",
      "|    total_timesteps      | 2869248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010342158 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.2        |\n",
      "|    n_updates            | 14000       |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    reward               | -3.2419024  |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1402       |\n",
      "|    time_elapsed         | 26790      |\n",
      "|    total_timesteps      | 2871296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01488781 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.346      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.3       |\n",
      "|    n_updates            | 14010      |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    reward               | -1.827475  |\n",
      "|    std                  | 10.3       |\n",
      "|    value_loss           | 26.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1403       |\n",
      "|    time_elapsed         | 26810      |\n",
      "|    total_timesteps      | 2873344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00374322 |\n",
      "|    clip_fraction        | 0.00903    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.585      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.7       |\n",
      "|    n_updates            | 14020      |\n",
      "|    policy_gradient_loss | -0.00415   |\n",
      "|    reward               | -2.0487912 |\n",
      "|    std                  | 10.3       |\n",
      "|    value_loss           | 97.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1404         |\n",
      "|    time_elapsed         | 26829        |\n",
      "|    total_timesteps      | 2875392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070309904 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.1         |\n",
      "|    n_updates            | 14030        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    reward               | -0.7716156   |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 95.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1405         |\n",
      "|    time_elapsed         | 26848        |\n",
      "|    total_timesteps      | 2877440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065662037 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 14040        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    reward               | 2.1707416    |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 69           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1406         |\n",
      "|    time_elapsed         | 26868        |\n",
      "|    total_timesteps      | 2879488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064990288 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 14050        |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    reward               | 0.42956173   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 54.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1407         |\n",
      "|    time_elapsed         | 26888        |\n",
      "|    total_timesteps      | 2881536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074159866 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.7         |\n",
      "|    n_updates            | 14060        |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    reward               | 0.07688781   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1408        |\n",
      "|    time_elapsed         | 26907       |\n",
      "|    total_timesteps      | 2883584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009611312 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 14070       |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | 2.1860387   |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1409        |\n",
      "|    time_elapsed         | 26926       |\n",
      "|    total_timesteps      | 2885632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007114727 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 14080       |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | 0.70481884  |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1410         |\n",
      "|    time_elapsed         | 26945        |\n",
      "|    total_timesteps      | 2887680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048348336 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.5         |\n",
      "|    n_updates            | 14090        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | -0.82233006  |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1411         |\n",
      "|    time_elapsed         | 26964        |\n",
      "|    total_timesteps      | 2889728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034030587 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.1         |\n",
      "|    n_updates            | 14100        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    reward               | -0.70560104  |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4492141.27\n",
      "total_reward: 3492141.27\n",
      "total_cost: 259631.61\n",
      "total_trades: 64522\n",
      "Sharpe: 0.816\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1412        |\n",
      "|    time_elapsed         | 26983       |\n",
      "|    total_timesteps      | 2891776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012538293 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 14110       |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    reward               | -4.377565   |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 69.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1413         |\n",
      "|    time_elapsed         | 27002        |\n",
      "|    total_timesteps      | 2893824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066000023 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.3         |\n",
      "|    n_updates            | 14120        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    reward               | 1.1781949    |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 66.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1414         |\n",
      "|    time_elapsed         | 27021        |\n",
      "|    total_timesteps      | 2895872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058731213 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 14130        |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    reward               | 6.992583     |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1415        |\n",
      "|    time_elapsed         | 27040       |\n",
      "|    total_timesteps      | 2897920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008957378 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.6        |\n",
      "|    n_updates            | 14140       |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    reward               | 0.33404976  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 27059       |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013167685 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.73        |\n",
      "|    n_updates            | 14150       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 0.40359232  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1417         |\n",
      "|    time_elapsed         | 27079        |\n",
      "|    total_timesteps      | 2902016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021638125 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.6         |\n",
      "|    n_updates            | 14160        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | -4.6284704   |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 91.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1418         |\n",
      "|    time_elapsed         | 27097        |\n",
      "|    total_timesteps      | 2904064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038017556 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 14170        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | -1.1421944   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 80.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1419         |\n",
      "|    time_elapsed         | 27116        |\n",
      "|    total_timesteps      | 2906112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068593235 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.109        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 14180        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 1.0523263    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1420         |\n",
      "|    time_elapsed         | 27135        |\n",
      "|    total_timesteps      | 2908160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050164424 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 14190        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | 1.5762954    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1421        |\n",
      "|    time_elapsed         | 27155       |\n",
      "|    total_timesteps      | 2910208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002193646 |\n",
      "|    clip_fraction        | 0.00591     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.4        |\n",
      "|    n_updates            | 14200       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | 3.689779    |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 91.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1422         |\n",
      "|    time_elapsed         | 27174        |\n",
      "|    total_timesteps      | 2912256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053552035 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 14210        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 1.1634881    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 49.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1423        |\n",
      "|    time_elapsed         | 27193       |\n",
      "|    total_timesteps      | 2914304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011438152 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 14220       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.48612314 |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1424        |\n",
      "|    time_elapsed         | 27212       |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005101551 |\n",
      "|    clip_fraction        | 0.0213      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.1        |\n",
      "|    n_updates            | 14230       |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    reward               | 2.468226    |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 93.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1425        |\n",
      "|    time_elapsed         | 27230       |\n",
      "|    total_timesteps      | 2918400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005305671 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 14240       |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    reward               | 4.347901    |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4211333.66\n",
      "total_reward: 3211333.66\n",
      "total_cost: 243431.41\n",
      "total_trades: 63311\n",
      "Sharpe: 0.766\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1426        |\n",
      "|    time_elapsed         | 27250       |\n",
      "|    total_timesteps      | 2920448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014278636 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | -0.0803     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.47        |\n",
      "|    n_updates            | 14250       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.34925824 |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1427         |\n",
      "|    time_elapsed         | 27270        |\n",
      "|    total_timesteps      | 2922496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034892585 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60           |\n",
      "|    n_updates            | 14260        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    reward               | 0.92213494   |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 82.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1428         |\n",
      "|    time_elapsed         | 27288        |\n",
      "|    total_timesteps      | 2924544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021785651 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.9         |\n",
      "|    n_updates            | 14270        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | 1.5389591    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 82.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1429         |\n",
      "|    time_elapsed         | 27308        |\n",
      "|    total_timesteps      | 2926592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090719275 |\n",
      "|    clip_fraction        | 0.0673       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.241        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 14280        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    reward               | -7.659341    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1430         |\n",
      "|    time_elapsed         | 27326        |\n",
      "|    total_timesteps      | 2928640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070315553 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 14290        |\n",
      "|    policy_gradient_loss | -0.00883     |\n",
      "|    reward               | 0.9028933    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 70.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1431         |\n",
      "|    time_elapsed         | 27345        |\n",
      "|    total_timesteps      | 2930688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012295095 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48           |\n",
      "|    n_updates            | 14300        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | -0.059348762 |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1432         |\n",
      "|    time_elapsed         | 27364        |\n",
      "|    total_timesteps      | 2932736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013750173 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.8         |\n",
      "|    n_updates            | 14310        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 1.2608495    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1433        |\n",
      "|    time_elapsed         | 27383       |\n",
      "|    total_timesteps      | 2934784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011394722 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0574      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 14320       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 2.506292    |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1434        |\n",
      "|    time_elapsed         | 27402       |\n",
      "|    total_timesteps      | 2936832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006726358 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 14330       |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 0.49388388  |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 97          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1435        |\n",
      "|    time_elapsed         | 27421       |\n",
      "|    total_timesteps      | 2938880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003341415 |\n",
      "|    clip_fraction        | 0.00811     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.5        |\n",
      "|    n_updates            | 14340       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | -0.82242805 |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1436        |\n",
      "|    time_elapsed         | 27440       |\n",
      "|    total_timesteps      | 2940928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007282119 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 14350       |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    reward               | 2.8551567   |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 60.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1437         |\n",
      "|    time_elapsed         | 27459        |\n",
      "|    total_timesteps      | 2942976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022650915 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 14360        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | -0.73637486  |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 89.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1438        |\n",
      "|    time_elapsed         | 27478       |\n",
      "|    total_timesteps      | 2945024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003332334 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.4        |\n",
      "|    n_updates            | 14370       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | -12.759858  |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1439       |\n",
      "|    time_elapsed         | 27496      |\n",
      "|    total_timesteps      | 2947072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00477346 |\n",
      "|    clip_fraction        | 0.0164     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -110       |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42.7       |\n",
      "|    n_updates            | 14380      |\n",
      "|    policy_gradient_loss | -0.00512   |\n",
      "|    reward               | -1.6401187 |\n",
      "|    std                  | 10.8       |\n",
      "|    value_loss           | 87.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5246267.55\n",
      "total_reward: 4246267.55\n",
      "total_cost: 257585.73\n",
      "total_trades: 64241\n",
      "Sharpe: 0.865\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 27515       |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013902329 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 14390       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 2.329463    |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1441        |\n",
      "|    time_elapsed         | 27534       |\n",
      "|    total_timesteps      | 2951168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009504547 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    reward               | 0.21707284  |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1442        |\n",
      "|    time_elapsed         | 27553       |\n",
      "|    total_timesteps      | 2953216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004453805 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.1        |\n",
      "|    n_updates            | 14410       |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | 1.9975227   |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1443        |\n",
      "|    time_elapsed         | 27571       |\n",
      "|    total_timesteps      | 2955264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010237038 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    reward               | -7.817972   |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1444        |\n",
      "|    time_elapsed         | 27590       |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007944976 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.5        |\n",
      "|    n_updates            | 14430       |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    reward               | 2.378348    |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 96.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1445         |\n",
      "|    time_elapsed         | 27609        |\n",
      "|    total_timesteps      | 2959360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039428626 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85           |\n",
      "|    n_updates            | 14440        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | 2.950645     |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1446         |\n",
      "|    time_elapsed         | 27627        |\n",
      "|    total_timesteps      | 2961408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056243623 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.8         |\n",
      "|    n_updates            | 14450        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | 1.3494573    |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1447        |\n",
      "|    time_elapsed         | 27646       |\n",
      "|    total_timesteps      | 2963456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009717006 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.8        |\n",
      "|    n_updates            | 14460       |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | 0.7955947   |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 93.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1448         |\n",
      "|    time_elapsed         | 27665        |\n",
      "|    total_timesteps      | 2965504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039207833 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.7         |\n",
      "|    n_updates            | 14470        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | 0.41836876   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1449         |\n",
      "|    time_elapsed         | 27684        |\n",
      "|    total_timesteps      | 2967552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022739621 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.4         |\n",
      "|    n_updates            | 14480        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | 0.52226377   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 212          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 107       |\n",
      "|    iterations           | 1450      |\n",
      "|    time_elapsed         | 27703     |\n",
      "|    total_timesteps      | 2969600   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0110554 |\n",
      "|    clip_fraction        | 0.0827    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -110      |\n",
      "|    explained_variance   | 0.265     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 22.6      |\n",
      "|    n_updates            | 14490     |\n",
      "|    policy_gradient_loss | -0.00916  |\n",
      "|    reward               | 1.7043253 |\n",
      "|    std                  | 11        |\n",
      "|    value_loss           | 39.1      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1451         |\n",
      "|    time_elapsed         | 27722        |\n",
      "|    total_timesteps      | 2971648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034910846 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 14500        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | 0.97723377   |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 203          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1452         |\n",
      "|    time_elapsed         | 27741        |\n",
      "|    total_timesteps      | 2973696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069060246 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.3         |\n",
      "|    n_updates            | 14510        |\n",
      "|    policy_gradient_loss | -0.00703     |\n",
      "|    reward               | 3.973705     |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1453         |\n",
      "|    time_elapsed         | 27760        |\n",
      "|    total_timesteps      | 2975744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057896404 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.2         |\n",
      "|    n_updates            | 14520        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    reward               | 1.0902259    |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 86.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5831062.07\n",
      "total_reward: 4831062.07\n",
      "total_cost: 236806.92\n",
      "total_trades: 63728\n",
      "Sharpe: 0.871\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1454         |\n",
      "|    time_elapsed         | 27778        |\n",
      "|    total_timesteps      | 2977792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008760132  |\n",
      "|    clip_fraction        | 0.0536       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.4         |\n",
      "|    n_updates            | 14530        |\n",
      "|    policy_gradient_loss | -0.00916     |\n",
      "|    reward               | -0.119112566 |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1455         |\n",
      "|    time_elapsed         | 27797        |\n",
      "|    total_timesteps      | 2979840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077684955 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.106        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 14540        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    reward               | 0.68351376   |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 256          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1456         |\n",
      "|    time_elapsed         | 27816        |\n",
      "|    total_timesteps      | 2981888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029042982 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.2         |\n",
      "|    n_updates            | 14550        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | -1.3374391   |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1457        |\n",
      "|    time_elapsed         | 27835       |\n",
      "|    total_timesteps      | 2983936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010981716 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.0976      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 1.1625326   |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1458         |\n",
      "|    time_elapsed         | 27854        |\n",
      "|    total_timesteps      | 2985984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082385875 |\n",
      "|    clip_fraction        | 0.0573       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.0474       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 14570        |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    reward               | 1.6851227    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 256          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1459         |\n",
      "|    time_elapsed         | 27872        |\n",
      "|    total_timesteps      | 2988032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071335556 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.0528       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 14580        |\n",
      "|    policy_gradient_loss | -0.00883     |\n",
      "|    reward               | -8.127669    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1460        |\n",
      "|    time_elapsed         | 27891       |\n",
      "|    total_timesteps      | 2990080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010483697 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 14590       |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | -2.2949963  |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 53.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1461         |\n",
      "|    time_elapsed         | 27910        |\n",
      "|    total_timesteps      | 2992128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051127584 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 14600        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | 2.37642      |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1462         |\n",
      "|    time_elapsed         | 27929        |\n",
      "|    total_timesteps      | 2994176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045145205 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 14610        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    reward               | 28.089733    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 196          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1463         |\n",
      "|    time_elapsed         | 27948        |\n",
      "|    total_timesteps      | 2996224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042650327 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.5         |\n",
      "|    n_updates            | 14620        |\n",
      "|    policy_gradient_loss | -0.000741    |\n",
      "|    reward               | -0.9965523   |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1464        |\n",
      "|    time_elapsed         | 27966       |\n",
      "|    total_timesteps      | 2998272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009281384 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 14630       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.7292888   |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 60.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1465         |\n",
      "|    time_elapsed         | 27985        |\n",
      "|    total_timesteps      | 3000320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015750783 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.6         |\n",
      "|    n_updates            | 14640        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | 1.0947366    |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1466        |\n",
      "|    time_elapsed         | 28003       |\n",
      "|    total_timesteps      | 3002368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002387093 |\n",
      "|    clip_fraction        | 0.00278     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 14650       |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | 2.9001265   |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1467        |\n",
      "|    time_elapsed         | 28022       |\n",
      "|    total_timesteps      | 3004416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010484185 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 14660       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 1.5961607   |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4292741.72\n",
      "total_reward: 3292741.72\n",
      "total_cost: 231883.14\n",
      "total_trades: 63442\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1468         |\n",
      "|    time_elapsed         | 28041        |\n",
      "|    total_timesteps      | 3006464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026980517 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.1         |\n",
      "|    n_updates            | 14670        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | -1.272384    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1469        |\n",
      "|    time_elapsed         | 28059       |\n",
      "|    total_timesteps      | 3008512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004526378 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 14680       |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | 3.8640063   |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1470        |\n",
      "|    time_elapsed         | 28078       |\n",
      "|    total_timesteps      | 3010560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003631219 |\n",
      "|    clip_fraction        | 0.00347     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.3        |\n",
      "|    n_updates            | 14690       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | 0.074413896 |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 78.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1471        |\n",
      "|    time_elapsed         | 28096       |\n",
      "|    total_timesteps      | 3012608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009265882 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 14700       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -0.4855699  |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 81.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1472       |\n",
      "|    time_elapsed         | 28114      |\n",
      "|    total_timesteps      | 3014656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01216101 |\n",
      "|    clip_fraction        | 0.0864     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.000497   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 124        |\n",
      "|    n_updates            | 14710      |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    reward               | 0.9866432  |\n",
      "|    std                  | 11.5       |\n",
      "|    value_loss           | 316        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1473        |\n",
      "|    time_elapsed         | 28133       |\n",
      "|    total_timesteps      | 3016704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011166401 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.00544     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 14720       |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    reward               | 0.2518162   |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1474       |\n",
      "|    time_elapsed         | 28151      |\n",
      "|    total_timesteps      | 3018752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01286463 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.0108     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.2       |\n",
      "|    n_updates            | 14730      |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | -1.3765352 |\n",
      "|    std                  | 11.5       |\n",
      "|    value_loss           | 33.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1475         |\n",
      "|    time_elapsed         | 28169        |\n",
      "|    total_timesteps      | 3020800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061650015 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.8         |\n",
      "|    n_updates            | 14740        |\n",
      "|    policy_gradient_loss | -0.00882     |\n",
      "|    reward               | -0.26374444  |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 225          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1476         |\n",
      "|    time_elapsed         | 28187        |\n",
      "|    total_timesteps      | 3022848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017984181 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.1         |\n",
      "|    n_updates            | 14750        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | -0.037802286 |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1477         |\n",
      "|    time_elapsed         | 28205        |\n",
      "|    total_timesteps      | 3024896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073009413 |\n",
      "|    clip_fraction        | 0.0447       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 14760        |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    reward               | 0.59710985   |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 68.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1478         |\n",
      "|    time_elapsed         | 28223        |\n",
      "|    total_timesteps      | 3026944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042069345 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 14770        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    reward               | -3.7259066   |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1479        |\n",
      "|    time_elapsed         | 28241       |\n",
      "|    total_timesteps      | 3028992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005318894 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 14780       |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    reward               | 0.29491234  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 243         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1480        |\n",
      "|    time_elapsed         | 28259       |\n",
      "|    total_timesteps      | 3031040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004284179 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 14790       |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | 0.7837824   |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1481        |\n",
      "|    time_elapsed         | 28277       |\n",
      "|    total_timesteps      | 3033088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010296097 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 14800       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.57074404  |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4900480.85\n",
      "total_reward: 3900480.85\n",
      "total_cost: 233702.27\n",
      "total_trades: 63738\n",
      "Sharpe: 0.780\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1482         |\n",
      "|    time_elapsed         | 28295        |\n",
      "|    total_timesteps      | 3035136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030876598 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.5         |\n",
      "|    n_updates            | 14810        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | 3.2611158    |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1483         |\n",
      "|    time_elapsed         | 28313        |\n",
      "|    total_timesteps      | 3037184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025074966 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71           |\n",
      "|    n_updates            | 14820        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | -1.8084924   |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1484        |\n",
      "|    time_elapsed         | 28331       |\n",
      "|    total_timesteps      | 3039232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008923838 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 14830       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | -3.6310172  |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1485        |\n",
      "|    time_elapsed         | 28349       |\n",
      "|    total_timesteps      | 3041280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004492855 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 14840       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | 0.88099116  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1486        |\n",
      "|    time_elapsed         | 28366       |\n",
      "|    total_timesteps      | 3043328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005496184 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.5        |\n",
      "|    n_updates            | 14850       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | 3.5485194   |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1487         |\n",
      "|    time_elapsed         | 28384        |\n",
      "|    total_timesteps      | 3045376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045115803 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.205        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.6         |\n",
      "|    n_updates            | 14860        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | -0.99238265  |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 88.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 28401       |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009479679 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.2        |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    reward               | -1.0948567  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 79.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1489         |\n",
      "|    time_elapsed         | 28418        |\n",
      "|    total_timesteps      | 3049472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029189473 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.9         |\n",
      "|    n_updates            | 14880        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    reward               | -0.21984097  |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1490         |\n",
      "|    time_elapsed         | 28435        |\n",
      "|    total_timesteps      | 3051520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012710618 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 14890        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | -8.651067    |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1491        |\n",
      "|    time_elapsed         | 28452       |\n",
      "|    total_timesteps      | 3053568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00968743  |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | -0.0348     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 14900       |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    reward               | -0.90727496 |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1492         |\n",
      "|    time_elapsed         | 28469        |\n",
      "|    total_timesteps      | 3055616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034707221 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.7         |\n",
      "|    n_updates            | 14910        |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    reward               | 0.05932325   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1493         |\n",
      "|    time_elapsed         | 28486        |\n",
      "|    total_timesteps      | 3057664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008693002 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 14920        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | -2.2166648   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1494        |\n",
      "|    time_elapsed         | 28504       |\n",
      "|    total_timesteps      | 3059712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004884643 |\n",
      "|    clip_fraction        | 0.00972     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 14930       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | 1.187841    |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 93.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1495        |\n",
      "|    time_elapsed         | 28522       |\n",
      "|    total_timesteps      | 3061760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010521796 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.4        |\n",
      "|    n_updates            | 14940       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -2.6499534  |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 69.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4677626.94\n",
      "total_reward: 3677626.94\n",
      "total_cost: 237970.16\n",
      "total_trades: 63109\n",
      "Sharpe: 0.770\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1496         |\n",
      "|    time_elapsed         | 28539        |\n",
      "|    total_timesteps      | 3063808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058864444 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.1         |\n",
      "|    n_updates            | 14950        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | 0.027892264  |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1497         |\n",
      "|    time_elapsed         | 28556        |\n",
      "|    total_timesteps      | 3065856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035347762 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.8         |\n",
      "|    n_updates            | 14960        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | -5.91902     |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1498       |\n",
      "|    time_elapsed         | 28574      |\n",
      "|    total_timesteps      | 3067904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01053473 |\n",
      "|    clip_fraction        | 0.0946     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -112       |\n",
      "|    explained_variance   | 0.0531     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.1       |\n",
      "|    n_updates            | 14970      |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    reward               | 1.0962     |\n",
      "|    std                  | 11.9       |\n",
      "|    value_loss           | 31         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1499         |\n",
      "|    time_elapsed         | 28591        |\n",
      "|    total_timesteps      | 3069952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025967776 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.8         |\n",
      "|    n_updates            | 14980        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | -0.82356054  |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 149          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1500        |\n",
      "|    time_elapsed         | 28609       |\n",
      "|    total_timesteps      | 3072000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005817783 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.3        |\n",
      "|    n_updates            | 14990       |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    reward               | -1.4850075  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1501         |\n",
      "|    time_elapsed         | 28626        |\n",
      "|    total_timesteps      | 3074048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092234025 |\n",
      "|    clip_fraction        | 0.0646       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 15000        |\n",
      "|    policy_gradient_loss | -0.00841     |\n",
      "|    reward               | -5.495909    |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 54.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1502        |\n",
      "|    time_elapsed         | 28643       |\n",
      "|    total_timesteps      | 3076096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005813976 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 15010       |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | -1.6011214  |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1503        |\n",
      "|    time_elapsed         | 28661       |\n",
      "|    total_timesteps      | 3078144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004850163 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 15020       |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | -2.0759506  |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1504        |\n",
      "|    time_elapsed         | 28680       |\n",
      "|    total_timesteps      | 3080192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005749901 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.5        |\n",
      "|    n_updates            | 15030       |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | 2.17323     |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1505        |\n",
      "|    time_elapsed         | 28698       |\n",
      "|    total_timesteps      | 3082240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012206253 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.0847      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.43        |\n",
      "|    n_updates            | 15040       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | 0.17114916  |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1506         |\n",
      "|    time_elapsed         | 28716        |\n",
      "|    total_timesteps      | 3084288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010996005 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.7         |\n",
      "|    n_updates            | 15050        |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    reward               | -0.023899797 |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1507         |\n",
      "|    time_elapsed         | 28734        |\n",
      "|    total_timesteps      | 3086336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023695775 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.8         |\n",
      "|    n_updates            | 15060        |\n",
      "|    policy_gradient_loss | -0.000673    |\n",
      "|    reward               | 2.6351843    |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1508        |\n",
      "|    time_elapsed         | 28751       |\n",
      "|    total_timesteps      | 3088384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007991562 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 15070       |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | -4.3377767  |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1509        |\n",
      "|    time_elapsed         | 28769       |\n",
      "|    total_timesteps      | 3090432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003987246 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 15080       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | 2.9548123   |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 92.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1510        |\n",
      "|    time_elapsed         | 28787       |\n",
      "|    total_timesteps      | 3092480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004564523 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.6        |\n",
      "|    n_updates            | 15090       |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    reward               | 2.6268559   |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5045065.68\n",
      "total_reward: 4045065.68\n",
      "total_cost: 232886.04\n",
      "total_trades: 64025\n",
      "Sharpe: 0.833\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1511         |\n",
      "|    time_elapsed         | 28805        |\n",
      "|    total_timesteps      | 3094528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032197032 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 15100        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | 2.2087495    |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 71.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1512        |\n",
      "|    time_elapsed         | 28822       |\n",
      "|    total_timesteps      | 3096576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011565268 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 15110       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -1.3736337  |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1513         |\n",
      "|    time_elapsed         | 28839        |\n",
      "|    total_timesteps      | 3098624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015454334 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.1         |\n",
      "|    n_updates            | 15120        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | 0.21908924   |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1514         |\n",
      "|    time_elapsed         | 28856        |\n",
      "|    total_timesteps      | 3100672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015677176 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.0672       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.6         |\n",
      "|    n_updates            | 15130        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | 1.5651745    |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 201          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1515        |\n",
      "|    time_elapsed         | 28873       |\n",
      "|    total_timesteps      | 3102720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010415943 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 15140       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 1.5131685   |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1516        |\n",
      "|    time_elapsed         | 28890       |\n",
      "|    total_timesteps      | 3104768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007215133 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 15150       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | 2.0633252   |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 93.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1517         |\n",
      "|    time_elapsed         | 28907        |\n",
      "|    total_timesteps      | 3106816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042209895 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 100          |\n",
      "|    n_updates            | 15160        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 1.8331528    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1518         |\n",
      "|    time_elapsed         | 28924        |\n",
      "|    total_timesteps      | 3108864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064308667 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 15170        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | -3.8742025   |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 50.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1519        |\n",
      "|    time_elapsed         | 28941       |\n",
      "|    total_timesteps      | 3110912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010806697 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 15180       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.0022266  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1520        |\n",
      "|    time_elapsed         | 28958       |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009787205 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.0208      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 15190       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | -0.15140392 |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1521        |\n",
      "|    time_elapsed         | 28975       |\n",
      "|    total_timesteps      | 3115008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007697182 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.5        |\n",
      "|    n_updates            | 15200       |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    reward               | -1.5803483  |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1522        |\n",
      "|    time_elapsed         | 28992       |\n",
      "|    total_timesteps      | 3117056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010886988 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.00916     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 15210       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 2.050851    |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1523        |\n",
      "|    time_elapsed         | 29008       |\n",
      "|    total_timesteps      | 3119104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009004045 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.0286      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.8        |\n",
      "|    n_updates            | 15220       |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | -0.24276197 |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1524         |\n",
      "|    time_elapsed         | 29025        |\n",
      "|    total_timesteps      | 3121152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069679944 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.2         |\n",
      "|    n_updates            | 15230        |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    reward               | -15.366625   |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 84.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5266513.68\n",
      "total_reward: 4266513.68\n",
      "total_cost: 204694.51\n",
      "total_trades: 62118\n",
      "Sharpe: 0.888\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1525         |\n",
      "|    time_elapsed         | 29042        |\n",
      "|    total_timesteps      | 3123200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077300104 |\n",
      "|    clip_fraction        | 0.068        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | -0.0469      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 15240        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    reward               | 1.353383     |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 63.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1526         |\n",
      "|    time_elapsed         | 29059        |\n",
      "|    total_timesteps      | 3125248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004346181  |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.0345       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 15250        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | -0.030555774 |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 91           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1527        |\n",
      "|    time_elapsed         | 29076       |\n",
      "|    total_timesteps      | 3127296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005405764 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.0424      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 15260       |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | 7.909934    |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1528         |\n",
      "|    time_elapsed         | 29093        |\n",
      "|    total_timesteps      | 3129344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039198166 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.0658       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 15270        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    reward               | -1.9096816   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1529        |\n",
      "|    time_elapsed         | 29110       |\n",
      "|    total_timesteps      | 3131392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007932604 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.33        |\n",
      "|    n_updates            | 15280       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | -1.0552268  |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1530         |\n",
      "|    time_elapsed         | 29127        |\n",
      "|    total_timesteps      | 3133440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039073084 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 15290        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    reward               | 1.1748785    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 95.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1531         |\n",
      "|    time_elapsed         | 29145        |\n",
      "|    total_timesteps      | 3135488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010428189 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 15300        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | 2.0492022    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 66.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1532        |\n",
      "|    time_elapsed         | 29162       |\n",
      "|    total_timesteps      | 3137536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012709556 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 15310       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -1.6675876  |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1533         |\n",
      "|    time_elapsed         | 29180        |\n",
      "|    total_timesteps      | 3139584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033537608 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 15320        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    reward               | 1.2416914    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 73.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1534         |\n",
      "|    time_elapsed         | 29197        |\n",
      "|    total_timesteps      | 3141632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038802056 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.7         |\n",
      "|    n_updates            | 15330        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    reward               | 3.1919239    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 93.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1535         |\n",
      "|    time_elapsed         | 29214        |\n",
      "|    total_timesteps      | 3143680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017257234 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 15340        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | -3.4900978   |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 59.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1536        |\n",
      "|    time_elapsed         | 29232       |\n",
      "|    total_timesteps      | 3145728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009003023 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 15350       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -1.2860385  |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1537         |\n",
      "|    time_elapsed         | 29249        |\n",
      "|    total_timesteps      | 3147776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045815194 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.3         |\n",
      "|    n_updates            | 15360        |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    reward               | 0.20613271   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 79.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1538         |\n",
      "|    time_elapsed         | 29266        |\n",
      "|    total_timesteps      | 3149824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036656312 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.252        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 15370        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    reward               | -0.02715616  |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 77.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3379241.03\n",
      "total_reward: 2379241.03\n",
      "total_cost: 206175.06\n",
      "total_trades: 61254\n",
      "Sharpe: 0.659\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1539        |\n",
      "|    time_elapsed         | 29283       |\n",
      "|    total_timesteps      | 3151872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009031998 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | -0.295      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 15380       |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | -0.45173323 |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1540        |\n",
      "|    time_elapsed         | 29301       |\n",
      "|    total_timesteps      | 3153920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006198626 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 15390       |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    reward               | -4.319896   |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1541         |\n",
      "|    time_elapsed         | 29318        |\n",
      "|    total_timesteps      | 3155968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049875043 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 15400        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    reward               | -4.8095818   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1542         |\n",
      "|    time_elapsed         | 29336        |\n",
      "|    total_timesteps      | 3158016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042975326 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 15410        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | -1.022026    |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1543        |\n",
      "|    time_elapsed         | 29353       |\n",
      "|    total_timesteps      | 3160064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005933815 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 15420       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 0.817187    |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1544         |\n",
      "|    time_elapsed         | 29370        |\n",
      "|    total_timesteps      | 3162112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055753104 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 15430        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | 0.12933305   |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 72.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1545        |\n",
      "|    time_elapsed         | 29388       |\n",
      "|    total_timesteps      | 3164160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003179076 |\n",
      "|    clip_fraction        | 0.00273     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 15440       |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    reward               | 0.5798961   |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1546         |\n",
      "|    time_elapsed         | 29405        |\n",
      "|    total_timesteps      | 3166208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065880036 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.15         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 15450        |\n",
      "|    policy_gradient_loss | -0.00726     |\n",
      "|    reward               | 1.0416069    |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1547         |\n",
      "|    time_elapsed         | 29422        |\n",
      "|    total_timesteps      | 3168256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037799405 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 15460        |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    reward               | 1.8813735    |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 59.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1548          |\n",
      "|    time_elapsed         | 29439         |\n",
      "|    total_timesteps      | 3170304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090336846 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.552         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.5          |\n",
      "|    n_updates            | 15470         |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    reward               | -5.6593904    |\n",
      "|    std                  | 13            |\n",
      "|    value_loss           | 53.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1549         |\n",
      "|    time_elapsed         | 29456        |\n",
      "|    total_timesteps      | 3172352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072916965 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 15480        |\n",
      "|    policy_gradient_loss | -0.009       |\n",
      "|    reward               | 0.8596823    |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1550        |\n",
      "|    time_elapsed         | 29474       |\n",
      "|    total_timesteps      | 3174400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007401877 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 15490       |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -0.27438468 |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1551        |\n",
      "|    time_elapsed         | 29492       |\n",
      "|    total_timesteps      | 3176448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006307455 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 15500       |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | -4.9597383  |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1552        |\n",
      "|    time_elapsed         | 29509       |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007030405 |\n",
      "|    clip_fraction        | 0.0481      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.5        |\n",
      "|    n_updates            | 15510       |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    reward               | 1.5280914   |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3376482.51\n",
      "total_reward: 2376482.51\n",
      "total_cost: 192472.18\n",
      "total_trades: 62050\n",
      "Sharpe: 0.685\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1553        |\n",
      "|    time_elapsed         | 29526       |\n",
      "|    total_timesteps      | 3180544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009090152 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.84        |\n",
      "|    n_updates            | 15520       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | 2.2683177   |\n",
      "|    std                  | 13.1        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1554         |\n",
      "|    time_elapsed         | 29543        |\n",
      "|    total_timesteps      | 3182592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013988549 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 15530        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | -0.1263682   |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 47.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1555         |\n",
      "|    time_elapsed         | 29560        |\n",
      "|    total_timesteps      | 3184640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031623915 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 15540        |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    reward               | -3.7857106   |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1556         |\n",
      "|    time_elapsed         | 29577        |\n",
      "|    total_timesteps      | 3186688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092654675 |\n",
      "|    clip_fraction        | 0.0636       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 15550        |\n",
      "|    policy_gradient_loss | -0.0097      |\n",
      "|    reward               | -3.3570073   |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1557         |\n",
      "|    time_elapsed         | 29594        |\n",
      "|    total_timesteps      | 3188736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043120477 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 15560        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    reward               | -5.104725    |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1558         |\n",
      "|    time_elapsed         | 29611        |\n",
      "|    total_timesteps      | 3190784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013313196 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.3         |\n",
      "|    n_updates            | 15570        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | 1.8022057    |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 58.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1559         |\n",
      "|    time_elapsed         | 29629        |\n",
      "|    total_timesteps      | 3192832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042568017 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 15580        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | -4.8974996   |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1560        |\n",
      "|    time_elapsed         | 29647       |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005981301 |\n",
      "|    clip_fraction        | 0.0145      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9           |\n",
      "|    n_updates            | 15590       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | 0.6736948   |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1561        |\n",
      "|    time_elapsed         | 29664       |\n",
      "|    total_timesteps      | 3196928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004443601 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 15600       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -0.1455223  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1562        |\n",
      "|    time_elapsed         | 29681       |\n",
      "|    total_timesteps      | 3198976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004743042 |\n",
      "|    clip_fraction        | 0.0085      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 15610       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | 1.1414999   |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1563        |\n",
      "|    time_elapsed         | 29698       |\n",
      "|    total_timesteps      | 3201024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008408043 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.21        |\n",
      "|    n_updates            | 15620       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | 0.09018386  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1564        |\n",
      "|    time_elapsed         | 29715       |\n",
      "|    total_timesteps      | 3203072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009649337 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 15630       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.26907018  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1565         |\n",
      "|    time_elapsed         | 29732        |\n",
      "|    total_timesteps      | 3205120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063181547 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 15640        |\n",
      "|    policy_gradient_loss | -0.00926     |\n",
      "|    reward               | -3.6127229   |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 57.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1566         |\n",
      "|    time_elapsed         | 29749        |\n",
      "|    total_timesteps      | 3207168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049455753 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 15650        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | 0.19679396   |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3562969.90\n",
      "total_reward: 2562969.90\n",
      "total_cost: 188785.11\n",
      "total_trades: 61237\n",
      "Sharpe: 0.686\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1567        |\n",
      "|    time_elapsed         | 29766       |\n",
      "|    total_timesteps      | 3209216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009351466 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.17        |\n",
      "|    n_updates            | 15660       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 0.051208716 |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1568         |\n",
      "|    time_elapsed         | 29783        |\n",
      "|    total_timesteps      | 3211264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033676927 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 15670        |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    reward               | -0.7952361   |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 46.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1569        |\n",
      "|    time_elapsed         | 29800       |\n",
      "|    total_timesteps      | 3213312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001990287 |\n",
      "|    clip_fraction        | 0.00439     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 15680       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | 0.6760066   |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1570        |\n",
      "|    time_elapsed         | 29818       |\n",
      "|    total_timesteps      | 3215360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010304114 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.39        |\n",
      "|    n_updates            | 15690       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | -0.937453   |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1571         |\n",
      "|    time_elapsed         | 29835        |\n",
      "|    total_timesteps      | 3217408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046932083 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 15700        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    reward               | 0.6391079    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1572        |\n",
      "|    time_elapsed         | 29852       |\n",
      "|    total_timesteps      | 3219456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003995207 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 15710       |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    reward               | -1.5968983  |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1573        |\n",
      "|    time_elapsed         | 29868       |\n",
      "|    total_timesteps      | 3221504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010364135 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 15720       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.041205596 |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1574        |\n",
      "|    time_elapsed         | 29886       |\n",
      "|    total_timesteps      | 3223552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008213935 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 15730       |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | 0.08977203  |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1575         |\n",
      "|    time_elapsed         | 29902        |\n",
      "|    total_timesteps      | 3225600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024130442 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 15740        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | 1.1007596    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 51.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1576        |\n",
      "|    time_elapsed         | 29919       |\n",
      "|    total_timesteps      | 3227648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005668367 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 15750       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 0.23874822  |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1577        |\n",
      "|    time_elapsed         | 29936       |\n",
      "|    total_timesteps      | 3229696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009683812 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 15760       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.8936377  |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1578        |\n",
      "|    time_elapsed         | 29953       |\n",
      "|    total_timesteps      | 3231744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005381202 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 15770       |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | -0.9252235  |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1579         |\n",
      "|    time_elapsed         | 29970        |\n",
      "|    total_timesteps      | 3233792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011855012 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 15780        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 2.2993817    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1580        |\n",
      "|    time_elapsed         | 29987       |\n",
      "|    total_timesteps      | 3235840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008857427 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 15790       |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | 0.07799341  |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3346734.22\n",
      "total_reward: 2346734.22\n",
      "total_cost: 112961.57\n",
      "total_trades: 57262\n",
      "Sharpe: 0.629\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1581         |\n",
      "|    time_elapsed         | 30004        |\n",
      "|    total_timesteps      | 3237888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053668367 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 15800        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    reward               | 2.1074834    |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1582         |\n",
      "|    time_elapsed         | 30021        |\n",
      "|    total_timesteps      | 3239936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008570369 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 15810        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | -7.0540223   |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 50.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1583         |\n",
      "|    time_elapsed         | 30037        |\n",
      "|    total_timesteps      | 3241984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020497586 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.205        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 15820        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 0.0026666506 |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1584         |\n",
      "|    time_elapsed         | 30055        |\n",
      "|    total_timesteps      | 3244032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009995611  |\n",
      "|    clip_fraction        | 0.0744       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 15830        |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    reward               | -0.038203306 |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1585         |\n",
      "|    time_elapsed         | 30072        |\n",
      "|    total_timesteps      | 3246080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046316097 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.173        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.4         |\n",
      "|    n_updates            | 15840        |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    reward               | 0.82563436   |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 70.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1586          |\n",
      "|    time_elapsed         | 30088         |\n",
      "|    total_timesteps      | 3248128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021168246 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.219         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.3          |\n",
      "|    n_updates            | 15850         |\n",
      "|    policy_gradient_loss | -0.00095      |\n",
      "|    reward               | 0.89598864    |\n",
      "|    std                  | 13.6          |\n",
      "|    value_loss           | 65.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1587         |\n",
      "|    time_elapsed         | 30105        |\n",
      "|    total_timesteps      | 3250176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073923627 |\n",
      "|    clip_fraction        | 0.0474       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.15         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 15860        |\n",
      "|    policy_gradient_loss | -0.00906     |\n",
      "|    reward               | 2.4335203    |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1588         |\n",
      "|    time_elapsed         | 30122        |\n",
      "|    total_timesteps      | 3252224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019440353 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.1         |\n",
      "|    n_updates            | 15870        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | 0.3493718    |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1589        |\n",
      "|    time_elapsed         | 30139       |\n",
      "|    total_timesteps      | 3254272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001757409 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 15880       |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    reward               | 0.10361992  |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1590        |\n",
      "|    time_elapsed         | 30156       |\n",
      "|    total_timesteps      | 3256320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006099876 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 15890       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | -0.40139696 |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1591        |\n",
      "|    time_elapsed         | 30172       |\n",
      "|    total_timesteps      | 3258368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006274256 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 15900       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 1.3720514   |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1592         |\n",
      "|    time_elapsed         | 30189        |\n",
      "|    total_timesteps      | 3260416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062269107 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 15910        |\n",
      "|    policy_gradient_loss | -0.00685     |\n",
      "|    reward               | -0.22524513  |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 44.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1593         |\n",
      "|    time_elapsed         | 30206        |\n",
      "|    total_timesteps      | 3262464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041497014 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 15920        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | -1.323318    |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 57.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1594       |\n",
      "|    time_elapsed         | 30223      |\n",
      "|    total_timesteps      | 3264512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00959867 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -117       |\n",
      "|    explained_variance   | 0.367      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.49       |\n",
      "|    n_updates            | 15930      |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | -0.7375984 |\n",
      "|    std                  | 13.8       |\n",
      "|    value_loss           | 19.2       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3132369.15\n",
      "total_reward: 2132369.15\n",
      "total_cost: 139524.38\n",
      "total_trades: 59491\n",
      "Sharpe: 0.624\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1595         |\n",
      "|    time_elapsed         | 30240        |\n",
      "|    total_timesteps      | 3266560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034854966 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 15940        |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    reward               | 0.3308888    |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 40.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 1596          |\n",
      "|    time_elapsed         | 30257         |\n",
      "|    total_timesteps      | 3268608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065128563 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -117          |\n",
      "|    explained_variance   | 0.506         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.1          |\n",
      "|    n_updates            | 15950         |\n",
      "|    policy_gradient_loss | -0.000661     |\n",
      "|    reward               | -3.4184144    |\n",
      "|    std                  | 13.8          |\n",
      "|    value_loss           | 47.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1597        |\n",
      "|    time_elapsed         | 30274       |\n",
      "|    total_timesteps      | 3270656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004795746 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 15960       |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | -4.598368   |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1598        |\n",
      "|    time_elapsed         | 30292       |\n",
      "|    total_timesteps      | 3272704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009237284 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 15970       |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    reward               | 0.434572    |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1599         |\n",
      "|    time_elapsed         | 30309        |\n",
      "|    total_timesteps      | 3274752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017757921 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 15980        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -3.6937294   |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 44.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1600         |\n",
      "|    time_elapsed         | 30326        |\n",
      "|    total_timesteps      | 3276800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058040926 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.4         |\n",
      "|    n_updates            | 15990        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | 0.65540385   |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 54.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1601        |\n",
      "|    time_elapsed         | 30343       |\n",
      "|    total_timesteps      | 3278848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008252182 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | -2.8493848  |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1602         |\n",
      "|    time_elapsed         | 30361        |\n",
      "|    total_timesteps      | 3280896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024782289 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 16010        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | -0.12751141  |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1603         |\n",
      "|    time_elapsed         | 30379        |\n",
      "|    total_timesteps      | 3282944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050379233 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 16020        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    reward               | 5.3969765    |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1604         |\n",
      "|    time_elapsed         | 30396        |\n",
      "|    total_timesteps      | 3284992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090453485 |\n",
      "|    clip_fraction        | 0.0766       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 16030        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    reward               | -0.060819227 |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1605         |\n",
      "|    time_elapsed         | 30414        |\n",
      "|    total_timesteps      | 3287040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051263515 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 16040        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    reward               | 1.2614942    |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 53.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1606        |\n",
      "|    time_elapsed         | 30431       |\n",
      "|    total_timesteps      | 3289088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004139818 |\n",
      "|    clip_fraction        | 0.00688     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 16050       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | 0.3695495   |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1607         |\n",
      "|    time_elapsed         | 30448        |\n",
      "|    total_timesteps      | 3291136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048529985 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 16060        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | 2.3919094    |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 48.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1608         |\n",
      "|    time_elapsed         | 30465        |\n",
      "|    total_timesteps      | 3293184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044746483 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 16070        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    reward               | -3.2208333   |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3606414.83\n",
      "total_reward: 2606414.83\n",
      "total_cost: 81857.96\n",
      "total_trades: 54944\n",
      "Sharpe: 0.676\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1609         |\n",
      "|    time_elapsed         | 30482        |\n",
      "|    total_timesteps      | 3295232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030385968 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 16080        |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    reward               | 0.38099852   |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1610        |\n",
      "|    time_elapsed         | 30498       |\n",
      "|    total_timesteps      | 3297280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004500862 |\n",
      "|    clip_fraction        | 0.00923     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 16090       |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | 2.2114177   |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1611        |\n",
      "|    time_elapsed         | 30515       |\n",
      "|    total_timesteps      | 3299328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010486599 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 16100       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.055792    |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1612        |\n",
      "|    time_elapsed         | 30533       |\n",
      "|    total_timesteps      | 3301376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005683325 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 16110       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | 0.16017745  |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1613         |\n",
      "|    time_elapsed         | 30549        |\n",
      "|    total_timesteps      | 3303424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063593993 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.6         |\n",
      "|    n_updates            | 16120        |\n",
      "|    policy_gradient_loss | -0.00813     |\n",
      "|    reward               | -4.866328    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 60.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1614        |\n",
      "|    time_elapsed         | 30566       |\n",
      "|    total_timesteps      | 3305472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001390656 |\n",
      "|    clip_fraction        | 0.000537    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 16130       |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    reward               | -1.4133617  |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1615         |\n",
      "|    time_elapsed         | 30583        |\n",
      "|    total_timesteps      | 3307520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030152295 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 16140        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 0.71761656   |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1616         |\n",
      "|    time_elapsed         | 30600        |\n",
      "|    total_timesteps      | 3309568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037563548 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 16150        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    reward               | 3.4645853    |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1617         |\n",
      "|    time_elapsed         | 30617        |\n",
      "|    total_timesteps      | 3311616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017005149 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 16160        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    reward               | -1.019936    |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 58           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1618        |\n",
      "|    time_elapsed         | 30634       |\n",
      "|    total_timesteps      | 3313664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008409944 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.53        |\n",
      "|    n_updates            | 16170       |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    reward               | 1.0659955   |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1619         |\n",
      "|    time_elapsed         | 30651        |\n",
      "|    total_timesteps      | 3315712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009079402 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 16180        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | 2.058523     |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 49.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1620         |\n",
      "|    time_elapsed         | 30668        |\n",
      "|    total_timesteps      | 3317760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016099934 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 16190        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | -0.01398183  |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 52.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1621         |\n",
      "|    time_elapsed         | 30685        |\n",
      "|    total_timesteps      | 3319808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031122235 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 16200        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    reward               | -2.9191964   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 41.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1622         |\n",
      "|    time_elapsed         | 30702        |\n",
      "|    total_timesteps      | 3321856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035827602 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 16210        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | -1.7205652   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1623         |\n",
      "|    time_elapsed         | 30719        |\n",
      "|    total_timesteps      | 3323904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032083383 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 16220        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | -2.6494186   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3506340.87\n",
      "total_reward: 2506340.87\n",
      "total_cost: 79101.03\n",
      "total_trades: 54511\n",
      "Sharpe: 0.660\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1624        |\n",
      "|    time_elapsed         | 30736       |\n",
      "|    total_timesteps      | 3325952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004303818 |\n",
      "|    clip_fraction        | 0.00571     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 16230       |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | 0.22589277  |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 52.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1625         |\n",
      "|    time_elapsed         | 30752        |\n",
      "|    total_timesteps      | 3328000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069505866 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 16240        |\n",
      "|    policy_gradient_loss | -0.00778     |\n",
      "|    reward               | -0.12949419  |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 1626          |\n",
      "|    time_elapsed         | 30769         |\n",
      "|    total_timesteps      | 3330048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086905604 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -118          |\n",
      "|    explained_variance   | 0.633         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.8          |\n",
      "|    n_updates            | 16250         |\n",
      "|    policy_gradient_loss | -0.00268      |\n",
      "|    reward               | -1.1646636    |\n",
      "|    std                  | 14.4          |\n",
      "|    value_loss           | 47.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1627         |\n",
      "|    time_elapsed         | 30786        |\n",
      "|    total_timesteps      | 3332096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012747284 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 16260        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 3.2078803    |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 45           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1628         |\n",
      "|    time_elapsed         | 30804        |\n",
      "|    total_timesteps      | 3334144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058898963 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 16270        |\n",
      "|    policy_gradient_loss | -0.00734     |\n",
      "|    reward               | -0.75705814  |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1629        |\n",
      "|    time_elapsed         | 30822       |\n",
      "|    total_timesteps      | 3336192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004154638 |\n",
      "|    clip_fraction        | 0.00801     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 16280       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | 1.0761504   |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1630         |\n",
      "|    time_elapsed         | 30839        |\n",
      "|    total_timesteps      | 3338240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041286564 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 16290        |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    reward               | 1.7723355    |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 54.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1631        |\n",
      "|    time_elapsed         | 30856       |\n",
      "|    total_timesteps      | 3340288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002593109 |\n",
      "|    clip_fraction        | 0.00107     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 16300       |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | -4.621484   |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1632        |\n",
      "|    time_elapsed         | 30873       |\n",
      "|    total_timesteps      | 3342336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008668842 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.35608545 |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1633         |\n",
      "|    time_elapsed         | 30890        |\n",
      "|    total_timesteps      | 3344384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038675363 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 16320        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | 0.33616257   |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 44.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1634         |\n",
      "|    time_elapsed         | 30906        |\n",
      "|    total_timesteps      | 3346432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051091984 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 16330        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | -0.6532085   |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 49.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1635        |\n",
      "|    time_elapsed         | 30924       |\n",
      "|    total_timesteps      | 3348480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008602226 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -5.7338066  |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1636         |\n",
      "|    time_elapsed         | 30941        |\n",
      "|    total_timesteps      | 3350528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072338674 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 16350        |\n",
      "|    policy_gradient_loss | -0.0076      |\n",
      "|    reward               | -1.0710241   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1637         |\n",
      "|    time_elapsed         | 30958        |\n",
      "|    total_timesteps      | 3352576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048399027 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 16360        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    reward               | 1.8031381    |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3328850.55\n",
      "total_reward: 2328850.55\n",
      "total_cost: 86125.43\n",
      "total_trades: 55854\n",
      "Sharpe: 0.630\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1638       |\n",
      "|    time_elapsed         | 30975      |\n",
      "|    total_timesteps      | 3354624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00628279 |\n",
      "|    clip_fraction        | 0.0244     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -118       |\n",
      "|    explained_variance   | 0.305      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.4       |\n",
      "|    n_updates            | 16370      |\n",
      "|    policy_gradient_loss | -0.0071    |\n",
      "|    reward               | 3.015701   |\n",
      "|    std                  | 14.6       |\n",
      "|    value_loss           | 42.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1639        |\n",
      "|    time_elapsed         | 30992       |\n",
      "|    total_timesteps      | 3356672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008231852 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 16380       |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    reward               | 0.32367325  |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1640       |\n",
      "|    time_elapsed         | 31009      |\n",
      "|    total_timesteps      | 3358720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00503981 |\n",
      "|    clip_fraction        | 0.0193     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -118       |\n",
      "|    explained_variance   | 0.536      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.3       |\n",
      "|    n_updates            | 16390      |\n",
      "|    policy_gradient_loss | -0.00497   |\n",
      "|    reward               | 10.261232  |\n",
      "|    std                  | 14.6       |\n",
      "|    value_loss           | 49.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1641         |\n",
      "|    time_elapsed         | 31026        |\n",
      "|    total_timesteps      | 3360768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061924253 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 16400        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | -2.8289516   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1642        |\n",
      "|    time_elapsed         | 31043       |\n",
      "|    total_timesteps      | 3362816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009149383 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.01        |\n",
      "|    n_updates            | 16410       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -0.28399846 |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1643         |\n",
      "|    time_elapsed         | 31060        |\n",
      "|    total_timesteps      | 3364864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026640785 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 16420        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | 0.55566      |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1644        |\n",
      "|    time_elapsed         | 31077       |\n",
      "|    total_timesteps      | 3366912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005969463 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 16430       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -8.795414   |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1645        |\n",
      "|    time_elapsed         | 31094       |\n",
      "|    total_timesteps      | 3368960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006308092 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 16440       |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | 0.40391746  |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1646         |\n",
      "|    time_elapsed         | 31111        |\n",
      "|    total_timesteps      | 3371008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029412408 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 16450        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | -0.04402292  |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 35.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1647         |\n",
      "|    time_elapsed         | 31128        |\n",
      "|    total_timesteps      | 3373056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011510667 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.333        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 16460        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | 1.8683832    |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 55.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1648         |\n",
      "|    time_elapsed         | 31145        |\n",
      "|    total_timesteps      | 3375104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036312495 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 16470        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 1.2998688    |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1649        |\n",
      "|    time_elapsed         | 31162       |\n",
      "|    total_timesteps      | 3377152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008069545 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.7363804   |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1650        |\n",
      "|    time_elapsed         | 31179       |\n",
      "|    total_timesteps      | 3379200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004199736 |\n",
      "|    clip_fraction        | 0.00981     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 16490       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | 0.34192526  |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1651         |\n",
      "|    time_elapsed         | 31196        |\n",
      "|    total_timesteps      | 3381248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063441806 |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.312        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 16500        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    reward               | 1.7029805    |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 66.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3476163.80\n",
      "total_reward: 2476163.80\n",
      "total_cost: 83483.41\n",
      "total_trades: 55101\n",
      "Sharpe: 0.667\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1652        |\n",
      "|    time_elapsed         | 31213       |\n",
      "|    total_timesteps      | 3383296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008118929 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.24        |\n",
      "|    n_updates            | 16510       |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    reward               | -2.0381627  |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1653         |\n",
      "|    time_elapsed         | 31230        |\n",
      "|    total_timesteps      | 3385344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024131818 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 16520        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | -0.32910943  |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1654         |\n",
      "|    time_elapsed         | 31247        |\n",
      "|    total_timesteps      | 3387392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023167222 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 16530        |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    reward               | 1.131684     |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1655         |\n",
      "|    time_elapsed         | 31264        |\n",
      "|    total_timesteps      | 3389440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064466977 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 16540        |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    reward               | 0.8649237    |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 42.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1656        |\n",
      "|    time_elapsed         | 31281       |\n",
      "|    total_timesteps      | 3391488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00596979  |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 16550       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -0.37851962 |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1657         |\n",
      "|    time_elapsed         | 31298        |\n",
      "|    total_timesteps      | 3393536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040598027 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.7         |\n",
      "|    n_updates            | 16560        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | 1.1608169    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1658         |\n",
      "|    time_elapsed         | 31315        |\n",
      "|    total_timesteps      | 3395584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028549791 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 16570        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | 0.15380567   |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 57.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1659         |\n",
      "|    time_elapsed         | 31332        |\n",
      "|    total_timesteps      | 3397632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094280075 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.99         |\n",
      "|    n_updates            | 16580        |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    reward               | -1.977953    |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1660         |\n",
      "|    time_elapsed         | 31349        |\n",
      "|    total_timesteps      | 3399680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047826506 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 16590        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | -0.7278809   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 46.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1661         |\n",
      "|    time_elapsed         | 31366        |\n",
      "|    total_timesteps      | 3401728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064169057 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.2         |\n",
      "|    n_updates            | 16600        |\n",
      "|    policy_gradient_loss | -0.00741     |\n",
      "|    reward               | 1.2581477    |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 49.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1662         |\n",
      "|    time_elapsed         | 31383        |\n",
      "|    total_timesteps      | 3403776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067223627 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 16610        |\n",
      "|    policy_gradient_loss | -0.00918     |\n",
      "|    reward               | -2.4855995   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1663         |\n",
      "|    time_elapsed         | 31400        |\n",
      "|    total_timesteps      | 3405824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065593957 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 16620        |\n",
      "|    policy_gradient_loss | -0.00977     |\n",
      "|    reward               | -1.8000624   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1664         |\n",
      "|    time_elapsed         | 31417        |\n",
      "|    total_timesteps      | 3407872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048639053 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 16630        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | -2.7744806   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1665         |\n",
      "|    time_elapsed         | 31434        |\n",
      "|    total_timesteps      | 3409920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059815776 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 16640        |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    reward               | 2.365427     |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3610780.54\n",
      "total_reward: 2610780.54\n",
      "total_cost: 76389.32\n",
      "total_trades: 54440\n",
      "Sharpe: 0.689\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1666         |\n",
      "|    time_elapsed         | 31451        |\n",
      "|    total_timesteps      | 3411968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065093734 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.85         |\n",
      "|    n_updates            | 16650        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    reward               | 1.8176129    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1667        |\n",
      "|    time_elapsed         | 31468       |\n",
      "|    total_timesteps      | 3414016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003360887 |\n",
      "|    clip_fraction        | 0.00596     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 16660       |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | -1.2848309  |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1668         |\n",
      "|    time_elapsed         | 31485        |\n",
      "|    total_timesteps      | 3416064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020019212 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 16670        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    reward               | 4.707335     |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 59.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1669         |\n",
      "|    time_elapsed         | 31502        |\n",
      "|    total_timesteps      | 3418112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056516523 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 16680        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | 1.2372919    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 40.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1670        |\n",
      "|    time_elapsed         | 31519       |\n",
      "|    total_timesteps      | 3420160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002874394 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 16690       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | -1.5583383  |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1671         |\n",
      "|    time_elapsed         | 31536        |\n",
      "|    total_timesteps      | 3422208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011850966 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 16700        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | 3.5177476    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 39.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1672        |\n",
      "|    time_elapsed         | 31553       |\n",
      "|    total_timesteps      | 3424256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005320661 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 16710       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | -1.9654704  |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1673         |\n",
      "|    time_elapsed         | 31570        |\n",
      "|    total_timesteps      | 3426304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065668896 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.2          |\n",
      "|    n_updates            | 16720        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    reward               | -3.1611838   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1674         |\n",
      "|    time_elapsed         | 31587        |\n",
      "|    total_timesteps      | 3428352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015399563 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 16730        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | 0.31933987   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1675        |\n",
      "|    time_elapsed         | 31604       |\n",
      "|    total_timesteps      | 3430400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003845113 |\n",
      "|    clip_fraction        | 0.0085      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 16740       |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | -1.5236683  |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1676         |\n",
      "|    time_elapsed         | 31621        |\n",
      "|    total_timesteps      | 3432448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071523692 |\n",
      "|    clip_fraction        | 0.0413       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.67         |\n",
      "|    n_updates            | 16750        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    reward               | -4.866408    |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1677        |\n",
      "|    time_elapsed         | 31638       |\n",
      "|    total_timesteps      | 3434496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002077608 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 16760       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 0.5542708   |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1678         |\n",
      "|    time_elapsed         | 31655        |\n",
      "|    total_timesteps      | 3436544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014741626 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 16770        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | -1.3941532   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1679        |\n",
      "|    time_elapsed         | 31672       |\n",
      "|    total_timesteps      | 3438592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003536054 |\n",
      "|    clip_fraction        | 0.00303     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 16780       |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | -2.2069361  |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3529704.25\n",
      "total_reward: 2529704.25\n",
      "total_cost: 90891.07\n",
      "total_trades: 56573\n",
      "Sharpe: 0.675\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1680        |\n",
      "|    time_elapsed         | 31689       |\n",
      "|    total_timesteps      | 3440640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004869624 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 16790       |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | 1.7703998   |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1681         |\n",
      "|    time_elapsed         | 31706        |\n",
      "|    total_timesteps      | 3442688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033776038 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 16800        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | -0.7258089   |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1682         |\n",
      "|    time_elapsed         | 31723        |\n",
      "|    total_timesteps      | 3444736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008039495 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 16810        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 0.24330465   |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 57.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1683         |\n",
      "|    time_elapsed         | 31740        |\n",
      "|    total_timesteps      | 3446784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074316147 |\n",
      "|    clip_fraction        | 0.046        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.3          |\n",
      "|    n_updates            | 16820        |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    reward               | -1.8440988   |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1684         |\n",
      "|    time_elapsed         | 31757        |\n",
      "|    total_timesteps      | 3448832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016406724 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 16830        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -0.026242757 |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 48.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1685         |\n",
      "|    time_elapsed         | 31773        |\n",
      "|    total_timesteps      | 3450880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015890598 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 16840        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -6.283104    |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 48.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1686         |\n",
      "|    time_elapsed         | 31790        |\n",
      "|    total_timesteps      | 3452928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041745272 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 16850        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -0.41021234  |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1687         |\n",
      "|    time_elapsed         | 31807        |\n",
      "|    total_timesteps      | 3454976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060778516 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 16860        |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    reward               | 3.7331438    |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1688        |\n",
      "|    time_elapsed         | 31824       |\n",
      "|    total_timesteps      | 3457024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002593859 |\n",
      "|    clip_fraction        | 0.00298     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 16870       |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | -1.0088794  |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1689         |\n",
      "|    time_elapsed         | 31841        |\n",
      "|    total_timesteps      | 3459072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034362823 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 16880        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | -1.5749656   |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 50.7         |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 108            |\n",
      "|    iterations           | 1690           |\n",
      "|    time_elapsed         | 31858          |\n",
      "|    total_timesteps      | 3461120        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0064430377   |\n",
      "|    clip_fraction        | 0.0243         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -120           |\n",
      "|    explained_variance   | 0.537          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 10.4           |\n",
      "|    n_updates            | 16890          |\n",
      "|    policy_gradient_loss | -0.00743       |\n",
      "|    reward               | -0.00017283918 |\n",
      "|    std                  | 15.5           |\n",
      "|    value_loss           | 30.3           |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1691         |\n",
      "|    time_elapsed         | 31875        |\n",
      "|    total_timesteps      | 3463168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016852571 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 16900        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 0.45982978   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 48.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1692        |\n",
      "|    time_elapsed         | 31892       |\n",
      "|    total_timesteps      | 3465216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001622947 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 16910       |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    reward               | 1.8999754   |\n",
      "|    std                  | 15.5        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1693         |\n",
      "|    time_elapsed         | 31909        |\n",
      "|    total_timesteps      | 3467264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064069275 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 16920        |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    reward               | -1.2696768   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3357681.54\n",
      "total_reward: 2357681.54\n",
      "total_cost: 129131.12\n",
      "total_trades: 59631\n",
      "Sharpe: 0.669\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1694        |\n",
      "|    time_elapsed         | 31926       |\n",
      "|    total_timesteps      | 3469312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002426779 |\n",
      "|    clip_fraction        | 0.00742     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 16930       |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 0.22310616  |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1695        |\n",
      "|    time_elapsed         | 31944       |\n",
      "|    total_timesteps      | 3471360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002714613 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 16940       |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | -2.8356948  |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1696        |\n",
      "|    time_elapsed         | 31960       |\n",
      "|    total_timesteps      | 3473408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002236872 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    reward               | -0.37077788 |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1697        |\n",
      "|    time_elapsed         | 31977       |\n",
      "|    total_timesteps      | 3475456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005730932 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 16960       |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | -0.86912787 |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1698         |\n",
      "|    time_elapsed         | 31994        |\n",
      "|    total_timesteps      | 3477504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033165587 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 16970        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -0.01822431  |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1699        |\n",
      "|    time_elapsed         | 32011       |\n",
      "|    total_timesteps      | 3479552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002863157 |\n",
      "|    clip_fraction        | 0.0019      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 16980       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | -2.8026428  |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 56.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1700         |\n",
      "|    time_elapsed         | 32028        |\n",
      "|    total_timesteps      | 3481600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064611738 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 16990        |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    reward               | 0.4430775    |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1701        |\n",
      "|    time_elapsed         | 32045       |\n",
      "|    total_timesteps      | 3483648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002362561 |\n",
      "|    clip_fraction        | 0.00332     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 17000       |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    reward               | -0.41075563 |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1702        |\n",
      "|    time_elapsed         | 32062       |\n",
      "|    total_timesteps      | 3485696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005383997 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 17010       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | 0.2326054   |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1703         |\n",
      "|    time_elapsed         | 32079        |\n",
      "|    total_timesteps      | 3487744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045634354 |\n",
      "|    clip_fraction        | 0.00796      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 17020        |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    reward               | 0.62498355   |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1704         |\n",
      "|    time_elapsed         | 32096        |\n",
      "|    total_timesteps      | 3489792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012591556 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.37         |\n",
      "|    n_updates            | 17030        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | 0.6289565    |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1705         |\n",
      "|    time_elapsed         | 32113        |\n",
      "|    total_timesteps      | 3491840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011801559 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 17040        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 4.5736666    |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 49.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1706         |\n",
      "|    time_elapsed         | 32130        |\n",
      "|    total_timesteps      | 3493888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006776061 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 17050        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | -0.339993    |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 1707       |\n",
      "|    time_elapsed         | 32147      |\n",
      "|    total_timesteps      | 3495936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00773743 |\n",
      "|    clip_fraction        | 0.0311     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -120       |\n",
      "|    explained_variance   | 0.439      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.51       |\n",
      "|    n_updates            | 17060      |\n",
      "|    policy_gradient_loss | -0.00744   |\n",
      "|    reward               | -1.4281144 |\n",
      "|    std                  | 15.8       |\n",
      "|    value_loss           | 18.6       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3923079.80\n",
      "total_reward: 2923079.80\n",
      "total_cost: 173035.97\n",
      "total_trades: 62565\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1708         |\n",
      "|    time_elapsed         | 32164        |\n",
      "|    total_timesteps      | 3497984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016908866 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 17070        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | -4.5044994   |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 49.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1709         |\n",
      "|    time_elapsed         | 32181        |\n",
      "|    total_timesteps      | 3500032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017649241 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 17080        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | 3.286883     |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 61.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1710        |\n",
      "|    time_elapsed         | 32198       |\n",
      "|    total_timesteps      | 3502080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006581134 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 17090       |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | -1.3976104  |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1711         |\n",
      "|    time_elapsed         | 32215        |\n",
      "|    total_timesteps      | 3504128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068577635 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.29         |\n",
      "|    n_updates            | 17100        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | -0.5429301   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1712         |\n",
      "|    time_elapsed         | 32232        |\n",
      "|    total_timesteps      | 3506176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044363667 |\n",
      "|    clip_fraction        | 0.00928      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 17110        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    reward               | -0.8231205   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1713         |\n",
      "|    time_elapsed         | 32249        |\n",
      "|    total_timesteps      | 3508224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030292454 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.168        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.5         |\n",
      "|    n_updates            | 17120        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -2.160019    |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 49.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1714        |\n",
      "|    time_elapsed         | 32265       |\n",
      "|    total_timesteps      | 3510272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009629881 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 17130       |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    reward               | 0.28760824  |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1715        |\n",
      "|    time_elapsed         | 32282       |\n",
      "|    total_timesteps      | 3512320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005577271 |\n",
      "|    clip_fraction        | 0.0217      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 17140       |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    reward               | -1.2189399  |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1716        |\n",
      "|    time_elapsed         | 32299       |\n",
      "|    total_timesteps      | 3514368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001584546 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 17150       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    reward               | 2.1870883   |\n",
      "|    std                  | 16          |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1717        |\n",
      "|    time_elapsed         | 32316       |\n",
      "|    total_timesteps      | 3516416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008473425 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 17160       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.43281406 |\n",
      "|    std                  | 16          |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1718         |\n",
      "|    time_elapsed         | 32333        |\n",
      "|    total_timesteps      | 3518464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028710961 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 17170        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 0.91693056   |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1719         |\n",
      "|    time_elapsed         | 32350        |\n",
      "|    total_timesteps      | 3520512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019157546 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 17180        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | 2.7187912    |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 44.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1720        |\n",
      "|    time_elapsed         | 32367       |\n",
      "|    total_timesteps      | 3522560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003699784 |\n",
      "|    clip_fraction        | 0.00488     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 17190       |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | 0.65043944  |\n",
      "|    std                  | 16          |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1721        |\n",
      "|    time_elapsed         | 32384       |\n",
      "|    total_timesteps      | 3524608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005597009 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 17200       |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | -0.5421891  |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3400606.69\n",
      "total_reward: 2400606.69\n",
      "total_cost: 181515.65\n",
      "total_trades: 63400\n",
      "Sharpe: 0.680\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1722         |\n",
      "|    time_elapsed         | 32401        |\n",
      "|    total_timesteps      | 3526656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054756594 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 17210        |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    reward               | 0.3350025    |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1723        |\n",
      "|    time_elapsed         | 32418       |\n",
      "|    total_timesteps      | 3528704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002797681 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 17220       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    reward               | -1.9975287  |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1724        |\n",
      "|    time_elapsed         | 32435       |\n",
      "|    total_timesteps      | 3530752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011546971 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.67        |\n",
      "|    n_updates            | 17230       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -0.6153477  |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1725         |\n",
      "|    time_elapsed         | 32452        |\n",
      "|    total_timesteps      | 3532800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025630798 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 17240        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    reward               | 0.13619526   |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1726        |\n",
      "|    time_elapsed         | 32469       |\n",
      "|    total_timesteps      | 3534848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007079547 |\n",
      "|    clip_fraction        | 0.0314      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 17250       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | -0.5631426  |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1727        |\n",
      "|    time_elapsed         | 32486       |\n",
      "|    total_timesteps      | 3536896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007629834 |\n",
      "|    clip_fraction        | 0.041       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 17260       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | -2.5971663  |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1728        |\n",
      "|    time_elapsed         | 32503       |\n",
      "|    total_timesteps      | 3538944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009037886 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 17270       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.28012833  |\n",
      "|    std                  | 16.3        |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1729         |\n",
      "|    time_elapsed         | 32520        |\n",
      "|    total_timesteps      | 3540992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029369052 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 17280        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | 2.8558831    |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1730         |\n",
      "|    time_elapsed         | 32537        |\n",
      "|    total_timesteps      | 3543040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021485342 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 17290        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | -5.243845    |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1731        |\n",
      "|    time_elapsed         | 32554       |\n",
      "|    total_timesteps      | 3545088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012033885 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.9         |\n",
      "|    n_updates            | 17300       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | -0.75452197 |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1732        |\n",
      "|    time_elapsed         | 32571       |\n",
      "|    total_timesteps      | 3547136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005427778 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 17310       |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    reward               | 0.6046355   |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1733         |\n",
      "|    time_elapsed         | 32588        |\n",
      "|    total_timesteps      | 3549184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015157564 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.1         |\n",
      "|    n_updates            | 17320        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | -0.26628903  |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 45.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1734         |\n",
      "|    time_elapsed         | 32605        |\n",
      "|    total_timesteps      | 3551232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062250886 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 17330        |\n",
      "|    policy_gradient_loss | -0.00836     |\n",
      "|    reward               | -0.2557182   |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1735         |\n",
      "|    time_elapsed         | 32622        |\n",
      "|    total_timesteps      | 3553280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031484594 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.54         |\n",
      "|    n_updates            | 17340        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -1.0093122   |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1736        |\n",
      "|    time_elapsed         | 32639       |\n",
      "|    total_timesteps      | 3555328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002049963 |\n",
      "|    clip_fraction        | 0.00229     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 17350       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | -6.4749274  |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3204639.30\n",
      "total_reward: 2204639.30\n",
      "total_cost: 95442.37\n",
      "total_trades: 56640\n",
      "Sharpe: 0.632\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1737        |\n",
      "|    time_elapsed         | 32656       |\n",
      "|    total_timesteps      | 3557376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007387367 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 17360       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | 0.7768538   |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1738        |\n",
      "|    time_elapsed         | 32673       |\n",
      "|    total_timesteps      | 3559424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007857087 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 17370       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    reward               | 0.27559412  |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1739         |\n",
      "|    time_elapsed         | 32690        |\n",
      "|    total_timesteps      | 3561472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040384107 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 17380        |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    reward               | 0.18944983   |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 1740          |\n",
      "|    time_elapsed         | 32707         |\n",
      "|    total_timesteps      | 3563520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030849708 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.563         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.5          |\n",
      "|    n_updates            | 17390         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | 0.017278532   |\n",
      "|    std                  | 16.6          |\n",
      "|    value_loss           | 34.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 1741        |\n",
      "|    time_elapsed         | 32724       |\n",
      "|    total_timesteps      | 3565568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005318003 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.23        |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 0.42168528  |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1742         |\n",
      "|    time_elapsed         | 32741        |\n",
      "|    total_timesteps      | 3567616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028354153 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 17410        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | -0.94308144  |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1743         |\n",
      "|    time_elapsed         | 32758        |\n",
      "|    total_timesteps      | 3569664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031684402 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 17420        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | -6.788337    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1744         |\n",
      "|    time_elapsed         | 32775        |\n",
      "|    total_timesteps      | 3571712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035684342 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 17430        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    reward               | -1.534954    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1745         |\n",
      "|    time_elapsed         | 32792        |\n",
      "|    total_timesteps      | 3573760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031407177 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 17440        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | -0.12299414  |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1746         |\n",
      "|    time_elapsed         | 32809        |\n",
      "|    total_timesteps      | 3575808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045397696 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.8         |\n",
      "|    n_updates            | 17450        |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    reward               | 0.650018     |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1747         |\n",
      "|    time_elapsed         | 32826        |\n",
      "|    total_timesteps      | 3577856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064765494 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 17460        |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    reward               | 6.9837685    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 1748         |\n",
      "|    time_elapsed         | 32844        |\n",
      "|    total_timesteps      | 3579904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064885253 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.01         |\n",
      "|    n_updates            | 17470        |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    reward               | 0.5063466    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 20.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1749         |\n",
      "|    time_elapsed         | 32861        |\n",
      "|    total_timesteps      | 3581952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033472115 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 17480        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | -0.046139773 |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1750        |\n",
      "|    time_elapsed         | 32878       |\n",
      "|    total_timesteps      | 3584000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003272121 |\n",
      "|    clip_fraction        | 0.00327     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 17490       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -1.2620032  |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3351060.81\n",
      "total_reward: 2351060.81\n",
      "total_cost: 101465.34\n",
      "total_trades: 57902\n",
      "Sharpe: 0.654\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1751        |\n",
      "|    time_elapsed         | 32895       |\n",
      "|    total_timesteps      | 3586048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009499187 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -1.5444926  |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 1752       |\n",
      "|    time_elapsed         | 32912      |\n",
      "|    total_timesteps      | 3588096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00614517 |\n",
      "|    clip_fraction        | 0.0283     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -122       |\n",
      "|    explained_variance   | 0.51       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.7       |\n",
      "|    n_updates            | 17510      |\n",
      "|    policy_gradient_loss | -0.00823   |\n",
      "|    reward               | 0.97153723 |\n",
      "|    std                  | 16.9       |\n",
      "|    value_loss           | 32.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1753         |\n",
      "|    time_elapsed         | 32929        |\n",
      "|    total_timesteps      | 3590144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028346907 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 17520        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | 2.4074872    |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 48.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1754        |\n",
      "|    time_elapsed         | 32946       |\n",
      "|    total_timesteps      | 3592192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003198931 |\n",
      "|    clip_fraction        | 0.00283     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 17530       |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | 0.7955398   |\n",
      "|    std                  | 16.9        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 1755       |\n",
      "|    time_elapsed         | 32963      |\n",
      "|    total_timesteps      | 3594240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00789769 |\n",
      "|    clip_fraction        | 0.0418     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -122       |\n",
      "|    explained_variance   | 0.511      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.2       |\n",
      "|    n_updates            | 17540      |\n",
      "|    policy_gradient_loss | -0.00897   |\n",
      "|    reward               | 1.8926722  |\n",
      "|    std                  | 17         |\n",
      "|    value_loss           | 21.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1756         |\n",
      "|    time_elapsed         | 32980        |\n",
      "|    total_timesteps      | 3596288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025568428 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 17550        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 0.45558137   |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 39.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1757         |\n",
      "|    time_elapsed         | 32997        |\n",
      "|    total_timesteps      | 3598336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040070973 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 17560        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 2.3875694    |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 51.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1758        |\n",
      "|    time_elapsed         | 33014       |\n",
      "|    total_timesteps      | 3600384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005247703 |\n",
      "|    clip_fraction        | 0.00894     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 17570       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | -1.152219   |\n",
      "|    std                  | 17.1        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1759         |\n",
      "|    time_elapsed         | 33031        |\n",
      "|    total_timesteps      | 3602432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029699907 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.87         |\n",
      "|    n_updates            | 17580        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | -0.66473836  |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1760         |\n",
      "|    time_elapsed         | 33048        |\n",
      "|    total_timesteps      | 3604480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051422752 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 17590        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    reward               | 1.691911     |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1761         |\n",
      "|    time_elapsed         | 33065        |\n",
      "|    total_timesteps      | 3606528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024161946 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 17600        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | -0.43511805  |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1762        |\n",
      "|    time_elapsed         | 33082       |\n",
      "|    total_timesteps      | 3608576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004258096 |\n",
      "|    clip_fraction        | 0.00742     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 17610       |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | 1.2388427   |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 1763       |\n",
      "|    time_elapsed         | 33099      |\n",
      "|    total_timesteps      | 3610624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00211082 |\n",
      "|    clip_fraction        | 0.00112    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -123       |\n",
      "|    explained_variance   | 0.696      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 17620      |\n",
      "|    policy_gradient_loss | -0.00491   |\n",
      "|    reward               | 0.97799516 |\n",
      "|    std                  | 17.2       |\n",
      "|    value_loss           | 34.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1764         |\n",
      "|    time_elapsed         | 33116        |\n",
      "|    total_timesteps      | 3612672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029993793 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 17630        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | 9.012457     |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3178153.94\n",
      "total_reward: 2178153.94\n",
      "total_cost: 97442.89\n",
      "total_trades: 57111\n",
      "Sharpe: 0.638\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1765        |\n",
      "|    time_elapsed         | 33133       |\n",
      "|    total_timesteps      | 3614720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007839693 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.89        |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | 1.2474811   |\n",
      "|    std                  | 17.3        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1766          |\n",
      "|    time_elapsed         | 33150         |\n",
      "|    total_timesteps      | 3616768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077122287 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.683         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.3          |\n",
      "|    n_updates            | 17650         |\n",
      "|    policy_gradient_loss | -0.00192      |\n",
      "|    reward               | 1.041823      |\n",
      "|    std                  | 17.3          |\n",
      "|    value_loss           | 34.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1767         |\n",
      "|    time_elapsed         | 33168        |\n",
      "|    total_timesteps      | 3618816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064098295 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 17660        |\n",
      "|    policy_gradient_loss | -0.00855     |\n",
      "|    reward               | 0.6475052    |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 51.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1768         |\n",
      "|    time_elapsed         | 33186        |\n",
      "|    total_timesteps      | 3620864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051254025 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 17670        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 1.05741      |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 52.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1769         |\n",
      "|    time_elapsed         | 33204        |\n",
      "|    total_timesteps      | 3622912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030892636 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 17680        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 0.6887384    |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1770         |\n",
      "|    time_elapsed         | 33222        |\n",
      "|    total_timesteps      | 3624960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008704319 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 17690        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 0.16714446   |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1771        |\n",
      "|    time_elapsed         | 33239       |\n",
      "|    total_timesteps      | 3627008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001819955 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 17700       |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | -0.7623644  |\n",
      "|    std                  | 17.3        |\n",
      "|    value_loss           | 49.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1772        |\n",
      "|    time_elapsed         | 33258       |\n",
      "|    total_timesteps      | 3629056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006272272 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.69        |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | 0.11301058  |\n",
      "|    std                  | 17.4        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1773         |\n",
      "|    time_elapsed         | 33275        |\n",
      "|    total_timesteps      | 3631104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020275502 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 17720        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | -2.2080812   |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1774        |\n",
      "|    time_elapsed         | 33292       |\n",
      "|    total_timesteps      | 3633152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000364912 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 17730       |\n",
      "|    policy_gradient_loss | -0.000835   |\n",
      "|    reward               | -1.9915032  |\n",
      "|    std                  | 17.4        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1775         |\n",
      "|    time_elapsed         | 33309        |\n",
      "|    total_timesteps      | 3635200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017950385 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 17740        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 1.4023641    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1776         |\n",
      "|    time_elapsed         | 33326        |\n",
      "|    total_timesteps      | 3637248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057688467 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 17750        |\n",
      "|    policy_gradient_loss | -0.00811     |\n",
      "|    reward               | -1.2240839   |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1777         |\n",
      "|    time_elapsed         | 33343        |\n",
      "|    total_timesteps      | 3639296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024452906 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 17760        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 0.4409339    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1778         |\n",
      "|    time_elapsed         | 33359        |\n",
      "|    total_timesteps      | 3641344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048272586 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 17770        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | 3.6105413    |\n",
      "|    std                  | 17.5         |\n",
      "|    value_loss           | 49.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3437325.17\n",
      "total_reward: 2437325.17\n",
      "total_cost: 114043.18\n",
      "total_trades: 58399\n",
      "Sharpe: 0.685\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1779         |\n",
      "|    time_elapsed         | 33378        |\n",
      "|    total_timesteps      | 3643392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070156455 |\n",
      "|    clip_fraction        | 0.0299       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 17780        |\n",
      "|    policy_gradient_loss | -0.0083      |\n",
      "|    reward               | 1.4290323    |\n",
      "|    std                  | 17.5         |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1780        |\n",
      "|    time_elapsed         | 33395       |\n",
      "|    total_timesteps      | 3645440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000301963 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 17790       |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    reward               | 0.1308705   |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1781         |\n",
      "|    time_elapsed         | 33412        |\n",
      "|    total_timesteps      | 3647488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032733942 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33           |\n",
      "|    n_updates            | 17800        |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    reward               | -3.338838    |\n",
      "|    std                  | 17.5         |\n",
      "|    value_loss           | 54.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1782        |\n",
      "|    time_elapsed         | 33429       |\n",
      "|    total_timesteps      | 3649536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008287342 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 17810       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | 0.43970305  |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1783         |\n",
      "|    time_elapsed         | 33446        |\n",
      "|    total_timesteps      | 3651584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045979056 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 17820        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    reward               | 0.9455131    |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1784         |\n",
      "|    time_elapsed         | 33463        |\n",
      "|    total_timesteps      | 3653632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051789917 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 17830        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    reward               | 2.82173      |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 55.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1785        |\n",
      "|    time_elapsed         | 33480       |\n",
      "|    total_timesteps      | 3655680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002835181 |\n",
      "|    clip_fraction        | 0.00127     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 17840       |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | 2.1077344   |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 1786       |\n",
      "|    time_elapsed         | 33497      |\n",
      "|    total_timesteps      | 3657728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00763914 |\n",
      "|    clip_fraction        | 0.0417     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -124       |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.39       |\n",
      "|    n_updates            | 17850      |\n",
      "|    policy_gradient_loss | -0.00974   |\n",
      "|    reward               | -1.2696055 |\n",
      "|    std                  | 17.7       |\n",
      "|    value_loss           | 30.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1787         |\n",
      "|    time_elapsed         | 33514        |\n",
      "|    total_timesteps      | 3659776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032056859 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 17860        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | 1.5907204    |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1788         |\n",
      "|    time_elapsed         | 33531        |\n",
      "|    total_timesteps      | 3661824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031311992 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 17870        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | 1.9009153    |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1789        |\n",
      "|    time_elapsed         | 33548       |\n",
      "|    total_timesteps      | 3663872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009911881 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.83934677  |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1790         |\n",
      "|    time_elapsed         | 33565        |\n",
      "|    total_timesteps      | 3665920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009934334 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 17890        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | 0.3572497    |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1791        |\n",
      "|    time_elapsed         | 33582       |\n",
      "|    total_timesteps      | 3667968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001163319 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 17900       |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    reward               | -5.7481604  |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1792         |\n",
      "|    time_elapsed         | 33599        |\n",
      "|    total_timesteps      | 3670016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018627483 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 17910        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | 0.26725584   |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3324849.53\n",
      "total_reward: 2324849.53\n",
      "total_cost: 92858.34\n",
      "total_trades: 56795\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1793        |\n",
      "|    time_elapsed         | 33616       |\n",
      "|    total_timesteps      | 3672064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004215085 |\n",
      "|    clip_fraction        | 0.00635     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 17920       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | -1.340319   |\n",
      "|    std                  | 17.9        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1794         |\n",
      "|    time_elapsed         | 33632        |\n",
      "|    total_timesteps      | 3674112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048506716 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 17930        |\n",
      "|    policy_gradient_loss | -0.00748     |\n",
      "|    reward               | -0.021248568 |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1795         |\n",
      "|    time_elapsed         | 33649        |\n",
      "|    total_timesteps      | 3676160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029268593 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.8         |\n",
      "|    n_updates            | 17940        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 2.7544978    |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1796        |\n",
      "|    time_elapsed         | 33666       |\n",
      "|    total_timesteps      | 3678208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008786692 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.8         |\n",
      "|    n_updates            | 17950       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 2.720749    |\n",
      "|    std                  | 18.1        |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1797         |\n",
      "|    time_elapsed         | 33683        |\n",
      "|    total_timesteps      | 3680256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015383186 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 17960        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | -0.23358703  |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1798         |\n",
      "|    time_elapsed         | 33700        |\n",
      "|    total_timesteps      | 3682304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013413281 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 17970        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | -0.35172507  |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 46.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1799        |\n",
      "|    time_elapsed         | 33717       |\n",
      "|    total_timesteps      | 3684352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005503651 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 17980       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | 4.4075594   |\n",
      "|    std                  | 18.1        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1800         |\n",
      "|    time_elapsed         | 33734        |\n",
      "|    total_timesteps      | 3686400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036037962 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 17990        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | 1.2323208    |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1801        |\n",
      "|    time_elapsed         | 33751       |\n",
      "|    total_timesteps      | 3688448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003045216 |\n",
      "|    clip_fraction        | 0.00586     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 18000       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -0.7087472  |\n",
      "|    std                  | 18.2        |\n",
      "|    value_loss           | 59.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1802         |\n",
      "|    time_elapsed         | 33768        |\n",
      "|    total_timesteps      | 3690496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004916993 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 18010        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | -4.877613    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1803        |\n",
      "|    time_elapsed         | 33785       |\n",
      "|    total_timesteps      | 3692544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005215224 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 18020       |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | -1.6715604  |\n",
      "|    std                  | 18.2        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1804        |\n",
      "|    time_elapsed         | 33802       |\n",
      "|    total_timesteps      | 3694592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00162142  |\n",
      "|    clip_fraction        | 0.000537    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 18030       |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    reward               | -0.36497572 |\n",
      "|    std                  | 18.2        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1805         |\n",
      "|    time_elapsed         | 33819        |\n",
      "|    total_timesteps      | 3696640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004490704 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 18040        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    reward               | 1.1203816    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 49.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1806         |\n",
      "|    time_elapsed         | 33836        |\n",
      "|    total_timesteps      | 3698688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066105993 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.14         |\n",
      "|    n_updates            | 18050        |\n",
      "|    policy_gradient_loss | -0.00683     |\n",
      "|    reward               | 0.095724545  |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2805661.27\n",
      "total_reward: 1805661.27\n",
      "total_cost: 129025.97\n",
      "total_trades: 59587\n",
      "Sharpe: 0.570\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1807         |\n",
      "|    time_elapsed         | 33852        |\n",
      "|    total_timesteps      | 3700736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026608917 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.71         |\n",
      "|    n_updates            | 18060        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -1.4953797   |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1808         |\n",
      "|    time_elapsed         | 33869        |\n",
      "|    total_timesteps      | 3702784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026874277 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 18070        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | -1.8637744   |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 40.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1809         |\n",
      "|    time_elapsed         | 33886        |\n",
      "|    total_timesteps      | 3704832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073235063 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.48         |\n",
      "|    n_updates            | 18080        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    reward               | 0.27531356   |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 28.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1810         |\n",
      "|    time_elapsed         | 33903        |\n",
      "|    total_timesteps      | 3706880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052828025 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 18090        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    reward               | 1.0432646    |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1811         |\n",
      "|    time_elapsed         | 33920        |\n",
      "|    total_timesteps      | 3708928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024016846 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 18100        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | 1.0066642    |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1812         |\n",
      "|    time_elapsed         | 33937        |\n",
      "|    total_timesteps      | 3710976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011701937 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 18110        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -0.94662213  |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1813         |\n",
      "|    time_elapsed         | 33954        |\n",
      "|    total_timesteps      | 3713024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085625425 |\n",
      "|    clip_fraction        | 0.0559       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.03         |\n",
      "|    n_updates            | 18120        |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    reward               | 0.8151717    |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 16.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1814        |\n",
      "|    time_elapsed         | 33971       |\n",
      "|    total_timesteps      | 3715072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001749464 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 18130       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    reward               | -0.29484144 |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1815        |\n",
      "|    time_elapsed         | 33989       |\n",
      "|    total_timesteps      | 3717120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002396206 |\n",
      "|    clip_fraction        | 0.00127     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 18140       |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    reward               | -1.936948   |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1816         |\n",
      "|    time_elapsed         | 34005        |\n",
      "|    total_timesteps      | 3719168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036163565 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 18150        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | 1.007436     |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1817         |\n",
      "|    time_elapsed         | 34022        |\n",
      "|    total_timesteps      | 3721216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023692106 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.48         |\n",
      "|    n_updates            | 18160        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | 0.7059394    |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1818         |\n",
      "|    time_elapsed         | 34039        |\n",
      "|    total_timesteps      | 3723264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009558912 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 18170        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | -2.2686374   |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1819        |\n",
      "|    time_elapsed         | 34056       |\n",
      "|    total_timesteps      | 3725312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002328015 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 18180       |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    reward               | -1.2188807  |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1820        |\n",
      "|    time_elapsed         | 34073       |\n",
      "|    total_timesteps      | 3727360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010791739 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.58        |\n",
      "|    n_updates            | 18190       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 0.13038483  |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2926144.48\n",
      "total_reward: 1926144.48\n",
      "total_cost: 178882.48\n",
      "total_trades: 62331\n",
      "Sharpe: 0.614\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1821         |\n",
      "|    time_elapsed         | 34090        |\n",
      "|    total_timesteps      | 3729408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046990355 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 18200        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | 0.41193455   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1822        |\n",
      "|    time_elapsed         | 34107       |\n",
      "|    total_timesteps      | 3731456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000482787 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 18210       |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    reward               | -1.1274067  |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1823         |\n",
      "|    time_elapsed         | 34124        |\n",
      "|    total_timesteps      | 3733504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060706106 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 18220        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    reward               | 0.09969408   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1824         |\n",
      "|    time_elapsed         | 34141        |\n",
      "|    total_timesteps      | 3735552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052150856 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 18230        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | 2.0385275    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1825         |\n",
      "|    time_elapsed         | 34158        |\n",
      "|    total_timesteps      | 3737600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017981867 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 18240        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | -3.1767943   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 57.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1826         |\n",
      "|    time_elapsed         | 34175        |\n",
      "|    total_timesteps      | 3739648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005306413 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.68         |\n",
      "|    n_updates            | 18250        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | 0.9650883    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1827        |\n",
      "|    time_elapsed         | 34192       |\n",
      "|    total_timesteps      | 3741696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005248928 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 18260       |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    reward               | 0.9038808   |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1828        |\n",
      "|    time_elapsed         | 34209       |\n",
      "|    total_timesteps      | 3743744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002584116 |\n",
      "|    clip_fraction        | 0.00439     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 18270       |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    reward               | -1.124229   |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1829         |\n",
      "|    time_elapsed         | 34226        |\n",
      "|    total_timesteps      | 3745792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014788352 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 18280        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -0.37416852  |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1830        |\n",
      "|    time_elapsed         | 34243       |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008316151 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.47        |\n",
      "|    n_updates            | 18290       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.8814456   |\n",
      "|    std                  | 18.6        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 1831       |\n",
      "|    time_elapsed         | 34260      |\n",
      "|    total_timesteps      | 3749888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0041368  |\n",
      "|    clip_fraction        | 0.0134     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -125       |\n",
      "|    explained_variance   | 0.556      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.2       |\n",
      "|    n_updates            | 18300      |\n",
      "|    policy_gradient_loss | -0.00614   |\n",
      "|    reward               | 0.76491636 |\n",
      "|    std                  | 18.6       |\n",
      "|    value_loss           | 29.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1832         |\n",
      "|    time_elapsed         | 34326        |\n",
      "|    total_timesteps      | 3751936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018080246 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 18310        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    reward               | -0.649394    |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1833         |\n",
      "|    time_elapsed         | 34343        |\n",
      "|    total_timesteps      | 3753984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056746416 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 18320        |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    reward               | 1.4388949    |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1834         |\n",
      "|    time_elapsed         | 34360        |\n",
      "|    total_timesteps      | 3756032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068297284 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 18330        |\n",
      "|    policy_gradient_loss | -0.00815     |\n",
      "|    reward               | -2.33946     |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2581951.97\n",
      "total_reward: 1581951.97\n",
      "total_cost: 251763.73\n",
      "total_trades: 65193\n",
      "Sharpe: 0.536\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1835         |\n",
      "|    time_elapsed         | 34376        |\n",
      "|    total_timesteps      | 3758080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045083477 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 18340        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -2.0657      |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1836          |\n",
      "|    time_elapsed         | 34393         |\n",
      "|    total_timesteps      | 3760128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096654805 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.634         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.6          |\n",
      "|    n_updates            | 18350         |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    reward               | 0.36304843    |\n",
      "|    std                  | 18.7          |\n",
      "|    value_loss           | 62.7          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 1837       |\n",
      "|    time_elapsed         | 34410      |\n",
      "|    total_timesteps      | 3762176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00922047 |\n",
      "|    clip_fraction        | 0.0581     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -125       |\n",
      "|    explained_variance   | 0.0947     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.14       |\n",
      "|    n_updates            | 18360      |\n",
      "|    policy_gradient_loss | -0.00946   |\n",
      "|    reward               | -6.803528  |\n",
      "|    std                  | 18.7       |\n",
      "|    value_loss           | 27.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1838         |\n",
      "|    time_elapsed         | 34427        |\n",
      "|    total_timesteps      | 3764224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037219478 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.8         |\n",
      "|    n_updates            | 18370        |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | 1.7989686    |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 87.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1839        |\n",
      "|    time_elapsed         | 34444       |\n",
      "|    total_timesteps      | 3766272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001673683 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 18380       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | 2.0971403   |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1840        |\n",
      "|    time_elapsed         | 34461       |\n",
      "|    total_timesteps      | 3768320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005991968 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 18390       |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    reward               | 1.8279078   |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1841        |\n",
      "|    time_elapsed         | 34478       |\n",
      "|    total_timesteps      | 3770368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005014032 |\n",
      "|    clip_fraction        | 0.00996     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 18400       |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    reward               | 0.37044245  |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 77.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1842         |\n",
      "|    time_elapsed         | 34495        |\n",
      "|    total_timesteps      | 3772416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013879575 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.7         |\n",
      "|    n_updates            | 18410        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | 1.3002837    |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 61.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1843         |\n",
      "|    time_elapsed         | 34512        |\n",
      "|    total_timesteps      | 3774464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009460343 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 18420        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    reward               | 0.63591665   |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 59.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1844        |\n",
      "|    time_elapsed         | 34529       |\n",
      "|    total_timesteps      | 3776512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007821851 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 18430       |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    reward               | 0.82122964  |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1845         |\n",
      "|    time_elapsed         | 34546        |\n",
      "|    total_timesteps      | 3778560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023611286 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 18440        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 0.31175172   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1846          |\n",
      "|    time_elapsed         | 34564         |\n",
      "|    total_timesteps      | 3780608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058030314 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.756         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.5          |\n",
      "|    n_updates            | 18450         |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    reward               | 3.0259898     |\n",
      "|    std                  | 18.9          |\n",
      "|    value_loss           | 57.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1847        |\n",
      "|    time_elapsed         | 34581       |\n",
      "|    total_timesteps      | 3782656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005115373 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 18460       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | -0.76709384 |\n",
      "|    std                  | 18.9        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1848        |\n",
      "|    time_elapsed         | 34598       |\n",
      "|    total_timesteps      | 3784704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004921103 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 18470       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | -0.7959843  |\n",
      "|    std                  | 18.9        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1849         |\n",
      "|    time_elapsed         | 34615        |\n",
      "|    total_timesteps      | 3786752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015154325 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42           |\n",
      "|    n_updates            | 18480        |\n",
      "|    policy_gradient_loss | -0.000692    |\n",
      "|    reward               | -0.6376175   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3155252.90\n",
      "total_reward: 2155252.90\n",
      "total_cost: 289978.08\n",
      "total_trades: 67142\n",
      "Sharpe: 0.624\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1850         |\n",
      "|    time_elapsed         | 34632        |\n",
      "|    total_timesteps      | 3788800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044658715 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.108        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 18490        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    reward               | 0.96940696   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1851         |\n",
      "|    time_elapsed         | 34649        |\n",
      "|    total_timesteps      | 3790848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050114826 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 18500        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 0.28561905   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 78           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1852         |\n",
      "|    time_elapsed         | 34665        |\n",
      "|    total_timesteps      | 3792896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014593198 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.7         |\n",
      "|    n_updates            | 18510        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | 0.91877484   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 71.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1853         |\n",
      "|    time_elapsed         | 34684        |\n",
      "|    total_timesteps      | 3794944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034467145 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 18520        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | -3.4431539   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 58.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1854         |\n",
      "|    time_elapsed         | 34702        |\n",
      "|    total_timesteps      | 3796992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050566164 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 18530        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    reward               | 0.37557632   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1855         |\n",
      "|    time_elapsed         | 34719        |\n",
      "|    total_timesteps      | 3799040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014011803 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.4         |\n",
      "|    n_updates            | 18540        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | 0.027190622  |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1856         |\n",
      "|    time_elapsed         | 34736        |\n",
      "|    total_timesteps      | 3801088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003793612 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 18550        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    reward               | -0.36364248  |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 78.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1857         |\n",
      "|    time_elapsed         | 34753        |\n",
      "|    total_timesteps      | 3803136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011557078 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 18560        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | 0.11933604   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 57.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1858         |\n",
      "|    time_elapsed         | 34770        |\n",
      "|    total_timesteps      | 3805184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032336507 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.1         |\n",
      "|    n_updates            | 18570        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | 1.9659054    |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 55.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1859         |\n",
      "|    time_elapsed         | 34787        |\n",
      "|    total_timesteps      | 3807232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077168224 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 18580        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    reward               | -0.5346386   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 59.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1860         |\n",
      "|    time_elapsed         | 34804        |\n",
      "|    total_timesteps      | 3809280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002757309 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.5         |\n",
      "|    n_updates            | 18590        |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    reward               | 0.26044187   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1861        |\n",
      "|    time_elapsed         | 34821       |\n",
      "|    total_timesteps      | 3811328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010456446 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.86        |\n",
      "|    n_updates            | 18600       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 1.1718249   |\n",
      "|    std                  | 19.1        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1862         |\n",
      "|    time_elapsed         | 34838        |\n",
      "|    total_timesteps      | 3813376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017998673 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42           |\n",
      "|    n_updates            | 18610        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | 0.7672942    |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 87.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1863          |\n",
      "|    time_elapsed         | 34855         |\n",
      "|    total_timesteps      | 3815424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017667588 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.724         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 41.9          |\n",
      "|    n_updates            | 18620         |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    reward               | 1.1952735     |\n",
      "|    std                  | 19.1          |\n",
      "|    value_loss           | 90.4          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3078444.75\n",
      "total_reward: 2078444.75\n",
      "total_cost: 241622.80\n",
      "total_trades: 65326\n",
      "Sharpe: 0.591\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1864         |\n",
      "|    time_elapsed         | 34872        |\n",
      "|    total_timesteps      | 3817472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030336312 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 18630        |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    reward               | -0.5291023   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1865         |\n",
      "|    time_elapsed         | 34889        |\n",
      "|    total_timesteps      | 3819520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010606307 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.5         |\n",
      "|    n_updates            | 18640        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 0.39202812   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 80           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1866          |\n",
      "|    time_elapsed         | 34907         |\n",
      "|    total_timesteps      | 3821568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021601742 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.726         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.5          |\n",
      "|    n_updates            | 18650         |\n",
      "|    policy_gradient_loss | -0.000911     |\n",
      "|    reward               | 10.411996     |\n",
      "|    std                  | 19.2          |\n",
      "|    value_loss           | 87.4          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 1867       |\n",
      "|    time_elapsed         | 34923      |\n",
      "|    total_timesteps      | 3823616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00232931 |\n",
      "|    clip_fraction        | 0.000732   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -126       |\n",
      "|    explained_variance   | 0.507      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.2       |\n",
      "|    n_updates            | 18660      |\n",
      "|    policy_gradient_loss | -0.00366   |\n",
      "|    reward               | 1.3375715  |\n",
      "|    std                  | 19.2       |\n",
      "|    value_loss           | 51         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1868         |\n",
      "|    time_elapsed         | 34940        |\n",
      "|    total_timesteps      | 3825664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046099033 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 18670        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 2.7582774    |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1869         |\n",
      "|    time_elapsed         | 34958        |\n",
      "|    total_timesteps      | 3827712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017128994 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.2         |\n",
      "|    n_updates            | 18680        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | -0.4885461   |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 69           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1870         |\n",
      "|    time_elapsed         | 34976        |\n",
      "|    total_timesteps      | 3829760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018208001 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 18690        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | -6.1011195   |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 93.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1871        |\n",
      "|    time_elapsed         | 34993       |\n",
      "|    total_timesteps      | 3831808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003146238 |\n",
      "|    clip_fraction        | 0.00537     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 18700       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | -0.81164086 |\n",
      "|    std                  | 19.3        |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1872        |\n",
      "|    time_elapsed         | 35010       |\n",
      "|    total_timesteps      | 3833856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006084299 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.5        |\n",
      "|    n_updates            | 18710       |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | 0.18546373  |\n",
      "|    std                  | 19.3        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1873         |\n",
      "|    time_elapsed         | 35027        |\n",
      "|    total_timesteps      | 3835904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006232083 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.6         |\n",
      "|    n_updates            | 18720        |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    reward               | 5.602736     |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 90.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1874         |\n",
      "|    time_elapsed         | 35045        |\n",
      "|    total_timesteps      | 3837952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060845455 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 18730        |\n",
      "|    policy_gradient_loss | -0.00698     |\n",
      "|    reward               | 4.942926     |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 47.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1875         |\n",
      "|    time_elapsed         | 35062        |\n",
      "|    total_timesteps      | 3840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024335557 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 18740        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | 0.87003523   |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 64.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1876        |\n",
      "|    time_elapsed         | 35079       |\n",
      "|    total_timesteps      | 3842048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000862273 |\n",
      "|    clip_fraction        | 0.000244    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.7        |\n",
      "|    n_updates            | 18750       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    reward               | 0.42770007  |\n",
      "|    std                  | 19.4        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1877         |\n",
      "|    time_elapsed         | 35095        |\n",
      "|    total_timesteps      | 3844096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018862081 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.5         |\n",
      "|    n_updates            | 18760        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | 0.26547167   |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 99.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2396519.15\n",
      "total_reward: 1396519.15\n",
      "total_cost: 245110.52\n",
      "total_trades: 65159\n",
      "Sharpe: 0.482\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1878         |\n",
      "|    time_elapsed         | 35113        |\n",
      "|    total_timesteps      | 3846144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062626023 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.16         |\n",
      "|    n_updates            | 18770        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    reward               | 1.2332014    |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1879         |\n",
      "|    time_elapsed         | 35130        |\n",
      "|    total_timesteps      | 3848192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018502453 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 18780        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -0.16626021  |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 72.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1880         |\n",
      "|    time_elapsed         | 35148        |\n",
      "|    total_timesteps      | 3850240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005502107 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.1         |\n",
      "|    n_updates            | 18790        |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    reward               | -0.75703883  |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1881         |\n",
      "|    time_elapsed         | 35165        |\n",
      "|    total_timesteps      | 3852288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026299078 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 18800        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    reward               | 1.5448785    |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 53.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1882         |\n",
      "|    time_elapsed         | 35182        |\n",
      "|    total_timesteps      | 3854336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028487092 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.6         |\n",
      "|    n_updates            | 18810        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | -4.220463    |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1883          |\n",
      "|    time_elapsed         | 35199         |\n",
      "|    total_timesteps      | 3856384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067371386 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.763         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 126           |\n",
      "|    n_updates            | 18820         |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    reward               | 0.013926798   |\n",
      "|    std                  | 19.5          |\n",
      "|    value_loss           | 157           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1884          |\n",
      "|    time_elapsed         | 35217         |\n",
      "|    total_timesteps      | 3858432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.001066468   |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.736         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.6          |\n",
      "|    n_updates            | 18830         |\n",
      "|    policy_gradient_loss | -0.00221      |\n",
      "|    reward               | -0.0152541995 |\n",
      "|    std                  | 19.5          |\n",
      "|    value_loss           | 140           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1885         |\n",
      "|    time_elapsed         | 35234        |\n",
      "|    total_timesteps      | 3860480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061083296 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.0955       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 18840        |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    reward               | -0.17521739  |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1886         |\n",
      "|    time_elapsed         | 35252        |\n",
      "|    total_timesteps      | 3862528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023052779 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.1         |\n",
      "|    n_updates            | 18850        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | -0.6069263   |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1887         |\n",
      "|    time_elapsed         | 35269        |\n",
      "|    total_timesteps      | 3864576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025537983 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 18860        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | -5.966536    |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 74.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1888         |\n",
      "|    time_elapsed         | 35286        |\n",
      "|    total_timesteps      | 3866624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011423326 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 18870        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | 0.8295235    |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1889        |\n",
      "|    time_elapsed         | 35304       |\n",
      "|    total_timesteps      | 3868672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002602701 |\n",
      "|    clip_fraction        | 0.00244     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 18880       |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | -0.5452494  |\n",
      "|    std                  | 19.6        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1890          |\n",
      "|    time_elapsed         | 35321         |\n",
      "|    total_timesteps      | 3870720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021534768 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.742         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 47            |\n",
      "|    n_updates            | 18890         |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    reward               | -2.9774156    |\n",
      "|    std                  | 19.7          |\n",
      "|    value_loss           | 98.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1891         |\n",
      "|    time_elapsed         | 35338        |\n",
      "|    total_timesteps      | 3872768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016614767 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.9         |\n",
      "|    n_updates            | 18900        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | 1.2315958    |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 87.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3135658.00\n",
      "total_reward: 2135658.00\n",
      "total_cost: 250587.54\n",
      "total_trades: 65497\n",
      "Sharpe: 0.581\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1892         |\n",
      "|    time_elapsed         | 35355        |\n",
      "|    total_timesteps      | 3874816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042962865 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.3         |\n",
      "|    n_updates            | 18910        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | 2.1062305    |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 72.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1893          |\n",
      "|    time_elapsed         | 35372         |\n",
      "|    total_timesteps      | 3876864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066316687 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.801         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 62.3          |\n",
      "|    n_updates            | 18920         |\n",
      "|    policy_gradient_loss | -0.00215      |\n",
      "|    reward               | 0.69843215    |\n",
      "|    std                  | 19.7          |\n",
      "|    value_loss           | 117           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1894          |\n",
      "|    time_elapsed         | 35390         |\n",
      "|    total_timesteps      | 3878912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032844537 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.754         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 50.4          |\n",
      "|    n_updates            | 18930         |\n",
      "|    policy_gradient_loss | -0.00129      |\n",
      "|    reward               | 3.610134      |\n",
      "|    std                  | 19.7          |\n",
      "|    value_loss           | 128           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1895         |\n",
      "|    time_elapsed         | 35407        |\n",
      "|    total_timesteps      | 3880960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036080538 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 18940        |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | -1.7911144   |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1896         |\n",
      "|    time_elapsed         | 35425        |\n",
      "|    total_timesteps      | 3883008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015626209 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.838        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 18950        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    reward               | -0.13923448  |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 64.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1897         |\n",
      "|    time_elapsed         | 35442        |\n",
      "|    total_timesteps      | 3885056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016891944 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.6         |\n",
      "|    n_updates            | 18960        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -2.7578895   |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1898         |\n",
      "|    time_elapsed         | 35459        |\n",
      "|    total_timesteps      | 3887104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019331295 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.1         |\n",
      "|    n_updates            | 18970        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 3.7409177    |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 57.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1899         |\n",
      "|    time_elapsed         | 35476        |\n",
      "|    total_timesteps      | 3889152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037009672 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.7         |\n",
      "|    n_updates            | 18980        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    reward               | -3.5562527   |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 86.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1900         |\n",
      "|    time_elapsed         | 35493        |\n",
      "|    total_timesteps      | 3891200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004285268 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.9         |\n",
      "|    n_updates            | 18990        |\n",
      "|    policy_gradient_loss | -0.000946    |\n",
      "|    reward               | 0.34688726   |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 94.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1901          |\n",
      "|    time_elapsed         | 35511         |\n",
      "|    total_timesteps      | 3893248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062022114 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.797         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 62.7          |\n",
      "|    n_updates            | 19000         |\n",
      "|    policy_gradient_loss | -0.000405     |\n",
      "|    reward               | -3.3895166    |\n",
      "|    std                  | 19.8          |\n",
      "|    value_loss           | 140           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1902        |\n",
      "|    time_elapsed         | 35528       |\n",
      "|    total_timesteps      | 3895296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008789056 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 19010       |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    reward               | 2.0340092   |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1903          |\n",
      "|    time_elapsed         | 35545         |\n",
      "|    total_timesteps      | 3897344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063902227 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.748         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 59            |\n",
      "|    n_updates            | 19020         |\n",
      "|    policy_gradient_loss | -0.00109      |\n",
      "|    reward               | -0.0836816    |\n",
      "|    std                  | 19.9          |\n",
      "|    value_loss           | 115           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1904          |\n",
      "|    time_elapsed         | 35562         |\n",
      "|    total_timesteps      | 3899392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034348152 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.766         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 63.7          |\n",
      "|    n_updates            | 19030         |\n",
      "|    policy_gradient_loss | -0.000899     |\n",
      "|    reward               | 3.6055913     |\n",
      "|    std                  | 19.9          |\n",
      "|    value_loss           | 121           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1905         |\n",
      "|    time_elapsed         | 35580        |\n",
      "|    total_timesteps      | 3901440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016585274 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 19040        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | -0.5682146   |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 54.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3007949.98\n",
      "total_reward: 2007949.98\n",
      "total_cost: 232376.12\n",
      "total_trades: 65585\n",
      "Sharpe: 0.571\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1906         |\n",
      "|    time_elapsed         | 35597        |\n",
      "|    total_timesteps      | 3903488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026143552 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 19050        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | 0.4911297    |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 70.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1907         |\n",
      "|    time_elapsed         | 35614        |\n",
      "|    total_timesteps      | 3905536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006538855 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.4         |\n",
      "|    n_updates            | 19060        |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    reward               | -31.724558   |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 84.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1908         |\n",
      "|    time_elapsed         | 35631        |\n",
      "|    total_timesteps      | 3907584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012479429 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.3         |\n",
      "|    n_updates            | 19070        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | 0.6022248    |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1909        |\n",
      "|    time_elapsed         | 35648       |\n",
      "|    total_timesteps      | 3909632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008171712 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 19080       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -1.0468146  |\n",
      "|    std                  | 20          |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1910         |\n",
      "|    time_elapsed         | 35665        |\n",
      "|    total_timesteps      | 3911680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025261808 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 19090        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | -0.28449294  |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 85.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1911          |\n",
      "|    time_elapsed         | 35682         |\n",
      "|    total_timesteps      | 3913728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043076382 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.786         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.2          |\n",
      "|    n_updates            | 19100         |\n",
      "|    policy_gradient_loss | -0.00193      |\n",
      "|    reward               | 2.0804923     |\n",
      "|    std                  | 20            |\n",
      "|    value_loss           | 78.5          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1912         |\n",
      "|    time_elapsed         | 35700        |\n",
      "|    total_timesteps      | 3915776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048396187 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 19110        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | -2.7712011   |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1913         |\n",
      "|    time_elapsed         | 35717        |\n",
      "|    total_timesteps      | 3917824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074406876 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.766        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 19120        |\n",
      "|    policy_gradient_loss | -0.00725     |\n",
      "|    reward               | 2.297181     |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 66.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1914          |\n",
      "|    time_elapsed         | 35734         |\n",
      "|    total_timesteps      | 3919872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069004553 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.74          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 48.2          |\n",
      "|    n_updates            | 19130         |\n",
      "|    policy_gradient_loss | -0.00183      |\n",
      "|    reward               | -2.2024698    |\n",
      "|    std                  | 20.1          |\n",
      "|    value_loss           | 85.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1915         |\n",
      "|    time_elapsed         | 35751        |\n",
      "|    total_timesteps      | 3921920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075735673 |\n",
      "|    clip_fraction        | 0.0604       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.6         |\n",
      "|    n_updates            | 19140        |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    reward               | -2.8715506   |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1916         |\n",
      "|    time_elapsed         | 35768        |\n",
      "|    total_timesteps      | 3923968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033628086 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 19150        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | -1.6431683   |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 78.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1917         |\n",
      "|    time_elapsed         | 35785        |\n",
      "|    total_timesteps      | 3926016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017633246 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 169          |\n",
      "|    n_updates            | 19160        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 1.6277831    |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 246          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1918          |\n",
      "|    time_elapsed         | 35802         |\n",
      "|    total_timesteps      | 3928064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062041346 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.461         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 73.8          |\n",
      "|    n_updates            | 19170         |\n",
      "|    policy_gradient_loss | -0.00283      |\n",
      "|    reward               | 0.34393105    |\n",
      "|    std                  | 20.3          |\n",
      "|    value_loss           | 183           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1919        |\n",
      "|    time_elapsed         | 35819       |\n",
      "|    total_timesteps      | 3930112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013172172 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 19180       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 0.8890582   |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2465420.77\n",
      "total_reward: 1465420.77\n",
      "total_cost: 240457.27\n",
      "total_trades: 65402\n",
      "Sharpe: 0.475\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1920         |\n",
      "|    time_elapsed         | 35836        |\n",
      "|    total_timesteps      | 3932160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008772566 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 19190        |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    reward               | -2.0187657   |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1921         |\n",
      "|    time_elapsed         | 35853        |\n",
      "|    total_timesteps      | 3934208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010644457 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39           |\n",
      "|    n_updates            | 19200        |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    reward               | 5.9090962    |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 93.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1922         |\n",
      "|    time_elapsed         | 35871        |\n",
      "|    total_timesteps      | 3936256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010098858 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.3         |\n",
      "|    n_updates            | 19210        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    reward               | -6.1264324   |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 81.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1923        |\n",
      "|    time_elapsed         | 35888       |\n",
      "|    total_timesteps      | 3938304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004287241 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 19220       |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | 0.1830856   |\n",
      "|    std                  | 20.5        |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1924        |\n",
      "|    time_elapsed         | 35905       |\n",
      "|    total_timesteps      | 3940352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002161528 |\n",
      "|    clip_fraction        | 0.00317     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 19230       |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    reward               | -1.5637438  |\n",
      "|    std                  | 20.5        |\n",
      "|    value_loss           | 77.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1925          |\n",
      "|    time_elapsed         | 35923         |\n",
      "|    total_timesteps      | 3942400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031691717 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.757         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 63            |\n",
      "|    n_updates            | 19240         |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    reward               | 0.7278547     |\n",
      "|    std                  | 20.5          |\n",
      "|    value_loss           | 122           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1926        |\n",
      "|    time_elapsed         | 35940       |\n",
      "|    total_timesteps      | 3944448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011544355 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 19250       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.13797477  |\n",
      "|    std                  | 20.5        |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1927         |\n",
      "|    time_elapsed         | 35957        |\n",
      "|    total_timesteps      | 3946496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003142916 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.1         |\n",
      "|    n_updates            | 19260        |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    reward               | -0.13908094  |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1928          |\n",
      "|    time_elapsed         | 35974         |\n",
      "|    total_timesteps      | 3948544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096423295 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.35          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 64.5          |\n",
      "|    n_updates            | 19270         |\n",
      "|    policy_gradient_loss | -0.00393      |\n",
      "|    reward               | 2.585163      |\n",
      "|    std                  | 20.5          |\n",
      "|    value_loss           | 180           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1929         |\n",
      "|    time_elapsed         | 35991        |\n",
      "|    total_timesteps      | 3950592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018396159 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.6         |\n",
      "|    n_updates            | 19280        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | 0.39773735   |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 66           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1930         |\n",
      "|    time_elapsed         | 36008        |\n",
      "|    total_timesteps      | 3952640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023776772 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34           |\n",
      "|    n_updates            | 19290        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | -0.41842696  |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 79.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1931          |\n",
      "|    time_elapsed         | 36025         |\n",
      "|    total_timesteps      | 3954688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026301443 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.81          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 53.1          |\n",
      "|    n_updates            | 19300         |\n",
      "|    policy_gradient_loss | -0.00176      |\n",
      "|    reward               | -9.810661     |\n",
      "|    std                  | 20.6          |\n",
      "|    value_loss           | 115           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1932         |\n",
      "|    time_elapsed         | 36043        |\n",
      "|    total_timesteps      | 3956736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007762455 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.6         |\n",
      "|    n_updates            | 19310        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | 1.6384054    |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 96.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1933        |\n",
      "|    time_elapsed         | 36060       |\n",
      "|    total_timesteps      | 3958784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010140143 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 19320       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | 0.8993664   |\n",
      "|    std                  | 20.7        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3081432.58\n",
      "total_reward: 2081432.58\n",
      "total_cost: 253950.84\n",
      "total_trades: 66395\n",
      "Sharpe: 0.586\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1934          |\n",
      "|    time_elapsed         | 36078         |\n",
      "|    total_timesteps      | 3960832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096597505 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.733         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 57.9          |\n",
      "|    n_updates            | 19330         |\n",
      "|    policy_gradient_loss | -0.00353      |\n",
      "|    reward               | 0.2330605     |\n",
      "|    std                  | 20.7          |\n",
      "|    value_loss           | 78.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1935         |\n",
      "|    time_elapsed         | 36096        |\n",
      "|    total_timesteps      | 3962880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027346394 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 19340        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | -1.3427755   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1936         |\n",
      "|    time_elapsed         | 36113        |\n",
      "|    total_timesteps      | 3964928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055442303 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 19350        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    reward               | -1.8897227   |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1937        |\n",
      "|    time_elapsed         | 36130       |\n",
      "|    total_timesteps      | 3966976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002280198 |\n",
      "|    clip_fraction        | 0.00127     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 19360       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -4.1253867  |\n",
      "|    std                  | 20.8        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1938         |\n",
      "|    time_elapsed         | 36148        |\n",
      "|    total_timesteps      | 3969024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040600225 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34           |\n",
      "|    n_updates            | 19370        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | -1.8704789   |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 78.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1939         |\n",
      "|    time_elapsed         | 36165        |\n",
      "|    total_timesteps      | 3971072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028943694 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.6         |\n",
      "|    n_updates            | 19380        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | 0.6513566    |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 71.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1940         |\n",
      "|    time_elapsed         | 36182        |\n",
      "|    total_timesteps      | 3973120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050795907 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.9         |\n",
      "|    n_updates            | 19390        |\n",
      "|    policy_gradient_loss | -0.00725     |\n",
      "|    reward               | -1.1454757   |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 58           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1941          |\n",
      "|    time_elapsed         | 36199         |\n",
      "|    total_timesteps      | 3975168       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041266752 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.74          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 37.6          |\n",
      "|    n_updates            | 19400         |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    reward               | -0.49546802   |\n",
      "|    std                  | 20.9          |\n",
      "|    value_loss           | 104           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1942         |\n",
      "|    time_elapsed         | 36217        |\n",
      "|    total_timesteps      | 3977216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023678062 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.4         |\n",
      "|    n_updates            | 19410        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | -0.27704823  |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 90           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1943        |\n",
      "|    time_elapsed         | 36234       |\n",
      "|    total_timesteps      | 3979264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007993304 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 19420       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -1.6600555  |\n",
      "|    std                  | 21          |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1944          |\n",
      "|    time_elapsed         | 36251         |\n",
      "|    total_timesteps      | 3981312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091032416 |\n",
      "|    clip_fraction        | 0.000684      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.818         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 49.1          |\n",
      "|    n_updates            | 19430         |\n",
      "|    policy_gradient_loss | -0.00193      |\n",
      "|    reward               | 0.68505365    |\n",
      "|    std                  | 21            |\n",
      "|    value_loss           | 78.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1945         |\n",
      "|    time_elapsed         | 36268        |\n",
      "|    total_timesteps      | 3983360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.418821e-05 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.6         |\n",
      "|    n_updates            | 19440        |\n",
      "|    policy_gradient_loss | -0.000549    |\n",
      "|    reward               | 2.6937032    |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1946         |\n",
      "|    time_elapsed         | 36285        |\n",
      "|    total_timesteps      | 3985408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026295641 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 19450        |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    reward               | 1.2054393    |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 57.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1947         |\n",
      "|    time_elapsed         | 36302        |\n",
      "|    total_timesteps      | 3987456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031207618 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.2         |\n",
      "|    n_updates            | 19460        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -0.4496589   |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 74           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2779721.07\n",
      "total_reward: 1779721.07\n",
      "total_cost: 242496.99\n",
      "total_trades: 65814\n",
      "Sharpe: 0.546\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1948          |\n",
      "|    time_elapsed         | 36319         |\n",
      "|    total_timesteps      | 3989504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027785948 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.632         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 60.1          |\n",
      "|    n_updates            | 19470         |\n",
      "|    policy_gradient_loss | -0.00151      |\n",
      "|    reward               | 0.72255       |\n",
      "|    std                  | 21.1          |\n",
      "|    value_loss           | 108           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1949         |\n",
      "|    time_elapsed         | 36336        |\n",
      "|    total_timesteps      | 3991552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002904866 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.6         |\n",
      "|    n_updates            | 19480        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    reward               | -0.3675509   |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1950         |\n",
      "|    time_elapsed         | 36354        |\n",
      "|    total_timesteps      | 3993600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076927515 |\n",
      "|    clip_fraction        | 0.0497       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 19490        |\n",
      "|    policy_gradient_loss | -0.00793     |\n",
      "|    reward               | -0.5635715   |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1951         |\n",
      "|    time_elapsed         | 36371        |\n",
      "|    total_timesteps      | 3995648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005603328 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 19500        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | -0.7804192   |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 78.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1952         |\n",
      "|    time_elapsed         | 36388        |\n",
      "|    total_timesteps      | 3997696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021463202 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.3         |\n",
      "|    n_updates            | 19510        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 0.04943012   |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 99.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1953         |\n",
      "|    time_elapsed         | 36405        |\n",
      "|    total_timesteps      | 3999744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040372033 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 19520        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    reward               | -1.513848    |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 52.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1954        |\n",
      "|    time_elapsed         | 36422       |\n",
      "|    total_timesteps      | 4001792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004618505 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 19530       |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | -1.0200096  |\n",
      "|    std                  | 21.2        |\n",
      "|    value_loss           | 74          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1955        |\n",
      "|    time_elapsed         | 36439       |\n",
      "|    total_timesteps      | 4003840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004036476 |\n",
      "|    clip_fraction        | 0.00898     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 19540       |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | 13.833243   |\n",
      "|    std                  | 21.2        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1956         |\n",
      "|    time_elapsed         | 36456        |\n",
      "|    total_timesteps      | 4005888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013117108 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.7         |\n",
      "|    n_updates            | 19550        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | 4.4420075    |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1957        |\n",
      "|    time_elapsed         | 36474       |\n",
      "|    total_timesteps      | 4007936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005998889 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 19560       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | -0.7723045  |\n",
      "|    std                  | 21.3        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1958         |\n",
      "|    time_elapsed         | 36491        |\n",
      "|    total_timesteps      | 4009984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013880208 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.2         |\n",
      "|    n_updates            | 19570        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | -0.7424001   |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 94.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1959         |\n",
      "|    time_elapsed         | 36509        |\n",
      "|    total_timesteps      | 4012032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017764309 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 19580        |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | -0.304556    |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 91.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1960        |\n",
      "|    time_elapsed         | 36526       |\n",
      "|    total_timesteps      | 4014080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006646661 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 19590       |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    reward               | 1.7456836   |\n",
      "|    std                  | 21.4        |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1961        |\n",
      "|    time_elapsed         | 36544       |\n",
      "|    total_timesteps      | 4016128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004188912 |\n",
      "|    clip_fraction        | 0.00737     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 19600       |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | -1.0888513  |\n",
      "|    std                  | 21.4        |\n",
      "|    value_loss           | 88.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1962         |\n",
      "|    time_elapsed         | 36561        |\n",
      "|    total_timesteps      | 4018176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014628991 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.277        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.1         |\n",
      "|    n_updates            | 19610        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | 0.68244624   |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2624336.10\n",
      "total_reward: 1624336.10\n",
      "total_cost: 257733.55\n",
      "total_trades: 66299\n",
      "Sharpe: 0.520\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1963         |\n",
      "|    time_elapsed         | 36578        |\n",
      "|    total_timesteps      | 4020224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008180843 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.7         |\n",
      "|    n_updates            | 19620        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | 1.9801975    |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 64.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1964         |\n",
      "|    time_elapsed         | 36595        |\n",
      "|    total_timesteps      | 4022272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054254867 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.3         |\n",
      "|    n_updates            | 19630        |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    reward               | -0.36578512  |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 88.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1965         |\n",
      "|    time_elapsed         | 36612        |\n",
      "|    total_timesteps      | 4024320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019350576 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.7         |\n",
      "|    n_updates            | 19640        |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    reward               | 0.8915277    |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 84.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1966          |\n",
      "|    time_elapsed         | 36630         |\n",
      "|    total_timesteps      | 4026368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046451832 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.635         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 73.1          |\n",
      "|    n_updates            | 19650         |\n",
      "|    policy_gradient_loss | -0.00136      |\n",
      "|    reward               | 0.65435874    |\n",
      "|    std                  | 21.6          |\n",
      "|    value_loss           | 111           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1967        |\n",
      "|    time_elapsed         | 36647       |\n",
      "|    total_timesteps      | 4028416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006645625 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 19660       |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | 0.5891871   |\n",
      "|    std                  | 21.7        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1968          |\n",
      "|    time_elapsed         | 36664         |\n",
      "|    total_timesteps      | 4030464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088412117 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.653         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.6          |\n",
      "|    n_updates            | 19670         |\n",
      "|    policy_gradient_loss | -0.00234      |\n",
      "|    reward               | -1.2084516    |\n",
      "|    std                  | 21.7          |\n",
      "|    value_loss           | 96.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1969         |\n",
      "|    time_elapsed         | 36681        |\n",
      "|    total_timesteps      | 4032512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013177774 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.843        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.6         |\n",
      "|    n_updates            | 19680        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    reward               | 1.0660838    |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1970        |\n",
      "|    time_elapsed         | 36698       |\n",
      "|    total_timesteps      | 4034560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008564112 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 19690       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.11274418 |\n",
      "|    std                  | 21.8        |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1971         |\n",
      "|    time_elapsed         | 36715        |\n",
      "|    total_timesteps      | 4036608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030916943 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.4         |\n",
      "|    n_updates            | 19700        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | -0.13759016  |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1972         |\n",
      "|    time_elapsed         | 36732        |\n",
      "|    total_timesteps      | 4038656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015219664 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.6         |\n",
      "|    n_updates            | 19710        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | 0.02758029   |\n",
      "|    std                  | 21.9         |\n",
      "|    value_loss           | 76.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1973         |\n",
      "|    time_elapsed         | 36749        |\n",
      "|    total_timesteps      | 4040704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034560338 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.6         |\n",
      "|    n_updates            | 19720        |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    reward               | 0.31169352   |\n",
      "|    std                  | 21.9         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1974        |\n",
      "|    time_elapsed         | 36766       |\n",
      "|    total_timesteps      | 4042752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007823866 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 19730       |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    reward               | 1.4749428   |\n",
      "|    std                  | 22          |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1975         |\n",
      "|    time_elapsed         | 36783        |\n",
      "|    total_timesteps      | 4044800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033100257 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 19740        |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    reward               | -2.7551372   |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 63.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1976          |\n",
      "|    time_elapsed         | 36801         |\n",
      "|    total_timesteps      | 4046848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082410604 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.396         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.1          |\n",
      "|    n_updates            | 19750         |\n",
      "|    policy_gradient_loss | -0.00227      |\n",
      "|    reward               | 1.0606408     |\n",
      "|    std                  | 22            |\n",
      "|    value_loss           | 95.6          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2624858.48\n",
      "total_reward: 1624858.48\n",
      "total_cost: 281647.21\n",
      "total_trades: 67728\n",
      "Sharpe: 0.523\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1977        |\n",
      "|    time_elapsed         | 36819       |\n",
      "|    total_timesteps      | 4048896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006252045 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 19760       |\n",
      "|    policy_gradient_loss | -0.00754    |\n",
      "|    reward               | 1.4196631   |\n",
      "|    std                  | 22.1        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1978         |\n",
      "|    time_elapsed         | 36836        |\n",
      "|    total_timesteps      | 4050944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029666498 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.4         |\n",
      "|    n_updates            | 19770        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | -2.4014194   |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 63.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1979        |\n",
      "|    time_elapsed         | 36853       |\n",
      "|    total_timesteps      | 4052992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001179141 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 19780       |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | 0.39540353  |\n",
      "|    std                  | 22.1        |\n",
      "|    value_loss           | 87.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1980         |\n",
      "|    time_elapsed         | 36871        |\n",
      "|    total_timesteps      | 4055040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011011267 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 19790        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | 1.1679001    |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 60.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1981         |\n",
      "|    time_elapsed         | 36888        |\n",
      "|    total_timesteps      | 4057088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074257688 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 19800        |\n",
      "|    policy_gradient_loss | -0.00975     |\n",
      "|    reward               | 0.6575011    |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 109          |\n",
      "|    iterations           | 1982         |\n",
      "|    time_elapsed         | 36905        |\n",
      "|    total_timesteps      | 4059136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009572187 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33           |\n",
      "|    n_updates            | 19810        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | 0.43893322   |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 74.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 109           |\n",
      "|    iterations           | 1983          |\n",
      "|    time_elapsed         | 36922         |\n",
      "|    total_timesteps      | 4061184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090928096 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.832         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 53.8          |\n",
      "|    n_updates            | 19820         |\n",
      "|    policy_gradient_loss | -0.00333      |\n",
      "|    reward               | -5.0170293    |\n",
      "|    std                  | 22.3          |\n",
      "|    value_loss           | 106           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 1984        |\n",
      "|    time_elapsed         | 36939       |\n",
      "|    total_timesteps      | 4063232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009014625 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 19830       |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    reward               | 6.5211716   |\n",
      "|    std                  | 22.3        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1985         |\n",
      "|    time_elapsed         | 36956        |\n",
      "|    total_timesteps      | 4065280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029342538 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.7         |\n",
      "|    n_updates            | 19840        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -0.10267236  |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1986         |\n",
      "|    time_elapsed         | 36974        |\n",
      "|    total_timesteps      | 4067328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018358221 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.0924       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 19850        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -0.15873756  |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1987         |\n",
      "|    time_elapsed         | 36990        |\n",
      "|    total_timesteps      | 4069376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008919205 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.6         |\n",
      "|    n_updates            | 19860        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | 1.9229807    |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 55.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1988        |\n",
      "|    time_elapsed         | 37008       |\n",
      "|    total_timesteps      | 4071424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004378953 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 19870       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 0.334336    |\n",
      "|    std                  | 22.3        |\n",
      "|    value_loss           | 62.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1989         |\n",
      "|    time_elapsed         | 37025        |\n",
      "|    total_timesteps      | 4073472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033569224 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.2         |\n",
      "|    n_updates            | 19880        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    reward               | 0.80587894   |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 76.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1990         |\n",
      "|    time_elapsed         | 37042        |\n",
      "|    total_timesteps      | 4075520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016742384 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.7         |\n",
      "|    n_updates            | 19890        |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | 1.1673825    |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 93.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2551134.54\n",
      "total_reward: 1551134.54\n",
      "total_cost: 287533.86\n",
      "total_trades: 67146\n",
      "Sharpe: 0.484\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 1991        |\n",
      "|    time_elapsed         | 37059       |\n",
      "|    total_timesteps      | 4077568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007356093 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.13        |\n",
      "|    n_updates            | 19900       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 2.6065962   |\n",
      "|    std                  | 22.4        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1992         |\n",
      "|    time_elapsed         | 37076        |\n",
      "|    total_timesteps      | 4079616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029887424 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.792        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 19910        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | 0.7172148    |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 75.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1993         |\n",
      "|    time_elapsed         | 37093        |\n",
      "|    total_timesteps      | 4081664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020892548 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56           |\n",
      "|    n_updates            | 19920        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | -0.74024093  |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1994         |\n",
      "|    time_elapsed         | 37111        |\n",
      "|    total_timesteps      | 4083712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019845653 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 19930        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | -4.365881    |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 65.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1995         |\n",
      "|    time_elapsed         | 37128        |\n",
      "|    total_timesteps      | 4085760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064228806 |\n",
      "|    clip_fraction        | 0.0299       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.851        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 19940        |\n",
      "|    policy_gradient_loss | -0.00875     |\n",
      "|    reward               | -0.80039495  |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 47.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1996         |\n",
      "|    time_elapsed         | 37145        |\n",
      "|    total_timesteps      | 4087808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014202865 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.8         |\n",
      "|    n_updates            | 19950        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | 4.1220593    |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 81.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 1997          |\n",
      "|    time_elapsed         | 37162         |\n",
      "|    total_timesteps      | 4089856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053642574 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.771         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.8          |\n",
      "|    n_updates            | 19960         |\n",
      "|    policy_gradient_loss | -0.00151      |\n",
      "|    reward               | 3.1754696     |\n",
      "|    std                  | 22.4          |\n",
      "|    value_loss           | 97.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1998         |\n",
      "|    time_elapsed         | 37179        |\n",
      "|    total_timesteps      | 4091904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057848953 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.87         |\n",
      "|    n_updates            | 19970        |\n",
      "|    policy_gradient_loss | -0.0075      |\n",
      "|    reward               | 1.5524732    |\n",
      "|    std                  | 22.5         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 1999         |\n",
      "|    time_elapsed         | 37197        |\n",
      "|    total_timesteps      | 4093952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016883023 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.2         |\n",
      "|    n_updates            | 19980        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -4.511912    |\n",
      "|    std                  | 22.5         |\n",
      "|    value_loss           | 71.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2000         |\n",
      "|    time_elapsed         | 37214        |\n",
      "|    total_timesteps      | 4096000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005975588 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.798        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.7         |\n",
      "|    n_updates            | 19990        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | 2.5547953    |\n",
      "|    std                  | 22.5         |\n",
      "|    value_loss           | 94.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2001        |\n",
      "|    time_elapsed         | 37231       |\n",
      "|    total_timesteps      | 4098048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010160843 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.59        |\n",
      "|    n_updates            | 20000       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.80242646 |\n",
      "|    std                  | 22.6        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2002        |\n",
      "|    time_elapsed         | 37248       |\n",
      "|    total_timesteps      | 4100096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003323427 |\n",
      "|    clip_fraction        | 0.00444     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 20010       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | 2.303033    |\n",
      "|    std                  | 22.6        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2003         |\n",
      "|    time_elapsed         | 37265        |\n",
      "|    total_timesteps      | 4102144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008757946 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.1         |\n",
      "|    n_updates            | 20020        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | 1.3853929    |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 94.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2004         |\n",
      "|    time_elapsed         | 37282        |\n",
      "|    total_timesteps      | 4104192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035214745 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 20030        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    reward               | -1.4696249   |\n",
      "|    std                  | 22.7         |\n",
      "|    value_loss           | 64.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5642543.61\n",
      "total_reward: 4642543.61\n",
      "total_cost: 280135.19\n",
      "total_trades: 67284\n",
      "Sharpe: 0.848\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2005        |\n",
      "|    time_elapsed         | 37300       |\n",
      "|    total_timesteps      | 4106240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008626204 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.3        |\n",
      "|    n_updates            | 20040       |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | 1.5912265   |\n",
      "|    std                  | 22.8        |\n",
      "|    value_loss           | 96.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2006         |\n",
      "|    time_elapsed         | 37317        |\n",
      "|    total_timesteps      | 4108288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038808393 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 20050        |\n",
      "|    policy_gradient_loss | -0.00825     |\n",
      "|    reward               | -1.2195029   |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2007        |\n",
      "|    time_elapsed         | 37334       |\n",
      "|    total_timesteps      | 4110336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003031375 |\n",
      "|    clip_fraction        | 0.0041      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.6        |\n",
      "|    n_updates            | 20060       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | -2.5884943  |\n",
      "|    std                  | 23          |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2008        |\n",
      "|    time_elapsed         | 37351       |\n",
      "|    total_timesteps      | 4112384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009585381 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 20070       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.6791453  |\n",
      "|    std                  | 23          |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2009         |\n",
      "|    time_elapsed         | 37369        |\n",
      "|    total_timesteps      | 4114432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018393202 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.2         |\n",
      "|    n_updates            | 20080        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -0.7652575   |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 86.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2010       |\n",
      "|    time_elapsed         | 37386      |\n",
      "|    total_timesteps      | 4116480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00220724 |\n",
      "|    clip_fraction        | 0.00107    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -131       |\n",
      "|    explained_variance   | 0.475      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.3       |\n",
      "|    n_updates            | 20090      |\n",
      "|    policy_gradient_loss | -0.00389   |\n",
      "|    reward               | 0.5759434  |\n",
      "|    std                  | 23.1       |\n",
      "|    value_loss           | 139        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2011        |\n",
      "|    time_elapsed         | 37403       |\n",
      "|    total_timesteps      | 4118528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003197033 |\n",
      "|    clip_fraction        | 0.00635     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 20100       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | -1.921729   |\n",
      "|    std                  | 23.1        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2012         |\n",
      "|    time_elapsed         | 37421        |\n",
      "|    total_timesteps      | 4120576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043753004 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 20110        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    reward               | 0.77171713   |\n",
      "|    std                  | 23.1         |\n",
      "|    value_loss           | 58           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2013         |\n",
      "|    time_elapsed         | 37438        |\n",
      "|    total_timesteps      | 4122624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014630784 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.3         |\n",
      "|    n_updates            | 20120        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | -1.4610841   |\n",
      "|    std                  | 23.1         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2014          |\n",
      "|    time_elapsed         | 37456         |\n",
      "|    total_timesteps      | 4124672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042185056 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.809         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.9          |\n",
      "|    n_updates            | 20130         |\n",
      "|    policy_gradient_loss | -0.00156      |\n",
      "|    reward               | 0.17110103    |\n",
      "|    std                  | 23.2          |\n",
      "|    value_loss           | 77.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2015         |\n",
      "|    time_elapsed         | 37474        |\n",
      "|    total_timesteps      | 4126720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111731365 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.0235       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 20140        |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    reward               | 0.18515329   |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2016          |\n",
      "|    time_elapsed         | 37492         |\n",
      "|    total_timesteps      | 4128768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092455774 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.432         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.4          |\n",
      "|    n_updates            | 20150         |\n",
      "|    policy_gradient_loss | -0.00366      |\n",
      "|    reward               | 0.31024545    |\n",
      "|    std                  | 23.3          |\n",
      "|    value_loss           | 135           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2017        |\n",
      "|    time_elapsed         | 37510       |\n",
      "|    total_timesteps      | 4130816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004265004 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.8        |\n",
      "|    n_updates            | 20160       |\n",
      "|    policy_gradient_loss | -0.000793   |\n",
      "|    reward               | -4.872775   |\n",
      "|    std                  | 23.3        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2018          |\n",
      "|    time_elapsed         | 37527         |\n",
      "|    total_timesteps      | 4132864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046530485 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.808         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18            |\n",
      "|    n_updates            | 20170         |\n",
      "|    policy_gradient_loss | -0.00124      |\n",
      "|    reward               | -1.381021     |\n",
      "|    std                  | 23.3          |\n",
      "|    value_loss           | 55            |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2985177.95\n",
      "total_reward: 1985177.95\n",
      "total_cost: 264022.79\n",
      "total_trades: 66357\n",
      "Sharpe: 0.552\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2019         |\n",
      "|    time_elapsed         | 37544        |\n",
      "|    total_timesteps      | 4134912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016526195 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 20180        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -1.3945642   |\n",
      "|    std                  | 23.4         |\n",
      "|    value_loss           | 56.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2020         |\n",
      "|    time_elapsed         | 37562        |\n",
      "|    total_timesteps      | 4136960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032528709 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.7         |\n",
      "|    n_updates            | 20190        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    reward               | -7.2148366   |\n",
      "|    std                  | 23.4         |\n",
      "|    value_loss           | 93.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2021          |\n",
      "|    time_elapsed         | 37579         |\n",
      "|    total_timesteps      | 4139008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085695274 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.822         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.1          |\n",
      "|    n_updates            | 20200         |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    reward               | -1.2803222    |\n",
      "|    std                  | 23.4          |\n",
      "|    value_loss           | 64            |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2022         |\n",
      "|    time_elapsed         | 37597        |\n",
      "|    total_timesteps      | 4141056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043664225 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 20210        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | -0.27654234  |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2023        |\n",
      "|    time_elapsed         | 37614       |\n",
      "|    total_timesteps      | 4143104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002349712 |\n",
      "|    clip_fraction        | 0.00391     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 20220       |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | 0.7187438   |\n",
      "|    std                  | 23.6        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2024          |\n",
      "|    time_elapsed         | 37631         |\n",
      "|    total_timesteps      | 4145152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053051923 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.723         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.2          |\n",
      "|    n_updates            | 20230         |\n",
      "|    policy_gradient_loss | -0.00249      |\n",
      "|    reward               | -0.5514575    |\n",
      "|    std                  | 23.6          |\n",
      "|    value_loss           | 77.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2025        |\n",
      "|    time_elapsed         | 37648       |\n",
      "|    total_timesteps      | 4147200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004341679 |\n",
      "|    clip_fraction        | 0.00791     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 20240       |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | 5.7341375   |\n",
      "|    std                  | 23.6        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2026          |\n",
      "|    time_elapsed         | 37666         |\n",
      "|    total_timesteps      | 4149248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095830054 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.834         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.9          |\n",
      "|    n_updates            | 20250         |\n",
      "|    policy_gradient_loss | -0.00211      |\n",
      "|    reward               | -6.344116     |\n",
      "|    std                  | 23.7          |\n",
      "|    value_loss           | 48.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2027          |\n",
      "|    time_elapsed         | 37683         |\n",
      "|    total_timesteps      | 4151296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092583895 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.811         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.4          |\n",
      "|    n_updates            | 20260         |\n",
      "|    policy_gradient_loss | -0.00226      |\n",
      "|    reward               | 0.30809185    |\n",
      "|    std                  | 23.7          |\n",
      "|    value_loss           | 64.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2028          |\n",
      "|    time_elapsed         | 37701         |\n",
      "|    total_timesteps      | 4153344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044427876 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.686         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23            |\n",
      "|    n_updates            | 20270         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | 2.030655      |\n",
      "|    std                  | 23.7          |\n",
      "|    value_loss           | 43.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2029         |\n",
      "|    time_elapsed         | 37718        |\n",
      "|    total_timesteps      | 4155392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025390927 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.833        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 20280        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 2.2994556    |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2030         |\n",
      "|    time_elapsed         | 37735        |\n",
      "|    total_timesteps      | 4157440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009675553 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 20290        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | -2.0827043   |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2031          |\n",
      "|    time_elapsed         | 37752         |\n",
      "|    total_timesteps      | 4159488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087713345 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.803         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.6          |\n",
      "|    n_updates            | 20300         |\n",
      "|    policy_gradient_loss | -0.00356      |\n",
      "|    reward               | -1.1133227    |\n",
      "|    std                  | 23.8          |\n",
      "|    value_loss           | 52.2          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2032         |\n",
      "|    time_elapsed         | 37770        |\n",
      "|    total_timesteps      | 4161536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066616004 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 20310        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    reward               | 0.5958629    |\n",
      "|    std                  | 23.9         |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2179583.06\n",
      "total_reward: 1179583.06\n",
      "total_cost: 250331.33\n",
      "total_trades: 66183\n",
      "Sharpe: 0.409\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2033         |\n",
      "|    time_elapsed         | 37787        |\n",
      "|    total_timesteps      | 4163584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022540744 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 20320        |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    reward               | 2.1909034    |\n",
      "|    std                  | 23.9         |\n",
      "|    value_loss           | 49.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2034          |\n",
      "|    time_elapsed         | 37804         |\n",
      "|    total_timesteps      | 4165632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045266032 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.665         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.7          |\n",
      "|    n_updates            | 20330         |\n",
      "|    policy_gradient_loss | -0.00193      |\n",
      "|    reward               | 1.2396342     |\n",
      "|    std                  | 24            |\n",
      "|    value_loss           | 63.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2035         |\n",
      "|    time_elapsed         | 37821        |\n",
      "|    total_timesteps      | 4167680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053109126 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 20340        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    reward               | -2.0353727   |\n",
      "|    std                  | 23.9         |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2036         |\n",
      "|    time_elapsed         | 37838        |\n",
      "|    total_timesteps      | 4169728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.002056465  |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 20350        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | -0.009577895 |\n",
      "|    std                  | 24           |\n",
      "|    value_loss           | 68.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2037         |\n",
      "|    time_elapsed         | 37855        |\n",
      "|    total_timesteps      | 4171776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009220734 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 20360        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | 1.2413738    |\n",
      "|    std                  | 24           |\n",
      "|    value_loss           | 55.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2038        |\n",
      "|    time_elapsed         | 37873       |\n",
      "|    total_timesteps      | 4173824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000567065 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 20370       |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    reward               | -1.6838017  |\n",
      "|    std                  | 24          |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2039        |\n",
      "|    time_elapsed         | 37890       |\n",
      "|    total_timesteps      | 4175872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009007269 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.99        |\n",
      "|    n_updates            | 20380       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -3.997746   |\n",
      "|    std                  | 24.1        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2040         |\n",
      "|    time_elapsed         | 37907        |\n",
      "|    total_timesteps      | 4177920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029247648 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.6         |\n",
      "|    n_updates            | 20390        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 0.7120499    |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 70.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2041         |\n",
      "|    time_elapsed         | 37925        |\n",
      "|    total_timesteps      | 4179968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010705574 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 20400        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    reward               | -0.28931406  |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 59.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2042         |\n",
      "|    time_elapsed         | 37942        |\n",
      "|    total_timesteps      | 4182016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022092795 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 20410        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 0.44065478   |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 50.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2043         |\n",
      "|    time_elapsed         | 37959        |\n",
      "|    total_timesteps      | 4184064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018522989 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.889        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 20420        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -1.1552247   |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 40.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2044         |\n",
      "|    time_elapsed         | 37977        |\n",
      "|    total_timesteps      | 4186112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010397648 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 20430        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | 0.3337097    |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 60.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2045          |\n",
      "|    time_elapsed         | 37996         |\n",
      "|    total_timesteps      | 4188160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021360887 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.83          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.8          |\n",
      "|    n_updates            | 20440         |\n",
      "|    policy_gradient_loss | -0.000332     |\n",
      "|    reward               | 0.24272938    |\n",
      "|    std                  | 24.3          |\n",
      "|    value_loss           | 43.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2046         |\n",
      "|    time_elapsed         | 38014        |\n",
      "|    total_timesteps      | 4190208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057249973 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.5          |\n",
      "|    n_updates            | 20450        |\n",
      "|    policy_gradient_loss | -0.0085      |\n",
      "|    reward               | 0.31668967   |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 18           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2369403.14\n",
      "total_reward: 1369403.14\n",
      "total_cost: 274248.15\n",
      "total_trades: 66634\n",
      "Sharpe: 0.465\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2047        |\n",
      "|    time_elapsed         | 38032       |\n",
      "|    total_timesteps      | 4192256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004307544 |\n",
      "|    clip_fraction        | 0.00864     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 20460       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | 0.30640644  |\n",
      "|    std                  | 24.4        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2048          |\n",
      "|    time_elapsed         | 38050         |\n",
      "|    total_timesteps      | 4194304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054819975 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.691         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.4          |\n",
      "|    n_updates            | 20470         |\n",
      "|    policy_gradient_loss | -0.00144      |\n",
      "|    reward               | -1.3653207    |\n",
      "|    std                  | 24.4          |\n",
      "|    value_loss           | 54.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2049         |\n",
      "|    time_elapsed         | 38067        |\n",
      "|    total_timesteps      | 4196352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015331081 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 20480        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | 3.9859285    |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2050         |\n",
      "|    time_elapsed         | 38085        |\n",
      "|    total_timesteps      | 4198400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021184837 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 20490        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | 5.6973495    |\n",
      "|    std                  | 24.5         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2051         |\n",
      "|    time_elapsed         | 38102        |\n",
      "|    total_timesteps      | 4200448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015804812 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.78         |\n",
      "|    n_updates            | 20500        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | -7.4778914   |\n",
      "|    std                  | 24.5         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2052         |\n",
      "|    time_elapsed         | 38119        |\n",
      "|    total_timesteps      | 4202496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028037818 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 20510        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | 2.209955     |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2053         |\n",
      "|    time_elapsed         | 38137        |\n",
      "|    total_timesteps      | 4204544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049767527 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.63         |\n",
      "|    n_updates            | 20520        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 0.7323759    |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2054         |\n",
      "|    time_elapsed         | 38154        |\n",
      "|    total_timesteps      | 4206592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007795246 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 20530        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 0.93417597   |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2055          |\n",
      "|    time_elapsed         | 38172         |\n",
      "|    total_timesteps      | 4208640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056402956 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.75          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.5          |\n",
      "|    n_updates            | 20540         |\n",
      "|    policy_gradient_loss | -0.00226      |\n",
      "|    reward               | 0.8180216     |\n",
      "|    std                  | 24.6          |\n",
      "|    value_loss           | 39.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2056        |\n",
      "|    time_elapsed         | 38189       |\n",
      "|    total_timesteps      | 4210688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007643377 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.07        |\n",
      "|    n_updates            | 20550       |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | 1.9580694   |\n",
      "|    std                  | 24.7        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2057         |\n",
      "|    time_elapsed         | 38206        |\n",
      "|    total_timesteps      | 4212736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011941066 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 20560        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | 0.7797643    |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 56.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2058         |\n",
      "|    time_elapsed         | 38223        |\n",
      "|    total_timesteps      | 4214784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003037781 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 20570        |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | 1.1091558    |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2059         |\n",
      "|    time_elapsed         | 38240        |\n",
      "|    total_timesteps      | 4216832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050151357 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 20580        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    reward               | 4.1895585    |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2060         |\n",
      "|    time_elapsed         | 38258        |\n",
      "|    total_timesteps      | 4218880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064165397 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 20590        |\n",
      "|    policy_gradient_loss | -0.00945     |\n",
      "|    reward               | -1.7459295   |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2756403.62\n",
      "total_reward: 1756403.62\n",
      "total_cost: 294781.18\n",
      "total_trades: 67619\n",
      "Sharpe: 0.589\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2061         |\n",
      "|    time_elapsed         | 38275        |\n",
      "|    total_timesteps      | 4220928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015855036 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33           |\n",
      "|    n_updates            | 20600        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | 0.5981683    |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 75.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2062          |\n",
      "|    time_elapsed         | 38292         |\n",
      "|    total_timesteps      | 4222976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060425216 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.782         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.5          |\n",
      "|    n_updates            | 20610         |\n",
      "|    policy_gradient_loss | -0.00191      |\n",
      "|    reward               | 0.081437334   |\n",
      "|    std                  | 24.8          |\n",
      "|    value_loss           | 39.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2063         |\n",
      "|    time_elapsed         | 38309        |\n",
      "|    total_timesteps      | 4225024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020735017 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.82         |\n",
      "|    n_updates            | 20620        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | -1.6906091   |\n",
      "|    std                  | 24.9         |\n",
      "|    value_loss           | 19.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2064        |\n",
      "|    time_elapsed         | 38326       |\n",
      "|    total_timesteps      | 4227072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008205917 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 20630       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.9155479   |\n",
      "|    std                  | 24.9        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2065         |\n",
      "|    time_elapsed         | 38343        |\n",
      "|    total_timesteps      | 4229120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011868272 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 20640        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | 1.650879     |\n",
      "|    std                  | 25           |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2066         |\n",
      "|    time_elapsed         | 38361        |\n",
      "|    total_timesteps      | 4231168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024856261 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.83         |\n",
      "|    n_updates            | 20650        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | 1.0178629    |\n",
      "|    std                  | 25           |\n",
      "|    value_loss           | 22.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2067         |\n",
      "|    time_elapsed         | 38378        |\n",
      "|    total_timesteps      | 4233216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040045027 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 20660        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    reward               | 0.36972126   |\n",
      "|    std                  | 25           |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2068         |\n",
      "|    time_elapsed         | 38395        |\n",
      "|    total_timesteps      | 4235264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024363962 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 20670        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -4.177562    |\n",
      "|    std                  | 25           |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2069        |\n",
      "|    time_elapsed         | 38412       |\n",
      "|    total_timesteps      | 4237312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000966243 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.13        |\n",
      "|    n_updates            | 20680       |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    reward               | 0.45608312  |\n",
      "|    std                  | 25.1        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2070       |\n",
      "|    time_elapsed         | 38429      |\n",
      "|    total_timesteps      | 4239360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00246832 |\n",
      "|    clip_fraction        | 0.00532    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -134       |\n",
      "|    explained_variance   | 0.528      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.45       |\n",
      "|    n_updates            | 20690      |\n",
      "|    policy_gradient_loss | -0.00443   |\n",
      "|    reward               | 0.18813166 |\n",
      "|    std                  | 25.1       |\n",
      "|    value_loss           | 20.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2071         |\n",
      "|    time_elapsed         | 38447        |\n",
      "|    total_timesteps      | 4241408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035049464 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 20700        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | -0.9581264   |\n",
      "|    std                  | 25.1         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2072         |\n",
      "|    time_elapsed         | 38464        |\n",
      "|    total_timesteps      | 4243456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018349405 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 20710        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | 1.498116     |\n",
      "|    std                  | 25.1         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2073        |\n",
      "|    time_elapsed         | 38481       |\n",
      "|    total_timesteps      | 4245504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003630864 |\n",
      "|    clip_fraction        | 0.00757     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.34        |\n",
      "|    n_updates            | 20720       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | 0.95143944  |\n",
      "|    std                  | 25.1        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2074        |\n",
      "|    time_elapsed         | 38498       |\n",
      "|    total_timesteps      | 4247552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002594707 |\n",
      "|    clip_fraction        | 0.00439     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 20730       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | 1.5713971   |\n",
      "|    std                  | 25.1        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2075          |\n",
      "|    time_elapsed         | 38515         |\n",
      "|    total_timesteps      | 4249600       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094064954 |\n",
      "|    clip_fraction        | 0.00215       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -134          |\n",
      "|    explained_variance   | 0.725         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.7          |\n",
      "|    n_updates            | 20740         |\n",
      "|    policy_gradient_loss | -0.00323      |\n",
      "|    reward               | 0.13196619    |\n",
      "|    std                  | 25.1          |\n",
      "|    value_loss           | 29.4          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2567420.75\n",
      "total_reward: 1567420.75\n",
      "total_cost: 224420.26\n",
      "total_trades: 64100\n",
      "Sharpe: 0.544\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2076         |\n",
      "|    time_elapsed         | 38532        |\n",
      "|    total_timesteps      | 4251648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018998145 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 20750        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | 1.0842913    |\n",
      "|    std                  | 25.1         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2077         |\n",
      "|    time_elapsed         | 38549        |\n",
      "|    total_timesteps      | 4253696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038903924 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.48         |\n",
      "|    n_updates            | 20760        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | -1.2835292   |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2078         |\n",
      "|    time_elapsed         | 38566        |\n",
      "|    total_timesteps      | 4255744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016396558 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.45         |\n",
      "|    n_updates            | 20770        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | 0.091631524  |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2079         |\n",
      "|    time_elapsed         | 38583        |\n",
      "|    total_timesteps      | 4257792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017936016 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.95         |\n",
      "|    n_updates            | 20780        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 0.9823242    |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2080        |\n",
      "|    time_elapsed         | 38600       |\n",
      "|    total_timesteps      | 4259840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004045837 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.54        |\n",
      "|    n_updates            | 20790       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | 1.3310611   |\n",
      "|    std                  | 25.3        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2081         |\n",
      "|    time_elapsed         | 38617        |\n",
      "|    total_timesteps      | 4261888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028318365 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 20800        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    reward               | -0.54140407  |\n",
      "|    std                  | 25.4         |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2082         |\n",
      "|    time_elapsed         | 38634        |\n",
      "|    total_timesteps      | 4263936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029944386 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.17         |\n",
      "|    n_updates            | 20810        |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | 2.748147     |\n",
      "|    std                  | 25.4         |\n",
      "|    value_loss           | 19.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2083         |\n",
      "|    time_elapsed         | 38651        |\n",
      "|    total_timesteps      | 4265984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027555195 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 20820        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | 1.6868128    |\n",
      "|    std                  | 25.4         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2084         |\n",
      "|    time_elapsed         | 38668        |\n",
      "|    total_timesteps      | 4268032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043482343 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 20830        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | 2.1457398    |\n",
      "|    std                  | 25.4         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2085         |\n",
      "|    time_elapsed         | 38685        |\n",
      "|    total_timesteps      | 4270080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024442645 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 20840        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | 0.5050296    |\n",
      "|    std                  | 25.5         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2086        |\n",
      "|    time_elapsed         | 38702       |\n",
      "|    total_timesteps      | 4272128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004919719 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.69        |\n",
      "|    n_updates            | 20850       |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | 0.73719937  |\n",
      "|    std                  | 25.5        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2087         |\n",
      "|    time_elapsed         | 38719        |\n",
      "|    total_timesteps      | 4274176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041067502 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.39         |\n",
      "|    n_updates            | 20860        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    reward               | -1.1446748   |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 15.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2088         |\n",
      "|    time_elapsed         | 38736        |\n",
      "|    total_timesteps      | 4276224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023310352 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 20870        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | -0.4511156   |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2089         |\n",
      "|    time_elapsed         | 38753        |\n",
      "|    total_timesteps      | 4278272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011677414 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 20880        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | 2.4931226    |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2860506.55\n",
      "total_reward: 1860506.55\n",
      "total_cost: 207322.27\n",
      "total_trades: 63072\n",
      "Sharpe: 0.607\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2090        |\n",
      "|    time_elapsed         | 38770       |\n",
      "|    total_timesteps      | 4280320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002306058 |\n",
      "|    clip_fraction        | 0.00161     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 20890       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | 1.6606183   |\n",
      "|    std                  | 25.7        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2091         |\n",
      "|    time_elapsed         | 38787        |\n",
      "|    total_timesteps      | 4282368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039088344 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 20900        |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    reward               | -3.0914373   |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2092        |\n",
      "|    time_elapsed         | 38804       |\n",
      "|    total_timesteps      | 4284416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004818839 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 20910       |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    reward               | 0.66709495  |\n",
      "|    std                  | 25.8        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2093         |\n",
      "|    time_elapsed         | 38821        |\n",
      "|    total_timesteps      | 4286464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020691124 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.76         |\n",
      "|    n_updates            | 20920        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | 0.4073213    |\n",
      "|    std                  | 25.8         |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2094         |\n",
      "|    time_elapsed         | 38839        |\n",
      "|    total_timesteps      | 4288512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035304977 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.58         |\n",
      "|    n_updates            | 20930        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    reward               | 0.77541757   |\n",
      "|    std                  | 25.8         |\n",
      "|    value_loss           | 19.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2095         |\n",
      "|    time_elapsed         | 38856        |\n",
      "|    total_timesteps      | 4290560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011705009 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 20940        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | -0.25104883  |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2096         |\n",
      "|    time_elapsed         | 38873        |\n",
      "|    total_timesteps      | 4292608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018867044 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 20950        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | 2.6505127    |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2097         |\n",
      "|    time_elapsed         | 38891        |\n",
      "|    total_timesteps      | 4294656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061530317 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3            |\n",
      "|    n_updates            | 20960        |\n",
      "|    policy_gradient_loss | -0.00712     |\n",
      "|    reward               | -1.0993975   |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 12.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2098         |\n",
      "|    time_elapsed         | 38908        |\n",
      "|    total_timesteps      | 4296704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035724198 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.19         |\n",
      "|    n_updates            | 20970        |\n",
      "|    policy_gradient_loss | -0.00831     |\n",
      "|    reward               | 0.60392624   |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 19.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2099         |\n",
      "|    time_elapsed         | 38925        |\n",
      "|    total_timesteps      | 4298752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031755692 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.59         |\n",
      "|    n_updates            | 20980        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    reward               | 2.0385983    |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2100        |\n",
      "|    time_elapsed         | 38942       |\n",
      "|    total_timesteps      | 4300800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003334089 |\n",
      "|    clip_fraction        | 0.00937     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 20990       |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    reward               | 0.11966932  |\n",
      "|    std                  | 26          |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2101        |\n",
      "|    time_elapsed         | 38959       |\n",
      "|    total_timesteps      | 4302848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004005204 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.64        |\n",
      "|    n_updates            | 21000       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -0.8020067  |\n",
      "|    std                  | 26.1        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2102         |\n",
      "|    time_elapsed         | 38976        |\n",
      "|    total_timesteps      | 4304896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019481616 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 21010        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -1.2611473   |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2103         |\n",
      "|    time_elapsed         | 38993        |\n",
      "|    total_timesteps      | 4306944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024364414 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 21020        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | -0.11960416  |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2967472.48\n",
      "total_reward: 1967472.48\n",
      "total_cost: 210024.56\n",
      "total_trades: 63104\n",
      "Sharpe: 0.635\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2104         |\n",
      "|    time_elapsed         | 39010        |\n",
      "|    total_timesteps      | 4308992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075565246 |\n",
      "|    clip_fraction        | 0.0439       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.16         |\n",
      "|    n_updates            | 21030        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    reward               | -0.6602945   |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2105         |\n",
      "|    time_elapsed         | 39027        |\n",
      "|    total_timesteps      | 4311040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017374035 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.42         |\n",
      "|    n_updates            | 21040        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -1.2861774   |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2106        |\n",
      "|    time_elapsed         | 39044       |\n",
      "|    total_timesteps      | 4313088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000542144 |\n",
      "|    clip_fraction        | 0.000879    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 21050       |\n",
      "|    policy_gradient_loss | -0.000584   |\n",
      "|    reward               | 1.4431286   |\n",
      "|    std                  | 26.2        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2107        |\n",
      "|    time_elapsed         | 39061       |\n",
      "|    total_timesteps      | 4315136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004388266 |\n",
      "|    clip_fraction        | 0.00664     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.38        |\n",
      "|    n_updates            | 21060       |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    reward               | 4.399348    |\n",
      "|    std                  | 26.2        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2108         |\n",
      "|    time_elapsed         | 39079        |\n",
      "|    total_timesteps      | 4317184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021871803 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.87         |\n",
      "|    n_updates            | 21070        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 2.692142     |\n",
      "|    std                  | 26.3         |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2109         |\n",
      "|    time_elapsed         | 39096        |\n",
      "|    total_timesteps      | 4319232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018625585 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 21080        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | -0.92880434  |\n",
      "|    std                  | 26.3         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2110         |\n",
      "|    time_elapsed         | 39114        |\n",
      "|    total_timesteps      | 4321280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013427909 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 21090        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | -2.3828733   |\n",
      "|    std                  | 26.3         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2111        |\n",
      "|    time_elapsed         | 39133       |\n",
      "|    total_timesteps      | 4323328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006849915 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.51        |\n",
      "|    n_updates            | 21100       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    reward               | -0.5640351  |\n",
      "|    std                  | 26.4        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2112         |\n",
      "|    time_elapsed         | 39151        |\n",
      "|    total_timesteps      | 4325376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040519247 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 21110        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 1.1925671    |\n",
      "|    std                  | 26.4         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2113         |\n",
      "|    time_elapsed         | 39169        |\n",
      "|    total_timesteps      | 4327424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013473835 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 21120        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | -0.61170083  |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2114         |\n",
      "|    time_elapsed         | 39187        |\n",
      "|    total_timesteps      | 4329472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051320316 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 21130        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    reward               | 0.32048255   |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2115         |\n",
      "|    time_elapsed         | 39204        |\n",
      "|    total_timesteps      | 4331520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026439468 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 21140        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | -0.17921533  |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2116        |\n",
      "|    time_elapsed         | 39222       |\n",
      "|    total_timesteps      | 4333568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003834818 |\n",
      "|    clip_fraction        | 0.00547     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 21150       |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | 0.49466625  |\n",
      "|    std                  | 26.5        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2117         |\n",
      "|    time_elapsed         | 39239        |\n",
      "|    total_timesteps      | 4335616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045126723 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.207        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 21160        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    reward               | 0.36432013   |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2523640.53\n",
      "total_reward: 1523640.53\n",
      "total_cost: 156741.78\n",
      "total_trades: 60740\n",
      "Sharpe: 0.530\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2118         |\n",
      "|    time_elapsed         | 39256        |\n",
      "|    total_timesteps      | 4337664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038029118 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 21170        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | -0.59703547  |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2119         |\n",
      "|    time_elapsed         | 39273        |\n",
      "|    total_timesteps      | 4339712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010358742 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 21180        |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | 0.27774432   |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 22.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2120         |\n",
      "|    time_elapsed         | 39290        |\n",
      "|    total_timesteps      | 4341760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010984631 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 21190        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | 0.37534884   |\n",
      "|    std                  | 26.7         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2121         |\n",
      "|    time_elapsed         | 39307        |\n",
      "|    total_timesteps      | 4343808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051827515 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.06         |\n",
      "|    n_updates            | 21200        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    reward               | 1.0807027    |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2122         |\n",
      "|    time_elapsed         | 39325        |\n",
      "|    total_timesteps      | 4345856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024878616 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 21210        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | -0.44896588  |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2123         |\n",
      "|    time_elapsed         | 39342        |\n",
      "|    total_timesteps      | 4347904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030438008 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 21220        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | 0.16253667   |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2124         |\n",
      "|    time_elapsed         | 39359        |\n",
      "|    total_timesteps      | 4349952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009260149 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 21230        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | -4.67343     |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2125         |\n",
      "|    time_elapsed         | 39376        |\n",
      "|    total_timesteps      | 4352000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043385727 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.99         |\n",
      "|    n_updates            | 21240        |\n",
      "|    policy_gradient_loss | -0.00863     |\n",
      "|    reward               | 0.18273586   |\n",
      "|    std                  | 26.9         |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2126         |\n",
      "|    time_elapsed         | 39393        |\n",
      "|    total_timesteps      | 4354048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014592505 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 21250        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | 0.8408523    |\n",
      "|    std                  | 27           |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2127         |\n",
      "|    time_elapsed         | 39410        |\n",
      "|    total_timesteps      | 4356096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029934782 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 21260        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | 1.7769971    |\n",
      "|    std                  | 27           |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2128         |\n",
      "|    time_elapsed         | 39428        |\n",
      "|    total_timesteps      | 4358144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060004485 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.46         |\n",
      "|    n_updates            | 21270        |\n",
      "|    policy_gradient_loss | -0.00908     |\n",
      "|    reward               | -0.11977956  |\n",
      "|    std                  | 27.1         |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2129         |\n",
      "|    time_elapsed         | 39445        |\n",
      "|    total_timesteps      | 4360192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018462224 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 21280        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | -0.42048082  |\n",
      "|    std                  | 27.1         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2130         |\n",
      "|    time_elapsed         | 39463        |\n",
      "|    total_timesteps      | 4362240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037114646 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 21290        |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    reward               | -6.0016117   |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2131         |\n",
      "|    time_elapsed         | 39480        |\n",
      "|    total_timesteps      | 4364288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014641479 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 21300        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | 0.4215034    |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3094522.30\n",
      "total_reward: 2094522.30\n",
      "total_cost: 180058.99\n",
      "total_trades: 61544\n",
      "Sharpe: 0.627\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2132         |\n",
      "|    time_elapsed         | 39497        |\n",
      "|    total_timesteps      | 4366336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017525898 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.4          |\n",
      "|    n_updates            | 21310        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -1.4811603   |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2133        |\n",
      "|    time_elapsed         | 39514       |\n",
      "|    total_timesteps      | 4368384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005443017 |\n",
      "|    clip_fraction        | 0.0251      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 21320       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | -3.170054   |\n",
      "|    std                  | 27.3        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2134         |\n",
      "|    time_elapsed         | 39531        |\n",
      "|    total_timesteps      | 4370432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018465517 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 21330        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | -2.2877748   |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2135         |\n",
      "|    time_elapsed         | 39549        |\n",
      "|    total_timesteps      | 4372480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037129072 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.51         |\n",
      "|    n_updates            | 21340        |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    reward               | -0.216892    |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 14.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2136         |\n",
      "|    time_elapsed         | 39566        |\n",
      "|    total_timesteps      | 4374528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056864494 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 21350        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    reward               | -0.10754511  |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2137          |\n",
      "|    time_elapsed         | 39583         |\n",
      "|    total_timesteps      | 4376576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042018588 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.461         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.2          |\n",
      "|    n_updates            | 21360         |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    reward               | -2.0057762    |\n",
      "|    std                  | 27.3          |\n",
      "|    value_loss           | 41.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2138         |\n",
      "|    time_elapsed         | 39600        |\n",
      "|    total_timesteps      | 4378624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033454585 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.83         |\n",
      "|    n_updates            | 21370        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    reward               | -2.6416838   |\n",
      "|    std                  | 27.4         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2139         |\n",
      "|    time_elapsed         | 39618        |\n",
      "|    total_timesteps      | 4380672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024679648 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 21380        |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    reward               | -0.022490107 |\n",
      "|    std                  | 27.4         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2140         |\n",
      "|    time_elapsed         | 39634        |\n",
      "|    total_timesteps      | 4382720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033866386 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.104        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 21390        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | 1.5154591    |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 52.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2141         |\n",
      "|    time_elapsed         | 39652        |\n",
      "|    total_timesteps      | 4384768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026243087 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 21400        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | -1.446255    |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2142         |\n",
      "|    time_elapsed         | 39669        |\n",
      "|    total_timesteps      | 4386816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053971265 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 21410        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    reward               | -1.8808903   |\n",
      "|    std                  | 27.7         |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2143         |\n",
      "|    time_elapsed         | 39686        |\n",
      "|    total_timesteps      | 4388864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023408304 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.08         |\n",
      "|    n_updates            | 21420        |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    reward               | -0.2547848   |\n",
      "|    std                  | 27.7         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2144         |\n",
      "|    time_elapsed         | 39703        |\n",
      "|    total_timesteps      | 4390912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020359287 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 21430        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | 1.1366224    |\n",
      "|    std                  | 27.7         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2145         |\n",
      "|    time_elapsed         | 39721        |\n",
      "|    total_timesteps      | 4392960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064336676 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.65         |\n",
      "|    n_updates            | 21440        |\n",
      "|    policy_gradient_loss | -0.00946     |\n",
      "|    reward               | 0.2394973    |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 15.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2690677.08\n",
      "total_reward: 1690677.08\n",
      "total_cost: 189298.03\n",
      "total_trades: 62153\n",
      "Sharpe: 0.564\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2146         |\n",
      "|    time_elapsed         | 39738        |\n",
      "|    total_timesteps      | 4395008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023925875 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.95         |\n",
      "|    n_updates            | 21450        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 0.6790784    |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2147         |\n",
      "|    time_elapsed         | 39756        |\n",
      "|    total_timesteps      | 4397056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029262486 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 21460        |\n",
      "|    policy_gradient_loss | -0.000497    |\n",
      "|    reward               | 0.6263096    |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2148        |\n",
      "|    time_elapsed         | 39773       |\n",
      "|    total_timesteps      | 4399104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001487453 |\n",
      "|    clip_fraction        | 0.00234     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 21470       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    reward               | -0.2999252  |\n",
      "|    std                  | 27.8        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2149        |\n",
      "|    time_elapsed         | 39792       |\n",
      "|    total_timesteps      | 4401152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003648528 |\n",
      "|    clip_fraction        | 0.0062      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 21480       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 1.7725427   |\n",
      "|    std                  | 27.9        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2150         |\n",
      "|    time_elapsed         | 39810        |\n",
      "|    total_timesteps      | 4403200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041740085 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 21490        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    reward               | 3.2769375    |\n",
      "|    std                  | 28           |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2151         |\n",
      "|    time_elapsed         | 39829        |\n",
      "|    total_timesteps      | 4405248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031791488 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.3         |\n",
      "|    n_updates            | 21500        |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    reward               | 1.3320849    |\n",
      "|    std                  | 28           |\n",
      "|    value_loss           | 53.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2152         |\n",
      "|    time_elapsed         | 39848        |\n",
      "|    total_timesteps      | 4407296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050476533 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.45         |\n",
      "|    n_updates            | 21510        |\n",
      "|    policy_gradient_loss | -0.00861     |\n",
      "|    reward               | 0.23320073   |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 15.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2153         |\n",
      "|    time_elapsed         | 39866        |\n",
      "|    total_timesteps      | 4409344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037937707 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.254        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.6         |\n",
      "|    n_updates            | 21520        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | -0.103454515 |\n",
      "|    std                  | 28.2         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2154          |\n",
      "|    time_elapsed         | 39885         |\n",
      "|    total_timesteps      | 4411392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073594716 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.515         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.7          |\n",
      "|    n_updates            | 21530         |\n",
      "|    policy_gradient_loss | -0.00177      |\n",
      "|    reward               | -4.364828     |\n",
      "|    std                  | 28.3          |\n",
      "|    value_loss           | 37            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2155         |\n",
      "|    time_elapsed         | 39904        |\n",
      "|    total_timesteps      | 4413440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025329632 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.27         |\n",
      "|    n_updates            | 21540        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -1.8919729   |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 28.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2156         |\n",
      "|    time_elapsed         | 39922        |\n",
      "|    total_timesteps      | 4415488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014859594 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 21550        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | 0.016568512  |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2157         |\n",
      "|    time_elapsed         | 39941        |\n",
      "|    total_timesteps      | 4417536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017123459 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 21560        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | -21.14372    |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2158         |\n",
      "|    time_elapsed         | 39961        |\n",
      "|    total_timesteps      | 4419584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012910409 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 21570        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | 0.33654857   |\n",
      "|    std                  | 28.4         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2159        |\n",
      "|    time_elapsed         | 39981       |\n",
      "|    total_timesteps      | 4421632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004601841 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.43        |\n",
      "|    n_updates            | 21580       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | 0.6500359   |\n",
      "|    std                  | 28.4        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2757905.23\n",
      "total_reward: 1757905.23\n",
      "total_cost: 180984.67\n",
      "total_trades: 61407\n",
      "Sharpe: 0.574\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2160         |\n",
      "|    time_elapsed         | 40000        |\n",
      "|    total_timesteps      | 4423680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022353572 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 21590        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | 0.7555375    |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2161         |\n",
      "|    time_elapsed         | 40019        |\n",
      "|    total_timesteps      | 4425728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005930944 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 21600        |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    reward               | -1.1701822   |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2162         |\n",
      "|    time_elapsed         | 40037        |\n",
      "|    total_timesteps      | 4427776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020511635 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.14         |\n",
      "|    n_updates            | 21610        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -0.32725585  |\n",
      "|    std                  | 28.6         |\n",
      "|    value_loss           | 19           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2163         |\n",
      "|    time_elapsed         | 40056        |\n",
      "|    total_timesteps      | 4429824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025413951 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.56         |\n",
      "|    n_updates            | 21620        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | -0.3164174   |\n",
      "|    std                  | 28.6         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2164         |\n",
      "|    time_elapsed         | 40074        |\n",
      "|    total_timesteps      | 4431872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007093829 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.74         |\n",
      "|    n_updates            | 21630        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    reward               | -0.5764171   |\n",
      "|    std                  | 28.6         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2165         |\n",
      "|    time_elapsed         | 40093        |\n",
      "|    total_timesteps      | 4433920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023462274 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 21640        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 1.6532753    |\n",
      "|    std                  | 28.7         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2166         |\n",
      "|    time_elapsed         | 40111        |\n",
      "|    total_timesteps      | 4435968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044602486 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.97         |\n",
      "|    n_updates            | 21650        |\n",
      "|    policy_gradient_loss | -0.00676     |\n",
      "|    reward               | 0.7672839    |\n",
      "|    std                  | 28.8         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2167        |\n",
      "|    time_elapsed         | 40130       |\n",
      "|    total_timesteps      | 4438016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003734075 |\n",
      "|    clip_fraction        | 0.0083      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.54        |\n",
      "|    n_updates            | 21660       |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | 0.197283    |\n",
      "|    std                  | 28.8        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2168         |\n",
      "|    time_elapsed         | 40148        |\n",
      "|    total_timesteps      | 4440064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037902715 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.16         |\n",
      "|    n_updates            | 21670        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | 0.7359463    |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2169        |\n",
      "|    time_elapsed         | 40167       |\n",
      "|    total_timesteps      | 4442112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005113214 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.56        |\n",
      "|    n_updates            | 21680       |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | 0.08962111  |\n",
      "|    std                  | 28.9        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2170         |\n",
      "|    time_elapsed         | 40186        |\n",
      "|    total_timesteps      | 4444160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022056275 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 21690        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    reward               | 0.27308148   |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2171         |\n",
      "|    time_elapsed         | 40204        |\n",
      "|    total_timesteps      | 4446208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013186611 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 21700        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | -2.6903126   |\n",
      "|    std                  | 29           |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2172         |\n",
      "|    time_elapsed         | 40223        |\n",
      "|    total_timesteps      | 4448256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020530801 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 21710        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    reward               | -2.1824026   |\n",
      "|    std                  | 29           |\n",
      "|    value_loss           | 27.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2173         |\n",
      "|    time_elapsed         | 40242        |\n",
      "|    total_timesteps      | 4450304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021846173 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 21720        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | 0.90592724   |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2583330.16\n",
      "total_reward: 1583330.16\n",
      "total_cost: 164802.49\n",
      "total_trades: 60267\n",
      "Sharpe: 0.532\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2174         |\n",
      "|    time_elapsed         | 40261        |\n",
      "|    total_timesteps      | 4452352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023114504 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 21730        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | -0.02213919  |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2175          |\n",
      "|    time_elapsed         | 40280         |\n",
      "|    total_timesteps      | 4454400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013693399 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.364         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.5          |\n",
      "|    n_updates            | 21740         |\n",
      "|    policy_gradient_loss | -0.000674     |\n",
      "|    reward               | 0.74602526    |\n",
      "|    std                  | 29.1          |\n",
      "|    value_loss           | 38.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2176        |\n",
      "|    time_elapsed         | 40299       |\n",
      "|    total_timesteps      | 4456448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007468052 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 21750       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    reward               | -0.27478802 |\n",
      "|    std                  | 29.2        |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2177         |\n",
      "|    time_elapsed         | 40318        |\n",
      "|    total_timesteps      | 4458496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007363696 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.56         |\n",
      "|    n_updates            | 21760        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | 1.5009153    |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2178         |\n",
      "|    time_elapsed         | 40336        |\n",
      "|    total_timesteps      | 4460544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004733959 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 21770        |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    reward               | -1.2539145   |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2179         |\n",
      "|    time_elapsed         | 40355        |\n",
      "|    total_timesteps      | 4462592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033320042 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 21780        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    reward               | 1.4446346    |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2180         |\n",
      "|    time_elapsed         | 40373        |\n",
      "|    total_timesteps      | 4464640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025714985 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 21790        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 1.9959068    |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2181        |\n",
      "|    time_elapsed         | 40391       |\n",
      "|    total_timesteps      | 4466688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003112852 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 21800       |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | -0.64063114 |\n",
      "|    std                  | 29.3        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2182         |\n",
      "|    time_elapsed         | 40410        |\n",
      "|    total_timesteps      | 4468736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027253493 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 21810        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | 0.21197249   |\n",
      "|    std                  | 29.4         |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2183        |\n",
      "|    time_elapsed         | 40428       |\n",
      "|    total_timesteps      | 4470784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004995387 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.46        |\n",
      "|    n_updates            | 21820       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -2.9322476  |\n",
      "|    std                  | 29.5        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2184         |\n",
      "|    time_elapsed         | 40447        |\n",
      "|    total_timesteps      | 4472832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017833703 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 21830        |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    reward               | 0.11547927   |\n",
      "|    std                  | 29.6         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2185         |\n",
      "|    time_elapsed         | 40466        |\n",
      "|    total_timesteps      | 4474880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019514696 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.265        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 21840        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | 0.5570369    |\n",
      "|    std                  | 29.6         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2186         |\n",
      "|    time_elapsed         | 40485        |\n",
      "|    total_timesteps      | 4476928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021610348 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.55         |\n",
      "|    n_updates            | 21850        |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    reward               | -2.5380707   |\n",
      "|    std                  | 29.6         |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2187         |\n",
      "|    time_elapsed         | 40503        |\n",
      "|    total_timesteps      | 4478976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022583683 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 21860        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | 0.17343883   |\n",
      "|    std                  | 29.7         |\n",
      "|    value_loss           | 22.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2188          |\n",
      "|    time_elapsed         | 40521         |\n",
      "|    total_timesteps      | 4481024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042267732 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.481         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.9          |\n",
      "|    n_updates            | 21870         |\n",
      "|    policy_gradient_loss | -0.000509     |\n",
      "|    reward               | -0.64662355   |\n",
      "|    std                  | 29.7          |\n",
      "|    value_loss           | 36.8          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2771462.65\n",
      "total_reward: 1771462.65\n",
      "total_cost: 138835.03\n",
      "total_trades: 58602\n",
      "Sharpe: 0.573\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2189         |\n",
      "|    time_elapsed         | 40540        |\n",
      "|    total_timesteps      | 4483072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008762458 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 21880        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | 2.3180404    |\n",
      "|    std                  | 29.7         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2190         |\n",
      "|    time_elapsed         | 40558        |\n",
      "|    total_timesteps      | 4485120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017652211 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8            |\n",
      "|    n_updates            | 21890        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | -1.6771808   |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2191         |\n",
      "|    time_elapsed         | 40577        |\n",
      "|    total_timesteps      | 4487168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024135937 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 21900        |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    reward               | -1.3709537   |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2192         |\n",
      "|    time_elapsed         | 40595        |\n",
      "|    total_timesteps      | 4489216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009499906 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 21910        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | 1.0957696    |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 49.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2193        |\n",
      "|    time_elapsed         | 40614       |\n",
      "|    total_timesteps      | 4491264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006546431 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 21920       |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | 1.8466698   |\n",
      "|    std                  | 29.9        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2194        |\n",
      "|    time_elapsed         | 40633       |\n",
      "|    total_timesteps      | 4493312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001308603 |\n",
      "|    clip_fraction        | 0.000684    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 21930       |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | 1.3720345   |\n",
      "|    std                  | 29.9        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2195       |\n",
      "|    time_elapsed         | 40651      |\n",
      "|    total_timesteps      | 4495360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00311239 |\n",
      "|    clip_fraction        | 0.00454    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -139       |\n",
      "|    explained_variance   | 0.642      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.3       |\n",
      "|    n_updates            | 21940      |\n",
      "|    policy_gradient_loss | -0.00553   |\n",
      "|    reward               | -1.1687953 |\n",
      "|    std                  | 30         |\n",
      "|    value_loss           | 31.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2196         |\n",
      "|    time_elapsed         | 40670        |\n",
      "|    total_timesteps      | 4497408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017907374 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.18         |\n",
      "|    n_updates            | 21950        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | 0.3910927    |\n",
      "|    std                  | 30           |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2197         |\n",
      "|    time_elapsed         | 40689        |\n",
      "|    total_timesteps      | 4499456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033435693 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.09         |\n",
      "|    n_updates            | 21960        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    reward               | -2.6179307   |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2198         |\n",
      "|    time_elapsed         | 40707        |\n",
      "|    total_timesteps      | 4501504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016715509 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 21970        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -1.8906972   |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2199          |\n",
      "|    time_elapsed         | 40726         |\n",
      "|    total_timesteps      | 4503552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043305097 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.54          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.5          |\n",
      "|    n_updates            | 21980         |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    reward               | 0.11256953    |\n",
      "|    std                  | 30.1          |\n",
      "|    value_loss           | 48.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2200         |\n",
      "|    time_elapsed         | 40744        |\n",
      "|    total_timesteps      | 4505600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060900864 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.84         |\n",
      "|    n_updates            | 21990        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    reward               | 1.5587994    |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 13.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2201         |\n",
      "|    time_elapsed         | 40762        |\n",
      "|    total_timesteps      | 4507648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005105699 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.57         |\n",
      "|    n_updates            | 22000        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | -0.79964674  |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2202         |\n",
      "|    time_elapsed         | 40781        |\n",
      "|    total_timesteps      | 4509696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004894241 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 22010        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | -0.92789924  |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 41.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2921096.58\n",
      "total_reward: 1921096.58\n",
      "total_cost: 131890.03\n",
      "total_trades: 58145\n",
      "Sharpe: 0.602\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2203         |\n",
      "|    time_elapsed         | 40799        |\n",
      "|    total_timesteps      | 4511744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014498043 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.27         |\n",
      "|    n_updates            | 22020        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | 3.4778485    |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2204         |\n",
      "|    time_elapsed         | 40818        |\n",
      "|    total_timesteps      | 4513792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029132182 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 22030        |\n",
      "|    policy_gradient_loss | -0.00699     |\n",
      "|    reward               | -0.4479592   |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2205         |\n",
      "|    time_elapsed         | 40837        |\n",
      "|    total_timesteps      | 4515840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014106601 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 22040        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 0.6511866    |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2206          |\n",
      "|    time_elapsed         | 40856         |\n",
      "|    total_timesteps      | 4517888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036566218 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.54          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32            |\n",
      "|    n_updates            | 22050         |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    reward               | -0.4204669    |\n",
      "|    std                  | 30.3          |\n",
      "|    value_loss           | 33.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2207         |\n",
      "|    time_elapsed         | 40874        |\n",
      "|    total_timesteps      | 4519936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036582341 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.09         |\n",
      "|    n_updates            | 22060        |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    reward               | 0.18735696   |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2208        |\n",
      "|    time_elapsed         | 40892       |\n",
      "|    total_timesteps      | 4521984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000544923 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 22070       |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    reward               | 1.1441386   |\n",
      "|    std                  | 30.4        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2209          |\n",
      "|    time_elapsed         | 40911         |\n",
      "|    total_timesteps      | 4524032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010985258 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.624         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.6          |\n",
      "|    n_updates            | 22080         |\n",
      "|    policy_gradient_loss | -0.000789     |\n",
      "|    reward               | 2.0769064     |\n",
      "|    std                  | 30.4          |\n",
      "|    value_loss           | 35.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2210         |\n",
      "|    time_elapsed         | 40930        |\n",
      "|    total_timesteps      | 4526080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047189766 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.4          |\n",
      "|    n_updates            | 22090        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | 1.9512988    |\n",
      "|    std                  | 30.4         |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2211         |\n",
      "|    time_elapsed         | 40949        |\n",
      "|    total_timesteps      | 4528128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010159275 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.6          |\n",
      "|    n_updates            | 22100        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 0.9336736    |\n",
      "|    std                  | 30.4         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2212          |\n",
      "|    time_elapsed         | 40968         |\n",
      "|    total_timesteps      | 4530176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049137184 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.57          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.4          |\n",
      "|    n_updates            | 22110         |\n",
      "|    policy_gradient_loss | -0.00218      |\n",
      "|    reward               | 1.4024405     |\n",
      "|    std                  | 30.5          |\n",
      "|    value_loss           | 43.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2213         |\n",
      "|    time_elapsed         | 40986        |\n",
      "|    total_timesteps      | 4532224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029724634 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 22120        |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    reward               | -0.36779815  |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2214         |\n",
      "|    time_elapsed         | 41005        |\n",
      "|    total_timesteps      | 4534272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028403946 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 22130        |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    reward               | -0.62277293  |\n",
      "|    std                  | 30.6         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2215          |\n",
      "|    time_elapsed         | 41024         |\n",
      "|    total_timesteps      | 4536320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020071631 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.681         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.4          |\n",
      "|    n_updates            | 22140         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | -0.61082876   |\n",
      "|    std                  | 30.6          |\n",
      "|    value_loss           | 31.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2216          |\n",
      "|    time_elapsed         | 41042         |\n",
      "|    total_timesteps      | 4538368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054188864 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.668         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.8          |\n",
      "|    n_updates            | 22150         |\n",
      "|    policy_gradient_loss | -0.00202      |\n",
      "|    reward               | 0.65342456    |\n",
      "|    std                  | 30.7          |\n",
      "|    value_loss           | 34.5          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3467830.69\n",
      "total_reward: 2467830.69\n",
      "total_cost: 154877.19\n",
      "total_trades: 60474\n",
      "Sharpe: 0.681\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2217        |\n",
      "|    time_elapsed         | 41060       |\n",
      "|    total_timesteps      | 4540416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006350372 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.21        |\n",
      "|    n_updates            | 22160       |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | 2.3865054   |\n",
      "|    std                  | 30.7        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2218          |\n",
      "|    time_elapsed         | 41078         |\n",
      "|    total_timesteps      | 4542464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040218318 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.469         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.5          |\n",
      "|    n_updates            | 22170         |\n",
      "|    policy_gradient_loss | -0.00175      |\n",
      "|    reward               | -0.19432539   |\n",
      "|    std                  | 30.7          |\n",
      "|    value_loss           | 37.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2219         |\n",
      "|    time_elapsed         | 41097        |\n",
      "|    total_timesteps      | 4544512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007694884 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | -0.25522804  |\n",
      "|    std                  | 30.7         |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2220         |\n",
      "|    time_elapsed         | 41115        |\n",
      "|    total_timesteps      | 4546560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015036876 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 22190        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    reward               | 0.17225674   |\n",
      "|    std                  | 30.8         |\n",
      "|    value_loss           | 27.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2221         |\n",
      "|    time_elapsed         | 41134        |\n",
      "|    total_timesteps      | 4548608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021257047 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.61         |\n",
      "|    n_updates            | 22200        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | 0.5972686    |\n",
      "|    std                  | 30.9         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2222         |\n",
      "|    time_elapsed         | 41153        |\n",
      "|    total_timesteps      | 4550656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035685573 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 22210        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | -0.70997906  |\n",
      "|    std                  | 30.9         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2223          |\n",
      "|    time_elapsed         | 41173         |\n",
      "|    total_timesteps      | 4552704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015600538 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.529         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.7          |\n",
      "|    n_updates            | 22220         |\n",
      "|    policy_gradient_loss | -0.000797     |\n",
      "|    reward               | 1.0372738     |\n",
      "|    std                  | 30.9          |\n",
      "|    value_loss           | 34.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2224        |\n",
      "|    time_elapsed         | 41191       |\n",
      "|    total_timesteps      | 4554752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009157401 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.86        |\n",
      "|    n_updates            | 22230       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.53005403 |\n",
      "|    std                  | 31.1        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2225          |\n",
      "|    time_elapsed         | 41210         |\n",
      "|    total_timesteps      | 4556800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067932945 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.34          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.2          |\n",
      "|    n_updates            | 22240         |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    reward               | -0.015411078  |\n",
      "|    std                  | 31.2          |\n",
      "|    value_loss           | 34.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2226          |\n",
      "|    time_elapsed         | 41229         |\n",
      "|    total_timesteps      | 4558848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034093088 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.532         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.9          |\n",
      "|    n_updates            | 22250         |\n",
      "|    policy_gradient_loss | -0.00112      |\n",
      "|    reward               | 1.0737575     |\n",
      "|    std                  | 31.2          |\n",
      "|    value_loss           | 31.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2227         |\n",
      "|    time_elapsed         | 41247        |\n",
      "|    total_timesteps      | 4560896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015674453 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 22260        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | 2.1130996    |\n",
      "|    std                  | 31.2         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2228         |\n",
      "|    time_elapsed         | 41266        |\n",
      "|    total_timesteps      | 4562944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030829774 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 22270        |\n",
      "|    policy_gradient_loss | -0.00773     |\n",
      "|    reward               | -1.1736171   |\n",
      "|    std                  | 31.3         |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2229         |\n",
      "|    time_elapsed         | 41284        |\n",
      "|    total_timesteps      | 4564992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021732503 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 22280        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | 1.7432984    |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2230         |\n",
      "|    time_elapsed         | 41303        |\n",
      "|    total_timesteps      | 4567040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011195508 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 22290        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | 1.4341567    |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3336184.89\n",
      "total_reward: 2336184.89\n",
      "total_cost: 144575.86\n",
      "total_trades: 58865\n",
      "Sharpe: 0.655\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2231         |\n",
      "|    time_elapsed         | 41321        |\n",
      "|    total_timesteps      | 4569088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014481556 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.08         |\n",
      "|    n_updates            | 22300        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 0.383758     |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2232         |\n",
      "|    time_elapsed         | 41340        |\n",
      "|    total_timesteps      | 4571136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004614595 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.38         |\n",
      "|    n_updates            | 22310        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    reward               | -1.0057594   |\n",
      "|    std                  | 31.5         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2233         |\n",
      "|    time_elapsed         | 41359        |\n",
      "|    total_timesteps      | 4573184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012152838 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 22320        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    reward               | -1.1554372   |\n",
      "|    std                  | 31.5         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2234        |\n",
      "|    time_elapsed         | 41377       |\n",
      "|    total_timesteps      | 4575232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00359083  |\n",
      "|    clip_fraction        | 0.00605     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 22330       |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | -0.95650464 |\n",
      "|    std                  | 31.6        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2235         |\n",
      "|    time_elapsed         | 41396        |\n",
      "|    total_timesteps      | 4577280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011341986 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 22340        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -1.9071779   |\n",
      "|    std                  | 31.6         |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2236         |\n",
      "|    time_elapsed         | 41414        |\n",
      "|    total_timesteps      | 4579328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015338256 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 22350        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | -3.847935    |\n",
      "|    std                  | 31.7         |\n",
      "|    value_loss           | 38.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2237         |\n",
      "|    time_elapsed         | 41433        |\n",
      "|    total_timesteps      | 4581376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019618091 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 22360        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | -0.8249183   |\n",
      "|    std                  | 31.7         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2238        |\n",
      "|    time_elapsed         | 41451       |\n",
      "|    total_timesteps      | 4583424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001814259 |\n",
      "|    clip_fraction        | 0.000879    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 22370       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | 0.74275786  |\n",
      "|    std                  | 31.7        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2239         |\n",
      "|    time_elapsed         | 41470        |\n",
      "|    total_timesteps      | 4585472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003496608 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 22380        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    reward               | 0.9956349    |\n",
      "|    std                  | 31.8         |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2240          |\n",
      "|    time_elapsed         | 41488         |\n",
      "|    total_timesteps      | 4587520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022945821 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.63          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.2          |\n",
      "|    n_updates            | 22390         |\n",
      "|    policy_gradient_loss | -0.00113      |\n",
      "|    reward               | 0.0359963     |\n",
      "|    std                  | 31.8          |\n",
      "|    value_loss           | 43.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2241         |\n",
      "|    time_elapsed         | 41506        |\n",
      "|    total_timesteps      | 4589568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056888815 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.72         |\n",
      "|    n_updates            | 22400        |\n",
      "|    policy_gradient_loss | -0.00765     |\n",
      "|    reward               | -0.5644219   |\n",
      "|    std                  | 31.9         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2242          |\n",
      "|    time_elapsed         | 41524         |\n",
      "|    total_timesteps      | 4591616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055863144 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.693         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.57          |\n",
      "|    n_updates            | 22410         |\n",
      "|    policy_gradient_loss | -0.00172      |\n",
      "|    reward               | 0.4367028     |\n",
      "|    std                  | 32            |\n",
      "|    value_loss           | 25.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2243         |\n",
      "|    time_elapsed         | 41543        |\n",
      "|    total_timesteps      | 4593664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002580441 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 22420        |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    reward               | 2.327439     |\n",
      "|    std                  | 32           |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2244         |\n",
      "|    time_elapsed         | 41562        |\n",
      "|    total_timesteps      | 4595712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030403372 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 22430        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -0.61203325  |\n",
      "|    std                  | 32           |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3129047.64\n",
      "total_reward: 2129047.64\n",
      "total_cost: 134319.22\n",
      "total_trades: 58861\n",
      "Sharpe: 0.624\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2245       |\n",
      "|    time_elapsed         | 41581      |\n",
      "|    total_timesteps      | 4597760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00152933 |\n",
      "|    clip_fraction        | 0.000488   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -141       |\n",
      "|    explained_variance   | 0.597      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 22440      |\n",
      "|    policy_gradient_loss | -0.00398   |\n",
      "|    reward               | -0.7588265 |\n",
      "|    std                  | 32.1       |\n",
      "|    value_loss           | 28.5       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2246          |\n",
      "|    time_elapsed         | 41599         |\n",
      "|    total_timesteps      | 4599808       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031283707 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.638         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.5          |\n",
      "|    n_updates            | 22450         |\n",
      "|    policy_gradient_loss | -0.0017       |\n",
      "|    reward               | 12.414342     |\n",
      "|    std                  | 32.1          |\n",
      "|    value_loss           | 39.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2247          |\n",
      "|    time_elapsed         | 41617         |\n",
      "|    total_timesteps      | 4601856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043877406 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.565         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.4          |\n",
      "|    n_updates            | 22460         |\n",
      "|    policy_gradient_loss | -0.00127      |\n",
      "|    reward               | 1.7800205     |\n",
      "|    std                  | 32.1          |\n",
      "|    value_loss           | 43.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2248         |\n",
      "|    time_elapsed         | 41637        |\n",
      "|    total_timesteps      | 4603904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015152909 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.72         |\n",
      "|    n_updates            | 22470        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -0.3480805   |\n",
      "|    std                  | 32.1         |\n",
      "|    value_loss           | 17.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2249         |\n",
      "|    time_elapsed         | 41656        |\n",
      "|    total_timesteps      | 4605952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016099529 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 22480        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | -0.017175054 |\n",
      "|    std                  | 32.2         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2250        |\n",
      "|    time_elapsed         | 41674       |\n",
      "|    total_timesteps      | 4608000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000987358 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 22490       |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    reward               | 1.8155454   |\n",
      "|    std                  | 32.3        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2251         |\n",
      "|    time_elapsed         | 41693        |\n",
      "|    total_timesteps      | 4610048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022367788 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 22500        |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    reward               | -2.5635571   |\n",
      "|    std                  | 32.3         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2252         |\n",
      "|    time_elapsed         | 41711        |\n",
      "|    total_timesteps      | 4612096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026266966 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.02         |\n",
      "|    n_updates            | 22510        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | -10.124322   |\n",
      "|    std                  | 32.4         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2253         |\n",
      "|    time_elapsed         | 41729        |\n",
      "|    total_timesteps      | 4614144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005509587 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 22520        |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    reward               | 0.44527966   |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2254          |\n",
      "|    time_elapsed         | 41748         |\n",
      "|    total_timesteps      | 4616192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066121615 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.129         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.8          |\n",
      "|    n_updates            | 22530         |\n",
      "|    policy_gradient_loss | -0.00198      |\n",
      "|    reward               | 14.375864     |\n",
      "|    std                  | 32.5          |\n",
      "|    value_loss           | 44            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2255        |\n",
      "|    time_elapsed         | 41766       |\n",
      "|    total_timesteps      | 4618240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003362193 |\n",
      "|    clip_fraction        | 0.00557     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 22540       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | 0.3004729   |\n",
      "|    std                  | 32.6        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2256          |\n",
      "|    time_elapsed         | 41785         |\n",
      "|    total_timesteps      | 4620288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042728276 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.624         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.5          |\n",
      "|    n_updates            | 22550         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | -1.6302117    |\n",
      "|    std                  | 32.6          |\n",
      "|    value_loss           | 33.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2257         |\n",
      "|    time_elapsed         | 41804        |\n",
      "|    total_timesteps      | 4622336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005078072 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 22560        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | 0.4306983    |\n",
      "|    std                  | 32.6         |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2258         |\n",
      "|    time_elapsed         | 41823        |\n",
      "|    total_timesteps      | 4624384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034569087 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.99         |\n",
      "|    n_updates            | 22570        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    reward               | -0.012507307 |\n",
      "|    std                  | 32.8         |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2937738.20\n",
      "total_reward: 1937738.20\n",
      "total_cost: 153794.93\n",
      "total_trades: 60313\n",
      "Sharpe: 0.605\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2259         |\n",
      "|    time_elapsed         | 41842        |\n",
      "|    total_timesteps      | 4626432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019861348 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 22580        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | 0.65618026   |\n",
      "|    std                  | 32.9         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2260         |\n",
      "|    time_elapsed         | 41860        |\n",
      "|    total_timesteps      | 4628480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014958283 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.27         |\n",
      "|    n_updates            | 22590        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 0.4415634    |\n",
      "|    std                  | 33           |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2261         |\n",
      "|    time_elapsed         | 41878        |\n",
      "|    total_timesteps      | 4630528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030249427 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 22600        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | -2.5711746   |\n",
      "|    std                  | 33           |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2262         |\n",
      "|    time_elapsed         | 41897        |\n",
      "|    total_timesteps      | 4632576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008124397 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 22610        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | -0.9664675   |\n",
      "|    std                  | 33.1         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2263        |\n",
      "|    time_elapsed         | 41916       |\n",
      "|    total_timesteps      | 4634624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001480802 |\n",
      "|    clip_fraction        | 0.000488    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 22620       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | -0.37509924 |\n",
      "|    std                  | 33.1        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2264        |\n",
      "|    time_elapsed         | 41935       |\n",
      "|    total_timesteps      | 4636672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000690465 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 22630       |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    reward               | 1.0466961   |\n",
      "|    std                  | 33.1        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2265         |\n",
      "|    time_elapsed         | 41953        |\n",
      "|    total_timesteps      | 4638720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062785167 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.13         |\n",
      "|    n_updates            | 22640        |\n",
      "|    policy_gradient_loss | -0.0097      |\n",
      "|    reward               | 1.5267429    |\n",
      "|    std                  | 33.3         |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2266         |\n",
      "|    time_elapsed         | 41971        |\n",
      "|    total_timesteps      | 4640768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009646935 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 22650        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | 0.15644266   |\n",
      "|    std                  | 33.3         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2267          |\n",
      "|    time_elapsed         | 41990         |\n",
      "|    total_timesteps      | 4642816       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028433723 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.554         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.1          |\n",
      "|    n_updates            | 22660         |\n",
      "|    policy_gradient_loss | -0.00133      |\n",
      "|    reward               | 1.5401465     |\n",
      "|    std                  | 33.3          |\n",
      "|    value_loss           | 37.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2268         |\n",
      "|    time_elapsed         | 42008        |\n",
      "|    total_timesteps      | 4644864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011304712 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 22670        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | 1.6046288    |\n",
      "|    std                  | 33.4         |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2269         |\n",
      "|    time_elapsed         | 42026        |\n",
      "|    total_timesteps      | 4646912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015253199 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 22680        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | 1.2582896    |\n",
      "|    std                  | 33.4         |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2270         |\n",
      "|    time_elapsed         | 42044        |\n",
      "|    total_timesteps      | 4648960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002536527 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 22690        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 2.243366     |\n",
      "|    std                  | 33.5         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2271         |\n",
      "|    time_elapsed         | 42063        |\n",
      "|    total_timesteps      | 4651008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003463981 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 22700        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | -1.7489855   |\n",
      "|    std                  | 33.5         |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2272        |\n",
      "|    time_elapsed         | 42081       |\n",
      "|    total_timesteps      | 4653056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004309426 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 22710       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | -1.9630269  |\n",
      "|    std                  | 33.6        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2752610.35\n",
      "total_reward: 1752610.35\n",
      "total_cost: 159394.95\n",
      "total_trades: 59808\n",
      "Sharpe: 0.570\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2273        |\n",
      "|    time_elapsed         | 42100       |\n",
      "|    total_timesteps      | 4655104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00144515  |\n",
      "|    clip_fraction        | 0.00239     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 22720       |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    reward               | -0.12740314 |\n",
      "|    std                  | 33.6        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2274         |\n",
      "|    time_elapsed         | 42118        |\n",
      "|    total_timesteps      | 4657152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005289038 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 22730        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    reward               | -0.44406748  |\n",
      "|    std                  | 33.6         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2275         |\n",
      "|    time_elapsed         | 42136        |\n",
      "|    total_timesteps      | 4659200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017746298 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 22740        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | 1.6750058    |\n",
      "|    std                  | 33.7         |\n",
      "|    value_loss           | 25.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2276         |\n",
      "|    time_elapsed         | 42154        |\n",
      "|    total_timesteps      | 4661248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006073456 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 22750        |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | 0.5991363    |\n",
      "|    std                  | 33.7         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2277          |\n",
      "|    time_elapsed         | 42173         |\n",
      "|    total_timesteps      | 4663296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068433816 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.604         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13            |\n",
      "|    n_updates            | 22760         |\n",
      "|    policy_gradient_loss | -0.00191      |\n",
      "|    reward               | 0.72651714    |\n",
      "|    std                  | 33.7          |\n",
      "|    value_loss           | 33.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2278          |\n",
      "|    time_elapsed         | 42192         |\n",
      "|    total_timesteps      | 4665344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044675707 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.562         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.2          |\n",
      "|    n_updates            | 22770         |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    reward               | -0.42937967   |\n",
      "|    std                  | 33.7          |\n",
      "|    value_loss           | 28.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2279         |\n",
      "|    time_elapsed         | 42211        |\n",
      "|    total_timesteps      | 4667392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036205347 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.06         |\n",
      "|    n_updates            | 22780        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    reward               | 1.7192849    |\n",
      "|    std                  | 33.7         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2280        |\n",
      "|    time_elapsed         | 42229       |\n",
      "|    total_timesteps      | 4669440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001957847 |\n",
      "|    clip_fraction        | 0.00137     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 22790       |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | -0.36955857 |\n",
      "|    std                  | 33.8        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2281         |\n",
      "|    time_elapsed         | 42248        |\n",
      "|    total_timesteps      | 4671488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011334093 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 22800        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | -3.9438524   |\n",
      "|    std                  | 33.8         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2282        |\n",
      "|    time_elapsed         | 42267       |\n",
      "|    total_timesteps      | 4673536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007542954 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.12        |\n",
      "|    n_updates            | 22810       |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    reward               | -1.2264796  |\n",
      "|    std                  | 34          |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2283         |\n",
      "|    time_elapsed         | 42285        |\n",
      "|    total_timesteps      | 4675584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010058223 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 22820        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | 0.54046243   |\n",
      "|    std                  | 34           |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2284          |\n",
      "|    time_elapsed         | 42304         |\n",
      "|    total_timesteps      | 4677632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048041678 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.661         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.4          |\n",
      "|    n_updates            | 22830         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | 2.0806956     |\n",
      "|    std                  | 34            |\n",
      "|    value_loss           | 31.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2285         |\n",
      "|    time_elapsed         | 42323        |\n",
      "|    total_timesteps      | 4679680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023615116 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 22840        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | 1.5948209    |\n",
      "|    std                  | 34.1         |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2286         |\n",
      "|    time_elapsed         | 42341        |\n",
      "|    total_timesteps      | 4681728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038080765 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 22850        |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    reward               | 0.70240647   |\n",
      "|    std                  | 34.2         |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2702142.56\n",
      "total_reward: 1702142.56\n",
      "total_cost: 158312.41\n",
      "total_trades: 60059\n",
      "Sharpe: 0.567\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2287         |\n",
      "|    time_elapsed         | 42359        |\n",
      "|    total_timesteps      | 4683776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010583912 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 22860        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 0.09497375   |\n",
      "|    std                  | 34.3         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2288         |\n",
      "|    time_elapsed         | 42378        |\n",
      "|    total_timesteps      | 4685824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004317959 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 22870        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | -0.02493139  |\n",
      "|    std                  | 34.3         |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2289         |\n",
      "|    time_elapsed         | 42396        |\n",
      "|    total_timesteps      | 4687872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030501755 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.47         |\n",
      "|    n_updates            | 22880        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    reward               | -0.66302466  |\n",
      "|    std                  | 34.3         |\n",
      "|    value_loss           | 17           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2290          |\n",
      "|    time_elapsed         | 42414         |\n",
      "|    total_timesteps      | 4689920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048539028 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.569         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.73          |\n",
      "|    n_updates            | 22890         |\n",
      "|    policy_gradient_loss | -0.00134      |\n",
      "|    reward               | 0.39244363    |\n",
      "|    std                  | 34.2          |\n",
      "|    value_loss           | 26.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2291         |\n",
      "|    time_elapsed         | 42433        |\n",
      "|    total_timesteps      | 4691968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011272237 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 22900        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 0.22680026   |\n",
      "|    std                  | 34.3         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2292         |\n",
      "|    time_elapsed         | 42452        |\n",
      "|    total_timesteps      | 4694016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012399986 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.63         |\n",
      "|    n_updates            | 22910        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | -0.9429289   |\n",
      "|    std                  | 34.3         |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2293        |\n",
      "|    time_elapsed         | 42470       |\n",
      "|    total_timesteps      | 4696064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001849281 |\n",
      "|    clip_fraction        | 0.00278     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.36        |\n",
      "|    n_updates            | 22920       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | -2.5114813  |\n",
      "|    std                  | 34.4        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2294         |\n",
      "|    time_elapsed         | 42488        |\n",
      "|    total_timesteps      | 4698112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019540207 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 22930        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | 3.643609     |\n",
      "|    std                  | 34.4         |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2295         |\n",
      "|    time_elapsed         | 42506        |\n",
      "|    total_timesteps      | 4700160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015130645 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 22940        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | -0.2555689   |\n",
      "|    std                  | 34.4         |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2296         |\n",
      "|    time_elapsed         | 42525        |\n",
      "|    total_timesteps      | 4702208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060378173 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.85         |\n",
      "|    n_updates            | 22950        |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    reward               | -2.0627954   |\n",
      "|    std                  | 34.6         |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2297        |\n",
      "|    time_elapsed         | 42543       |\n",
      "|    total_timesteps      | 4704256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001621393 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 22960       |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    reward               | 0.2108776   |\n",
      "|    std                  | 34.5        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2298          |\n",
      "|    time_elapsed         | 42562         |\n",
      "|    total_timesteps      | 4706304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088129315 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.688         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.9          |\n",
      "|    n_updates            | 22970         |\n",
      "|    policy_gradient_loss | -0.00243      |\n",
      "|    reward               | -3.5639763    |\n",
      "|    std                  | 34.5          |\n",
      "|    value_loss           | 31.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2299        |\n",
      "|    time_elapsed         | 42581       |\n",
      "|    total_timesteps      | 4708352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005454586 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 22980       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | 3.4367874   |\n",
      "|    std                  | 34.7        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2300        |\n",
      "|    time_elapsed         | 42600       |\n",
      "|    total_timesteps      | 4710400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00284592  |\n",
      "|    clip_fraction        | 0.00752     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 22990       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | -0.13159673 |\n",
      "|    std                  | 34.7        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2301         |\n",
      "|    time_elapsed         | 42618        |\n",
      "|    total_timesteps      | 4712448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027506505 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 23000        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | 1.7316552    |\n",
      "|    std                  | 34.8         |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2996165.02\n",
      "total_reward: 1996165.02\n",
      "total_cost: 121001.10\n",
      "total_trades: 57410\n",
      "Sharpe: 0.596\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2302         |\n",
      "|    time_elapsed         | 42637        |\n",
      "|    total_timesteps      | 4714496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013670034 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 23010        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | -4.1036963   |\n",
      "|    std                  | 34.8         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2303         |\n",
      "|    time_elapsed         | 42655        |\n",
      "|    total_timesteps      | 4716544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033316268 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 23020        |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    reward               | 1.9643947    |\n",
      "|    std                  | 34.8         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2304         |\n",
      "|    time_elapsed         | 42674        |\n",
      "|    total_timesteps      | 4718592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005584409 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 23030        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | -0.20494674  |\n",
      "|    std                  | 34.9         |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2305         |\n",
      "|    time_elapsed         | 42692        |\n",
      "|    total_timesteps      | 4720640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012129841 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 23040        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | 0.089420415  |\n",
      "|    std                  | 34.9         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2306         |\n",
      "|    time_elapsed         | 42711        |\n",
      "|    total_timesteps      | 4722688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035424738 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 23050        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    reward               | 1.510246     |\n",
      "|    std                  | 35           |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2307        |\n",
      "|    time_elapsed         | 42730       |\n",
      "|    total_timesteps      | 4724736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001089149 |\n",
      "|    clip_fraction        | 9.77e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.23        |\n",
      "|    n_updates            | 23060       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | -0.96626806 |\n",
      "|    std                  | 35          |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2308         |\n",
      "|    time_elapsed         | 42749        |\n",
      "|    total_timesteps      | 4726784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013881391 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 23070        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | 2.8297768    |\n",
      "|    std                  | 35           |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2309        |\n",
      "|    time_elapsed         | 42767       |\n",
      "|    total_timesteps      | 4728832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003958659 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 23080       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -5.9057517  |\n",
      "|    std                  | 35.1        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2310        |\n",
      "|    time_elapsed         | 42786       |\n",
      "|    total_timesteps      | 4730880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002284789 |\n",
      "|    clip_fraction        | 0.00171     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 23090       |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | 1.4562309   |\n",
      "|    std                  | 35.3        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2311          |\n",
      "|    time_elapsed         | 42805         |\n",
      "|    total_timesteps      | 4732928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058040855 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.501         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.5          |\n",
      "|    n_updates            | 23100         |\n",
      "|    policy_gradient_loss | -0.002        |\n",
      "|    reward               | -1.3548437    |\n",
      "|    std                  | 35.3          |\n",
      "|    value_loss           | 41            |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2312          |\n",
      "|    time_elapsed         | 42823         |\n",
      "|    total_timesteps      | 4734976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020057146 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.669         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.5          |\n",
      "|    n_updates            | 23110         |\n",
      "|    policy_gradient_loss | -0.00103      |\n",
      "|    reward               | 1.7120264     |\n",
      "|    std                  | 35.3          |\n",
      "|    value_loss           | 37.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2313        |\n",
      "|    time_elapsed         | 42842       |\n",
      "|    total_timesteps      | 4737024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004980903 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.11        |\n",
      "|    n_updates            | 23120       |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | 0.70582575  |\n",
      "|    std                  | 35.4        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2314        |\n",
      "|    time_elapsed         | 42860       |\n",
      "|    total_timesteps      | 4739072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001103681 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 23130       |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    reward               | -1.680926   |\n",
      "|    std                  | 35.4        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2315         |\n",
      "|    time_elapsed         | 42879        |\n",
      "|    total_timesteps      | 4741120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007723188 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 23140        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | -1.4004108   |\n",
      "|    std                  | 35.4         |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2972959.44\n",
      "total_reward: 1972959.44\n",
      "total_cost: 155087.82\n",
      "total_trades: 60131\n",
      "Sharpe: 0.602\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2316         |\n",
      "|    time_elapsed         | 42898        |\n",
      "|    total_timesteps      | 4743168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045539127 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 23150        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | 0.20131223   |\n",
      "|    std                  | 35.5         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2317         |\n",
      "|    time_elapsed         | 42916        |\n",
      "|    total_timesteps      | 4745216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026629388 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.94         |\n",
      "|    n_updates            | 23160        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | 0.9836831    |\n",
      "|    std                  | 35.6         |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2318         |\n",
      "|    time_elapsed         | 42935        |\n",
      "|    total_timesteps      | 4747264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005782315 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 23170        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | 0.6733163    |\n",
      "|    std                  | 35.7         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2319          |\n",
      "|    time_elapsed         | 42954         |\n",
      "|    total_timesteps      | 4749312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040803623 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.554         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.4          |\n",
      "|    n_updates            | 23180         |\n",
      "|    policy_gradient_loss | -0.00198      |\n",
      "|    reward               | 0.3108502     |\n",
      "|    std                  | 35.7          |\n",
      "|    value_loss           | 32.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2320         |\n",
      "|    time_elapsed         | 42972        |\n",
      "|    total_timesteps      | 4751360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037258163 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 23190        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    reward               | 0.15905544   |\n",
      "|    std                  | 35.7         |\n",
      "|    value_loss           | 22.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2321          |\n",
      "|    time_elapsed         | 42990         |\n",
      "|    total_timesteps      | 4753408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081208406 |\n",
      "|    clip_fraction        | 0.00107       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.62          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.8          |\n",
      "|    n_updates            | 23200         |\n",
      "|    policy_gradient_loss | -0.00227      |\n",
      "|    reward               | -2.580312     |\n",
      "|    std                  | 35.8          |\n",
      "|    value_loss           | 29.9          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2322          |\n",
      "|    time_elapsed         | 43009         |\n",
      "|    total_timesteps      | 4755456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082631153 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.296         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16            |\n",
      "|    n_updates            | 23210         |\n",
      "|    policy_gradient_loss | -0.00186      |\n",
      "|    reward               | 2.0361438     |\n",
      "|    std                  | 35.8          |\n",
      "|    value_loss           | 47.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2323         |\n",
      "|    time_elapsed         | 43027        |\n",
      "|    total_timesteps      | 4757504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023026937 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.09         |\n",
      "|    n_updates            | 23220        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    reward               | -0.33881035  |\n",
      "|    std                  | 35.8         |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2324         |\n",
      "|    time_elapsed         | 43046        |\n",
      "|    total_timesteps      | 4759552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005944767 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 23230        |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    reward               | 0.08620788   |\n",
      "|    std                  | 35.8         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2325         |\n",
      "|    time_elapsed         | 43064        |\n",
      "|    total_timesteps      | 4761600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006413722 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 23240        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | 1.832524     |\n",
      "|    std                  | 35.8         |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2326         |\n",
      "|    time_elapsed         | 43082        |\n",
      "|    total_timesteps      | 4763648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009904114 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.76         |\n",
      "|    n_updates            | 23250        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | 2.2724075    |\n",
      "|    std                  | 35.9         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2327         |\n",
      "|    time_elapsed         | 43101        |\n",
      "|    total_timesteps      | 4765696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021125358 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.69         |\n",
      "|    n_updates            | 23260        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | 0.47510216   |\n",
      "|    std                  | 35.9         |\n",
      "|    value_loss           | 17.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2328         |\n",
      "|    time_elapsed         | 43119        |\n",
      "|    total_timesteps      | 4767744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011263482 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 23270        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | 0.8993983    |\n",
      "|    std                  | 35.9         |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2329          |\n",
      "|    time_elapsed         | 43138         |\n",
      "|    total_timesteps      | 4769792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074450497 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.547         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.2          |\n",
      "|    n_updates            | 23280         |\n",
      "|    policy_gradient_loss | -0.00268      |\n",
      "|    reward               | -10.103091    |\n",
      "|    std                  | 36            |\n",
      "|    value_loss           | 36.8          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2947082.29\n",
      "total_reward: 1947082.29\n",
      "total_cost: 156576.34\n",
      "total_trades: 60418\n",
      "Sharpe: 0.589\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2330         |\n",
      "|    time_elapsed         | 43156        |\n",
      "|    total_timesteps      | 4771840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029221254 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.6          |\n",
      "|    n_updates            | 23290        |\n",
      "|    policy_gradient_loss | -0.00513     |\n",
      "|    reward               | 1.8473291    |\n",
      "|    std                  | 36           |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2331         |\n",
      "|    time_elapsed         | 43176        |\n",
      "|    total_timesteps      | 4773888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006830392 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 23300        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -0.4914468   |\n",
      "|    std                  | 36.1         |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2332          |\n",
      "|    time_elapsed         | 43194         |\n",
      "|    total_timesteps      | 4775936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038216956 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.607         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.6          |\n",
      "|    n_updates            | 23310         |\n",
      "|    policy_gradient_loss | -0.00158      |\n",
      "|    reward               | -4.8764215    |\n",
      "|    std                  | 36.1          |\n",
      "|    value_loss           | 35.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2333         |\n",
      "|    time_elapsed         | 43213        |\n",
      "|    total_timesteps      | 4777984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006982252 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.58         |\n",
      "|    n_updates            | 23320        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 1.5542595    |\n",
      "|    std                  | 36.1         |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2334        |\n",
      "|    time_elapsed         | 43232       |\n",
      "|    total_timesteps      | 4780032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002002006 |\n",
      "|    clip_fraction        | 0.0019      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.37        |\n",
      "|    n_updates            | 23330       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    reward               | 0.105868496 |\n",
      "|    std                  | 36.2        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2335         |\n",
      "|    time_elapsed         | 43251        |\n",
      "|    total_timesteps      | 4782080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004862004 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 23340        |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | 5.8387403    |\n",
      "|    std                  | 36.2         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2336          |\n",
      "|    time_elapsed         | 43270         |\n",
      "|    total_timesteps      | 4784128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048072118 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.506         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.5          |\n",
      "|    n_updates            | 23350         |\n",
      "|    policy_gradient_loss | -0.00217      |\n",
      "|    reward               | -0.7998873    |\n",
      "|    std                  | 36.3          |\n",
      "|    value_loss           | 30.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2337        |\n",
      "|    time_elapsed         | 43288       |\n",
      "|    total_timesteps      | 4786176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007245112 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.15        |\n",
      "|    n_updates            | 23360       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | -0.06001623 |\n",
      "|    std                  | 36.5        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2338         |\n",
      "|    time_elapsed         | 43306        |\n",
      "|    total_timesteps      | 4788224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003097077 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 23370        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | -0.20751306  |\n",
      "|    std                  | 36.5         |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2339         |\n",
      "|    time_elapsed         | 43324        |\n",
      "|    total_timesteps      | 4790272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002641789 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 23380        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    reward               | 0.29793546   |\n",
      "|    std                  | 36.5         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2340         |\n",
      "|    time_elapsed         | 43343        |\n",
      "|    total_timesteps      | 4792320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016257495 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 23390        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 1.2382432    |\n",
      "|    std                  | 36.5         |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2341         |\n",
      "|    time_elapsed         | 43362        |\n",
      "|    total_timesteps      | 4794368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014632049 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.91         |\n",
      "|    n_updates            | 23400        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | -1.9384043   |\n",
      "|    std                  | 36.6         |\n",
      "|    value_loss           | 15.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2342          |\n",
      "|    time_elapsed         | 43380         |\n",
      "|    total_timesteps      | 4796416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029738244 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.745         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.6          |\n",
      "|    n_updates            | 23410         |\n",
      "|    policy_gradient_loss | -0.00135      |\n",
      "|    reward               | -0.2855773    |\n",
      "|    std                  | 36.6          |\n",
      "|    value_loss           | 27.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2343          |\n",
      "|    time_elapsed         | 43400         |\n",
      "|    total_timesteps      | 4798464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035514546 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.428         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.9          |\n",
      "|    n_updates            | 23420         |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    reward               | 0.5616867     |\n",
      "|    std                  | 36.6          |\n",
      "|    value_loss           | 31.5          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2992799.10\n",
      "total_reward: 1992799.10\n",
      "total_cost: 141275.14\n",
      "total_trades: 59696\n",
      "Sharpe: 0.613\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2344         |\n",
      "|    time_elapsed         | 43418        |\n",
      "|    total_timesteps      | 4800512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023092446 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.09         |\n",
      "|    n_updates            | 23430        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -0.6186134   |\n",
      "|    std                  | 36.7         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2345          |\n",
      "|    time_elapsed         | 43436         |\n",
      "|    total_timesteps      | 4802560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023705469 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.693         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.8          |\n",
      "|    n_updates            | 23440         |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    reward               | -0.3228787    |\n",
      "|    std                  | 36.7          |\n",
      "|    value_loss           | 28.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2346         |\n",
      "|    time_elapsed         | 43455        |\n",
      "|    total_timesteps      | 4804608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003475786 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 23450        |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | 0.6158092    |\n",
      "|    std                  | 36.7         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2347         |\n",
      "|    time_elapsed         | 43474        |\n",
      "|    total_timesteps      | 4806656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032228238 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 23460        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | 0.61463267   |\n",
      "|    std                  | 36.9         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2348          |\n",
      "|    time_elapsed         | 43493         |\n",
      "|    total_timesteps      | 4808704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089386385 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.502         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.6          |\n",
      "|    n_updates            | 23470         |\n",
      "|    policy_gradient_loss | -0.0025       |\n",
      "|    reward               | -1.7266674    |\n",
      "|    std                  | 37            |\n",
      "|    value_loss           | 29.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2349         |\n",
      "|    time_elapsed         | 43511        |\n",
      "|    total_timesteps      | 4810752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006597418 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 23480        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    reward               | 1.784303     |\n",
      "|    std                  | 37           |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2350         |\n",
      "|    time_elapsed         | 43530        |\n",
      "|    total_timesteps      | 4812800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002540646 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 23490        |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    reward               | -0.72827953  |\n",
      "|    std                  | 37           |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2351         |\n",
      "|    time_elapsed         | 43549        |\n",
      "|    total_timesteps      | 4814848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019440141 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.58         |\n",
      "|    n_updates            | 23500        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | -0.8991845   |\n",
      "|    std                  | 37.1         |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2352         |\n",
      "|    time_elapsed         | 43568        |\n",
      "|    total_timesteps      | 4816896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006529473 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.93         |\n",
      "|    n_updates            | 23510        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 0.45730874   |\n",
      "|    std                  | 37.1         |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2353          |\n",
      "|    time_elapsed         | 43587         |\n",
      "|    total_timesteps      | 4818944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031265145 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.658         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.2          |\n",
      "|    n_updates            | 23520         |\n",
      "|    policy_gradient_loss | -0.00136      |\n",
      "|    reward               | 0.3708505     |\n",
      "|    std                  | 37.1          |\n",
      "|    value_loss           | 31.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2354         |\n",
      "|    time_elapsed         | 43605        |\n",
      "|    total_timesteps      | 4820992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028032246 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.63         |\n",
      "|    n_updates            | 23530        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    reward               | 1.0405006    |\n",
      "|    std                  | 37.1         |\n",
      "|    value_loss           | 17.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2355         |\n",
      "|    time_elapsed         | 43624        |\n",
      "|    total_timesteps      | 4823040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009299811 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 23540        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | -0.24169984  |\n",
      "|    std                  | 37.1         |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2356          |\n",
      "|    time_elapsed         | 43643         |\n",
      "|    total_timesteps      | 4825088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031569047 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.425         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.5          |\n",
      "|    n_updates            | 23550         |\n",
      "|    policy_gradient_loss | -0.00177      |\n",
      "|    reward               | -2.9190326    |\n",
      "|    std                  | 37.1          |\n",
      "|    value_loss           | 40.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2357          |\n",
      "|    time_elapsed         | 43662         |\n",
      "|    total_timesteps      | 4827136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047774767 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.526         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.4          |\n",
      "|    n_updates            | 23560         |\n",
      "|    policy_gradient_loss | -0.00213      |\n",
      "|    reward               | 0.9741925     |\n",
      "|    std                  | 37.2          |\n",
      "|    value_loss           | 32.3          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2863376.90\n",
      "total_reward: 1863376.90\n",
      "total_cost: 119784.62\n",
      "total_trades: 58302\n",
      "Sharpe: 0.586\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2358         |\n",
      "|    time_elapsed         | 43681        |\n",
      "|    total_timesteps      | 4829184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019298955 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.79         |\n",
      "|    n_updates            | 23570        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 1.3271124    |\n",
      "|    std                  | 37.2         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2359          |\n",
      "|    time_elapsed         | 43700         |\n",
      "|    total_timesteps      | 4831232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057044864 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.634         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.8          |\n",
      "|    n_updates            | 23580         |\n",
      "|    policy_gradient_loss | -0.00219      |\n",
      "|    reward               | -19.67485     |\n",
      "|    std                  | 37.2          |\n",
      "|    value_loss           | 33.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2360         |\n",
      "|    time_elapsed         | 43718        |\n",
      "|    total_timesteps      | 4833280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004487348 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 23590        |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    reward               | 0.38324502   |\n",
      "|    std                  | 37.3         |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2361         |\n",
      "|    time_elapsed         | 43737        |\n",
      "|    total_timesteps      | 4835328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037410262 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.2          |\n",
      "|    n_updates            | 23600        |\n",
      "|    policy_gradient_loss | -0.00774     |\n",
      "|    reward               | -0.14157455  |\n",
      "|    std                  | 37.4         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2362          |\n",
      "|    time_elapsed         | 43755         |\n",
      "|    total_timesteps      | 4837376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029830786 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.622         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.9          |\n",
      "|    n_updates            | 23610         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | -0.2798867    |\n",
      "|    std                  | 37.4          |\n",
      "|    value_loss           | 35.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2363          |\n",
      "|    time_elapsed         | 43774         |\n",
      "|    total_timesteps      | 4839424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018483165 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.618         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.6          |\n",
      "|    n_updates            | 23620         |\n",
      "|    policy_gradient_loss | -0.000999     |\n",
      "|    reward               | 1.0548438     |\n",
      "|    std                  | 37.4          |\n",
      "|    value_loss           | 41.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2364         |\n",
      "|    time_elapsed         | 43792        |\n",
      "|    total_timesteps      | 4841472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008631225 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 23630        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 0.254177     |\n",
      "|    std                  | 37.5         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2365         |\n",
      "|    time_elapsed         | 43811        |\n",
      "|    total_timesteps      | 4843520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010181359 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 23640        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | 0.5503975    |\n",
      "|    std                  | 37.5         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2366         |\n",
      "|    time_elapsed         | 43829        |\n",
      "|    total_timesteps      | 4845568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006619442 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 23650        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    reward               | -1.4999977   |\n",
      "|    std                  | 37.5         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2367         |\n",
      "|    time_elapsed         | 43848        |\n",
      "|    total_timesteps      | 4847616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005751134 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 23660        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 0.30648822   |\n",
      "|    std                  | 37.6         |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2368         |\n",
      "|    time_elapsed         | 43866        |\n",
      "|    total_timesteps      | 4849664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025911157 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 23670        |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | 1.0729471    |\n",
      "|    std                  | 37.6         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2369         |\n",
      "|    time_elapsed         | 43886        |\n",
      "|    total_timesteps      | 4851712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005426308 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 23680        |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | -0.21986158  |\n",
      "|    std                  | 37.6         |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2370          |\n",
      "|    time_elapsed         | 43905         |\n",
      "|    total_timesteps      | 4853760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053639425 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.719         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.6          |\n",
      "|    n_updates            | 23690         |\n",
      "|    policy_gradient_loss | -0.00184      |\n",
      "|    reward               | -0.29397213   |\n",
      "|    std                  | 37.6          |\n",
      "|    value_loss           | 37.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2371         |\n",
      "|    time_elapsed         | 43925        |\n",
      "|    total_timesteps      | 4855808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023685258 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.75         |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | 0.08080998   |\n",
      "|    std                  | 37.7         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3355568.25\n",
      "total_reward: 2355568.25\n",
      "total_cost: 128214.72\n",
      "total_trades: 58973\n",
      "Sharpe: 0.651\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2372          |\n",
      "|    time_elapsed         | 43944         |\n",
      "|    total_timesteps      | 4857856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035321288 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.797         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.1          |\n",
      "|    n_updates            | 23710         |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    reward               | -0.5821819    |\n",
      "|    std                  | 37.7          |\n",
      "|    value_loss           | 24.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2373          |\n",
      "|    time_elapsed         | 43962         |\n",
      "|    total_timesteps      | 4859904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014700723 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.631         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.8          |\n",
      "|    n_updates            | 23720         |\n",
      "|    policy_gradient_loss | -0.00095      |\n",
      "|    reward               | -0.2615358    |\n",
      "|    std                  | 37.7          |\n",
      "|    value_loss           | 40.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2374          |\n",
      "|    time_elapsed         | 43981         |\n",
      "|    total_timesteps      | 4861952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028463607 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.678         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.3          |\n",
      "|    n_updates            | 23730         |\n",
      "|    policy_gradient_loss | -0.00156      |\n",
      "|    reward               | -0.2925629    |\n",
      "|    std                  | 37.7          |\n",
      "|    value_loss           | 31.8          |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 2375      |\n",
      "|    time_elapsed         | 43999     |\n",
      "|    total_timesteps      | 4864000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0026285 |\n",
      "|    clip_fraction        | 0.00313   |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -146      |\n",
      "|    explained_variance   | 0.703     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 12.6      |\n",
      "|    n_updates            | 23740     |\n",
      "|    policy_gradient_loss | -0.00409  |\n",
      "|    reward               | 1.0614012 |\n",
      "|    std                  | 37.8      |\n",
      "|    value_loss           | 24.2      |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2376          |\n",
      "|    time_elapsed         | 44018         |\n",
      "|    total_timesteps      | 4866048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039306693 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.647         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.41          |\n",
      "|    n_updates            | 23750         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    reward               | 0.057485007   |\n",
      "|    std                  | 37.8          |\n",
      "|    value_loss           | 28.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2377         |\n",
      "|    time_elapsed         | 44037        |\n",
      "|    total_timesteps      | 4868096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006046778 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 23760        |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    reward               | -0.75205845  |\n",
      "|    std                  | 37.8         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2378        |\n",
      "|    time_elapsed         | 44055       |\n",
      "|    total_timesteps      | 4870144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004768324 |\n",
      "|    clip_fraction        | 0.0102      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.78        |\n",
      "|    n_updates            | 23770       |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | 0.37977153  |\n",
      "|    std                  | 38          |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2379          |\n",
      "|    time_elapsed         | 44074         |\n",
      "|    total_timesteps      | 4872192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080655725 |\n",
      "|    clip_fraction        | 0.00269       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.733         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11            |\n",
      "|    n_updates            | 23780         |\n",
      "|    policy_gradient_loss | -0.00242      |\n",
      "|    reward               | 1.2820302     |\n",
      "|    std                  | 38            |\n",
      "|    value_loss           | 23.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2380          |\n",
      "|    time_elapsed         | 44092         |\n",
      "|    total_timesteps      | 4874240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7078403e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.65          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.27          |\n",
      "|    n_updates            | 23790         |\n",
      "|    policy_gradient_loss | -0.000653     |\n",
      "|    reward               | -0.74606067   |\n",
      "|    std                  | 38            |\n",
      "|    value_loss           | 33.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2381         |\n",
      "|    time_elapsed         | 44112        |\n",
      "|    total_timesteps      | 4876288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024370528 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 23800        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | 0.87625134   |\n",
      "|    std                  | 38.1         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2382        |\n",
      "|    time_elapsed         | 44130       |\n",
      "|    total_timesteps      | 4878336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003641937 |\n",
      "|    clip_fraction        | 0.00698     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.81        |\n",
      "|    n_updates            | 23810       |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | 0.5539833   |\n",
      "|    std                  | 38.1        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2383          |\n",
      "|    time_elapsed         | 44149         |\n",
      "|    total_timesteps      | 4880384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050560746 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.681         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.1          |\n",
      "|    n_updates            | 23820         |\n",
      "|    policy_gradient_loss | -0.00193      |\n",
      "|    reward               | -2.0301242    |\n",
      "|    std                  | 38.2          |\n",
      "|    value_loss           | 26.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2384          |\n",
      "|    time_elapsed         | 44167         |\n",
      "|    total_timesteps      | 4882432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080987404 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.74          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9             |\n",
      "|    n_updates            | 23830         |\n",
      "|    policy_gradient_loss | -0.00357      |\n",
      "|    reward               | -2.2809477    |\n",
      "|    std                  | 38.2          |\n",
      "|    value_loss           | 25.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2385         |\n",
      "|    time_elapsed         | 44187        |\n",
      "|    total_timesteps      | 4884480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034447797 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.98         |\n",
      "|    n_updates            | 23840        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | -0.7515824   |\n",
      "|    std                  | 38.3         |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3320814.19\n",
      "total_reward: 2320814.19\n",
      "total_cost: 138813.32\n",
      "total_trades: 59669\n",
      "Sharpe: 0.668\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2386         |\n",
      "|    time_elapsed         | 44206        |\n",
      "|    total_timesteps      | 4886528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005966935 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.66         |\n",
      "|    n_updates            | 23850        |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    reward               | -0.5893123   |\n",
      "|    std                  | 38.3         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2387          |\n",
      "|    time_elapsed         | 44225         |\n",
      "|    total_timesteps      | 4888576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.9426565e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.556         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.5          |\n",
      "|    n_updates            | 23860         |\n",
      "|    policy_gradient_loss | -0.000831     |\n",
      "|    reward               | -7.9512415    |\n",
      "|    std                  | 38.4          |\n",
      "|    value_loss           | 33.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2388         |\n",
      "|    time_elapsed         | 44244        |\n",
      "|    total_timesteps      | 4890624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025135598 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.39         |\n",
      "|    n_updates            | 23870        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | -1.923963    |\n",
      "|    std                  | 38.4         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2389         |\n",
      "|    time_elapsed         | 44263        |\n",
      "|    total_timesteps      | 4892672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010838604 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 23880        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -1.2016404   |\n",
      "|    std                  | 38.4         |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2390          |\n",
      "|    time_elapsed         | 44281         |\n",
      "|    total_timesteps      | 4894720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024706486 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.675         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.1          |\n",
      "|    n_updates            | 23890         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    reward               | 0.6014495     |\n",
      "|    std                  | 38.4          |\n",
      "|    value_loss           | 31.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2391          |\n",
      "|    time_elapsed         | 44301         |\n",
      "|    total_timesteps      | 4896768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031042134 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.624         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.53          |\n",
      "|    n_updates            | 23900         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | -0.2446194    |\n",
      "|    std                  | 38.5          |\n",
      "|    value_loss           | 25.2          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2392         |\n",
      "|    time_elapsed         | 44320        |\n",
      "|    total_timesteps      | 4898816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024869477 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.16         |\n",
      "|    n_updates            | 23910        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    reward               | 0.5303241    |\n",
      "|    std                  | 38.5         |\n",
      "|    value_loss           | 18           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2393         |\n",
      "|    time_elapsed         | 44339        |\n",
      "|    total_timesteps      | 4900864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010958172 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 23920        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 0.3311852    |\n",
      "|    std                  | 38.6         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2394          |\n",
      "|    time_elapsed         | 44358         |\n",
      "|    total_timesteps      | 4902912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065001426 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.74          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.72          |\n",
      "|    n_updates            | 23930         |\n",
      "|    policy_gradient_loss | -0.00185      |\n",
      "|    reward               | 0.53243744    |\n",
      "|    std                  | 38.7          |\n",
      "|    value_loss           | 25.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2395         |\n",
      "|    time_elapsed         | 44377        |\n",
      "|    total_timesteps      | 4904960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025489258 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9            |\n",
      "|    n_updates            | 23940        |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    reward               | 0.34155703   |\n",
      "|    std                  | 38.8         |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2396         |\n",
      "|    time_elapsed         | 44395        |\n",
      "|    total_timesteps      | 4907008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006774098 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.67         |\n",
      "|    n_updates            | 23950        |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    reward               | -0.2628709   |\n",
      "|    std                  | 38.9         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2397          |\n",
      "|    time_elapsed         | 44413         |\n",
      "|    total_timesteps      | 4909056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045522678 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.743         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.1          |\n",
      "|    n_updates            | 23960         |\n",
      "|    policy_gradient_loss | -0.00125      |\n",
      "|    reward               | 2.2305443     |\n",
      "|    std                  | 38.9          |\n",
      "|    value_loss           | 29.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2398          |\n",
      "|    time_elapsed         | 44431         |\n",
      "|    total_timesteps      | 4911104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064199325 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.681         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.1          |\n",
      "|    n_updates            | 23970         |\n",
      "|    policy_gradient_loss | -0.00151      |\n",
      "|    reward               | -2.5326817    |\n",
      "|    std                  | 39            |\n",
      "|    value_loss           | 22.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2399         |\n",
      "|    time_elapsed         | 44450        |\n",
      "|    total_timesteps      | 4913152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021808883 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.68         |\n",
      "|    n_updates            | 23980        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | 0.8555318    |\n",
      "|    std                  | 39           |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2400         |\n",
      "|    time_elapsed         | 44468        |\n",
      "|    total_timesteps      | 4915200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006576966 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 23990        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 4.4998274    |\n",
      "|    std                  | 39           |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2953617.06\n",
      "total_reward: 1953617.06\n",
      "total_cost: 123477.51\n",
      "total_trades: 58227\n",
      "Sharpe: 0.586\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2401          |\n",
      "|    time_elapsed         | 44486         |\n",
      "|    total_timesteps      | 4917248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013482542 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.72          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.78          |\n",
      "|    n_updates            | 24000         |\n",
      "|    policy_gradient_loss | -0.000804     |\n",
      "|    reward               | -2.8499558    |\n",
      "|    std                  | 39            |\n",
      "|    value_loss           | 29.2          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2402         |\n",
      "|    time_elapsed         | 44505        |\n",
      "|    total_timesteps      | 4919296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037519336 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.75         |\n",
      "|    n_updates            | 24010        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    reward               | -1.8682517   |\n",
      "|    std                  | 39.2         |\n",
      "|    value_loss           | 14.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2403         |\n",
      "|    time_elapsed         | 44523        |\n",
      "|    total_timesteps      | 4921344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010496991 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.55         |\n",
      "|    n_updates            | 24020        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -0.5160203   |\n",
      "|    std                  | 39.3         |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2404          |\n",
      "|    time_elapsed         | 44541         |\n",
      "|    total_timesteps      | 4923392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075018243 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.736         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.9          |\n",
      "|    n_updates            | 24030         |\n",
      "|    policy_gradient_loss | -0.00315      |\n",
      "|    reward               | -0.15482728   |\n",
      "|    std                  | 39.3          |\n",
      "|    value_loss           | 26.4          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2405          |\n",
      "|    time_elapsed         | 44560         |\n",
      "|    total_timesteps      | 4925440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042695794 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.615         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.24          |\n",
      "|    n_updates            | 24040         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | 0.56393117    |\n",
      "|    std                  | 39.4          |\n",
      "|    value_loss           | 22.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2406        |\n",
      "|    time_elapsed         | 44578       |\n",
      "|    total_timesteps      | 4927488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001364107 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.3         |\n",
      "|    n_updates            | 24050       |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    reward               | -2.423636   |\n",
      "|    std                  | 39.5        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2407          |\n",
      "|    time_elapsed         | 44596         |\n",
      "|    total_timesteps      | 4929536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035602594 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.585         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.7          |\n",
      "|    n_updates            | 24060         |\n",
      "|    policy_gradient_loss | -0.00189      |\n",
      "|    reward               | 0.74602085    |\n",
      "|    std                  | 39.5          |\n",
      "|    value_loss           | 25.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2408         |\n",
      "|    time_elapsed         | 44614        |\n",
      "|    total_timesteps      | 4931584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015355558 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 24070        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -1.1866984   |\n",
      "|    std                  | 39.5         |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2409         |\n",
      "|    time_elapsed         | 44633        |\n",
      "|    total_timesteps      | 4933632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068828557 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.97         |\n",
      "|    n_updates            | 24080        |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    reward               | 0.8539371    |\n",
      "|    std                  | 39.5         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2410        |\n",
      "|    time_elapsed         | 44651       |\n",
      "|    total_timesteps      | 4935680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001415089 |\n",
      "|    clip_fraction        | 0.000635    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 24090       |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | -0.14272642 |\n",
      "|    std                  | 39.6        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2411          |\n",
      "|    time_elapsed         | 44670         |\n",
      "|    total_timesteps      | 4937728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032209174 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.581         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.1          |\n",
      "|    n_updates            | 24100         |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    reward               | -3.5847337    |\n",
      "|    std                  | 39.6          |\n",
      "|    value_loss           | 43.6          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2412          |\n",
      "|    time_elapsed         | 44688         |\n",
      "|    total_timesteps      | 4939776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082874903 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.457         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.7          |\n",
      "|    n_updates            | 24110         |\n",
      "|    policy_gradient_loss | -0.00254      |\n",
      "|    reward               | 0.060773972   |\n",
      "|    std                  | 39.7          |\n",
      "|    value_loss           | 30.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2413          |\n",
      "|    time_elapsed         | 44706         |\n",
      "|    total_timesteps      | 4941824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086456735 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.607         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.2          |\n",
      "|    n_updates            | 24120         |\n",
      "|    policy_gradient_loss | -0.00264      |\n",
      "|    reward               | 0.09698736    |\n",
      "|    std                  | 39.8          |\n",
      "|    value_loss           | 28            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2414          |\n",
      "|    time_elapsed         | 44725         |\n",
      "|    total_timesteps      | 4943872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028187942 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.632         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.2          |\n",
      "|    n_updates            | 24130         |\n",
      "|    policy_gradient_loss | -0.00149      |\n",
      "|    reward               | -0.5792317    |\n",
      "|    std                  | 39.8          |\n",
      "|    value_loss           | 40.8          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3347224.69\n",
      "total_reward: 2347224.69\n",
      "total_cost: 144996.72\n",
      "total_trades: 59465\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2415          |\n",
      "|    time_elapsed         | 44743         |\n",
      "|    total_timesteps      | 4945920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037674292 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.566         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.8          |\n",
      "|    n_updates            | 24140         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | -1.3907517    |\n",
      "|    std                  | 39.8          |\n",
      "|    value_loss           | 39.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2416         |\n",
      "|    time_elapsed         | 44761        |\n",
      "|    total_timesteps      | 4947968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012230857 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.39         |\n",
      "|    n_updates            | 24150        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -0.4471364   |\n",
      "|    std                  | 39.9         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2417         |\n",
      "|    time_elapsed         | 44779        |\n",
      "|    total_timesteps      | 4950016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006214434 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 24160        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | 1.219828     |\n",
      "|    std                  | 40           |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2418          |\n",
      "|    time_elapsed         | 44797         |\n",
      "|    total_timesteps      | 4952064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041239327 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.554         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.35          |\n",
      "|    n_updates            | 24170         |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | 0.3622053     |\n",
      "|    std                  | 40            |\n",
      "|    value_loss           | 32.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2419         |\n",
      "|    time_elapsed         | 44815        |\n",
      "|    total_timesteps      | 4954112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026864298 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.43         |\n",
      "|    n_updates            | 24180        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | -0.016840342 |\n",
      "|    std                  | 40.1         |\n",
      "|    value_loss           | 17.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2420         |\n",
      "|    time_elapsed         | 44835        |\n",
      "|    total_timesteps      | 4956160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019596333 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.46         |\n",
      "|    n_updates            | 24190        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | 0.5880841    |\n",
      "|    std                  | 40.1         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2421          |\n",
      "|    time_elapsed         | 44854         |\n",
      "|    total_timesteps      | 4958208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022124546 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.659         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.2          |\n",
      "|    n_updates            | 24200         |\n",
      "|    policy_gradient_loss | -0.000872     |\n",
      "|    reward               | -1.6236476    |\n",
      "|    std                  | 40.1          |\n",
      "|    value_loss           | 35.6          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2422         |\n",
      "|    time_elapsed         | 44874        |\n",
      "|    total_timesteps      | 4960256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011360949 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.18         |\n",
      "|    n_updates            | 24210        |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    reward               | -0.15354423  |\n",
      "|    std                  | 40.1         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2423       |\n",
      "|    time_elapsed         | 44892      |\n",
      "|    total_timesteps      | 4962304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00149697 |\n",
      "|    clip_fraction        | 0.000391   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -147       |\n",
      "|    explained_variance   | 0.522      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.65       |\n",
      "|    n_updates            | 24220      |\n",
      "|    policy_gradient_loss | -0.00323   |\n",
      "|    reward               | -0.7053628 |\n",
      "|    std                  | 40.1       |\n",
      "|    value_loss           | 20.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2424         |\n",
      "|    time_elapsed         | 44911        |\n",
      "|    total_timesteps      | 4964352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009227303 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.54         |\n",
      "|    n_updates            | 24230        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | 1.9287951    |\n",
      "|    std                  | 40.1         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2425         |\n",
      "|    time_elapsed         | 44930        |\n",
      "|    total_timesteps      | 4966400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005621783 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 24240        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | -0.18621065  |\n",
      "|    std                  | 40.2         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2426         |\n",
      "|    time_elapsed         | 44948        |\n",
      "|    total_timesteps      | 4968448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055395076 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.41         |\n",
      "|    n_updates            | 24250        |\n",
      "|    policy_gradient_loss | -0.00874     |\n",
      "|    reward               | -0.013292641 |\n",
      "|    std                  | 40.1         |\n",
      "|    value_loss           | 13.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2427        |\n",
      "|    time_elapsed         | 44967       |\n",
      "|    total_timesteps      | 4970496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001514961 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 24260       |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    reward               | 0.09281512  |\n",
      "|    std                  | 40.2        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2428          |\n",
      "|    time_elapsed         | 44986         |\n",
      "|    total_timesteps      | 4972544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016147285 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.541         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.6          |\n",
      "|    n_updates            | 24270         |\n",
      "|    policy_gradient_loss | -0.000918     |\n",
      "|    reward               | 5.4279957     |\n",
      "|    std                  | 40.2          |\n",
      "|    value_loss           | 37.9          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2759968.33\n",
      "total_reward: 1759968.33\n",
      "total_cost: 156281.58\n",
      "total_trades: 60425\n",
      "Sharpe: 0.554\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2429         |\n",
      "|    time_elapsed         | 45004        |\n",
      "|    total_timesteps      | 4974592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006684052 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.12         |\n",
      "|    n_updates            | 24280        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    reward               | 0.5117675    |\n",
      "|    std                  | 40.2         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2430         |\n",
      "|    time_elapsed         | 45023        |\n",
      "|    total_timesteps      | 4976640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017664384 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.53         |\n",
      "|    n_updates            | 24290        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | 1.2599041    |\n",
      "|    std                  | 40.4         |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2431          |\n",
      "|    time_elapsed         | 45042         |\n",
      "|    total_timesteps      | 4978688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034871153 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.643         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.7          |\n",
      "|    n_updates            | 24300         |\n",
      "|    policy_gradient_loss | -0.00197      |\n",
      "|    reward               | -0.11917577   |\n",
      "|    std                  | 40.4          |\n",
      "|    value_loss           | 30.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2432          |\n",
      "|    time_elapsed         | 45060         |\n",
      "|    total_timesteps      | 4980736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018626009 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.653         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.6          |\n",
      "|    n_updates            | 24310         |\n",
      "|    policy_gradient_loss | -0.00136      |\n",
      "|    reward               | -1.3833474    |\n",
      "|    std                  | 40.4          |\n",
      "|    value_loss           | 26.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2433         |\n",
      "|    time_elapsed         | 45079        |\n",
      "|    total_timesteps      | 4982784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008370043 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 24320        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 0.047227476  |\n",
      "|    std                  | 40.5         |\n",
      "|    value_loss           | 20.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2434         |\n",
      "|    time_elapsed         | 45097        |\n",
      "|    total_timesteps      | 4984832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002673976 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 24330        |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    reward               | 0.4745422    |\n",
      "|    std                  | 40.5         |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2435         |\n",
      "|    time_elapsed         | 45116        |\n",
      "|    total_timesteps      | 4986880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.106485e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 24340        |\n",
      "|    policy_gradient_loss | -0.000674    |\n",
      "|    reward               | -0.026112394 |\n",
      "|    std                  | 40.5         |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2436         |\n",
      "|    time_elapsed         | 45134        |\n",
      "|    total_timesteps      | 4988928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018409634 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.8          |\n",
      "|    n_updates            | 24350        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -0.018636048 |\n",
      "|    std                  | 40.6         |\n",
      "|    value_loss           | 17.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2437         |\n",
      "|    time_elapsed         | 45153        |\n",
      "|    total_timesteps      | 4990976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012726602 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 24360        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    reward               | 0.6722192    |\n",
      "|    std                  | 40.7         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2438          |\n",
      "|    time_elapsed         | 45172         |\n",
      "|    total_timesteps      | 4993024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053829595 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.709         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.9          |\n",
      "|    n_updates            | 24370         |\n",
      "|    policy_gradient_loss | -0.0014       |\n",
      "|    reward               | -0.63552827   |\n",
      "|    std                  | 40.7          |\n",
      "|    value_loss           | 26.4          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2439          |\n",
      "|    time_elapsed         | 45191         |\n",
      "|    total_timesteps      | 4995072       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031308492 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.697         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.15          |\n",
      "|    n_updates            | 24380         |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    reward               | 1.5957456     |\n",
      "|    std                  | 40.8          |\n",
      "|    value_loss           | 23.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2440         |\n",
      "|    time_elapsed         | 45211        |\n",
      "|    total_timesteps      | 4997120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038079985 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.43         |\n",
      "|    n_updates            | 24390        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | 0.4900045    |\n",
      "|    std                  | 40.9         |\n",
      "|    value_loss           | 18.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2441         |\n",
      "|    time_elapsed         | 45230        |\n",
      "|    total_timesteps      | 4999168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014134675 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.96         |\n",
      "|    n_updates            | 24400        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | -0.5513939   |\n",
      "|    std                  | 41.1         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2442          |\n",
      "|    time_elapsed         | 45251         |\n",
      "|    total_timesteps      | 5001216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014931607 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.742         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.6          |\n",
      "|    n_updates            | 24410         |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    reward               | -0.9568794    |\n",
      "|    std                  | 41.1          |\n",
      "|    value_loss           | 26.4          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2979060.10\n",
      "total_reward: 1979060.10\n",
      "total_cost: 162337.12\n",
      "total_trades: 60565\n",
      "Sharpe: 0.595\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2443         |\n",
      "|    time_elapsed         | 45269        |\n",
      "|    total_timesteps      | 5003264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025506548 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.71         |\n",
      "|    n_updates            | 24420        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | -0.71285737  |\n",
      "|    std                  | 41.2         |\n",
      "|    value_loss           | 16.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2444         |\n",
      "|    time_elapsed         | 45289        |\n",
      "|    total_timesteps      | 5005312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007045754 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 24430        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | -1.3861017   |\n",
      "|    std                  | 41.2         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2445         |\n",
      "|    time_elapsed         | 45307        |\n",
      "|    total_timesteps      | 5007360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004414575 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 24440        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | -0.88035625  |\n",
      "|    std                  | 41.3         |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2446         |\n",
      "|    time_elapsed         | 45327        |\n",
      "|    total_timesteps      | 5009408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009543565 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 24450        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 0.52885926   |\n",
      "|    std                  | 41.3         |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2447         |\n",
      "|    time_elapsed         | 45346        |\n",
      "|    total_timesteps      | 5011456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013519155 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.4          |\n",
      "|    n_updates            | 24460        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | 0.22789994   |\n",
      "|    std                  | 41.4         |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2448         |\n",
      "|    time_elapsed         | 45365        |\n",
      "|    total_timesteps      | 5013504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010983506 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.1          |\n",
      "|    n_updates            | 24470        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | 13.918699    |\n",
      "|    std                  | 41.4         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2449        |\n",
      "|    time_elapsed         | 45383       |\n",
      "|    total_timesteps      | 5015552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0010893   |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 24480       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    reward               | -0.08105207 |\n",
      "|    std                  | 41.6        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2450         |\n",
      "|    time_elapsed         | 45402        |\n",
      "|    total_timesteps      | 5017600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065207295 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.59         |\n",
      "|    n_updates            | 24490        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    reward               | 0.09642424   |\n",
      "|    std                  | 41.7         |\n",
      "|    value_loss           | 14.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2451         |\n",
      "|    time_elapsed         | 45420        |\n",
      "|    total_timesteps      | 5019648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008413902 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.24         |\n",
      "|    n_updates            | 24500        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | 0.4190649    |\n",
      "|    std                  | 41.7         |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2452          |\n",
      "|    time_elapsed         | 45439         |\n",
      "|    total_timesteps      | 5021696       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016996625 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.695         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.5          |\n",
      "|    n_updates            | 24510         |\n",
      "|    policy_gradient_loss | -0.000965     |\n",
      "|    reward               | -2.1923344    |\n",
      "|    std                  | 41.7          |\n",
      "|    value_loss           | 28.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2453          |\n",
      "|    time_elapsed         | 45457         |\n",
      "|    total_timesteps      | 5023744       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00097031705 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.69          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.22          |\n",
      "|    n_updates            | 24520         |\n",
      "|    policy_gradient_loss | -0.00243      |\n",
      "|    reward               | 1.9379056     |\n",
      "|    std                  | 41.8          |\n",
      "|    value_loss           | 20.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2454         |\n",
      "|    time_elapsed         | 45475        |\n",
      "|    total_timesteps      | 5025792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013811564 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.06         |\n",
      "|    n_updates            | 24530        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | -0.7343394   |\n",
      "|    std                  | 41.9         |\n",
      "|    value_loss           | 15.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2455          |\n",
      "|    time_elapsed         | 45494         |\n",
      "|    total_timesteps      | 5027840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023725157 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.455         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.8          |\n",
      "|    n_updates            | 24540         |\n",
      "|    policy_gradient_loss | -0.000937     |\n",
      "|    reward               | 1.8573178     |\n",
      "|    std                  | 41.9          |\n",
      "|    value_loss           | 35.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2456        |\n",
      "|    time_elapsed         | 45513       |\n",
      "|    total_timesteps      | 5029888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000379154 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 24550       |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    reward               | 2.5869725   |\n",
      "|    std                  | 41.9        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3133908.06\n",
      "total_reward: 2133908.06\n",
      "total_cost: 142042.21\n",
      "total_trades: 58858\n",
      "Sharpe: 0.614\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2457         |\n",
      "|    time_elapsed         | 45532        |\n",
      "|    total_timesteps      | 5031936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025307783 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.36         |\n",
      "|    n_updates            | 24560        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | -1.3445907   |\n",
      "|    std                  | 42           |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2458         |\n",
      "|    time_elapsed         | 45551        |\n",
      "|    total_timesteps      | 5033984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013672283 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 24570        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 0.088084824  |\n",
      "|    std                  | 42           |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2459          |\n",
      "|    time_elapsed         | 45569         |\n",
      "|    total_timesteps      | 5036032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036164554 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.701         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11            |\n",
      "|    n_updates            | 24580         |\n",
      "|    policy_gradient_loss | -0.000909     |\n",
      "|    reward               | -2.5389361    |\n",
      "|    std                  | 42.1          |\n",
      "|    value_loss           | 25.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2460        |\n",
      "|    time_elapsed         | 45588       |\n",
      "|    total_timesteps      | 5038080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001362853 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.18        |\n",
      "|    n_updates            | 24590       |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    reward               | -0.5225632  |\n",
      "|    std                  | 42.1        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2461          |\n",
      "|    time_elapsed         | 45606         |\n",
      "|    total_timesteps      | 5040128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079683634 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.701         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.43          |\n",
      "|    n_updates            | 24600         |\n",
      "|    policy_gradient_loss | -0.00277      |\n",
      "|    reward               | -2.2772036    |\n",
      "|    std                  | 42.1          |\n",
      "|    value_loss           | 21.1          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2462         |\n",
      "|    time_elapsed         | 45625        |\n",
      "|    total_timesteps      | 5042176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001906353 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.09         |\n",
      "|    n_updates            | 24610        |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | 1.1622146    |\n",
      "|    std                  | 42.1         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2463         |\n",
      "|    time_elapsed         | 45644        |\n",
      "|    total_timesteps      | 5044224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008883055 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 24620        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | -0.7467335   |\n",
      "|    std                  | 42.2         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2464         |\n",
      "|    time_elapsed         | 45662        |\n",
      "|    total_timesteps      | 5046272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028269019 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.28         |\n",
      "|    n_updates            | 24630        |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    reward               | 3.0473485    |\n",
      "|    std                  | 42.2         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2465          |\n",
      "|    time_elapsed         | 45680         |\n",
      "|    total_timesteps      | 5048320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078410114 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.644         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.4          |\n",
      "|    n_updates            | 24640         |\n",
      "|    policy_gradient_loss | -0.0024       |\n",
      "|    reward               | 0.80862075    |\n",
      "|    std                  | 42.3          |\n",
      "|    value_loss           | 24.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2466          |\n",
      "|    time_elapsed         | 45698         |\n",
      "|    total_timesteps      | 5050368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088913704 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.708         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.81          |\n",
      "|    n_updates            | 24650         |\n",
      "|    policy_gradient_loss | -0.00242      |\n",
      "|    reward               | 0.040534105   |\n",
      "|    std                  | 42.3          |\n",
      "|    value_loss           | 28.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2467        |\n",
      "|    time_elapsed         | 45716       |\n",
      "|    total_timesteps      | 5052416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004654142 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.82        |\n",
      "|    n_updates            | 24660       |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | -0.267925   |\n",
      "|    std                  | 42.5        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2468          |\n",
      "|    time_elapsed         | 45734         |\n",
      "|    total_timesteps      | 5054464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039360658 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.688         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.9          |\n",
      "|    n_updates            | 24670         |\n",
      "|    policy_gradient_loss | -0.0013       |\n",
      "|    reward               | -0.5394647    |\n",
      "|    std                  | 42.6          |\n",
      "|    value_loss           | 25.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2469          |\n",
      "|    time_elapsed         | 45752         |\n",
      "|    total_timesteps      | 5056512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035365327 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.746         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17            |\n",
      "|    n_updates            | 24680         |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    reward               | -2.508441     |\n",
      "|    std                  | 42.6          |\n",
      "|    value_loss           | 27.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2470          |\n",
      "|    time_elapsed         | 45771         |\n",
      "|    total_timesteps      | 5058560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022895957 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.652         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.7          |\n",
      "|    n_updates            | 24690         |\n",
      "|    policy_gradient_loss | -0.00153      |\n",
      "|    reward               | 0.75596184    |\n",
      "|    std                  | 42.6          |\n",
      "|    value_loss           | 26.1          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3116082.37\n",
      "total_reward: 2116082.37\n",
      "total_cost: 166790.73\n",
      "total_trades: 60808\n",
      "Sharpe: 0.625\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2471         |\n",
      "|    time_elapsed         | 45790        |\n",
      "|    total_timesteps      | 5060608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012470039 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.51         |\n",
      "|    n_updates            | 24700        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | 1.2693946    |\n",
      "|    std                  | 42.6         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2472         |\n",
      "|    time_elapsed         | 45808        |\n",
      "|    total_timesteps      | 5062656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004703769 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 24710        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | 4.1993623    |\n",
      "|    std                  | 42.7         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2473          |\n",
      "|    time_elapsed         | 45827         |\n",
      "|    total_timesteps      | 5064704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082781765 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.715         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.83          |\n",
      "|    n_updates            | 24720         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | -6.8346004    |\n",
      "|    std                  | 42.7          |\n",
      "|    value_loss           | 25.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2474         |\n",
      "|    time_elapsed         | 45845        |\n",
      "|    total_timesteps      | 5066752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012977716 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.89         |\n",
      "|    n_updates            | 24730        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -2.4668171   |\n",
      "|    std                  | 42.7         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2475         |\n",
      "|    time_elapsed         | 45863        |\n",
      "|    total_timesteps      | 5068800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007151727 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.53         |\n",
      "|    n_updates            | 24740        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | -2.1254637   |\n",
      "|    std                  | 42.7         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2476          |\n",
      "|    time_elapsed         | 45881         |\n",
      "|    total_timesteps      | 5070848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029367584 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.695         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.3          |\n",
      "|    n_updates            | 24750         |\n",
      "|    policy_gradient_loss | -0.00177      |\n",
      "|    reward               | -1.86894      |\n",
      "|    std                  | 42.7          |\n",
      "|    value_loss           | 25.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2477         |\n",
      "|    time_elapsed         | 45900        |\n",
      "|    total_timesteps      | 5072896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014250003 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 24760        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | 0.22245772   |\n",
      "|    std                  | 42.8         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2478         |\n",
      "|    time_elapsed         | 45918        |\n",
      "|    total_timesteps      | 5074944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036221314 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.49         |\n",
      "|    n_updates            | 24770        |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    reward               | -0.784061    |\n",
      "|    std                  | 43           |\n",
      "|    value_loss           | 17.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2479          |\n",
      "|    time_elapsed         | 45937         |\n",
      "|    total_timesteps      | 5076992       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.8145945e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.692         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.8          |\n",
      "|    n_updates            | 24780         |\n",
      "|    policy_gradient_loss | -0.000823     |\n",
      "|    reward               | 5.9388094     |\n",
      "|    std                  | 43            |\n",
      "|    value_loss           | 32.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2480         |\n",
      "|    time_elapsed         | 45955        |\n",
      "|    total_timesteps      | 5079040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003947673 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.86         |\n",
      "|    n_updates            | 24790        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    reward               | -1.3797392   |\n",
      "|    std                  | 43           |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2481         |\n",
      "|    time_elapsed         | 45975        |\n",
      "|    total_timesteps      | 5081088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015069391 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.91         |\n",
      "|    n_updates            | 24800        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | 2.3535333    |\n",
      "|    std                  | 43.1         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2482          |\n",
      "|    time_elapsed         | 45994         |\n",
      "|    total_timesteps      | 5083136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046132773 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.764         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.41          |\n",
      "|    n_updates            | 24810         |\n",
      "|    policy_gradient_loss | -0.00224      |\n",
      "|    reward               | 0.16861723    |\n",
      "|    std                  | 43.2          |\n",
      "|    value_loss           | 25.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2483          |\n",
      "|    time_elapsed         | 46013         |\n",
      "|    total_timesteps      | 5085184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013635622 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.743         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.2          |\n",
      "|    n_updates            | 24820         |\n",
      "|    policy_gradient_loss | -0.000773     |\n",
      "|    reward               | 3.4294946     |\n",
      "|    std                  | 43.2          |\n",
      "|    value_loss           | 33.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2484        |\n",
      "|    time_elapsed         | 46031       |\n",
      "|    total_timesteps      | 5087232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002048885 |\n",
      "|    clip_fraction        | 0.00161     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.32        |\n",
      "|    n_updates            | 24830       |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    reward               | 0.075442836 |\n",
      "|    std                  | 43.4        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3105027.52\n",
      "total_reward: 2105027.52\n",
      "total_cost: 171000.30\n",
      "total_trades: 61570\n",
      "Sharpe: 0.616\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2485         |\n",
      "|    time_elapsed         | 46049        |\n",
      "|    total_timesteps      | 5089280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018324422 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.91         |\n",
      "|    n_updates            | 24840        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | 0.021829044  |\n",
      "|    std                  | 43.5         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2486          |\n",
      "|    time_elapsed         | 46067         |\n",
      "|    total_timesteps      | 5091328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075562694 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.777         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.8          |\n",
      "|    n_updates            | 24850         |\n",
      "|    policy_gradient_loss | -0.00261      |\n",
      "|    reward               | 2.4375203     |\n",
      "|    std                  | 43.6          |\n",
      "|    value_loss           | 25.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2487          |\n",
      "|    time_elapsed         | 46086         |\n",
      "|    total_timesteps      | 5093376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046056468 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.687         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.79          |\n",
      "|    n_updates            | 24860         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | 0.29311743    |\n",
      "|    std                  | 43.6          |\n",
      "|    value_loss           | 24.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2488          |\n",
      "|    time_elapsed         | 46104         |\n",
      "|    total_timesteps      | 5095424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096648687 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.666         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.54          |\n",
      "|    n_updates            | 24870         |\n",
      "|    policy_gradient_loss | -0.00228      |\n",
      "|    reward               | -0.6517276    |\n",
      "|    std                  | 43.6          |\n",
      "|    value_loss           | 19.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2489          |\n",
      "|    time_elapsed         | 46123         |\n",
      "|    total_timesteps      | 5097472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036701947 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.637         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.02          |\n",
      "|    n_updates            | 24880         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | -0.41652694   |\n",
      "|    std                  | 43.7          |\n",
      "|    value_loss           | 26.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2490          |\n",
      "|    time_elapsed         | 46142         |\n",
      "|    total_timesteps      | 5099520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030131757 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.735         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.2          |\n",
      "|    n_updates            | 24890         |\n",
      "|    policy_gradient_loss | -0.00119      |\n",
      "|    reward               | 0.8053406     |\n",
      "|    std                  | 43.7          |\n",
      "|    value_loss           | 27.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2491         |\n",
      "|    time_elapsed         | 46161        |\n",
      "|    total_timesteps      | 5101568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017781022 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.75         |\n",
      "|    n_updates            | 24900        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | 2.239112     |\n",
      "|    std                  | 43.8         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2492         |\n",
      "|    time_elapsed         | 46180        |\n",
      "|    total_timesteps      | 5103616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006946903 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 24910        |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    reward               | 2.129556     |\n",
      "|    std                  | 43.9         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2493         |\n",
      "|    time_elapsed         | 46198        |\n",
      "|    total_timesteps      | 5105664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001017804 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 24920        |\n",
      "|    policy_gradient_loss | -0.00048     |\n",
      "|    reward               | 1.2212797    |\n",
      "|    std                  | 43.9         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2494          |\n",
      "|    time_elapsed         | 46217         |\n",
      "|    total_timesteps      | 5107712       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023231399 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.741         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.12          |\n",
      "|    n_updates            | 24930         |\n",
      "|    policy_gradient_loss | -0.000794     |\n",
      "|    reward               | 1.3341407     |\n",
      "|    std                  | 43.9          |\n",
      "|    value_loss           | 22            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2495         |\n",
      "|    time_elapsed         | 46236        |\n",
      "|    total_timesteps      | 5109760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014672887 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.81         |\n",
      "|    n_updates            | 24940        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    reward               | 2.7284868    |\n",
      "|    std                  | 44           |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2496         |\n",
      "|    time_elapsed         | 46254        |\n",
      "|    total_timesteps      | 5111808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006115923 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 24950        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | -0.6154011   |\n",
      "|    std                  | 44.1         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2497          |\n",
      "|    time_elapsed         | 46272         |\n",
      "|    total_timesteps      | 5113856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012909755 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.411         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.7          |\n",
      "|    n_updates            | 24960         |\n",
      "|    policy_gradient_loss | -0.000716     |\n",
      "|    reward               | -2.7034163    |\n",
      "|    std                  | 44.1          |\n",
      "|    value_loss           | 38.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2498         |\n",
      "|    time_elapsed         | 46291        |\n",
      "|    total_timesteps      | 5115904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025948458 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.05         |\n",
      "|    n_updates            | 24970        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | 2.2311363    |\n",
      "|    std                  | 44.2         |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3067288.02\n",
      "total_reward: 2067288.02\n",
      "total_cost: 142393.99\n",
      "total_trades: 59486\n",
      "Sharpe: 0.622\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2499         |\n",
      "|    time_elapsed         | 46309        |\n",
      "|    total_timesteps      | 5117952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017498407 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.26         |\n",
      "|    n_updates            | 24980        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | -0.8540255   |\n",
      "|    std                  | 44.3         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2500         |\n",
      "|    time_elapsed         | 46328        |\n",
      "|    total_timesteps      | 5120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008466997 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 24990        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 2.7207887    |\n",
      "|    std                  | 44.3         |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2501         |\n",
      "|    time_elapsed         | 46346        |\n",
      "|    total_timesteps      | 5122048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011479198 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.09         |\n",
      "|    n_updates            | 25000        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | 1.3608131    |\n",
      "|    std                  | 44.4         |\n",
      "|    value_loss           | 19           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2502         |\n",
      "|    time_elapsed         | 46364        |\n",
      "|    total_timesteps      | 5124096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023101962 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.59         |\n",
      "|    n_updates            | 25010        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | -0.89370406  |\n",
      "|    std                  | 44.4         |\n",
      "|    value_loss           | 18.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2503          |\n",
      "|    time_elapsed         | 46383         |\n",
      "|    total_timesteps      | 5126144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024325654 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.607         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.1          |\n",
      "|    n_updates            | 25020         |\n",
      "|    policy_gradient_loss | -0.00122      |\n",
      "|    reward               | 2.6257849     |\n",
      "|    std                  | 44.4          |\n",
      "|    value_loss           | 35.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2504          |\n",
      "|    time_elapsed         | 46402         |\n",
      "|    total_timesteps      | 5128192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020258539 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.673         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.5          |\n",
      "|    n_updates            | 25030         |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | 1.8129165     |\n",
      "|    std                  | 44.4          |\n",
      "|    value_loss           | 29.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2505        |\n",
      "|    time_elapsed         | 46420       |\n",
      "|    total_timesteps      | 5130240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002080754 |\n",
      "|    clip_fraction        | 0.00112     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.1         |\n",
      "|    n_updates            | 25040       |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    reward               | 0.29572773  |\n",
      "|    std                  | 44.5        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2506         |\n",
      "|    time_elapsed         | 46438        |\n",
      "|    total_timesteps      | 5132288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010238849 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.46         |\n",
      "|    n_updates            | 25050        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | -0.16359572  |\n",
      "|    std                  | 44.6         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2507         |\n",
      "|    time_elapsed         | 46457        |\n",
      "|    total_timesteps      | 5134336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001983812 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 25060        |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    reward               | 3.8022416    |\n",
      "|    std                  | 44.6         |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2508         |\n",
      "|    time_elapsed         | 46475        |\n",
      "|    total_timesteps      | 5136384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020728332 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.28         |\n",
      "|    n_updates            | 25070        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | 0.18327023   |\n",
      "|    std                  | 44.7         |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2509          |\n",
      "|    time_elapsed         | 46493         |\n",
      "|    total_timesteps      | 5138432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034475833 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.783         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.4           |\n",
      "|    n_updates            | 25080         |\n",
      "|    policy_gradient_loss | -0.00133      |\n",
      "|    reward               | 2.125666      |\n",
      "|    std                  | 44.7          |\n",
      "|    value_loss           | 21.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2510          |\n",
      "|    time_elapsed         | 46511         |\n",
      "|    total_timesteps      | 5140480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035460948 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.769         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.5          |\n",
      "|    n_updates            | 25090         |\n",
      "|    policy_gradient_loss | -0.00158      |\n",
      "|    reward               | 12.05471      |\n",
      "|    std                  | 44.7          |\n",
      "|    value_loss           | 25.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2511          |\n",
      "|    time_elapsed         | 46530         |\n",
      "|    total_timesteps      | 5142528       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065358763 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.503         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.3          |\n",
      "|    n_updates            | 25100         |\n",
      "|    policy_gradient_loss | -0.00174      |\n",
      "|    reward               | -5.900965     |\n",
      "|    std                  | 44.7          |\n",
      "|    value_loss           | 29.2          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2512         |\n",
      "|    time_elapsed         | 46548        |\n",
      "|    total_timesteps      | 5144576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019627525 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 25110        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | -1.9566956   |\n",
      "|    std                  | 44.7         |\n",
      "|    value_loss           | 22.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2513         |\n",
      "|    time_elapsed         | 46567        |\n",
      "|    total_timesteps      | 5146624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007689474 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 25120        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    reward               | 1.0273029    |\n",
      "|    std                  | 44.7         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3156837.70\n",
      "total_reward: 2156837.70\n",
      "total_cost: 132368.56\n",
      "total_trades: 58928\n",
      "Sharpe: 0.625\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2514         |\n",
      "|    time_elapsed         | 46585        |\n",
      "|    total_timesteps      | 5148672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005806263 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 25130        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | -1.2573743   |\n",
      "|    std                  | 44.8         |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2515         |\n",
      "|    time_elapsed         | 46604        |\n",
      "|    total_timesteps      | 5150720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009838748 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.03         |\n",
      "|    n_updates            | 25140        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | 0.37362388   |\n",
      "|    std                  | 44.9         |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2516         |\n",
      "|    time_elapsed         | 46622        |\n",
      "|    total_timesteps      | 5152768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011387069 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.76         |\n",
      "|    n_updates            | 25150        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    reward               | -2.1495688   |\n",
      "|    std                  | 44.9         |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2517         |\n",
      "|    time_elapsed         | 46641        |\n",
      "|    total_timesteps      | 5154816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.589593e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 25160        |\n",
      "|    policy_gradient_loss | -0.000382    |\n",
      "|    reward               | 1.5351181    |\n",
      "|    std                  | 44.9         |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2518         |\n",
      "|    time_elapsed         | 46659        |\n",
      "|    total_timesteps      | 5156864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009772117 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 25170        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | -1.2062593   |\n",
      "|    std                  | 44.9         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2519       |\n",
      "|    time_elapsed         | 46678      |\n",
      "|    total_timesteps      | 5158912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00216618 |\n",
      "|    clip_fraction        | 0.00083    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -150       |\n",
      "|    explained_variance   | 0.592      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.79       |\n",
      "|    n_updates            | 25180      |\n",
      "|    policy_gradient_loss | -0.00422   |\n",
      "|    reward               | -4.2194285 |\n",
      "|    std                  | 44.9       |\n",
      "|    value_loss           | 20.4       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2520          |\n",
      "|    time_elapsed         | 46696         |\n",
      "|    total_timesteps      | 5160960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041317256 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.752         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.6          |\n",
      "|    n_updates            | 25190         |\n",
      "|    policy_gradient_loss | -0.00224      |\n",
      "|    reward               | 2.1266248     |\n",
      "|    std                  | 44.9          |\n",
      "|    value_loss           | 31            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2521          |\n",
      "|    time_elapsed         | 46714         |\n",
      "|    total_timesteps      | 5163008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035982646 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.641         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.4          |\n",
      "|    n_updates            | 25200         |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    reward               | -0.096858665  |\n",
      "|    std                  | 45            |\n",
      "|    value_loss           | 33.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2522         |\n",
      "|    time_elapsed         | 46733        |\n",
      "|    total_timesteps      | 5165056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021525642 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.93         |\n",
      "|    n_updates            | 25210        |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | 0.7235984    |\n",
      "|    std                  | 45.1         |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2523          |\n",
      "|    time_elapsed         | 46752         |\n",
      "|    total_timesteps      | 5167104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061394076 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.1          |\n",
      "|    n_updates            | 25220         |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    reward               | -0.16683908   |\n",
      "|    std                  | 45.2          |\n",
      "|    value_loss           | 25.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2524         |\n",
      "|    time_elapsed         | 46771        |\n",
      "|    total_timesteps      | 5169152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.387017e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 25230        |\n",
      "|    policy_gradient_loss | -0.000625    |\n",
      "|    reward               | -1.8774221   |\n",
      "|    std                  | 45.2         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2525         |\n",
      "|    time_elapsed         | 46790        |\n",
      "|    total_timesteps      | 5171200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012610748 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.92         |\n",
      "|    n_updates            | 25240        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 1.7745316    |\n",
      "|    std                  | 45.2         |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2526         |\n",
      "|    time_elapsed         | 46808        |\n",
      "|    total_timesteps      | 5173248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012389161 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.97         |\n",
      "|    n_updates            | 25250        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | 0.6719995    |\n",
      "|    std                  | 45.3         |\n",
      "|    value_loss           | 18.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2527          |\n",
      "|    time_elapsed         | 46828         |\n",
      "|    total_timesteps      | 5175296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029338244 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.791         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13            |\n",
      "|    n_updates            | 25260         |\n",
      "|    policy_gradient_loss | -0.00145      |\n",
      "|    reward               | -1.2085866    |\n",
      "|    std                  | 45.3          |\n",
      "|    value_loss           | 27.9          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3181437.28\n",
      "total_reward: 2181437.28\n",
      "total_cost: 139375.81\n",
      "total_trades: 59570\n",
      "Sharpe: 0.636\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2528         |\n",
      "|    time_elapsed         | 46847        |\n",
      "|    total_timesteps      | 5177344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004657044 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 25270        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    reward               | 1.3975185    |\n",
      "|    std                  | 45.4         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2529        |\n",
      "|    time_elapsed         | 46865       |\n",
      "|    total_timesteps      | 5179392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000908002 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 25280       |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | 0.113681    |\n",
      "|    std                  | 45.4        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2530         |\n",
      "|    time_elapsed         | 46883        |\n",
      "|    total_timesteps      | 5181440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012916385 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.96         |\n",
      "|    n_updates            | 25290        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | 0.19365194   |\n",
      "|    std                  | 45.4         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2531          |\n",
      "|    time_elapsed         | 46901         |\n",
      "|    total_timesteps      | 5183488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047320273 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.449         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17            |\n",
      "|    n_updates            | 25300         |\n",
      "|    policy_gradient_loss | -0.00191      |\n",
      "|    reward               | 0.68383133    |\n",
      "|    std                  | 45.5          |\n",
      "|    value_loss           | 34.6          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2532         |\n",
      "|    time_elapsed         | 46920        |\n",
      "|    total_timesteps      | 5185536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021111723 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.36         |\n",
      "|    n_updates            | 25310        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | 0.37868914   |\n",
      "|    std                  | 45.6         |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2533         |\n",
      "|    time_elapsed         | 46941        |\n",
      "|    total_timesteps      | 5187584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020190652 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 25320        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | 1.873174     |\n",
      "|    std                  | 45.6         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2534          |\n",
      "|    time_elapsed         | 46961         |\n",
      "|    total_timesteps      | 5189632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031143025 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.71          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.8          |\n",
      "|    n_updates            | 25330         |\n",
      "|    policy_gradient_loss | -0.00222      |\n",
      "|    reward               | -5.6053443    |\n",
      "|    std                  | 45.7          |\n",
      "|    value_loss           | 38.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2535          |\n",
      "|    time_elapsed         | 46980         |\n",
      "|    total_timesteps      | 5191680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022953012 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.52          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.49          |\n",
      "|    n_updates            | 25340         |\n",
      "|    policy_gradient_loss | -0.00118      |\n",
      "|    reward               | -2.0106075    |\n",
      "|    std                  | 45.7          |\n",
      "|    value_loss           | 29.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2536        |\n",
      "|    time_elapsed         | 46999       |\n",
      "|    total_timesteps      | 5193728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002777928 |\n",
      "|    clip_fraction        | 0.00229     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.4         |\n",
      "|    n_updates            | 25350       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | 0.18025295  |\n",
      "|    std                  | 45.8        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2537         |\n",
      "|    time_elapsed         | 47018        |\n",
      "|    total_timesteps      | 5195776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010305971 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 25360        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    reward               | -0.6135771   |\n",
      "|    std                  | 45.9         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2538          |\n",
      "|    time_elapsed         | 47037         |\n",
      "|    total_timesteps      | 5197824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034596463 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.664         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.6          |\n",
      "|    n_updates            | 25370         |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    reward               | 1.0004281     |\n",
      "|    std                  | 45.9          |\n",
      "|    value_loss           | 34.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2539         |\n",
      "|    time_elapsed         | 47056        |\n",
      "|    total_timesteps      | 5199872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022959807 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.31         |\n",
      "|    n_updates            | 25380        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | -0.6703548   |\n",
      "|    std                  | 46.1         |\n",
      "|    value_loss           | 18.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2540         |\n",
      "|    time_elapsed         | 47075        |\n",
      "|    total_timesteps      | 5201920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006876445 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 25390        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | 0.61988395   |\n",
      "|    std                  | 46.2         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2541         |\n",
      "|    time_elapsed         | 47094        |\n",
      "|    total_timesteps      | 5203968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001394435 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 25400        |\n",
      "|    policy_gradient_loss | -0.000636    |\n",
      "|    reward               | 0.3801474    |\n",
      "|    std                  | 46.3         |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3143533.14\n",
      "total_reward: 2143533.14\n",
      "total_cost: 215517.78\n",
      "total_trades: 64674\n",
      "Sharpe: 0.641\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2542         |\n",
      "|    time_elapsed         | 47113        |\n",
      "|    total_timesteps      | 5206016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010516907 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 25410        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | -2.3477259   |\n",
      "|    std                  | 46.3         |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2543        |\n",
      "|    time_elapsed         | 47131       |\n",
      "|    total_timesteps      | 5208064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002087464 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.9         |\n",
      "|    n_updates            | 25420       |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    reward               | 0.11958894  |\n",
      "|    std                  | 46.3        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2544          |\n",
      "|    time_elapsed         | 47149         |\n",
      "|    total_timesteps      | 5210112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030674908 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.669         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.9          |\n",
      "|    n_updates            | 25430         |\n",
      "|    policy_gradient_loss | -0.00192      |\n",
      "|    reward               | 1.8045545     |\n",
      "|    std                  | 46.3          |\n",
      "|    value_loss           | 37.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2545          |\n",
      "|    time_elapsed         | 47167         |\n",
      "|    total_timesteps      | 5212160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047651064 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.517         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.1          |\n",
      "|    n_updates            | 25440         |\n",
      "|    policy_gradient_loss | -0.00176      |\n",
      "|    reward               | -0.21062683   |\n",
      "|    std                  | 46.4          |\n",
      "|    value_loss           | 34            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2546          |\n",
      "|    time_elapsed         | 47186         |\n",
      "|    total_timesteps      | 5214208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039443283 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.627         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.3          |\n",
      "|    n_updates            | 25450         |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    reward               | 0.06219567    |\n",
      "|    std                  | 46.4          |\n",
      "|    value_loss           | 28.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2547         |\n",
      "|    time_elapsed         | 47204        |\n",
      "|    total_timesteps      | 5216256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012882502 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 25460        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 0.8944464    |\n",
      "|    std                  | 46.4         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2548          |\n",
      "|    time_elapsed         | 47223         |\n",
      "|    total_timesteps      | 5218304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062410627 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.437         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.7          |\n",
      "|    n_updates            | 25470         |\n",
      "|    policy_gradient_loss | -0.00199      |\n",
      "|    reward               | 2.0614645     |\n",
      "|    std                  | 46.5          |\n",
      "|    value_loss           | 42.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2549         |\n",
      "|    time_elapsed         | 47242        |\n",
      "|    total_timesteps      | 5220352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012311684 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.09         |\n",
      "|    n_updates            | 25480        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | 1.0187956    |\n",
      "|    std                  | 46.6         |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2550         |\n",
      "|    time_elapsed         | 47260        |\n",
      "|    total_timesteps      | 5222400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010093049 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 25490        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 0.50648797   |\n",
      "|    std                  | 46.7         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2551        |\n",
      "|    time_elapsed         | 47280       |\n",
      "|    total_timesteps      | 5224448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000447727 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 25500       |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    reward               | -1.6320552  |\n",
      "|    std                  | 46.7        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2552         |\n",
      "|    time_elapsed         | 47299        |\n",
      "|    total_timesteps      | 5226496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004562277 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.52         |\n",
      "|    n_updates            | 25510        |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    reward               | -1.0484506   |\n",
      "|    std                  | 46.8         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2553         |\n",
      "|    time_elapsed         | 47319        |\n",
      "|    total_timesteps      | 5228544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026991323 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.65         |\n",
      "|    n_updates            | 25520        |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    reward               | -1.3012544   |\n",
      "|    std                  | 46.9         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2554         |\n",
      "|    time_elapsed         | 47337        |\n",
      "|    total_timesteps      | 5230592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005797234 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 25530        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 0.20132276   |\n",
      "|    std                  | 46.9         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2555          |\n",
      "|    time_elapsed         | 47356         |\n",
      "|    total_timesteps      | 5232640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022821897 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.514         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.7          |\n",
      "|    n_updates            | 25540         |\n",
      "|    policy_gradient_loss | -0.00137      |\n",
      "|    reward               | 0.5449108     |\n",
      "|    std                  | 46.9          |\n",
      "|    value_loss           | 36.9          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3021564.98\n",
      "total_reward: 2021564.98\n",
      "total_cost: 244417.24\n",
      "total_trades: 66078\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2556         |\n",
      "|    time_elapsed         | 47374        |\n",
      "|    total_timesteps      | 5234688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048153726 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.78         |\n",
      "|    n_updates            | 25550        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | 0.37455726   |\n",
      "|    std                  | 47.2         |\n",
      "|    value_loss           | 13.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2557         |\n",
      "|    time_elapsed         | 47393        |\n",
      "|    total_timesteps      | 5236736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010382684 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 25560        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | -0.22816741  |\n",
      "|    std                  | 47.3         |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2558         |\n",
      "|    time_elapsed         | 47411        |\n",
      "|    total_timesteps      | 5238784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.398033e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 25570        |\n",
      "|    policy_gradient_loss | -0.000805    |\n",
      "|    reward               | 1.7859175    |\n",
      "|    std                  | 47.3         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2559         |\n",
      "|    time_elapsed         | 47430        |\n",
      "|    total_timesteps      | 5240832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022777042 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 25580        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | 0.68044865   |\n",
      "|    std                  | 47.5         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2560         |\n",
      "|    time_elapsed         | 47448        |\n",
      "|    total_timesteps      | 5242880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017335485 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 25590        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -0.020075569 |\n",
      "|    std                  | 47.6         |\n",
      "|    value_loss           | 22.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2561          |\n",
      "|    time_elapsed         | 47467         |\n",
      "|    total_timesteps      | 5244928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022441847 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.586         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.5          |\n",
      "|    n_updates            | 25600         |\n",
      "|    policy_gradient_loss | -0.000943     |\n",
      "|    reward               | 3.9758666     |\n",
      "|    std                  | 47.6          |\n",
      "|    value_loss           | 36.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2562          |\n",
      "|    time_elapsed         | 47485         |\n",
      "|    total_timesteps      | 5246976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043900617 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.434         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.7          |\n",
      "|    n_updates            | 25610         |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    reward               | 0.39998806    |\n",
      "|    std                  | 47.7          |\n",
      "|    value_loss           | 40.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2563         |\n",
      "|    time_elapsed         | 47504        |\n",
      "|    total_timesteps      | 5249024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031033172 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.32         |\n",
      "|    n_updates            | 25620        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | -2.618013    |\n",
      "|    std                  | 47.8         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2564         |\n",
      "|    time_elapsed         | 47522        |\n",
      "|    total_timesteps      | 5251072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011967816 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.3          |\n",
      "|    n_updates            | 25630        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 1.6086217    |\n",
      "|    std                  | 47.8         |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2565         |\n",
      "|    time_elapsed         | 47541        |\n",
      "|    total_timesteps      | 5253120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006148483 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 25640        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 3.5130103    |\n",
      "|    std                  | 47.9         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2566          |\n",
      "|    time_elapsed         | 47559         |\n",
      "|    total_timesteps      | 5255168       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036148314 |\n",
      "|    clip_fraction        | 0.00083       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.377         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.76          |\n",
      "|    n_updates            | 25650         |\n",
      "|    policy_gradient_loss | -0.00177      |\n",
      "|    reward               | 0.5158994     |\n",
      "|    std                  | 47.9          |\n",
      "|    value_loss           | 29.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2567         |\n",
      "|    time_elapsed         | 47578        |\n",
      "|    total_timesteps      | 5257216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025800276 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.71         |\n",
      "|    n_updates            | 25660        |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | -0.7574992   |\n",
      "|    std                  | 48.1         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2568          |\n",
      "|    time_elapsed         | 47596         |\n",
      "|    total_timesteps      | 5259264       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068237644 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.595         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.2          |\n",
      "|    n_updates            | 25670         |\n",
      "|    policy_gradient_loss | -0.00313      |\n",
      "|    reward               | 0.5904945     |\n",
      "|    std                  | 48.1          |\n",
      "|    value_loss           | 33.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2569         |\n",
      "|    time_elapsed         | 47615        |\n",
      "|    total_timesteps      | 5261312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002210548 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 25680        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    reward               | 0.948909     |\n",
      "|    std                  | 48.2         |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3798092.25\n",
      "total_reward: 2798092.25\n",
      "total_cost: 313491.56\n",
      "total_trades: 69677\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2570         |\n",
      "|    time_elapsed         | 47634        |\n",
      "|    total_timesteps      | 5263360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030328897 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.14         |\n",
      "|    n_updates            | 25690        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | -0.029039737 |\n",
      "|    std                  | 48.2         |\n",
      "|    value_loss           | 20.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2571          |\n",
      "|    time_elapsed         | 47653         |\n",
      "|    total_timesteps      | 5265408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057804654 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.509         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.7          |\n",
      "|    n_updates            | 25700         |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    reward               | -0.3973713    |\n",
      "|    std                  | 48.3          |\n",
      "|    value_loss           | 38.1          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2572          |\n",
      "|    time_elapsed         | 47671         |\n",
      "|    total_timesteps      | 5267456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047101273 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.632         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.6          |\n",
      "|    n_updates            | 25710         |\n",
      "|    policy_gradient_loss | -0.00184      |\n",
      "|    reward               | -1.5786995    |\n",
      "|    std                  | 48.3          |\n",
      "|    value_loss           | 38.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2573          |\n",
      "|    time_elapsed         | 47689         |\n",
      "|    total_timesteps      | 5269504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078590773 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.501         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.99          |\n",
      "|    n_updates            | 25720         |\n",
      "|    policy_gradient_loss | -0.00244      |\n",
      "|    reward               | 0.26581287    |\n",
      "|    std                  | 48.3          |\n",
      "|    value_loss           | 22            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2574         |\n",
      "|    time_elapsed         | 47708        |\n",
      "|    total_timesteps      | 5271552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006018355 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 25730        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 0.4484641    |\n",
      "|    std                  | 48.4         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2575          |\n",
      "|    time_elapsed         | 47727         |\n",
      "|    total_timesteps      | 5273600       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078223104 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.644         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.1          |\n",
      "|    n_updates            | 25740         |\n",
      "|    policy_gradient_loss | -0.0029       |\n",
      "|    reward               | -1.7245153    |\n",
      "|    std                  | 48.4          |\n",
      "|    value_loss           | 44.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2576          |\n",
      "|    time_elapsed         | 47746         |\n",
      "|    total_timesteps      | 5275648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017814731 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.665         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.7          |\n",
      "|    n_updates            | 25750         |\n",
      "|    policy_gradient_loss | -0.000709     |\n",
      "|    reward               | -1.0591708    |\n",
      "|    std                  | 48.4          |\n",
      "|    value_loss           | 29.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2577         |\n",
      "|    time_elapsed         | 47765        |\n",
      "|    total_timesteps      | 5277696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018382011 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.43         |\n",
      "|    n_updates            | 25760        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 0.16430932   |\n",
      "|    std                  | 48.5         |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2578        |\n",
      "|    time_elapsed         | 47783       |\n",
      "|    total_timesteps      | 5279744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000683845 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 25770       |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    reward               | -0.21368256 |\n",
      "|    std                  | 48.6        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2579        |\n",
      "|    time_elapsed         | 47802       |\n",
      "|    total_timesteps      | 5281792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001366981 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 25780       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | -0.3103092  |\n",
      "|    std                  | 48.6        |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2580         |\n",
      "|    time_elapsed         | 47820        |\n",
      "|    total_timesteps      | 5283840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021056472 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.3          |\n",
      "|    n_updates            | 25790        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | 1.8908625    |\n",
      "|    std                  | 48.7         |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2581         |\n",
      "|    time_elapsed         | 47838        |\n",
      "|    total_timesteps      | 5285888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018266734 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 25800        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | -0.32603317  |\n",
      "|    std                  | 48.9         |\n",
      "|    value_loss           | 67.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2582         |\n",
      "|    time_elapsed         | 47857        |\n",
      "|    total_timesteps      | 5287936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018029955 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.4         |\n",
      "|    n_updates            | 25810        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | 0.1964451    |\n",
      "|    std                  | 49           |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2583         |\n",
      "|    time_elapsed         | 47875        |\n",
      "|    total_timesteps      | 5289984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017049995 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 25820        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | -0.56780785  |\n",
      "|    std                  | 49.1         |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3575108.21\n",
      "total_reward: 2575108.21\n",
      "total_cost: 193505.58\n",
      "total_trades: 63109\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2584         |\n",
      "|    time_elapsed         | 47894        |\n",
      "|    total_timesteps      | 5292032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016798251 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 25830        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | -0.7197165   |\n",
      "|    std                  | 49.2         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2585         |\n",
      "|    time_elapsed         | 47913        |\n",
      "|    total_timesteps      | 5294080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013058488 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 25840        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    reward               | -4.6340575   |\n",
      "|    std                  | 49.3         |\n",
      "|    value_loss           | 57.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2586         |\n",
      "|    time_elapsed         | 47931        |\n",
      "|    total_timesteps      | 5296128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013945419 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.265        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 25850        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | 0.13994834   |\n",
      "|    std                  | 49.3         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2587         |\n",
      "|    time_elapsed         | 47949        |\n",
      "|    total_timesteps      | 5298176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010650037 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 25860        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 0.0061574797 |\n",
      "|    std                  | 49.4         |\n",
      "|    value_loss           | 27.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2588        |\n",
      "|    time_elapsed         | 47967       |\n",
      "|    total_timesteps      | 5300224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002534111 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 25870       |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | 0.06676655  |\n",
      "|    std                  | 49.4        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2589         |\n",
      "|    time_elapsed         | 47986        |\n",
      "|    total_timesteps      | 5302272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006556022 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 25880        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 3.8872194    |\n",
      "|    std                  | 49.5         |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2590         |\n",
      "|    time_elapsed         | 48004        |\n",
      "|    total_timesteps      | 5304320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014438614 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.47         |\n",
      "|    n_updates            | 25890        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | 2.6721616    |\n",
      "|    std                  | 49.6         |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2591        |\n",
      "|    time_elapsed         | 48023       |\n",
      "|    total_timesteps      | 5306368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001856317 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.65        |\n",
      "|    n_updates            | 25900       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    reward               | 1.4843603   |\n",
      "|    std                  | 49.6        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2592          |\n",
      "|    time_elapsed         | 48041         |\n",
      "|    total_timesteps      | 5308416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043792662 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.546         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.3          |\n",
      "|    n_updates            | 25910         |\n",
      "|    policy_gradient_loss | -0.00136      |\n",
      "|    reward               | -3.509533     |\n",
      "|    std                  | 49.6          |\n",
      "|    value_loss           | 37.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2593          |\n",
      "|    time_elapsed         | 48060         |\n",
      "|    total_timesteps      | 5310464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026294016 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.6           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.9          |\n",
      "|    n_updates            | 25920         |\n",
      "|    policy_gradient_loss | -0.00125      |\n",
      "|    reward               | -0.6961413    |\n",
      "|    std                  | 49.7          |\n",
      "|    value_loss           | 33.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2594        |\n",
      "|    time_elapsed         | 48079       |\n",
      "|    total_timesteps      | 5312512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000950009 |\n",
      "|    clip_fraction        | 0.00103     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.4         |\n",
      "|    n_updates            | 25930       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | -0.4931338  |\n",
      "|    std                  | 49.8        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2595          |\n",
      "|    time_elapsed         | 48098         |\n",
      "|    total_timesteps      | 5314560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029355814 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.618         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.2          |\n",
      "|    n_updates            | 25940         |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    reward               | 0.113254756   |\n",
      "|    std                  | 49.8          |\n",
      "|    value_loss           | 33.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2596         |\n",
      "|    time_elapsed         | 48117        |\n",
      "|    total_timesteps      | 5316608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.352659e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 25950        |\n",
      "|    policy_gradient_loss | -0.00058     |\n",
      "|    reward               | -0.76300627  |\n",
      "|    std                  | 49.8         |\n",
      "|    value_loss           | 47.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2597         |\n",
      "|    time_elapsed         | 48135        |\n",
      "|    total_timesteps      | 5318656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011341049 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.36         |\n",
      "|    n_updates            | 25960        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | -2.288749    |\n",
      "|    std                  | 49.8         |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3620607.99\n",
      "total_reward: 2620607.99\n",
      "total_cost: 200586.99\n",
      "total_trades: 63346\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2598          |\n",
      "|    time_elapsed         | 48154         |\n",
      "|    total_timesteps      | 5320704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087297766 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.8          |\n",
      "|    n_updates            | 25970         |\n",
      "|    policy_gradient_loss | -0.00234      |\n",
      "|    reward               | -1.5377274    |\n",
      "|    std                  | 49.9          |\n",
      "|    value_loss           | 28.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2599          |\n",
      "|    time_elapsed         | 48172         |\n",
      "|    total_timesteps      | 5322752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022148728 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.558         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.2          |\n",
      "|    n_updates            | 25980         |\n",
      "|    policy_gradient_loss | -0.00145      |\n",
      "|    reward               | 3.4279964     |\n",
      "|    std                  | 49.9          |\n",
      "|    value_loss           | 44.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2600        |\n",
      "|    time_elapsed         | 48191       |\n",
      "|    total_timesteps      | 5324800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001237259 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 25990       |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    reward               | -2.9309833  |\n",
      "|    std                  | 50          |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2601        |\n",
      "|    time_elapsed         | 48209       |\n",
      "|    total_timesteps      | 5326848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000723389 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 26000       |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    reward               | 1.9543902   |\n",
      "|    std                  | 50.1        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2602          |\n",
      "|    time_elapsed         | 48228         |\n",
      "|    total_timesteps      | 5328896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095118996 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.662         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.8          |\n",
      "|    n_updates            | 26010         |\n",
      "|    policy_gradient_loss | -0.00318      |\n",
      "|    reward               | -2.0401456    |\n",
      "|    std                  | 50.1          |\n",
      "|    value_loss           | 33.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2603          |\n",
      "|    time_elapsed         | 48247         |\n",
      "|    total_timesteps      | 5330944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027681788 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.71          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.7          |\n",
      "|    n_updates            | 26020         |\n",
      "|    policy_gradient_loss | -0.00119      |\n",
      "|    reward               | 1.3240273     |\n",
      "|    std                  | 50.1          |\n",
      "|    value_loss           | 42.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2604         |\n",
      "|    time_elapsed         | 48266        |\n",
      "|    total_timesteps      | 5332992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007400639 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.22         |\n",
      "|    n_updates            | 26030        |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | -1.6131191   |\n",
      "|    std                  | 50.2         |\n",
      "|    value_loss           | 22.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2605         |\n",
      "|    time_elapsed         | 48284        |\n",
      "|    total_timesteps      | 5335040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011905874 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.92         |\n",
      "|    n_updates            | 26040        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 1.6157026    |\n",
      "|    std                  | 50.2         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2606         |\n",
      "|    time_elapsed         | 48303        |\n",
      "|    total_timesteps      | 5337088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002181768 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 26050        |\n",
      "|    policy_gradient_loss | -0.000998    |\n",
      "|    reward               | -2.407932    |\n",
      "|    std                  | 50.3         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2607          |\n",
      "|    time_elapsed         | 48322         |\n",
      "|    total_timesteps      | 5339136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037565216 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.684         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.7          |\n",
      "|    n_updates            | 26060         |\n",
      "|    policy_gradient_loss | -0.00172      |\n",
      "|    reward               | -2.2740679    |\n",
      "|    std                  | 50.3          |\n",
      "|    value_loss           | 37.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2608        |\n",
      "|    time_elapsed         | 48340       |\n",
      "|    total_timesteps      | 5341184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002857112 |\n",
      "|    clip_fraction        | 0.00322     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.14        |\n",
      "|    n_updates            | 26070       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | 0.55189073  |\n",
      "|    std                  | 50.4        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2609          |\n",
      "|    time_elapsed         | 48359         |\n",
      "|    total_timesteps      | 5343232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025136475 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.65          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.4          |\n",
      "|    n_updates            | 26080         |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    reward               | -0.53671247   |\n",
      "|    std                  | 50.4          |\n",
      "|    value_loss           | 61.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2610         |\n",
      "|    time_elapsed         | 48378        |\n",
      "|    total_timesteps      | 5345280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003009299 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 26090        |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    reward               | -0.18791643  |\n",
      "|    std                  | 50.4         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2611         |\n",
      "|    time_elapsed         | 48397        |\n",
      "|    total_timesteps      | 5347328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017990022 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.56         |\n",
      "|    n_updates            | 26100        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | -0.4845514   |\n",
      "|    std                  | 50.5         |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4096027.32\n",
      "total_reward: 3096027.32\n",
      "total_cost: 268228.27\n",
      "total_trades: 66998\n",
      "Sharpe: 0.779\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2612          |\n",
      "|    time_elapsed         | 48416         |\n",
      "|    total_timesteps      | 5349376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063521625 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.598         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.11          |\n",
      "|    n_updates            | 26110         |\n",
      "|    policy_gradient_loss | -0.00229      |\n",
      "|    reward               | 0.944676      |\n",
      "|    std                  | 50.5          |\n",
      "|    value_loss           | 33            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2613          |\n",
      "|    time_elapsed         | 48434         |\n",
      "|    total_timesteps      | 5351424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036610954 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.351         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.3          |\n",
      "|    n_updates            | 26120         |\n",
      "|    policy_gradient_loss | -0.00176      |\n",
      "|    reward               | 0.6507631     |\n",
      "|    std                  | 50.5          |\n",
      "|    value_loss           | 51.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2614         |\n",
      "|    time_elapsed         | 48453        |\n",
      "|    total_timesteps      | 5353472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043584974 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 26130        |\n",
      "|    policy_gradient_loss | -0.00774     |\n",
      "|    reward               | 0.59259945   |\n",
      "|    std                  | 50.6         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2615         |\n",
      "|    time_elapsed         | 48472        |\n",
      "|    total_timesteps      | 5355520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007535913 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 26140        |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    reward               | -1.9607508   |\n",
      "|    std                  | 50.7         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2616          |\n",
      "|    time_elapsed         | 48491         |\n",
      "|    total_timesteps      | 5357568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013027224 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.625         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.1          |\n",
      "|    n_updates            | 26150         |\n",
      "|    policy_gradient_loss | -0.000829     |\n",
      "|    reward               | 4.49831       |\n",
      "|    std                  | 50.8          |\n",
      "|    value_loss           | 43.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2617         |\n",
      "|    time_elapsed         | 48510        |\n",
      "|    total_timesteps      | 5359616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005550175 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 26160        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 4.9385047    |\n",
      "|    std                  | 50.8         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2618         |\n",
      "|    time_elapsed         | 48529        |\n",
      "|    total_timesteps      | 5361664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019151141 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 26170        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | -0.24745734  |\n",
      "|    std                  | 51           |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2619         |\n",
      "|    time_elapsed         | 48548        |\n",
      "|    total_timesteps      | 5363712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010094836 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 26180        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -1.0119414   |\n",
      "|    std                  | 51.2         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2620          |\n",
      "|    time_elapsed         | 48567         |\n",
      "|    total_timesteps      | 5365760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019750107 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.615         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.2          |\n",
      "|    n_updates            | 26190         |\n",
      "|    policy_gradient_loss | -0.00104      |\n",
      "|    reward               | -0.7076502    |\n",
      "|    std                  | 51.2          |\n",
      "|    value_loss           | 50.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2621         |\n",
      "|    time_elapsed         | 48585        |\n",
      "|    total_timesteps      | 5367808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020191176 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.04         |\n",
      "|    n_updates            | 26200        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | 1.3165096    |\n",
      "|    std                  | 51.5         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2622         |\n",
      "|    time_elapsed         | 48604        |\n",
      "|    total_timesteps      | 5369856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011313525 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.7          |\n",
      "|    n_updates            | 26210        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | 0.525838     |\n",
      "|    std                  | 51.5         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2623         |\n",
      "|    time_elapsed         | 48624        |\n",
      "|    total_timesteps      | 5371904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003512372 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.168        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 26220        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | 0.98313123   |\n",
      "|    std                  | 51.6         |\n",
      "|    value_loss           | 61.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2624          |\n",
      "|    time_elapsed         | 48642         |\n",
      "|    total_timesteps      | 5373952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047441633 |\n",
      "|    clip_fraction        | 0.00229       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.57          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.4          |\n",
      "|    n_updates            | 26230         |\n",
      "|    policy_gradient_loss | -0.00127      |\n",
      "|    reward               | -1.9891629    |\n",
      "|    std                  | 51.6          |\n",
      "|    value_loss           | 31.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2625         |\n",
      "|    time_elapsed         | 48661        |\n",
      "|    total_timesteps      | 5376000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027256156 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.8          |\n",
      "|    n_updates            | 26240        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | 0.20336665   |\n",
      "|    std                  | 51.8         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2626         |\n",
      "|    time_elapsed         | 48680        |\n",
      "|    total_timesteps      | 5378048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002982449 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 26250        |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    reward               | -4.251289    |\n",
      "|    std                  | 51.8         |\n",
      "|    value_loss           | 49.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3014734.68\n",
      "total_reward: 2014734.68\n",
      "total_cost: 175387.74\n",
      "total_trades: 61605\n",
      "Sharpe: 0.610\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2627         |\n",
      "|    time_elapsed         | 48699        |\n",
      "|    total_timesteps      | 5380096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.178507e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 26260        |\n",
      "|    policy_gradient_loss | -0.000634    |\n",
      "|    reward               | -0.13195045  |\n",
      "|    std                  | 51.8         |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2628         |\n",
      "|    time_elapsed         | 48717        |\n",
      "|    total_timesteps      | 5382144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028039024 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.51         |\n",
      "|    n_updates            | 26270        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    reward               | -0.37716776  |\n",
      "|    std                  | 51.9         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2629         |\n",
      "|    time_elapsed         | 48736        |\n",
      "|    total_timesteps      | 5384192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005249212 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 26280        |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    reward               | -0.05237925  |\n",
      "|    std                  | 51.9         |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2630         |\n",
      "|    time_elapsed         | 48756        |\n",
      "|    total_timesteps      | 5386240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005072123 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 26290        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | 4.880423     |\n",
      "|    std                  | 52           |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2631         |\n",
      "|    time_elapsed         | 48774        |\n",
      "|    total_timesteps      | 5388288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004694071 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.65         |\n",
      "|    n_updates            | 26300        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | -0.024061343 |\n",
      "|    std                  | 52.1         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2632         |\n",
      "|    time_elapsed         | 48793        |\n",
      "|    total_timesteps      | 5390336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018253773 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.67         |\n",
      "|    n_updates            | 26310        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | -3.9045024   |\n",
      "|    std                  | 52.3         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2633         |\n",
      "|    time_elapsed         | 48811        |\n",
      "|    total_timesteps      | 5392384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005544999 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 26320        |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    reward               | 2.583023     |\n",
      "|    std                  | 52.3         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2634         |\n",
      "|    time_elapsed         | 48830        |\n",
      "|    total_timesteps      | 5394432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008790373 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 26330        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 0.63596904   |\n",
      "|    std                  | 52.4         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2635         |\n",
      "|    time_elapsed         | 48849        |\n",
      "|    total_timesteps      | 5396480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015810836 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.61         |\n",
      "|    n_updates            | 26340        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | -0.24350312  |\n",
      "|    std                  | 52.4         |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2636         |\n",
      "|    time_elapsed         | 48867        |\n",
      "|    total_timesteps      | 5398528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014611082 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.19         |\n",
      "|    n_updates            | 26350        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | 2.2922664    |\n",
      "|    std                  | 52.5         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2637          |\n",
      "|    time_elapsed         | 48886         |\n",
      "|    total_timesteps      | 5400576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039571853 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.546         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.3          |\n",
      "|    n_updates            | 26360         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | -3.2312386    |\n",
      "|    std                  | 52.5          |\n",
      "|    value_loss           | 35.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2638         |\n",
      "|    time_elapsed         | 48904        |\n",
      "|    total_timesteps      | 5402624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012248971 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.89         |\n",
      "|    n_updates            | 26370        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | -2.0319092   |\n",
      "|    std                  | 52.6         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2639         |\n",
      "|    time_elapsed         | 48923        |\n",
      "|    total_timesteps      | 5404672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006582375 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 26380        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | 1.3521457    |\n",
      "|    std                  | 52.7         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2640         |\n",
      "|    time_elapsed         | 48942        |\n",
      "|    total_timesteps      | 5406720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008555809 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 26390        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | -0.33429077  |\n",
      "|    std                  | 52.8         |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3508189.31\n",
      "total_reward: 2508189.31\n",
      "total_cost: 410425.65\n",
      "total_trades: 73381\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2641         |\n",
      "|    time_elapsed         | 48961        |\n",
      "|    total_timesteps      | 5408768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004905652 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 26400        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | 2.1685417    |\n",
      "|    std                  | 52.8         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2642        |\n",
      "|    time_elapsed         | 48979       |\n",
      "|    total_timesteps      | 5410816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002070603 |\n",
      "|    clip_fraction        | 0.00278     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.56        |\n",
      "|    n_updates            | 26410       |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    reward               | 0.39324954  |\n",
      "|    std                  | 52.9        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2643         |\n",
      "|    time_elapsed         | 48998        |\n",
      "|    total_timesteps      | 5412864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010122443 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 26420        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 0.5786263    |\n",
      "|    std                  | 53           |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2644          |\n",
      "|    time_elapsed         | 49017         |\n",
      "|    total_timesteps      | 5414912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028574758 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.503         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.8          |\n",
      "|    n_updates            | 26430         |\n",
      "|    policy_gradient_loss | -0.00115      |\n",
      "|    reward               | 2.6630018     |\n",
      "|    std                  | 53            |\n",
      "|    value_loss           | 40            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2645         |\n",
      "|    time_elapsed         | 49035        |\n",
      "|    total_timesteps      | 5416960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050019594 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.2          |\n",
      "|    n_updates            | 26440        |\n",
      "|    policy_gradient_loss | -0.00756     |\n",
      "|    reward               | -0.30559826  |\n",
      "|    std                  | 53.3         |\n",
      "|    value_loss           | 11.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2646          |\n",
      "|    time_elapsed         | 49054         |\n",
      "|    total_timesteps      | 5419008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00076829875 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.1          |\n",
      "|    n_updates            | 26450         |\n",
      "|    policy_gradient_loss | -0.00233      |\n",
      "|    reward               | 2.9252434     |\n",
      "|    std                  | 53.3          |\n",
      "|    value_loss           | 27.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2647         |\n",
      "|    time_elapsed         | 49072        |\n",
      "|    total_timesteps      | 5421056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006097349 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 26460        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | 2.713956     |\n",
      "|    std                  | 53.4         |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2648          |\n",
      "|    time_elapsed         | 49090         |\n",
      "|    total_timesteps      | 5423104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075220945 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.606         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.3          |\n",
      "|    n_updates            | 26470         |\n",
      "|    policy_gradient_loss | -0.00265      |\n",
      "|    reward               | -1.3145465    |\n",
      "|    std                  | 53.5          |\n",
      "|    value_loss           | 29.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2649         |\n",
      "|    time_elapsed         | 49109        |\n",
      "|    total_timesteps      | 5425152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015507028 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.52         |\n",
      "|    n_updates            | 26480        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -0.153651    |\n",
      "|    std                  | 53.6         |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2650         |\n",
      "|    time_elapsed         | 49127        |\n",
      "|    total_timesteps      | 5427200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003139775 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 26490        |\n",
      "|    policy_gradient_loss | -0.000958    |\n",
      "|    reward               | -20.959345   |\n",
      "|    std                  | 53.6         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2651          |\n",
      "|    time_elapsed         | 49146         |\n",
      "|    total_timesteps      | 5429248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033314194 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.617         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.5          |\n",
      "|    n_updates            | 26500         |\n",
      "|    policy_gradient_loss | -0.0019       |\n",
      "|    reward               | -0.48110965   |\n",
      "|    std                  | 53.6          |\n",
      "|    value_loss           | 41.3          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2652         |\n",
      "|    time_elapsed         | 49165        |\n",
      "|    total_timesteps      | 5431296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030493704 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 26510        |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    reward               | 1.0642637    |\n",
      "|    std                  | 53.8         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2653         |\n",
      "|    time_elapsed         | 49183        |\n",
      "|    total_timesteps      | 5433344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009582448 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 26520        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | 0.686782     |\n",
      "|    std                  | 53.9         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2654          |\n",
      "|    time_elapsed         | 49201         |\n",
      "|    total_timesteps      | 5435392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025102965 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.662         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20            |\n",
      "|    n_updates            | 26530         |\n",
      "|    policy_gradient_loss | -0.000843     |\n",
      "|    reward               | -0.86433554   |\n",
      "|    std                  | 53.9          |\n",
      "|    value_loss           | 39.1          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2766363.98\n",
      "total_reward: 1766363.98\n",
      "total_cost: 223162.07\n",
      "total_trades: 64079\n",
      "Sharpe: 0.567\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2655         |\n",
      "|    time_elapsed         | 49220        |\n",
      "|    total_timesteps      | 5437440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007799959 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 26540        |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | -2.69696     |\n",
      "|    std                  | 54           |\n",
      "|    value_loss           | 25.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2656         |\n",
      "|    time_elapsed         | 49240        |\n",
      "|    total_timesteps      | 5439488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008179358 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.37         |\n",
      "|    n_updates            | 26550        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | -0.9634015   |\n",
      "|    std                  | 54           |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2657         |\n",
      "|    time_elapsed         | 49259        |\n",
      "|    total_timesteps      | 5441536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002981532 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 26560        |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    reward               | -1.4381281   |\n",
      "|    std                  | 54.1         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2658        |\n",
      "|    time_elapsed         | 49278       |\n",
      "|    total_timesteps      | 5443584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003914144 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -156        |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 26570       |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | -4.447407   |\n",
      "|    std                  | 54.1        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2659         |\n",
      "|    time_elapsed         | 49296        |\n",
      "|    total_timesteps      | 5445632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026910743 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 26580        |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    reward               | 2.7120476    |\n",
      "|    std                  | 54.2         |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2660         |\n",
      "|    time_elapsed         | 49315        |\n",
      "|    total_timesteps      | 5447680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012326707 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.23         |\n",
      "|    n_updates            | 26590        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | -0.24585287  |\n",
      "|    std                  | 54.4         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2661         |\n",
      "|    time_elapsed         | 49334        |\n",
      "|    total_timesteps      | 5449728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006375668 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 26600        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | 3.4766178    |\n",
      "|    std                  | 54.4         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2662       |\n",
      "|    time_elapsed         | 49352      |\n",
      "|    total_timesteps      | 5451776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00252881 |\n",
      "|    clip_fraction        | 0.00308    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -156       |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.4        |\n",
      "|    n_updates            | 26610      |\n",
      "|    policy_gradient_loss | -0.0047    |\n",
      "|    reward               | 0.825707   |\n",
      "|    std                  | 54.7       |\n",
      "|    value_loss           | 14.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2663        |\n",
      "|    time_elapsed         | 49371       |\n",
      "|    total_timesteps      | 5453824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001993643 |\n",
      "|    clip_fraction        | 0.00308     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -156        |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 26620       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -0.25678182 |\n",
      "|    std                  | 54.8        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2664        |\n",
      "|    time_elapsed         | 49389       |\n",
      "|    total_timesteps      | 5455872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000169353 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -156        |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 26630       |\n",
      "|    policy_gradient_loss | -0.000714   |\n",
      "|    reward               | 1.4582955   |\n",
      "|    std                  | 54.9        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2665         |\n",
      "|    time_elapsed         | 49408        |\n",
      "|    total_timesteps      | 5457920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011519671 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.83         |\n",
      "|    n_updates            | 26640        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -0.8661993   |\n",
      "|    std                  | 54.9         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2666        |\n",
      "|    time_elapsed         | 49427       |\n",
      "|    total_timesteps      | 5459968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002476206 |\n",
      "|    clip_fraction        | 0.0062      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -156        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 26650       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | 0.27341267  |\n",
      "|    std                  | 55          |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2667          |\n",
      "|    time_elapsed         | 49445         |\n",
      "|    total_timesteps      | 5462016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060654443 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.633         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.2          |\n",
      "|    n_updates            | 26660         |\n",
      "|    policy_gradient_loss | -0.00213      |\n",
      "|    reward               | -0.18298948   |\n",
      "|    std                  | 55.1          |\n",
      "|    value_loss           | 27.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2668         |\n",
      "|    time_elapsed         | 49464        |\n",
      "|    total_timesteps      | 5464064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013200016 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 26670        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | 0.8809385    |\n",
      "|    std                  | 55.2         |\n",
      "|    value_loss           | 39.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3093525.59\n",
      "total_reward: 2093525.59\n",
      "total_cost: 443485.74\n",
      "total_trades: 74523\n",
      "Sharpe: 0.676\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2669         |\n",
      "|    time_elapsed         | 49635        |\n",
      "|    total_timesteps      | 5466112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037299455 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.7          |\n",
      "|    n_updates            | 26680        |\n",
      "|    policy_gradient_loss | -0.00706     |\n",
      "|    reward               | 0.055439796  |\n",
      "|    std                  | 55.4         |\n",
      "|    value_loss           | 13.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2670         |\n",
      "|    time_elapsed         | 49653        |\n",
      "|    total_timesteps      | 5468160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012371762 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 26690        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | 1.8797662    |\n",
      "|    std                  | 55.5         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2671          |\n",
      "|    time_elapsed         | 49671         |\n",
      "|    total_timesteps      | 5470208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069577177 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.579         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.7          |\n",
      "|    n_updates            | 26700         |\n",
      "|    policy_gradient_loss | -0.00197      |\n",
      "|    reward               | 1.9822471     |\n",
      "|    std                  | 55.6          |\n",
      "|    value_loss           | 25.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2672         |\n",
      "|    time_elapsed         | 49690        |\n",
      "|    total_timesteps      | 5472256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027120633 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.29         |\n",
      "|    n_updates            | 26710        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | 0.7183792    |\n",
      "|    std                  | 55.8         |\n",
      "|    value_loss           | 18           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2673         |\n",
      "|    time_elapsed         | 49708        |\n",
      "|    total_timesteps      | 5474304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009842814 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 26720        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | 3.5767763    |\n",
      "|    std                  | 55.8         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2674          |\n",
      "|    time_elapsed         | 49728         |\n",
      "|    total_timesteps      | 5476352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018832402 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.648         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.67          |\n",
      "|    n_updates            | 26730         |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    reward               | 1.6146448     |\n",
      "|    std                  | 55.9          |\n",
      "|    value_loss           | 27.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2675          |\n",
      "|    time_elapsed         | 49746         |\n",
      "|    total_timesteps      | 5478400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082147063 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.67          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.4          |\n",
      "|    n_updates            | 26740         |\n",
      "|    policy_gradient_loss | -0.00291      |\n",
      "|    reward               | -0.5714861    |\n",
      "|    std                  | 55.9          |\n",
      "|    value_loss           | 26            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2676         |\n",
      "|    time_elapsed         | 49765        |\n",
      "|    total_timesteps      | 5480448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033710776 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 26750        |\n",
      "|    policy_gradient_loss | -0.00665     |\n",
      "|    reward               | 1.1975917    |\n",
      "|    std                  | 56.2         |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2677          |\n",
      "|    time_elapsed         | 49784         |\n",
      "|    total_timesteps      | 5482496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062183547 |\n",
      "|    clip_fraction        | 0.00137       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.608         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.7          |\n",
      "|    n_updates            | 26760         |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    reward               | -0.9097184    |\n",
      "|    std                  | 56.3          |\n",
      "|    value_loss           | 39            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2678          |\n",
      "|    time_elapsed         | 49802         |\n",
      "|    total_timesteps      | 5484544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053050567 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.539         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.9          |\n",
      "|    n_updates            | 26770         |\n",
      "|    policy_gradient_loss | -0.000689     |\n",
      "|    reward               | -1.1867943    |\n",
      "|    std                  | 56.4          |\n",
      "|    value_loss           | 58.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2679         |\n",
      "|    time_elapsed         | 49821        |\n",
      "|    total_timesteps      | 5486592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019252326 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.0919       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.65         |\n",
      "|    n_updates            | 26780        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | 0.12811822   |\n",
      "|    std                  | 56.4         |\n",
      "|    value_loss           | 16.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2680         |\n",
      "|    time_elapsed         | 49839        |\n",
      "|    total_timesteps      | 5488640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005776138 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 26790        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | 0.23717938   |\n",
      "|    std                  | 56.4         |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2681        |\n",
      "|    time_elapsed         | 49858       |\n",
      "|    total_timesteps      | 5490688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000799275 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 26800       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | 5.3172927   |\n",
      "|    std                  | 56.4        |\n",
      "|    value_loss           | 59.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2682         |\n",
      "|    time_elapsed         | 49877        |\n",
      "|    total_timesteps      | 5492736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009083059 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 26810        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | -0.5341895   |\n",
      "|    std                  | 56.6         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2726388.53\n",
      "total_reward: 1726388.53\n",
      "total_cost: 450904.31\n",
      "total_trades: 74881\n",
      "Sharpe: 0.619\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2683         |\n",
      "|    time_elapsed         | 49897        |\n",
      "|    total_timesteps      | 5494784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010237072 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 26820        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 2.1858504    |\n",
      "|    std                  | 56.7         |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2684         |\n",
      "|    time_elapsed         | 49916        |\n",
      "|    total_timesteps      | 5496832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003795506 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 26830        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | 0.09685719   |\n",
      "|    std                  | 56.7         |\n",
      "|    value_loss           | 52.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2685         |\n",
      "|    time_elapsed         | 49935        |\n",
      "|    total_timesteps      | 5498880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007522948 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 26840        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | 0.4096661    |\n",
      "|    std                  | 56.8         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2686        |\n",
      "|    time_elapsed         | 49954       |\n",
      "|    total_timesteps      | 5500928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004914349 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.39        |\n",
      "|    n_updates            | 26850       |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | 0.61572504  |\n",
      "|    std                  | 57          |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2687          |\n",
      "|    time_elapsed         | 49972         |\n",
      "|    total_timesteps      | 5502976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026270337 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.483         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.9          |\n",
      "|    n_updates            | 26860         |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    reward               | 0.33826515    |\n",
      "|    std                  | 57            |\n",
      "|    value_loss           | 35.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2688         |\n",
      "|    time_elapsed         | 49990        |\n",
      "|    total_timesteps      | 5505024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014468392 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.225        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 26870        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | 1.8956879    |\n",
      "|    std                  | 57.1         |\n",
      "|    value_loss           | 67.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2689         |\n",
      "|    time_elapsed         | 50009        |\n",
      "|    total_timesteps      | 5507072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017862922 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 26880        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | -1.4086306   |\n",
      "|    std                  | 57.2         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2690         |\n",
      "|    time_elapsed         | 50027        |\n",
      "|    total_timesteps      | 5509120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005883641 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 26890        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | -0.6544397   |\n",
      "|    std                  | 57.2         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2691          |\n",
      "|    time_elapsed         | 50046         |\n",
      "|    total_timesteps      | 5511168       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054094713 |\n",
      "|    clip_fraction        | 0.00122       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.354         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18            |\n",
      "|    n_updates            | 26900         |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    reward               | -0.24511649   |\n",
      "|    std                  | 57.2          |\n",
      "|    value_loss           | 61.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2692         |\n",
      "|    time_elapsed         | 50065        |\n",
      "|    total_timesteps      | 5513216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002779171 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 26910        |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    reward               | 0.88753223   |\n",
      "|    std                  | 57.3         |\n",
      "|    value_loss           | 55.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2693         |\n",
      "|    time_elapsed         | 50084        |\n",
      "|    total_timesteps      | 5515264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046438705 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.35         |\n",
      "|    n_updates            | 26920        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    reward               | -1.525702    |\n",
      "|    std                  | 57.4         |\n",
      "|    value_loss           | 12           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2694         |\n",
      "|    time_elapsed         | 50103        |\n",
      "|    total_timesteps      | 5517312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005266429 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 26930        |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    reward               | 2.2400763    |\n",
      "|    std                  | 57.5         |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2695         |\n",
      "|    time_elapsed         | 50121        |\n",
      "|    total_timesteps      | 5519360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007520425 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.2         |\n",
      "|    n_updates            | 26940        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | -1.2604705   |\n",
      "|    std                  | 57.6         |\n",
      "|    value_loss           | 51.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2696         |\n",
      "|    time_elapsed         | 50140        |\n",
      "|    total_timesteps      | 5521408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038556494 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.75         |\n",
      "|    n_updates            | 26950        |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    reward               | -1.2854582   |\n",
      "|    std                  | 57.6         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2869822.19\n",
      "total_reward: 1869822.19\n",
      "total_cost: 468813.21\n",
      "total_trades: 75490\n",
      "Sharpe: 0.623\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2697         |\n",
      "|    time_elapsed         | 50158        |\n",
      "|    total_timesteps      | 5523456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010541356 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 26960        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 1.628837     |\n",
      "|    std                  | 57.7         |\n",
      "|    value_loss           | 75.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2698         |\n",
      "|    time_elapsed         | 50176        |\n",
      "|    total_timesteps      | 5525504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005457528 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 26970        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | 0.9152496    |\n",
      "|    std                  | 57.8         |\n",
      "|    value_loss           | 45.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2699         |\n",
      "|    time_elapsed         | 50195        |\n",
      "|    total_timesteps      | 5527552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006613969 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 26980        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | -0.20618379  |\n",
      "|    std                  | 57.8         |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2700          |\n",
      "|    time_elapsed         | 50215         |\n",
      "|    total_timesteps      | 5529600       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093071035 |\n",
      "|    clip_fraction        | 0.00137       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.408         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.64          |\n",
      "|    n_updates            | 26990         |\n",
      "|    policy_gradient_loss | -0.00239      |\n",
      "|    reward               | 1.5912502     |\n",
      "|    std                  | 57.9          |\n",
      "|    value_loss           | 43.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2701          |\n",
      "|    time_elapsed         | 50233         |\n",
      "|    total_timesteps      | 5531648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047890496 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.543         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28            |\n",
      "|    n_updates            | 27000         |\n",
      "|    policy_gradient_loss | -0.00186      |\n",
      "|    reward               | -1.1168215    |\n",
      "|    std                  | 58            |\n",
      "|    value_loss           | 54.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2702         |\n",
      "|    time_elapsed         | 50252        |\n",
      "|    total_timesteps      | 5533696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003370475 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 27010        |\n",
      "|    policy_gradient_loss | -0.000956    |\n",
      "|    reward               | 0.74747634   |\n",
      "|    std                  | 58           |\n",
      "|    value_loss           | 57.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2703        |\n",
      "|    time_elapsed         | 50270       |\n",
      "|    total_timesteps      | 5535744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004403621 |\n",
      "|    clip_fraction        | 0.00815     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.02        |\n",
      "|    n_updates            | 27020       |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | 1.3565396   |\n",
      "|    std                  | 58.2        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2704          |\n",
      "|    time_elapsed         | 50289         |\n",
      "|    total_timesteps      | 5537792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064512773 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.394         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.4          |\n",
      "|    n_updates            | 27030         |\n",
      "|    policy_gradient_loss | -0.00244      |\n",
      "|    reward               | 0.39202976    |\n",
      "|    std                  | 58.2          |\n",
      "|    value_loss           | 62.4          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2705          |\n",
      "|    time_elapsed         | 50307         |\n",
      "|    total_timesteps      | 5539840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056527794 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.212         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 54.8          |\n",
      "|    n_updates            | 27040         |\n",
      "|    policy_gradient_loss | -0.00188      |\n",
      "|    reward               | -2.2132947    |\n",
      "|    std                  | 58.4          |\n",
      "|    value_loss           | 74.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2706         |\n",
      "|    time_elapsed         | 50326        |\n",
      "|    total_timesteps      | 5541888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022436236 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.0731       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 27050        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -1.0601304   |\n",
      "|    std                  | 58.5         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2707         |\n",
      "|    time_elapsed         | 50344        |\n",
      "|    total_timesteps      | 5543936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024770047 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.201        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 27060        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | 1.1779861    |\n",
      "|    std                  | 58.7         |\n",
      "|    value_loss           | 52.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2708          |\n",
      "|    time_elapsed         | 50363         |\n",
      "|    total_timesteps      | 5545984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087088894 |\n",
      "|    clip_fraction        | 0.00264       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.542         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.17          |\n",
      "|    n_updates            | 27070         |\n",
      "|    policy_gradient_loss | -0.00189      |\n",
      "|    reward               | -0.41143504   |\n",
      "|    std                  | 58.7          |\n",
      "|    value_loss           | 34            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2709         |\n",
      "|    time_elapsed         | 50382        |\n",
      "|    total_timesteps      | 5548032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011511175 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.137        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 27080        |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    reward               | -0.19038144  |\n",
      "|    std                  | 58.8         |\n",
      "|    value_loss           | 48.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2710        |\n",
      "|    time_elapsed         | 50400       |\n",
      "|    total_timesteps      | 5550080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004194088 |\n",
      "|    clip_fraction        | 0.00698     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.38        |\n",
      "|    n_updates            | 27090       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -3.1765065  |\n",
      "|    std                  | 58.9        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3424272.72\n",
      "total_reward: 2424272.72\n",
      "total_cost: 439783.43\n",
      "total_trades: 74079\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2711         |\n",
      "|    time_elapsed         | 50419        |\n",
      "|    total_timesteps      | 5552128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009323264 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.169        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 27100        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | -0.09867881  |\n",
      "|    std                  | 59           |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2712         |\n",
      "|    time_elapsed         | 50437        |\n",
      "|    total_timesteps      | 5554176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013728531 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 27110        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -7.6270986   |\n",
      "|    std                  | 59.1         |\n",
      "|    value_loss           | 39.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2713         |\n",
      "|    time_elapsed         | 50456        |\n",
      "|    total_timesteps      | 5556224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012976093 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.86         |\n",
      "|    n_updates            | 27120        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -0.068896614 |\n",
      "|    std                  | 59.1         |\n",
      "|    value_loss           | 16.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2714         |\n",
      "|    time_elapsed         | 50475        |\n",
      "|    total_timesteps      | 5558272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009579676 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.89         |\n",
      "|    n_updates            | 27130        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | -0.7629089   |\n",
      "|    std                  | 59.2         |\n",
      "|    value_loss           | 14.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2715         |\n",
      "|    time_elapsed         | 50494        |\n",
      "|    total_timesteps      | 5560320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010830048 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 27140        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 2.7053561    |\n",
      "|    std                  | 59.2         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2716        |\n",
      "|    time_elapsed         | 50513       |\n",
      "|    total_timesteps      | 5562368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000672178 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 27150       |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | -1.8378674  |\n",
      "|    std                  | 59.2        |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2717         |\n",
      "|    time_elapsed         | 50531        |\n",
      "|    total_timesteps      | 5564416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028299948 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.86         |\n",
      "|    n_updates            | 27160        |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    reward               | -0.25153828  |\n",
      "|    std                  | 59.3         |\n",
      "|    value_loss           | 14.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2718          |\n",
      "|    time_elapsed         | 50551         |\n",
      "|    total_timesteps      | 5566464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025254893 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.627         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.73          |\n",
      "|    n_updates            | 27170         |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    reward               | 1.571519      |\n",
      "|    std                  | 59.4          |\n",
      "|    value_loss           | 28.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2719          |\n",
      "|    time_elapsed         | 50569         |\n",
      "|    total_timesteps      | 5568512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068685145 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.569         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.9          |\n",
      "|    n_updates            | 27180         |\n",
      "|    policy_gradient_loss | -0.0027       |\n",
      "|    reward               | -2.334322     |\n",
      "|    std                  | 59.5          |\n",
      "|    value_loss           | 35.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2720         |\n",
      "|    time_elapsed         | 50588        |\n",
      "|    total_timesteps      | 5570560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030594165 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.196        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 27190        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | -0.8901356   |\n",
      "|    std                  | 59.6         |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2721         |\n",
      "|    time_elapsed         | 50606        |\n",
      "|    total_timesteps      | 5572608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012075091 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29           |\n",
      "|    n_updates            | 27200        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -1.4559896   |\n",
      "|    std                  | 59.8         |\n",
      "|    value_loss           | 47.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 2722       |\n",
      "|    time_elapsed         | 50625      |\n",
      "|    total_timesteps      | 5574656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0011866  |\n",
      "|    clip_fraction        | 0.000439   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -159       |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.6       |\n",
      "|    n_updates            | 27210      |\n",
      "|    policy_gradient_loss | -0.00332   |\n",
      "|    reward               | -0.5977763 |\n",
      "|    std                  | 59.9       |\n",
      "|    value_loss           | 38.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2723         |\n",
      "|    time_elapsed         | 50643        |\n",
      "|    total_timesteps      | 5576704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013345163 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.311        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.73         |\n",
      "|    n_updates            | 27220        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    reward               | 0.30267575   |\n",
      "|    std                  | 60           |\n",
      "|    value_loss           | 19.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2724          |\n",
      "|    time_elapsed         | 50662         |\n",
      "|    total_timesteps      | 5578752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069440715 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.332         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 24.4          |\n",
      "|    n_updates            | 27230         |\n",
      "|    policy_gradient_loss | -0.00212      |\n",
      "|    reward               | 0.8413331     |\n",
      "|    std                  | 60.2          |\n",
      "|    value_loss           | 38.8          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2474209.66\n",
      "total_reward: 1474209.66\n",
      "total_cost: 503004.32\n",
      "total_trades: 76842\n",
      "Sharpe: 0.563\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2725        |\n",
      "|    time_elapsed         | 50680       |\n",
      "|    total_timesteps      | 5580800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001035182 |\n",
      "|    clip_fraction        | 0.00156     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 27240       |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | 0.33087146  |\n",
      "|    std                  | 60.2        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2726        |\n",
      "|    time_elapsed         | 50699       |\n",
      "|    total_timesteps      | 5582848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000705834 |\n",
      "|    clip_fraction        | 0.000684    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 27250       |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    reward               | 0.5623849   |\n",
      "|    std                  | 60.3        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2727        |\n",
      "|    time_elapsed         | 50717       |\n",
      "|    total_timesteps      | 5584896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004720779 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.51        |\n",
      "|    n_updates            | 27260       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | -2.4459207  |\n",
      "|    std                  | 60.5        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2728         |\n",
      "|    time_elapsed         | 50735        |\n",
      "|    total_timesteps      | 5586944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013029609 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 27270        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 0.35749775   |\n",
      "|    std                  | 60.7         |\n",
      "|    value_loss           | 50.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2729         |\n",
      "|    time_elapsed         | 50754        |\n",
      "|    total_timesteps      | 5588992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010545334 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 27280        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | 2.1558516    |\n",
      "|    std                  | 60.8         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2730          |\n",
      "|    time_elapsed         | 50772         |\n",
      "|    total_timesteps      | 5591040       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054667774 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.374         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.9          |\n",
      "|    n_updates            | 27290         |\n",
      "|    policy_gradient_loss | -0.00204      |\n",
      "|    reward               | -4.689146     |\n",
      "|    std                  | 60.7          |\n",
      "|    value_loss           | 33.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2731         |\n",
      "|    time_elapsed         | 50791        |\n",
      "|    total_timesteps      | 5593088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004915813 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 27300        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | 0.7995427    |\n",
      "|    std                  | 60.8         |\n",
      "|    value_loss           | 51.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2732          |\n",
      "|    time_elapsed         | 50810         |\n",
      "|    total_timesteps      | 5595136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023458939 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.594         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.2          |\n",
      "|    n_updates            | 27310         |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    reward               | 0.38973528    |\n",
      "|    std                  | 60.8          |\n",
      "|    value_loss           | 38.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2733          |\n",
      "|    time_elapsed         | 50829         |\n",
      "|    total_timesteps      | 5597184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020805452 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.511         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.3          |\n",
      "|    n_updates            | 27320         |\n",
      "|    policy_gradient_loss | -0.000892     |\n",
      "|    reward               | -0.3225773    |\n",
      "|    std                  | 60.8          |\n",
      "|    value_loss           | 49.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2734         |\n",
      "|    time_elapsed         | 50848        |\n",
      "|    total_timesteps      | 5599232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034739643 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.44         |\n",
      "|    n_updates            | 27330        |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | 0.9602366    |\n",
      "|    std                  | 61           |\n",
      "|    value_loss           | 12.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2735         |\n",
      "|    time_elapsed         | 50866        |\n",
      "|    total_timesteps      | 5601280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007135047 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 27340        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 0.07681164   |\n",
      "|    std                  | 61           |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2736          |\n",
      "|    time_elapsed         | 50884         |\n",
      "|    total_timesteps      | 5603328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012262823 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.713         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.1          |\n",
      "|    n_updates            | 27350         |\n",
      "|    policy_gradient_loss | -0.000845     |\n",
      "|    reward               | 3.316475      |\n",
      "|    std                  | 61.1          |\n",
      "|    value_loss           | 32.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2737          |\n",
      "|    time_elapsed         | 50903         |\n",
      "|    total_timesteps      | 5605376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068750366 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.597         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.06          |\n",
      "|    n_updates            | 27360         |\n",
      "|    policy_gradient_loss | -0.00249      |\n",
      "|    reward               | -0.4192365    |\n",
      "|    std                  | 61.1          |\n",
      "|    value_loss           | 21.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2738         |\n",
      "|    time_elapsed         | 50921        |\n",
      "|    total_timesteps      | 5607424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007515546 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.31         |\n",
      "|    n_updates            | 27370        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | -1.1905406   |\n",
      "|    std                  | 61.2         |\n",
      "|    value_loss           | 17.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2739          |\n",
      "|    time_elapsed         | 50940         |\n",
      "|    total_timesteps      | 5609472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080189935 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.625         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.8          |\n",
      "|    n_updates            | 27380         |\n",
      "|    policy_gradient_loss | -0.00342      |\n",
      "|    reward               | 6.646107      |\n",
      "|    std                  | 61.2          |\n",
      "|    value_loss           | 38.6          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3117137.15\n",
      "total_reward: 2117137.15\n",
      "total_cost: 461632.58\n",
      "total_trades: 74999\n",
      "Sharpe: 0.689\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2740          |\n",
      "|    time_elapsed         | 50958         |\n",
      "|    total_timesteps      | 5611520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051714864 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.47          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.1          |\n",
      "|    n_updates            | 27390         |\n",
      "|    policy_gradient_loss | -0.00175      |\n",
      "|    reward               | 0.32209376    |\n",
      "|    std                  | 61.1          |\n",
      "|    value_loss           | 37.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2741         |\n",
      "|    time_elapsed         | 50976        |\n",
      "|    total_timesteps      | 5613568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042837923 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.32         |\n",
      "|    n_updates            | 27400        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | -0.045284327 |\n",
      "|    std                  | 61.4         |\n",
      "|    value_loss           | 10.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2742         |\n",
      "|    time_elapsed         | 50995        |\n",
      "|    total_timesteps      | 5615616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007984469 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 27410        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 0.49686348   |\n",
      "|    std                  | 61.5         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2743          |\n",
      "|    time_elapsed         | 51013         |\n",
      "|    total_timesteps      | 5617664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012117342 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.647         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.8           |\n",
      "|    n_updates            | 27420         |\n",
      "|    policy_gradient_loss | -0.000711     |\n",
      "|    reward               | -1.8880886    |\n",
      "|    std                  | 61.5          |\n",
      "|    value_loss           | 24.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2744         |\n",
      "|    time_elapsed         | 51032        |\n",
      "|    total_timesteps      | 5619712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022889487 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.77         |\n",
      "|    n_updates            | 27430        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | 0.6422371    |\n",
      "|    std                  | 61.6         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2745         |\n",
      "|    time_elapsed         | 51051        |\n",
      "|    total_timesteps      | 5621760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017281561 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.59         |\n",
      "|    n_updates            | 27440        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | 0.08113589   |\n",
      "|    std                  | 61.7         |\n",
      "|    value_loss           | 17.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2746         |\n",
      "|    time_elapsed         | 51069        |\n",
      "|    total_timesteps      | 5623808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006094317 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 27450        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | -2.5346181   |\n",
      "|    std                  | 61.7         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2747          |\n",
      "|    time_elapsed         | 51088         |\n",
      "|    total_timesteps      | 5625856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038915657 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.474         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.9          |\n",
      "|    n_updates            | 27460         |\n",
      "|    policy_gradient_loss | -0.00207      |\n",
      "|    reward               | -1.1027997    |\n",
      "|    std                  | 61.7          |\n",
      "|    value_loss           | 22.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2748         |\n",
      "|    time_elapsed         | 51106        |\n",
      "|    total_timesteps      | 5627904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010496145 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 27470        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.5034186    |\n",
      "|    std                  | 61.7         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2749         |\n",
      "|    time_elapsed         | 51124        |\n",
      "|    total_timesteps      | 5629952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012012252 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6            |\n",
      "|    n_updates            | 27480        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -0.14054988  |\n",
      "|    std                  | 61.8         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2750          |\n",
      "|    time_elapsed         | 51143         |\n",
      "|    total_timesteps      | 5632000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068430847 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.8          |\n",
      "|    n_updates            | 27490         |\n",
      "|    policy_gradient_loss | -0.00236      |\n",
      "|    reward               | -2.234791     |\n",
      "|    std                  | 61.8          |\n",
      "|    value_loss           | 37.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2751         |\n",
      "|    time_elapsed         | 51163        |\n",
      "|    total_timesteps      | 5634048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041904775 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.1          |\n",
      "|    n_updates            | 27500        |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    reward               | -1.2255142   |\n",
      "|    std                  | 61.9         |\n",
      "|    value_loss           | 15.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2752          |\n",
      "|    time_elapsed         | 51182         |\n",
      "|    total_timesteps      | 5636096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028508238 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.518         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.9          |\n",
      "|    n_updates            | 27510         |\n",
      "|    policy_gradient_loss | -0.00103      |\n",
      "|    reward               | 0.726641      |\n",
      "|    std                  | 62            |\n",
      "|    value_loss           | 62.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2753         |\n",
      "|    time_elapsed         | 51201        |\n",
      "|    total_timesteps      | 5638144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005438698 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 27520        |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    reward               | 1.5962421    |\n",
      "|    std                  | 62           |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2462208.75\n",
      "total_reward: 1462208.75\n",
      "total_cost: 449412.10\n",
      "total_trades: 75132\n",
      "Sharpe: 0.558\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2754         |\n",
      "|    time_elapsed         | 51221        |\n",
      "|    total_timesteps      | 5640192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021662805 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.1          |\n",
      "|    n_updates            | 27530        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | -0.62377965  |\n",
      "|    std                  | 62           |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2755         |\n",
      "|    time_elapsed         | 51239        |\n",
      "|    total_timesteps      | 5642240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012893726 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 27540        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -0.39959362  |\n",
      "|    std                  | 62.1         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2756         |\n",
      "|    time_elapsed         | 51257        |\n",
      "|    total_timesteps      | 5644288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009667261 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 27550        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 1.2504758    |\n",
      "|    std                  | 62.2         |\n",
      "|    value_loss           | 46.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2757         |\n",
      "|    time_elapsed         | 51276        |\n",
      "|    total_timesteps      | 5646336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002396814 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28           |\n",
      "|    n_updates            | 27560        |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    reward               | 0.14061911   |\n",
      "|    std                  | 62.2         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2758         |\n",
      "|    time_elapsed         | 51294        |\n",
      "|    total_timesteps      | 5648384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027408947 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.61         |\n",
      "|    n_updates            | 27570        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | -1.0888392   |\n",
      "|    std                  | 62.6         |\n",
      "|    value_loss           | 16.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2759          |\n",
      "|    time_elapsed         | 51312         |\n",
      "|    total_timesteps      | 5650432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077449356 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.687         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.09          |\n",
      "|    n_updates            | 27580         |\n",
      "|    policy_gradient_loss | -0.00396      |\n",
      "|    reward               | -0.63727546   |\n",
      "|    std                  | 62.7          |\n",
      "|    value_loss           | 33.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2760         |\n",
      "|    time_elapsed         | 51331        |\n",
      "|    total_timesteps      | 5652480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013513557 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.0467       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.5         |\n",
      "|    n_updates            | 27590        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | 0.32894236   |\n",
      "|    std                  | 62.8         |\n",
      "|    value_loss           | 73.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2761         |\n",
      "|    time_elapsed         | 51349        |\n",
      "|    total_timesteps      | 5654528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035489853 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.31         |\n",
      "|    n_updates            | 27600        |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | 0.1120757    |\n",
      "|    std                  | 62.8         |\n",
      "|    value_loss           | 12.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2762         |\n",
      "|    time_elapsed         | 51368        |\n",
      "|    total_timesteps      | 5656576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006928866 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 27610        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | 0.38236663   |\n",
      "|    std                  | 62.9         |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2763        |\n",
      "|    time_elapsed         | 51386       |\n",
      "|    total_timesteps      | 5658624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002074859 |\n",
      "|    clip_fraction        | 0.00317     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -160        |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76          |\n",
      "|    n_updates            | 27620       |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    reward               | -7.927418   |\n",
      "|    std                  | 63.1        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2764         |\n",
      "|    time_elapsed         | 51404        |\n",
      "|    total_timesteps      | 5660672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016480398 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 27630        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 0.3149447    |\n",
      "|    std                  | 63.2         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2765         |\n",
      "|    time_elapsed         | 51423        |\n",
      "|    total_timesteps      | 5662720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016171962 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.119        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 27640        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -1.5229352   |\n",
      "|    std                  | 63.3         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2766          |\n",
      "|    time_elapsed         | 51441         |\n",
      "|    total_timesteps      | 5664768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066529994 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.032         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.9          |\n",
      "|    n_updates            | 27650         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    reward               | -2.9599657    |\n",
      "|    std                  | 63.4          |\n",
      "|    value_loss           | 82.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2767         |\n",
      "|    time_elapsed         | 51460        |\n",
      "|    total_timesteps      | 5666816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008343527 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 27660        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | 5.103109     |\n",
      "|    std                  | 63.4         |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2182469.24\n",
      "total_reward: 1182469.24\n",
      "total_cost: 493253.26\n",
      "total_trades: 76524\n",
      "Sharpe: 0.484\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2768         |\n",
      "|    time_elapsed         | 51479        |\n",
      "|    total_timesteps      | 5668864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029186273 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.17         |\n",
      "|    n_updates            | 27670        |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | 0.4932098    |\n",
      "|    std                  | 63.6         |\n",
      "|    value_loss           | 14.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2769         |\n",
      "|    time_elapsed         | 51497        |\n",
      "|    total_timesteps      | 5670912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006757097 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.2         |\n",
      "|    n_updates            | 27680        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    reward               | 1.1484388    |\n",
      "|    std                  | 63.7         |\n",
      "|    value_loss           | 40.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2770          |\n",
      "|    time_elapsed         | 51516         |\n",
      "|    total_timesteps      | 5672960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044377227 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.505         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.9          |\n",
      "|    n_updates            | 27690         |\n",
      "|    policy_gradient_loss | -0.0014       |\n",
      "|    reward               | 0.043644022   |\n",
      "|    std                  | 63.8          |\n",
      "|    value_loss           | 41.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2771         |\n",
      "|    time_elapsed         | 51535        |\n",
      "|    total_timesteps      | 5675008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019771508 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.26         |\n",
      "|    n_updates            | 27700        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 1.21012      |\n",
      "|    std                  | 64           |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2772         |\n",
      "|    time_elapsed         | 51553        |\n",
      "|    total_timesteps      | 5677056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016069358 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.63         |\n",
      "|    n_updates            | 27710        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | 0.4448659    |\n",
      "|    std                  | 64           |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2773         |\n",
      "|    time_elapsed         | 51571        |\n",
      "|    total_timesteps      | 5679104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005284097 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 27720        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    reward               | -0.15608315  |\n",
      "|    std                  | 64.1         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2774         |\n",
      "|    time_elapsed         | 51590        |\n",
      "|    total_timesteps      | 5681152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018883728 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 27730        |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | 0.77474266   |\n",
      "|    std                  | 64.2         |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2775          |\n",
      "|    time_elapsed         | 51608         |\n",
      "|    total_timesteps      | 5683200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0038971237  |\n",
      "|    clip_fraction        | 0.00889       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.107         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.74          |\n",
      "|    n_updates            | 27740         |\n",
      "|    policy_gradient_loss | -0.00684      |\n",
      "|    reward               | -0.0069119507 |\n",
      "|    std                  | 64.3          |\n",
      "|    value_loss           | 12.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2776         |\n",
      "|    time_elapsed         | 51627        |\n",
      "|    total_timesteps      | 5685248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013269042 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.0391       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.7         |\n",
      "|    n_updates            | 27750        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 0.12981148   |\n",
      "|    std                  | 64.4         |\n",
      "|    value_loss           | 56.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2777         |\n",
      "|    time_elapsed         | 51646        |\n",
      "|    total_timesteps      | 5687296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026887138 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.0563       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49           |\n",
      "|    n_updates            | 27760        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | 1.962676     |\n",
      "|    std                  | 64.6         |\n",
      "|    value_loss           | 71.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2778         |\n",
      "|    time_elapsed         | 51664        |\n",
      "|    total_timesteps      | 5689344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008974243 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.245        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 27770        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | -0.98029685  |\n",
      "|    std                  | 64.7         |\n",
      "|    value_loss           | 25.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2779         |\n",
      "|    time_elapsed         | 51683        |\n",
      "|    total_timesteps      | 5691392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020787423 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 27780        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 0.46123824   |\n",
      "|    std                  | 64.8         |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2780         |\n",
      "|    time_elapsed         | 51702        |\n",
      "|    total_timesteps      | 5693440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008158126 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 27790        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | 0.24681337   |\n",
      "|    std                  | 64.9         |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2781         |\n",
      "|    time_elapsed         | 51721        |\n",
      "|    total_timesteps      | 5695488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010773863 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 27800        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | -0.15998767  |\n",
      "|    std                  | 64.9         |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3353992.83\n",
      "total_reward: 2353992.83\n",
      "total_cost: 494433.12\n",
      "total_trades: 76589\n",
      "Sharpe: 0.706\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2782         |\n",
      "|    time_elapsed         | 51740        |\n",
      "|    total_timesteps      | 5697536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035492347 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.106        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.04         |\n",
      "|    n_updates            | 27810        |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    reward               | -0.2237642   |\n",
      "|    std                  | 65.2         |\n",
      "|    value_loss           | 15.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2783          |\n",
      "|    time_elapsed         | 51760         |\n",
      "|    total_timesteps      | 5699584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069108093 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.105         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.5          |\n",
      "|    n_updates            | 27820         |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    reward               | -2.731249     |\n",
      "|    std                  | 65.3          |\n",
      "|    value_loss           | 52.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2784          |\n",
      "|    time_elapsed         | 51780         |\n",
      "|    total_timesteps      | 5701632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058075355 |\n",
      "|    clip_fraction        | 0.000684      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.324         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25            |\n",
      "|    n_updates            | 27830         |\n",
      "|    policy_gradient_loss | -0.00196      |\n",
      "|    reward               | 6.4039807     |\n",
      "|    std                  | 65.3          |\n",
      "|    value_loss           | 52            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2785         |\n",
      "|    time_elapsed         | 51799        |\n",
      "|    total_timesteps      | 5703680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015835704 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.67         |\n",
      "|    n_updates            | 27840        |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    reward               | 0.63418144   |\n",
      "|    std                  | 65.5         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2786         |\n",
      "|    time_elapsed         | 51817        |\n",
      "|    total_timesteps      | 5705728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008072638 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 27850        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | 3.0705419    |\n",
      "|    std                  | 65.5         |\n",
      "|    value_loss           | 58.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2787         |\n",
      "|    time_elapsed         | 51837        |\n",
      "|    total_timesteps      | 5707776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004988315 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 27860        |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    reward               | -1.6993241   |\n",
      "|    std                  | 65.6         |\n",
      "|    value_loss           | 51.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2788        |\n",
      "|    time_elapsed         | 51855       |\n",
      "|    total_timesteps      | 5709824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000719039 |\n",
      "|    clip_fraction        | 0.0041      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -161        |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 27870       |\n",
      "|    policy_gradient_loss | -0.000352   |\n",
      "|    reward               | -5.4162126  |\n",
      "|    std                  | 65.6        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2789         |\n",
      "|    time_elapsed         | 51874        |\n",
      "|    total_timesteps      | 5711872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023026068 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.08         |\n",
      "|    n_updates            | 27880        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 1.1163795    |\n",
      "|    std                  | 65.8         |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2790         |\n",
      "|    time_elapsed         | 51893        |\n",
      "|    total_timesteps      | 5713920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014724662 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 27890        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 0.5444619    |\n",
      "|    std                  | 65.9         |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2791          |\n",
      "|    time_elapsed         | 51911         |\n",
      "|    total_timesteps      | 5715968       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064343493 |\n",
      "|    clip_fraction        | 0.00107       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.325         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.6          |\n",
      "|    n_updates            | 27900         |\n",
      "|    policy_gradient_loss | -0.000953     |\n",
      "|    reward               | 2.4984622     |\n",
      "|    std                  | 65.9          |\n",
      "|    value_loss           | 77.1          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2792         |\n",
      "|    time_elapsed         | 51930        |\n",
      "|    total_timesteps      | 5718016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027724868 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.34         |\n",
      "|    n_updates            | 27910        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    reward               | 2.4648814    |\n",
      "|    std                  | 66.1         |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2793         |\n",
      "|    time_elapsed         | 51948        |\n",
      "|    total_timesteps      | 5720064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019381406 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 27920        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    reward               | 0.49664474   |\n",
      "|    std                  | 66.2         |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2794         |\n",
      "|    time_elapsed         | 51967        |\n",
      "|    total_timesteps      | 5722112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016145783 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.21         |\n",
      "|    n_updates            | 27930        |\n",
      "|    policy_gradient_loss | -0.000812    |\n",
      "|    reward               | -0.3305026   |\n",
      "|    std                  | 66.2         |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2795         |\n",
      "|    time_elapsed         | 51986        |\n",
      "|    total_timesteps      | 5724160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021203656 |\n",
      "|    clip_fraction        | 0.00747      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 27940        |\n",
      "|    policy_gradient_loss | -0.000791    |\n",
      "|    reward               | -1.3091117   |\n",
      "|    std                  | 66.4         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3197230.62\n",
      "total_reward: 2197230.62\n",
      "total_cost: 504589.22\n",
      "total_trades: 76497\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2796         |\n",
      "|    time_elapsed         | 52005        |\n",
      "|    total_timesteps      | 5726208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024258536 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.3         |\n",
      "|    n_updates            | 27950        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | -0.25479716  |\n",
      "|    std                  | 66.6         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2797         |\n",
      "|    time_elapsed         | 52024        |\n",
      "|    total_timesteps      | 5728256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027201446 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.0962       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 27960        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | 0.090515114  |\n",
      "|    std                  | 66.8         |\n",
      "|    value_loss           | 49.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2798         |\n",
      "|    time_elapsed         | 52043        |\n",
      "|    total_timesteps      | 5730304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003784422 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 27970        |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    reward               | 0.14991687   |\n",
      "|    std                  | 66.9         |\n",
      "|    value_loss           | 52           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2799         |\n",
      "|    time_elapsed         | 52061        |\n",
      "|    total_timesteps      | 5732352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051854467 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.84         |\n",
      "|    n_updates            | 27980        |\n",
      "|    policy_gradient_loss | -0.00925     |\n",
      "|    reward               | 1.1177517    |\n",
      "|    std                  | 67.1         |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2800         |\n",
      "|    time_elapsed         | 52080        |\n",
      "|    total_timesteps      | 5734400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008482745 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 27990        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | 1.7656406    |\n",
      "|    std                  | 67.2         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2801          |\n",
      "|    time_elapsed         | 52098         |\n",
      "|    total_timesteps      | 5736448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048093303 |\n",
      "|    clip_fraction        | 0.0019        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.24          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.5          |\n",
      "|    n_updates            | 28000         |\n",
      "|    policy_gradient_loss | -0.00166      |\n",
      "|    reward               | 1.8745126     |\n",
      "|    std                  | 67.3          |\n",
      "|    value_loss           | 41.3          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2802         |\n",
      "|    time_elapsed         | 52117        |\n",
      "|    total_timesteps      | 5738496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022330026 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.208        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 28010        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | -6.3764153   |\n",
      "|    std                  | 67.4         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2803          |\n",
      "|    time_elapsed         | 52136         |\n",
      "|    total_timesteps      | 5740544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053992716 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.359         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.9          |\n",
      "|    n_updates            | 28020         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | -0.7866462    |\n",
      "|    std                  | 67.5          |\n",
      "|    value_loss           | 46            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2804         |\n",
      "|    time_elapsed         | 52154        |\n",
      "|    total_timesteps      | 5742592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010416202 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 28030        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | 3.8650465    |\n",
      "|    std                  | 67.5         |\n",
      "|    value_loss           | 69.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2805         |\n",
      "|    time_elapsed         | 52173        |\n",
      "|    total_timesteps      | 5744640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007551806 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 28040        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | 0.43510982   |\n",
      "|    std                  | 67.7         |\n",
      "|    value_loss           | 51.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2806        |\n",
      "|    time_elapsed         | 52191       |\n",
      "|    total_timesteps      | 5746688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006718085 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -162        |\n",
      "|    explained_variance   | 0.0624      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.76        |\n",
      "|    n_updates            | 28050       |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    reward               | -1.3750457  |\n",
      "|    std                  | 68          |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2807         |\n",
      "|    time_elapsed         | 52210        |\n",
      "|    total_timesteps      | 5748736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025174273 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.101        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.2         |\n",
      "|    n_updates            | 28060        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | -1.0026059   |\n",
      "|    std                  | 68.1         |\n",
      "|    value_loss           | 64           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2808          |\n",
      "|    time_elapsed         | 52229         |\n",
      "|    total_timesteps      | 5750784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069533277 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.128         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.9          |\n",
      "|    n_updates            | 28070         |\n",
      "|    policy_gradient_loss | -0.00215      |\n",
      "|    reward               | 0.8980363     |\n",
      "|    std                  | 68.2          |\n",
      "|    value_loss           | 58.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2809         |\n",
      "|    time_elapsed         | 52247        |\n",
      "|    total_timesteps      | 5752832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014159898 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.319        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.36         |\n",
      "|    n_updates            | 28080        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | -1.3423218   |\n",
      "|    std                  | 68.3         |\n",
      "|    value_loss           | 18.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2423436.88\n",
      "total_reward: 1423436.88\n",
      "total_cost: 465873.52\n",
      "total_trades: 74966\n",
      "Sharpe: 0.532\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2810         |\n",
      "|    time_elapsed         | 52267        |\n",
      "|    total_timesteps      | 5754880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021749204 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 28090        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -1.9560217   |\n",
      "|    std                  | 68.6         |\n",
      "|    value_loss           | 38.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2811         |\n",
      "|    time_elapsed         | 52286        |\n",
      "|    total_timesteps      | 5756928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010516134 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.19         |\n",
      "|    n_updates            | 28100        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 2.55374      |\n",
      "|    std                  | 68.6         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2812          |\n",
      "|    time_elapsed         | 52304         |\n",
      "|    total_timesteps      | 5758976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063501205 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.421         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.72          |\n",
      "|    n_updates            | 28110         |\n",
      "|    policy_gradient_loss | -0.00103      |\n",
      "|    reward               | 0.19205603    |\n",
      "|    std                  | 68.7          |\n",
      "|    value_loss           | 28.7          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2813        |\n",
      "|    time_elapsed         | 52322       |\n",
      "|    total_timesteps      | 5761024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003387346 |\n",
      "|    clip_fraction        | 0.00967     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -163        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.52        |\n",
      "|    n_updates            | 28120       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | 1.1310816   |\n",
      "|    std                  | 68.9        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2814         |\n",
      "|    time_elapsed         | 52341        |\n",
      "|    total_timesteps      | 5763072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025897669 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.026        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 28130        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | 0.10896191   |\n",
      "|    std                  | 69.2         |\n",
      "|    value_loss           | 49.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2815         |\n",
      "|    time_elapsed         | 52359        |\n",
      "|    total_timesteps      | 5765120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004762571 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 28140        |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    reward               | -1.4413033   |\n",
      "|    std                  | 69.2         |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2816         |\n",
      "|    time_elapsed         | 52377        |\n",
      "|    total_timesteps      | 5767168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019415026 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.319        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.75         |\n",
      "|    n_updates            | 28150        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | 0.5718344    |\n",
      "|    std                  | 69.3         |\n",
      "|    value_loss           | 15.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2817         |\n",
      "|    time_elapsed         | 52396        |\n",
      "|    total_timesteps      | 5769216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020371994 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 28160        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | -0.17285834  |\n",
      "|    std                  | 69.6         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2818         |\n",
      "|    time_elapsed         | 52414        |\n",
      "|    total_timesteps      | 5771264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010660941 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 28170        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 3.8256898    |\n",
      "|    std                  | 69.7         |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2819         |\n",
      "|    time_elapsed         | 52433        |\n",
      "|    total_timesteps      | 5773312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005787896 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.359        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 28180        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    reward               | 1.8697088    |\n",
      "|    std                  | 69.8         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2820         |\n",
      "|    time_elapsed         | 52452        |\n",
      "|    total_timesteps      | 5775360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008124877 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.167        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 28190        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | 2.4140294    |\n",
      "|    std                  | 69.8         |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2821         |\n",
      "|    time_elapsed         | 52470        |\n",
      "|    total_timesteps      | 5777408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017598886 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 28200        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | 0.7820717    |\n",
      "|    std                  | 69.9         |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2822         |\n",
      "|    time_elapsed         | 52489        |\n",
      "|    total_timesteps      | 5779456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008595033 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 28210        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | -0.41921404  |\n",
      "|    std                  | 70.1         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2823         |\n",
      "|    time_elapsed         | 52507        |\n",
      "|    total_timesteps      | 5781504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048653916 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.58         |\n",
      "|    n_updates            | 28220        |\n",
      "|    policy_gradient_loss | -0.00788     |\n",
      "|    reward               | -1.0922676   |\n",
      "|    std                  | 70.3         |\n",
      "|    value_loss           | 10.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2607397.54\n",
      "total_reward: 1607397.54\n",
      "total_cost: 498474.04\n",
      "total_trades: 76555\n",
      "Sharpe: 0.572\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2824          |\n",
      "|    time_elapsed         | 52526         |\n",
      "|    total_timesteps      | 5783552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043150486 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -163          |\n",
      "|    explained_variance   | 0.562         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.1          |\n",
      "|    n_updates            | 28230         |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    reward               | 0.53182364    |\n",
      "|    std                  | 70.3          |\n",
      "|    value_loss           | 44.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2825         |\n",
      "|    time_elapsed         | 52544        |\n",
      "|    total_timesteps      | 5785600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010310232 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 28240        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | 0.5971702    |\n",
      "|    std                  | 70.3         |\n",
      "|    value_loss           | 51           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2826         |\n",
      "|    time_elapsed         | 52563        |\n",
      "|    total_timesteps      | 5787648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017509935 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.61         |\n",
      "|    n_updates            | 28250        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | 0.3967717    |\n",
      "|    std                  | 70.3         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2827         |\n",
      "|    time_elapsed         | 52581        |\n",
      "|    total_timesteps      | 5789696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012891758 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.83         |\n",
      "|    n_updates            | 28260        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 0.6242623    |\n",
      "|    std                  | 70.5         |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2828         |\n",
      "|    time_elapsed         | 52599        |\n",
      "|    total_timesteps      | 5791744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015572814 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.4          |\n",
      "|    n_updates            | 28270        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | 0.9140691    |\n",
      "|    std                  | 70.6         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2829         |\n",
      "|    time_elapsed         | 52617        |\n",
      "|    total_timesteps      | 5793792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014223154 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 28280        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | 1.0936636    |\n",
      "|    std                  | 70.8         |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2830        |\n",
      "|    time_elapsed         | 52635       |\n",
      "|    total_timesteps      | 5795840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004274144 |\n",
      "|    clip_fraction        | 0.00972     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -163        |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.75        |\n",
      "|    n_updates            | 28290       |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | -1.4560632  |\n",
      "|    std                  | 70.8        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2831         |\n",
      "|    time_elapsed         | 52654        |\n",
      "|    total_timesteps      | 5797888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010752348 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 28300        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | -0.65349364  |\n",
      "|    std                  | 70.9         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2832         |\n",
      "|    time_elapsed         | 52672        |\n",
      "|    total_timesteps      | 5799936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007010818 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 28310        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | -0.25197527  |\n",
      "|    std                  | 70.9         |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2833         |\n",
      "|    time_elapsed         | 52690        |\n",
      "|    total_timesteps      | 5801984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016632148 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.119        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.96         |\n",
      "|    n_updates            | 28320        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -1.2998557   |\n",
      "|    std                  | 70.9         |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2834         |\n",
      "|    time_elapsed         | 52709        |\n",
      "|    total_timesteps      | 5804032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028472722 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.0281       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 28330        |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    reward               | -0.57731164  |\n",
      "|    std                  | 71.3         |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2835         |\n",
      "|    time_elapsed         | 52727        |\n",
      "|    total_timesteps      | 5806080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00070231   |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.87         |\n",
      "|    n_updates            | 28340        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | -0.063836485 |\n",
      "|    std                  | 71.3         |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2836          |\n",
      "|    time_elapsed         | 52746         |\n",
      "|    total_timesteps      | 5808128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041082583 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -164          |\n",
      "|    explained_variance   | 0.393         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.9          |\n",
      "|    n_updates            | 28350         |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    reward               | 0.065534085   |\n",
      "|    std                  | 71.3          |\n",
      "|    value_loss           | 32.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2837         |\n",
      "|    time_elapsed         | 52764        |\n",
      "|    total_timesteps      | 5810176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021034973 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.99         |\n",
      "|    n_updates            | 28360        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.44437486   |\n",
      "|    std                  | 71.4         |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2667377.58\n",
      "total_reward: 1667377.58\n",
      "total_cost: 489236.96\n",
      "total_trades: 76805\n",
      "Sharpe: 0.609\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2838         |\n",
      "|    time_elapsed         | 52783        |\n",
      "|    total_timesteps      | 5812224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021322425 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.145        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.5          |\n",
      "|    n_updates            | 28370        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -0.30989322  |\n",
      "|    std                  | 71.5         |\n",
      "|    value_loss           | 39.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2839         |\n",
      "|    time_elapsed         | 52802        |\n",
      "|    total_timesteps      | 5814272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014234335 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 28380        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | 15.741497    |\n",
      "|    std                  | 71.7         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2840        |\n",
      "|    time_elapsed         | 52820       |\n",
      "|    total_timesteps      | 5816320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004448776 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -164        |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 28390       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | 0.41605014  |\n",
      "|    std                  | 72          |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2841          |\n",
      "|    time_elapsed         | 52839         |\n",
      "|    total_timesteps      | 5818368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084254926 |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -164          |\n",
      "|    explained_variance   | 0.365         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.8          |\n",
      "|    n_updates            | 28400         |\n",
      "|    policy_gradient_loss | -0.00209      |\n",
      "|    reward               | 1.4458412     |\n",
      "|    std                  | 72.1          |\n",
      "|    value_loss           | 30.5          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2842         |\n",
      "|    time_elapsed         | 52857        |\n",
      "|    total_timesteps      | 5820416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007438259 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.62         |\n",
      "|    n_updates            | 28410        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | 0.50365365   |\n",
      "|    std                  | 72.1         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2843         |\n",
      "|    time_elapsed         | 52876        |\n",
      "|    total_timesteps      | 5822464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024638362 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.64         |\n",
      "|    n_updates            | 28420        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | -3.6800182   |\n",
      "|    std                  | 72.3         |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2844          |\n",
      "|    time_elapsed         | 52895         |\n",
      "|    total_timesteps      | 5824512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082194794 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -164          |\n",
      "|    explained_variance   | 0.698         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.45          |\n",
      "|    n_updates            | 28430         |\n",
      "|    policy_gradient_loss | -0.0025       |\n",
      "|    reward               | -1.2164394    |\n",
      "|    std                  | 72.3          |\n",
      "|    value_loss           | 16.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2845          |\n",
      "|    time_elapsed         | 52914         |\n",
      "|    total_timesteps      | 5826560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030830578 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -164          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.34          |\n",
      "|    n_updates            | 28440         |\n",
      "|    policy_gradient_loss | -0.00125      |\n",
      "|    reward               | -0.9825555    |\n",
      "|    std                  | 72.4          |\n",
      "|    value_loss           | 27.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2846         |\n",
      "|    time_elapsed         | 52933        |\n",
      "|    total_timesteps      | 5828608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002717955 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 28450        |\n",
      "|    policy_gradient_loss | -0.000981    |\n",
      "|    reward               | -0.953302    |\n",
      "|    std                  | 72.4         |\n",
      "|    value_loss           | 38.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2847         |\n",
      "|    time_elapsed         | 52951        |\n",
      "|    total_timesteps      | 5830656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021463057 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.45         |\n",
      "|    n_updates            | 28460        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | 1.002594     |\n",
      "|    std                  | 72.6         |\n",
      "|    value_loss           | 16.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2848         |\n",
      "|    time_elapsed         | 52970        |\n",
      "|    total_timesteps      | 5832704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007941213 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.261        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 28470        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 1.3800602    |\n",
      "|    std                  | 72.6         |\n",
      "|    value_loss           | 47.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2849          |\n",
      "|    time_elapsed         | 52988         |\n",
      "|    total_timesteps      | 5834752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065236085 |\n",
      "|    clip_fraction        | 0.00132       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -164          |\n",
      "|    explained_variance   | 0.507         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.3          |\n",
      "|    n_updates            | 28480         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | 5.1757183     |\n",
      "|    std                  | 72.6          |\n",
      "|    value_loss           | 41.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2850         |\n",
      "|    time_elapsed         | 53006        |\n",
      "|    total_timesteps      | 5836800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025196418 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.05         |\n",
      "|    n_updates            | 28490        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | 1.2790805    |\n",
      "|    std                  | 72.7         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2851         |\n",
      "|    time_elapsed         | 53025        |\n",
      "|    total_timesteps      | 5838848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005572537 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 28500        |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    reward               | -0.10091602  |\n",
      "|    std                  | 72.8         |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2852         |\n",
      "|    time_elapsed         | 53044        |\n",
      "|    total_timesteps      | 5840896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010751026 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 28510        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | -17.463951   |\n",
      "|    std                  | 73           |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3226367.58\n",
      "total_reward: 2226367.58\n",
      "total_cost: 346896.89\n",
      "total_trades: 71144\n",
      "Sharpe: 0.682\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2853          |\n",
      "|    time_elapsed         | 53062         |\n",
      "|    total_timesteps      | 5842944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046709183 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -164          |\n",
      "|    explained_variance   | 0.666         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.5          |\n",
      "|    n_updates            | 28520         |\n",
      "|    policy_gradient_loss | -0.00159      |\n",
      "|    reward               | 0.27525       |\n",
      "|    std                  | 73.1          |\n",
      "|    value_loss           | 32.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2854         |\n",
      "|    time_elapsed         | 53081        |\n",
      "|    total_timesteps      | 5844992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013514676 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.71         |\n",
      "|    n_updates            | 28530        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 0.3871519    |\n",
      "|    std                  | 73.2         |\n",
      "|    value_loss           | 20.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2855         |\n",
      "|    time_elapsed         | 53101        |\n",
      "|    total_timesteps      | 5847040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015386713 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 28540        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | 1.0722822    |\n",
      "|    std                  | 73.4         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2856          |\n",
      "|    time_elapsed         | 53119         |\n",
      "|    total_timesteps      | 5849088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033419856 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -165          |\n",
      "|    explained_variance   | 0.448         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.4          |\n",
      "|    n_updates            | 28550         |\n",
      "|    policy_gradient_loss | -0.00138      |\n",
      "|    reward               | 0.9623151     |\n",
      "|    std                  | 73.5          |\n",
      "|    value_loss           | 38.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2857          |\n",
      "|    time_elapsed         | 53138         |\n",
      "|    total_timesteps      | 5851136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096885307 |\n",
      "|    clip_fraction        | 0.00171       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -165          |\n",
      "|    explained_variance   | 0.408         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.04          |\n",
      "|    n_updates            | 28560         |\n",
      "|    policy_gradient_loss | -0.00202      |\n",
      "|    reward               | -2.244401     |\n",
      "|    std                  | 73.5          |\n",
      "|    value_loss           | 19.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2858          |\n",
      "|    time_elapsed         | 53157         |\n",
      "|    total_timesteps      | 5853184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087273173 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -165          |\n",
      "|    explained_variance   | 0.612         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.03          |\n",
      "|    n_updates            | 28570         |\n",
      "|    policy_gradient_loss | -0.00254      |\n",
      "|    reward               | -0.89287764   |\n",
      "|    std                  | 73.7          |\n",
      "|    value_loss           | 22            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2859          |\n",
      "|    time_elapsed         | 53175         |\n",
      "|    total_timesteps      | 5855232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022819659 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -165          |\n",
      "|    explained_variance   | 0.611         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.6          |\n",
      "|    n_updates            | 28580         |\n",
      "|    policy_gradient_loss | -0.000922     |\n",
      "|    reward               | -4.032937     |\n",
      "|    std                  | 73.8          |\n",
      "|    value_loss           | 36.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2860          |\n",
      "|    time_elapsed         | 53194         |\n",
      "|    total_timesteps      | 5857280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092295464 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -165          |\n",
      "|    explained_variance   | 0.366         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.44          |\n",
      "|    n_updates            | 28590         |\n",
      "|    policy_gradient_loss | -0.00303      |\n",
      "|    reward               | 2.084608      |\n",
      "|    std                  | 73.9          |\n",
      "|    value_loss           | 21.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2861         |\n",
      "|    time_elapsed         | 53212        |\n",
      "|    total_timesteps      | 5859328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010464205 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.16         |\n",
      "|    n_updates            | 28600        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | -0.41157722  |\n",
      "|    std                  | 74           |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2862         |\n",
      "|    time_elapsed         | 53230        |\n",
      "|    total_timesteps      | 5861376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009663674 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 28610        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 0.27267212   |\n",
      "|    std                  | 74.1         |\n",
      "|    value_loss           | 35           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2863         |\n",
      "|    time_elapsed         | 53248        |\n",
      "|    total_timesteps      | 5863424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004026515 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 28620        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | -1.2277972   |\n",
      "|    std                  | 74.2         |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2864          |\n",
      "|    time_elapsed         | 53266         |\n",
      "|    total_timesteps      | 5865472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096559286 |\n",
      "|    clip_fraction        | 0.0019        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -165          |\n",
      "|    explained_variance   | 0.384         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.09          |\n",
      "|    n_updates            | 28630         |\n",
      "|    policy_gradient_loss | -0.00196      |\n",
      "|    reward               | 0.25848714    |\n",
      "|    std                  | 74.3          |\n",
      "|    value_loss           | 17.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2865         |\n",
      "|    time_elapsed         | 53285        |\n",
      "|    total_timesteps      | 5867520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014086904 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 28640        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | 0.51303643   |\n",
      "|    std                  | 74.6         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2866          |\n",
      "|    time_elapsed         | 53303         |\n",
      "|    total_timesteps      | 5869568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036844052 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -165          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.7          |\n",
      "|    n_updates            | 28650         |\n",
      "|    policy_gradient_loss | -0.00153      |\n",
      "|    reward               | 1.5931673     |\n",
      "|    std                  | 74.7          |\n",
      "|    value_loss           | 24            |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3041297.08\n",
      "total_reward: 2041297.08\n",
      "total_cost: 329297.36\n",
      "total_trades: 69959\n",
      "Sharpe: 0.647\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2867         |\n",
      "|    time_elapsed         | 53321        |\n",
      "|    total_timesteps      | 5871616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020761674 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.68         |\n",
      "|    n_updates            | 28660        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | -2.0285203   |\n",
      "|    std                  | 74.7         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2868         |\n",
      "|    time_elapsed         | 53339        |\n",
      "|    total_timesteps      | 5873664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023699468 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 28670        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | -2.5404606   |\n",
      "|    std                  | 74.9         |\n",
      "|    value_loss           | 22.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2869         |\n",
      "|    time_elapsed         | 53358        |\n",
      "|    total_timesteps      | 5875712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013237864 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 28680        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | -0.25317046  |\n",
      "|    std                  | 75           |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2870          |\n",
      "|    time_elapsed         | 53376         |\n",
      "|    total_timesteps      | 5877760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024263229 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -165          |\n",
      "|    explained_variance   | 0.392         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.7          |\n",
      "|    n_updates            | 28690         |\n",
      "|    policy_gradient_loss | -0.000655     |\n",
      "|    reward               | 0.44894916    |\n",
      "|    std                  | 75.1          |\n",
      "|    value_loss           | 42.2          |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 2871      |\n",
      "|    time_elapsed         | 53394     |\n",
      "|    total_timesteps      | 5879808   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0040191 |\n",
      "|    clip_fraction        | 0.00996   |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -165      |\n",
      "|    explained_variance   | 0.463     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 2.9       |\n",
      "|    n_updates            | 28700     |\n",
      "|    policy_gradient_loss | -0.00775  |\n",
      "|    reward               | 0.9300286 |\n",
      "|    std                  | 75.4      |\n",
      "|    value_loss           | 10.9      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2872         |\n",
      "|    time_elapsed         | 53412        |\n",
      "|    total_timesteps      | 5881856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026283453 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 28710        |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | 0.40227905   |\n",
      "|    std                  | 75.3         |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2873         |\n",
      "|    time_elapsed         | 53430        |\n",
      "|    total_timesteps      | 5883904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006341876 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 28720        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 3.4164584    |\n",
      "|    std                  | 75.4         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2874         |\n",
      "|    time_elapsed         | 53449        |\n",
      "|    total_timesteps      | 5885952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012041079 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.91         |\n",
      "|    n_updates            | 28730        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | -2.2805254   |\n",
      "|    std                  | 75.6         |\n",
      "|    value_loss           | 22.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2875         |\n",
      "|    time_elapsed         | 53467        |\n",
      "|    total_timesteps      | 5888000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027085666 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.38         |\n",
      "|    n_updates            | 28740        |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    reward               | 0.6233015    |\n",
      "|    std                  | 75.6         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2876         |\n",
      "|    time_elapsed         | 53485        |\n",
      "|    total_timesteps      | 5890048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006001394 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 28750        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 0.31082937   |\n",
      "|    std                  | 75.7         |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2877          |\n",
      "|    time_elapsed         | 53503         |\n",
      "|    total_timesteps      | 5892096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033803235 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.558         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.8          |\n",
      "|    n_updates            | 28760         |\n",
      "|    policy_gradient_loss | -0.00144      |\n",
      "|    reward               | -1.5789298    |\n",
      "|    std                  | 75.7          |\n",
      "|    value_loss           | 34            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2878         |\n",
      "|    time_elapsed         | 53522        |\n",
      "|    total_timesteps      | 5894144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020307521 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 28770        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | -1.1955032   |\n",
      "|    std                  | 75.9         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2879         |\n",
      "|    time_elapsed         | 53541        |\n",
      "|    total_timesteps      | 5896192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003688071 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 28780        |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    reward               | -0.4085162   |\n",
      "|    std                  | 75.9         |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2880          |\n",
      "|    time_elapsed         | 53561         |\n",
      "|    total_timesteps      | 5898240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029096683 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.478         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.7          |\n",
      "|    n_updates            | 28790         |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    reward               | -0.31695554   |\n",
      "|    std                  | 76            |\n",
      "|    value_loss           | 37.4          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3969036.71\n",
      "total_reward: 2969036.71\n",
      "total_cost: 524589.81\n",
      "total_trades: 78699\n",
      "Sharpe: 0.811\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2881         |\n",
      "|    time_elapsed         | 53579        |\n",
      "|    total_timesteps      | 5900288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064468966 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.04         |\n",
      "|    n_updates            | 28800        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    reward               | -1.0612508   |\n",
      "|    std                  | 76.4         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2882          |\n",
      "|    time_elapsed         | 53597         |\n",
      "|    total_timesteps      | 5902336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073404587 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.0951        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 54.7          |\n",
      "|    n_updates            | 28810         |\n",
      "|    policy_gradient_loss | -0.00198      |\n",
      "|    reward               | 1.3416661     |\n",
      "|    std                  | 76.5          |\n",
      "|    value_loss           | 61.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2883         |\n",
      "|    time_elapsed         | 53616        |\n",
      "|    total_timesteps      | 5904384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008621273 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 28820        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | -10.487418   |\n",
      "|    std                  | 76.7         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2884         |\n",
      "|    time_elapsed         | 53635        |\n",
      "|    total_timesteps      | 5906432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003291988 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 28830        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    reward               | -0.01884399  |\n",
      "|    std                  | 76.7         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2885         |\n",
      "|    time_elapsed         | 53653        |\n",
      "|    total_timesteps      | 5908480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011657374 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.53         |\n",
      "|    n_updates            | 28840        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | -2.1218586   |\n",
      "|    std                  | 76.9         |\n",
      "|    value_loss           | 19.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2886          |\n",
      "|    time_elapsed         | 53672         |\n",
      "|    total_timesteps      | 5910528       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073620875 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.639         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13            |\n",
      "|    n_updates            | 28850         |\n",
      "|    policy_gradient_loss | -0.00247      |\n",
      "|    reward               | 0.55638456    |\n",
      "|    std                  | 77.1          |\n",
      "|    value_loss           | 28.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2887          |\n",
      "|    time_elapsed         | 53690         |\n",
      "|    total_timesteps      | 5912576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027890792 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.597         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.5          |\n",
      "|    n_updates            | 28860         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | 0.72882265    |\n",
      "|    std                  | 77.1          |\n",
      "|    value_loss           | 38.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2888         |\n",
      "|    time_elapsed         | 53709        |\n",
      "|    total_timesteps      | 5914624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015188679 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.95         |\n",
      "|    n_updates            | 28870        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 0.37898472   |\n",
      "|    std                  | 77.1         |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2889         |\n",
      "|    time_elapsed         | 53728        |\n",
      "|    total_timesteps      | 5916672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010509638 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 28880        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 0.9852708    |\n",
      "|    std                  | 77.1         |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2890          |\n",
      "|    time_elapsed         | 53746         |\n",
      "|    total_timesteps      | 5918720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077611743 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.614         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.6          |\n",
      "|    n_updates            | 28890         |\n",
      "|    policy_gradient_loss | -0.00226      |\n",
      "|    reward               | 0.567108      |\n",
      "|    std                  | 77.3          |\n",
      "|    value_loss           | 32.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2891         |\n",
      "|    time_elapsed         | 53765        |\n",
      "|    total_timesteps      | 5920768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010846654 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.21         |\n",
      "|    n_updates            | 28900        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | 0.95227486   |\n",
      "|    std                  | 77.5         |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2892         |\n",
      "|    time_elapsed         | 53783        |\n",
      "|    total_timesteps      | 5922816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016492127 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.325        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 28910        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | 0.55153507   |\n",
      "|    std                  | 77.8         |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2893          |\n",
      "|    time_elapsed         | 53801         |\n",
      "|    total_timesteps      | 5924864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049492775 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.564         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.7          |\n",
      "|    n_updates            | 28920         |\n",
      "|    policy_gradient_loss | -0.00183      |\n",
      "|    reward               | 1.7433976     |\n",
      "|    std                  | 77.9          |\n",
      "|    value_loss           | 34.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2894          |\n",
      "|    time_elapsed         | 53819         |\n",
      "|    total_timesteps      | 5926912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079565844 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.605         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.7          |\n",
      "|    n_updates            | 28930         |\n",
      "|    policy_gradient_loss | -0.00265      |\n",
      "|    reward               | -0.637574     |\n",
      "|    std                  | 78.1          |\n",
      "|    value_loss           | 43.3          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2914212.04\n",
      "total_reward: 1914212.04\n",
      "total_cost: 318847.45\n",
      "total_trades: 69703\n",
      "Sharpe: 0.629\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2895         |\n",
      "|    time_elapsed         | 53837        |\n",
      "|    total_timesteps      | 5928960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028423239 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.6          |\n",
      "|    n_updates            | 28940        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 0.28467068   |\n",
      "|    std                  | 78.2         |\n",
      "|    value_loss           | 16.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2896         |\n",
      "|    time_elapsed         | 53855        |\n",
      "|    total_timesteps      | 5931008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016473267 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.97         |\n",
      "|    n_updates            | 28950        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -1.2048693   |\n",
      "|    std                  | 78.3         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2897         |\n",
      "|    time_elapsed         | 53873        |\n",
      "|    total_timesteps      | 5933056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005164576 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 28960        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | -0.18797897  |\n",
      "|    std                  | 78.3         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2898         |\n",
      "|    time_elapsed         | 53892        |\n",
      "|    total_timesteps      | 5935104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005304357 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.32         |\n",
      "|    n_updates            | 28970        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | 1.8074101    |\n",
      "|    std                  | 78.3         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2899        |\n",
      "|    time_elapsed         | 53910       |\n",
      "|    total_timesteps      | 5937152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002557439 |\n",
      "|    clip_fraction        | 0.00225     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -166        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 28980       |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | 1.697456    |\n",
      "|    std                  | 78.4        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2900         |\n",
      "|    time_elapsed         | 53928        |\n",
      "|    total_timesteps      | 5939200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008520981 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 28990        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | 0.04089362   |\n",
      "|    std                  | 78.5         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2901          |\n",
      "|    time_elapsed         | 53946         |\n",
      "|    total_timesteps      | 5941248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023985095 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -167          |\n",
      "|    explained_variance   | 0.308         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.2          |\n",
      "|    n_updates            | 29000         |\n",
      "|    policy_gradient_loss | -0.000778     |\n",
      "|    reward               | 0.5218532     |\n",
      "|    std                  | 78.6          |\n",
      "|    value_loss           | 45.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2902         |\n",
      "|    time_elapsed         | 53964        |\n",
      "|    total_timesteps      | 5943296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018725365 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.02         |\n",
      "|    n_updates            | 29010        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 0.9374436    |\n",
      "|    std                  | 78.7         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2903         |\n",
      "|    time_elapsed         | 53982        |\n",
      "|    total_timesteps      | 5945344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016480526 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 29020        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 0.4121914    |\n",
      "|    std                  | 78.8         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2904          |\n",
      "|    time_elapsed         | 54000         |\n",
      "|    total_timesteps      | 5947392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040372816 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -167          |\n",
      "|    explained_variance   | 0.573         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.9          |\n",
      "|    n_updates            | 29030         |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    reward               | 0.7319196     |\n",
      "|    std                  | 78.9          |\n",
      "|    value_loss           | 39.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2905          |\n",
      "|    time_elapsed         | 54018         |\n",
      "|    total_timesteps      | 5949440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075980567 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -167          |\n",
      "|    explained_variance   | 0.45          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.1          |\n",
      "|    n_updates            | 29040         |\n",
      "|    policy_gradient_loss | -0.00205      |\n",
      "|    reward               | -0.7612483    |\n",
      "|    std                  | 79            |\n",
      "|    value_loss           | 26.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2906         |\n",
      "|    time_elapsed         | 54036        |\n",
      "|    total_timesteps      | 5951488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016497518 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 29050        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 0.22782628   |\n",
      "|    std                  | 79.3         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2907         |\n",
      "|    time_elapsed         | 54054        |\n",
      "|    total_timesteps      | 5953536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008867794 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 29060        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | 0.32280537   |\n",
      "|    std                  | 79.4         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2908         |\n",
      "|    time_elapsed         | 54073        |\n",
      "|    total_timesteps      | 5955584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005399815 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 29070        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | 1.7774714    |\n",
      "|    std                  | 79.5         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2691559.20\n",
      "total_reward: 1691559.20\n",
      "total_cost: 173167.40\n",
      "total_trades: 61309\n",
      "Sharpe: 0.550\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2909         |\n",
      "|    time_elapsed         | 54091        |\n",
      "|    total_timesteps      | 5957632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007556097 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 29080        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | -0.40010425  |\n",
      "|    std                  | 79.7         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2910         |\n",
      "|    time_elapsed         | 54109        |\n",
      "|    total_timesteps      | 5959680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016343746 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.86         |\n",
      "|    n_updates            | 29090        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | 0.8300473    |\n",
      "|    std                  | 79.7         |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2911         |\n",
      "|    time_elapsed         | 54127        |\n",
      "|    total_timesteps      | 5961728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013700831 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 29100        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    reward               | -0.21741726  |\n",
      "|    std                  | 79.9         |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2912         |\n",
      "|    time_elapsed         | 54146        |\n",
      "|    total_timesteps      | 5963776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061615007 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.25         |\n",
      "|    n_updates            | 29110        |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    reward               | -0.6195466   |\n",
      "|    std                  | 80.4         |\n",
      "|    value_loss           | 10.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2913         |\n",
      "|    time_elapsed         | 54164        |\n",
      "|    total_timesteps      | 5965824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005481808 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 29120        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | -0.6387748   |\n",
      "|    std                  | 80.5         |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2914         |\n",
      "|    time_elapsed         | 54182        |\n",
      "|    total_timesteps      | 5967872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001485649 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.77         |\n",
      "|    n_updates            | 29130        |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    reward               | -4.5012403   |\n",
      "|    std                  | 80.6         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2915         |\n",
      "|    time_elapsed         | 54200        |\n",
      "|    total_timesteps      | 5969920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006118192 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.69         |\n",
      "|    n_updates            | 29140        |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    reward               | 2.190544     |\n",
      "|    std                  | 80.7         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2916         |\n",
      "|    time_elapsed         | 54218        |\n",
      "|    total_timesteps      | 5971968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017909163 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.21         |\n",
      "|    n_updates            | 29150        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | -0.38831353  |\n",
      "|    std                  | 80.8         |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2917        |\n",
      "|    time_elapsed         | 54236       |\n",
      "|    total_timesteps      | 5974016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000690595 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -167        |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 29160       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    reward               | 1.3168869   |\n",
      "|    std                  | 81          |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2918         |\n",
      "|    time_elapsed         | 54255        |\n",
      "|    total_timesteps      | 5976064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003260994 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 29170        |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    reward               | -1.1360658   |\n",
      "|    std                  | 81.1         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2919         |\n",
      "|    time_elapsed         | 54274        |\n",
      "|    total_timesteps      | 5978112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036241377 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.49         |\n",
      "|    n_updates            | 29180        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | 0.04836435   |\n",
      "|    std                  | 81.3         |\n",
      "|    value_loss           | 15           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2920          |\n",
      "|    time_elapsed         | 54293         |\n",
      "|    total_timesteps      | 5980160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012371421 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -168          |\n",
      "|    explained_variance   | 0.649         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.8          |\n",
      "|    n_updates            | 29190         |\n",
      "|    policy_gradient_loss | -0.000762     |\n",
      "|    reward               | -0.07504734   |\n",
      "|    std                  | 81.4          |\n",
      "|    value_loss           | 27.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2921          |\n",
      "|    time_elapsed         | 54311         |\n",
      "|    total_timesteps      | 5982208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033058826 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -168          |\n",
      "|    explained_variance   | 0.643         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.6          |\n",
      "|    n_updates            | 29200         |\n",
      "|    policy_gradient_loss | -0.00193      |\n",
      "|    reward               | -0.17528464   |\n",
      "|    std                  | 81.5          |\n",
      "|    value_loss           | 25.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2922        |\n",
      "|    time_elapsed         | 54330       |\n",
      "|    total_timesteps      | 5984256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001657495 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -168        |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.95        |\n",
      "|    n_updates            | 29210       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | 3.1576984   |\n",
      "|    std                  | 81.5        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3806993.63\n",
      "total_reward: 2806993.63\n",
      "total_cost: 501745.49\n",
      "total_trades: 77758\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2923          |\n",
      "|    time_elapsed         | 54349         |\n",
      "|    total_timesteps      | 5986304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067601795 |\n",
      "|    clip_fraction        | 0.00259       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -168          |\n",
      "|    explained_variance   | 0.46          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.4          |\n",
      "|    n_updates            | 29220         |\n",
      "|    policy_gradient_loss | -0.00191      |\n",
      "|    reward               | 0.62795085    |\n",
      "|    std                  | 81.7          |\n",
      "|    value_loss           | 31.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2924         |\n",
      "|    time_elapsed         | 54367        |\n",
      "|    total_timesteps      | 5988352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006382208 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 29230        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | 4.1972127    |\n",
      "|    std                  | 81.8         |\n",
      "|    value_loss           | 73.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2925         |\n",
      "|    time_elapsed         | 54386        |\n",
      "|    total_timesteps      | 5990400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004866897 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 29240        |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | -0.9697705   |\n",
      "|    std                  | 81.9         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2926         |\n",
      "|    time_elapsed         | 54405        |\n",
      "|    total_timesteps      | 5992448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012235093 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.81         |\n",
      "|    n_updates            | 29250        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -0.5728313   |\n",
      "|    std                  | 82.1         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2927          |\n",
      "|    time_elapsed         | 54425         |\n",
      "|    total_timesteps      | 5994496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056622206 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -168          |\n",
      "|    explained_variance   | 0.533         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.6          |\n",
      "|    n_updates            | 29260         |\n",
      "|    policy_gradient_loss | -0.00216      |\n",
      "|    reward               | 1.2460928     |\n",
      "|    std                  | 82.2          |\n",
      "|    value_loss           | 40.4          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2928          |\n",
      "|    time_elapsed         | 54444         |\n",
      "|    total_timesteps      | 5996544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024119698 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -168          |\n",
      "|    explained_variance   | 0.6           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.1          |\n",
      "|    n_updates            | 29270         |\n",
      "|    policy_gradient_loss | -0.000876     |\n",
      "|    reward               | -1.433292     |\n",
      "|    std                  | 82.3          |\n",
      "|    value_loss           | 37.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2929        |\n",
      "|    time_elapsed         | 54463       |\n",
      "|    total_timesteps      | 5998592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001616241 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -168        |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.73        |\n",
      "|    n_updates            | 29280       |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | -4.2480817  |\n",
      "|    std                  | 82.6        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 2930          |\n",
      "|    time_elapsed         | 54481         |\n",
      "|    total_timesteps      | 6000640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079455937 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -168          |\n",
      "|    explained_variance   | 0.626         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.55          |\n",
      "|    n_updates            | 29290         |\n",
      "|    policy_gradient_loss | -0.00232      |\n",
      "|    reward               | -0.25938964   |\n",
      "|    std                  | 82.5          |\n",
      "|    value_loss           | 25.1          |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# model_ppo2.load('42')\n",
    "print('load')\n",
    "trained_ppo2 = agent_con.train_model(model=model_ppo2, \n",
    "                             tb_log_name=\"7\",\n",
    "                             total_timesteps=6000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23766/4244563930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_sac = agent.train_model(model=model_sac, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=60000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Select action according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mnext_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# Compute the next Q values: min over all critics targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnext_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/policies.py\u001b[0m in \u001b[0;36maction_log_prob\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_dist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# return action and associated log prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mlog_prob_from_params\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mactions_from_params\u001b[0;34m(self, mean_actions, log_std, deterministic)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Update the proba distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SquashedDiagGaussianDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSquashedDiagGaussianDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0maction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<'2020-07-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n",
    "\n",
    "trained_ppo2.save('76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       18.824245\n",
       "std         8.489311\n",
       "min         9.140000\n",
       "25%        13.330000\n",
       "50%        16.139999\n",
       "75%        21.309999\n",
       "max        82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.40400183105453"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       34.574233\n",
       "std        43.787150\n",
       "min         0.000000\n",
       "25%        14.966105\n",
       "50%        24.124290\n",
       "75%        39.162080\n",
       "max       652.505555\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.45132359815483"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_ppo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50015/536458364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     environment = e_trade_gym)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df_account_value, df_actions = DRLAgent.DRL_prediction(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_ppo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     environment = e_trade_gym)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_ppo' is not defined"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "ERxw3KqLkcP4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50015/1680983300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50015/2509563385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50015/1118186915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_actions' is not defined"
     ]
    }
   ],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50015/2746174370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d-%Hh%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbacktest_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_stats_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mperf_stats_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/perf_stats_all_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50015/57827447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m baseline_df = get_baseline(\n\u001b[1;32m      4\u001b[0m         \u001b[0mticker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"^DJI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         end = df_account_value.loc[len(df_account_value)-1,'date'])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "qg1kvfemrrQH"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50015/2351900042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.loc[0,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50015/1309470278.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50015/2064601725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Dow Jones Index: ^DJI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# NASDAQ 100: ^NDX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m backtest_plot(df_account_value, \n\u001b[0m\u001b[1;32m      7\u001b[0m              \u001b[0mbaseline_ticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^DJI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m              \u001b[0mbaseline_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "BzBaE63H3RLc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value2, df_actions2 = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo2, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "ZYeOjax-7H_5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.249455\n",
      "Cumulative returns     0.345739\n",
      "Annual volatility      0.155328\n",
      "Sharpe ratio           1.515886\n",
      "Calmar ratio           2.465160\n",
      "Stability              0.876490\n",
      "Max drawdown          -0.101192\n",
      "Omega ratio            1.295766\n",
      "Sortino ratio          2.360984\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.956143\n",
      "Daily value at risk   -0.018635\n",
      "dtype: float64\n",
      "==============Get Baseline Stats===========\n",
      "Annual return          0.269722\n",
      "Cumulative returns     0.374922\n",
      "Annual volatility      0.139083\n",
      "Sharpe ratio           1.792302\n",
      "Calmar ratio           3.020136\n",
      "Stability              0.919220\n",
      "Max drawdown          -0.089308\n",
      "Omega ratio            1.347571\n",
      "Sortino ratio          2.655481\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.052781\n",
      "Daily value at risk   -0.016534\n",
      "dtype: float64\n",
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-10-28</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>16</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>24.945%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>34.574%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>15.533%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-10.119%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-1.864%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.12</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.73</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.23</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.05</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.60</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.09%</td>\n",
       "      <td>-3.21%</td>\n",
       "      <td>5.88%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value2)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'2.csv')\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value2.loc[0,'date'],\n",
    "        end = df_account_value2.loc[len(df_account_value2)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value2, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value2.loc[0,'date'],\n",
    "             baseline_end = df_account_value2.loc[len(df_account_value2)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
