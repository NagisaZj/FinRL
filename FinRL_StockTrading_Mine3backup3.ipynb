{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)   \n",
    "* [RLlib Section](#7)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "ef0ba8d0-f57a-4c74-bb0b-46737762677d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-8i1_yu6g\n",
      "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-8i1_yu6g\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.19.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.1.5)\n",
      "Collecting stockstats\n",
      "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Collecting elegantrl\n",
      "  Downloading elegantrl-0.3.2-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.3.0-py3-none-any.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 65.2 MB/s \n",
      "\u001b[?25hCollecting ray[default]\n",
      "  Downloading ray-1.9.1-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 57.6 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 42.9 MB/s \n",
      "\u001b[?25hCollecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 71.5 MB/s \n",
      "\u001b[?25hCollecting gputil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "Collecting exchange_calendars\n",
      "  Downloading exchange_calendars-3.5.tar.gz (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 35.6 MB/s \n",
      "\u001b[?25hCollecting alpaca_trade_api\n",
      "  Downloading alpaca_trade_api-1.4.3-py3-none-any.whl (36 kB)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting jqdatasdk\n",
      "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting wrds\n",
      "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n",
      "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n",
      "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n",
      "Collecting pre-commit\n",
      "  Downloading pre_commit-2.16.0-py2.py3-none-any.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 55.1 MB/s \n",
      "\u001b[?25hCollecting pybullet\n",
      "  Downloading pybullet-3.2.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (90.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 90.8 MB 244 bytes/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n",
      "Collecting box2d-py\n",
      "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 50.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n",
      "Collecting websocket-client<2,>=0.56.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting PyYAML==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 52.7 MB/s \n",
      "\u001b[?25hCollecting msgpack==1.0.2\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 60.4 MB/s \n",
      "\u001b[?25hCollecting aiohttp==3.7.4\n",
      "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 55.5 MB/s \n",
      "\u001b[?25hCollecting websockets<10,>=8.0\n",
      "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 48.7 MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 56.6 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 57.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 68.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 28.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 21.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 70.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 14.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 65.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.85-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 59.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.84-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.83-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.82-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.81-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.80-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 35.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.79-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.78-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 20.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.77-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.76-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.75-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.74-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 34.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.73-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.72-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.71-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.70-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.69-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.68-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 60.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.67-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.66-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.65-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.64-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.63-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.62-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.61-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.60-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 57.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.59-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.58-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.57-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.56-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.55-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.54-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.53-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.52-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.51-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.6 MB/s \n",
      "\u001b[?25hCollecting aiodns>=1.1.1\n",
      "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 60.7 MB/s \n",
      "\u001b[?25hCollecting cryptography>=2.6.1\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 42.6 MB/s \n",
      "\u001b[?25hCollecting pycares>=4.0.0\n",
      "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 44.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n",
      "Collecting pyluach\n",
      "  Downloading pyluach-1.3.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.11.2)\n",
      "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.2.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.27)\n",
      "Collecting thriftpy2>=0.3.9\n",
      "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
      "\u001b[K     |████████████████████████████████| 361 kB 50.4 MB/s \n",
      "\u001b[?25hCollecting pymysql>=0.7.6\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n",
      "Collecting ply<4.0,>=3.4\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n",
      "Collecting cfgv>=2.0.0\n",
      "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n",
      "Collecting identify>=1.0.0\n",
      "  Downloading identify-2.4.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting virtualenv>=20.0.8\n",
      "  Downloading virtualenv-20.11.0-py2.py3-none-any.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 39.6 MB/s \n",
      "\u001b[?25hCollecting nodeenv>=0.11.1\n",
      "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.4.0)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "\u001b[K     |████████████████████████████████| 461 kB 32.3 MB/s \n",
      "\u001b[?25hCollecting platformdirs<3,>=2\n",
      "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.12.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.0-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 57.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n",
      "Collecting aioredis<2\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 50.8 MB/s \n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 70.8 MB/s \n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (5.2.1)\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
      "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 213 kB/s \n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 53.5 MB/s \n",
      "\u001b[?25hCollecting hiredis\n",
      "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n",
      "Collecting blessed>=1.17.1\n",
      "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n",
      "Collecting int-date>=0.1.7\n",
      "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting mock\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 45.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.10)\n",
      "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat\n",
      "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for finrl: filename=finrl-0.3.3-py3-none-any.whl size=3885640 sha256=1667a85b9c8c0a7a8efbf04d5ebf154d5d1ea119a32e922d094820030ce0e7e4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/17/ff/bd/1bc602a0352762b0b24041b88536d803ae343ed0a711fcf55e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for elegantrl: filename=elegantrl-0.3.2-py3-none-any.whl size=168744 sha256=7773813204e1a2954730bd149444640d5155458fc82b6910ec4e661879797016\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75775 sha256=e3753b24d032afc5ef0b133c50557002ca9fed8416e2205e1547fc81af5c124a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39777 sha256=6cc78a6b3f88187e2798221487acba0361bb1d094b6c82496348fb4c85f7686b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
      "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for exchange-calendars: filename=exchange_calendars-3.5-py3-none-any.whl size=179487 sha256=3d877d78e29a28c4b098f4a0b1d0106458d7f73b52f6c7a43d0757d55c11d44b\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/21/43/b6ae2605dd767f6cd5a5b0b70c93a9a75823e44b3ccb92bce7\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=33dcd980f1b32f0582d029fcef126ae53327fb90724eee8c33bc3b4dbebda4b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
      "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940507 sha256=429244bf5fd89014c79f01bf0e4a59477258cd2b88978e3125b54f4bd62a88f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=b831a9dba6682b3e0a7ae05d7c2ba465918426c72474917e56e0850ac8c73263\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
      "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat\n",
      "Installing collected packages: multidict, yarl, lxml, deprecated, async-timeout, redis, PyYAML, pycares, ply, platformdirs, opencensus-context, msgpack, hiredis, frozenlist, distlib, blessed, aiohttp, websockets, websocket-client, virtualenv, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, opencensus, nodeenv, mock, int-date, identify, gpustat, empyrical, cryptography, colorful, cfgv, box2d-py, aiosignal, aioredis, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "Successfully installed PyYAML-5.4.1 aiodns-3.0.0 aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 alpaca-trade-api-1.4.3 async-timeout-3.0.1 blessed-1.19.0 box2d-py-2.3.8 ccxt-1.61.51 cfgv-3.3.1 colorful-0.5.4 cryptography-36.0.1 deprecated-1.2.13 distlib-0.3.4 elegantrl-0.3.2 empyrical-0.5.5 exchange-calendars-3.5 finrl-0.3.3 frozenlist-1.2.0 gpustat-1.0.0b1 gputil-1.4.0 hiredis-2.0.0 identify-2.4.1 int-date-0.1.8 jqdatasdk-1.8.10 lxml-4.7.1 lz4-3.1.10 mock-4.0.3 msgpack-1.0.2 multidict-5.2.0 nodeenv-1.6.0 opencensus-0.8.0 opencensus-context-0.1.2 platformdirs-2.4.1 ply-3.11 pre-commit-2.16.0 psycopg2-binary-2.9.2 py-spy-0.3.11 pybullet-3.2.1 pycares-4.1.2 pyfolio-0.9.2+75.g4b901f6 pyluach-1.3.0 pymysql-1.0.2 ray-1.9.1 redis-4.1.0 stable-baselines3-1.3.0 stockstats-0.3.2 tensorboardX-2.4.1 thriftpy2-0.4.14 virtualenv-20.11.0 websocket-client-1.2.3 websockets-9.1 wrds-3.1.1 yarl-1.6.3 yfinance-0.1.67\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zj/anaconda3/envs/finrl/lib/python3.7/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.tusharedownloader import TushareDownloader\n",
    "from finrl.finrl_meta.data_processors.processor_alpaca import AlpacaProcessor\n",
    "from finrl.finrl_meta.data_processors.processor_wrds import WrdsProcessor\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading_conservative import StockTradingEnvCon\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot2 import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "5302d7c0-1c68-4c6e-b30e-b1395bdc109e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-01'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "config.TRAIN_START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FUnY8WEfLq3C",
    "outputId": "35dd8c5b-d58f-49b8-e4df-ae7e122448cd"
   },
   "outputs": [],
   "source": [
    "# from config.py TRAIN_END_DATE is a string\n",
    "# config.TRAIN_END_DATE\n",
    "# df2=TushareDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83c7f894-3757-473b-8afb-a904e6caabda",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "7a991dfe-f39c-40db-ec44-7c416cdce7dc"
   },
   "outputs": [],
   "source": [
    "# print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94360, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "210fade5-e912-40df-be99-4ad00bdb9d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date       open       high        low      close  \\\n",
       "0           0  2008-12-31   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31  43.700001  45.099998  43.700001  30.628819   \n",
       "\n",
       "      volume   tic  day  \n",
       "0  607541200  AAPL    2  \n",
       "1    6287200  AMGN    2  \n",
       "2    9625600   AXP    2  \n",
       "3    5443100    BA    2  \n",
       "4    6277400   CAT    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fe = FeatureEngineer(\n",
    "#                     use_technical_indicator=True,\n",
    "#                     tech_indicator_list = config.INDICATORS,\n",
    "#                     use_vix=True,\n",
    "#                     use_turbulence=True,\n",
    "#                     user_defined_feature = False)\n",
    "\n",
    "# processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "# list_ticker = processed[\"tic\"].unique().tolist()\n",
    "# list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "# combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "# processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "# processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "grvhGJJII3Xn",
    "outputId": "733758c3-3552-4aa5-e1f9-789bd4ce0c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CRM</td>\n",
       "      <td>7.712500</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>5367600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.180000</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.120001</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>37513700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>74.629997</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>9964300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>DIS</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>22.520000</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>9012100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>GS</td>\n",
       "      <td>82.239998</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>81.120003</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>14894100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic       open       high        low      close  \\\n",
       "0           0  2008-12-31  AAPL   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  AMGN  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31   AXP  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31    BA  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31   CAT  43.700001  45.099998  43.700001  30.628819   \n",
       "5           5  2008-12-31   CRM   7.712500   8.130000   7.707500   8.002500   \n",
       "6           6  2008-12-31  CSCO  16.180000  16.549999  16.120001  11.787783   \n",
       "7           7  2008-12-31   CVX  72.900002  74.629997  72.900002  43.314438   \n",
       "8           8  2008-12-31   DIS  22.570000  22.950001  22.520000  19.538342   \n",
       "9           9  2008-12-31    GS  82.239998  86.150002  81.120003  69.224182   \n",
       "\n",
       "        volume  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  607541200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "1    6287200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "2    9625600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "3    5443100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "4    6277400.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "5    5367600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "6   37513700.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "7    9964300.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "8    9012100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "9   14894100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma   vix  turbulence  \n",
       "0      2.606277      2.606277  40.0         0.0  \n",
       "1     43.924454     43.924454  40.0         0.0  \n",
       "2     14.908465     14.908465  40.0         0.0  \n",
       "3     32.005894     32.005894  40.0         0.0  \n",
       "4     30.628819     30.628819  40.0         0.0  \n",
       "5      8.002500      8.002500  40.0         0.0  \n",
       "6     11.787783     11.787783  40.0         0.0  \n",
       "7     43.314438     43.314438  40.0         0.0  \n",
       "8     19.538342     19.538342  40.0         0.0  \n",
       "9     69.224182     69.224182  40.0         0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full=pd.read_csv('./2.csv')\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01\n",
    "## Trade data split: 2020-07-01 to 2021-10-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "9744\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121795</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>288.570007</td>\n",
       "      <td>296.450012</td>\n",
       "      <td>287.660004</td>\n",
       "      <td>287.776794</td>\n",
       "      <td>2932900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>303.925869</td>\n",
       "      <td>271.251255</td>\n",
       "      <td>52.413046</td>\n",
       "      <td>-25.838431</td>\n",
       "      <td>1.846804</td>\n",
       "      <td>288.020689</td>\n",
       "      <td>281.001438</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121796</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>193.750000</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>190.737244</td>\n",
       "      <td>9040100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048786</td>\n",
       "      <td>198.750528</td>\n",
       "      <td>185.041391</td>\n",
       "      <td>53.021033</td>\n",
       "      <td>-51.550760</td>\n",
       "      <td>2.013358</td>\n",
       "      <td>191.485037</td>\n",
       "      <td>181.677683</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121797</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.919998</td>\n",
       "      <td>55.290001</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>50.376743</td>\n",
       "      <td>17414800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.437111</td>\n",
       "      <td>53.918425</td>\n",
       "      <td>48.729324</td>\n",
       "      <td>48.097044</td>\n",
       "      <td>-51.018262</td>\n",
       "      <td>8.508886</td>\n",
       "      <td>51.012123</td>\n",
       "      <td>51.464679</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121798</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>42.580002</td>\n",
       "      <td>41.759998</td>\n",
       "      <td>39.035732</td>\n",
       "      <td>4782100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083986</td>\n",
       "      <td>42.609305</td>\n",
       "      <td>36.487095</td>\n",
       "      <td>48.830181</td>\n",
       "      <td>-14.508130</td>\n",
       "      <td>1.500723</td>\n",
       "      <td>39.135190</td>\n",
       "      <td>38.935129</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121799</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>119.220001</td>\n",
       "      <td>120.129997</td>\n",
       "      <td>118.540001</td>\n",
       "      <td>116.121765</td>\n",
       "      <td>6836400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.886569</td>\n",
       "      <td>119.473758</td>\n",
       "      <td>113.510454</td>\n",
       "      <td>48.159665</td>\n",
       "      <td>-69.938795</td>\n",
       "      <td>3.847271</td>\n",
       "      <td>117.787627</td>\n",
       "      <td>119.723273</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date  tic        open        high         low  \\\n",
       "2892      121795  2020-06-30  UNH  288.570007  296.450012  287.660004   \n",
       "2892      121796  2020-06-30    V  191.490005  193.750000  190.160004   \n",
       "2892      121797  2020-06-30   VZ   54.919998   55.290001   54.360001   \n",
       "2892      121798  2020-06-30  WBA   42.119999   42.580002   41.759998   \n",
       "2892      121799  2020-06-30  WMT  119.220001  120.129997  118.540001   \n",
       "\n",
       "           close      volume  day      macd     boll_ub     boll_lb  \\\n",
       "2892  287.776794   2932900.0  1.0 -0.019475  303.925869  271.251255   \n",
       "2892  190.737244   9040100.0  1.0  1.048786  198.750528  185.041391   \n",
       "2892   50.376743  17414800.0  1.0 -0.437111   53.918425   48.729324   \n",
       "2892   39.035732   4782100.0  1.0 -0.083986   42.609305   36.487095   \n",
       "2892  116.121765   6836400.0  1.0 -0.886569  119.473758  113.510454   \n",
       "\n",
       "         rsi_30     cci_30     dx_30  close_30_sma  close_60_sma    vix  \\\n",
       "2892  52.413046 -25.838431  1.846804    288.020689    281.001438  30.43   \n",
       "2892  53.021033 -51.550760  2.013358    191.485037    181.677683  30.43   \n",
       "2892  48.097044 -51.018262  8.508886     51.012123     51.464679  30.43   \n",
       "2892  48.830181 -14.508130  1.500723     39.135190     38.935129  30.43   \n",
       "2892  48.159665 -69.938795  3.847271    117.787627    119.723273  30.43   \n",
       "\n",
       "      turbulence  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "e_train_gym_conservative = StockTradingEnvCon(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "env_train_con, _ = e_train_gym_conservative.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "agent_con = DRLAgent(env = env_train_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 67         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -1.41      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -72.8      |\n",
      "|    reward             | 0.19451597 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.68       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 68         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -0.115     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -70.2      |\n",
      "|    reward             | -1.4624771 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.55       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -167     |\n",
      "|    reward             | 5.02583  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    reward             | 5.606354 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 368       |\n",
      "|    reward             | -7.546301 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 164       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0.0793    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 145       |\n",
      "|    reward             | 0.4507672 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -0.0998    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -78.4      |\n",
      "|    reward             | -2.1521304 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0.00557     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | -0.80710465 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 70.3        |\n",
      "|    reward             | -0.11950674 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -35.7      |\n",
      "|    reward             | -4.1389766 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -245     |\n",
      "|    reward             | 6.363784 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -63.1      |\n",
      "|    reward             | 0.07753525 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | -0.000831 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 48.9      |\n",
      "|    reward             | -4.088032 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 179       |\n",
      "|    reward             | 2.0626597 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 40.8      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 169       |\n",
      "|    reward             | 4.8591986 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 21.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 85.1       |\n",
      "|    reward             | 0.85958314 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.29       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -141     |\n",
      "|    reward             | 5.65319  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -41       |\n",
      "|    reward             | 1.1973313 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.57      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -26.6      |\n",
      "|    reward             | 0.36287376 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40         |\n",
      "|    explained_variance | -0.0091     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -83.6       |\n",
      "|    reward             | -0.30971453 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 13.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 204       |\n",
      "|    reward             | 1.7650424 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -153       |\n",
      "|    reward             | -7.5710273 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 23.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -2.04e+03  |\n",
      "|    reward             | -14.886115 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3e+03      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 51        |\n",
      "|    reward             | 0.0559524 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -46.7     |\n",
      "|    reward             | -0.434364 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 5.71      |\n",
      "|    reward             | 4.8586307 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | -0.4118847 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 328       |\n",
      "|    reward             | 1.0554261 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 66.3      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.88      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -116      |\n",
      "|    reward             | 2.3091433 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -20.7      |\n",
      "|    reward             | 0.38583377 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 223        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 43.7       |\n",
      "|    reward             | -0.3664559 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -38.8      |\n",
      "|    reward             | -0.4616701 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 96.4       |\n",
      "|    reward             | 0.11014476 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.58       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -3.93     |\n",
      "|    reward             | 2.1390972 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 76.4       |\n",
      "|    reward             | 0.16336557 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.35       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -85.2     |\n",
      "|    reward             | 1.0221922 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 225       |\n",
      "|    reward             | 1.1701288 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 38.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 33.2      |\n",
      "|    reward             | 2.4472284 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 41.3       |\n",
      "|    reward             | -1.2081411 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -0.481    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -5.13     |\n",
      "|    reward             | 1.3224076 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2         |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | -0.25540048 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.837       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.000881  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | 1.3826902 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -64       |\n",
      "|    reward             | 3.9822705 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 63.9       |\n",
      "|    reward             | 0.95108056 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 86.2       |\n",
      "|    reward             | -2.1539907 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 102       |\n",
      "|    reward             | 4.8509326 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0.00948     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -105        |\n",
      "|    reward             | -0.22313617 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 8.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -104        |\n",
      "|    reward             | -0.99914765 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 353        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -33.2      |\n",
      "|    reward             | 0.20132123 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.946      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 360        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -7.57e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 46.2       |\n",
      "|    reward             | 0.26696855 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 367        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -83.4      |\n",
      "|    reward             | -1.8360271 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 374       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -359      |\n",
      "|    reward             | 3.2874866 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 92.2      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3161472.69\n",
      "total_reward: 2161472.69\n",
      "total_cost: 19221.41\n",
      "total_trades: 41334\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -7.54     |\n",
      "|    reward             | 0.2828299 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.19252001 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 396       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -15       |\n",
      "|    reward             | 2.0577734 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.6       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -46.9       |\n",
      "|    reward             | -0.06746031 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0.00117    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -37.6      |\n",
      "|    reward             | 0.18157594 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 418       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0.0166    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    reward             | 0.6473793 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | 0.22656512 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.251      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 59.9       |\n",
      "|    reward             | -0.8028962 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 439        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | -1.7693416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 446         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 20.2        |\n",
      "|    reward             | -0.10761352 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 454      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 203      |\n",
      "|    reward             | 3.869458 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 34.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -0.0428   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 110       |\n",
      "|    reward             | 1.2343621 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.67      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | -2.028344 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -66.8      |\n",
      "|    reward             | 0.33169752 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.98       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 483      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.00675  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -869     |\n",
      "|    reward             | -8.09732 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 536      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 490        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 28.9       |\n",
      "|    reward             | 0.56556416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -176       |\n",
      "|    reward             | -2.9329143 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 88.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 504        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 72.3       |\n",
      "|    reward             | 0.22214015 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 511        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 105        |\n",
      "|    reward             | -0.6425189 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -360        |\n",
      "|    reward             | -0.22756429 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 80.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -430        |\n",
      "|    reward             | -0.44158605 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 131         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 533        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 404        |\n",
      "|    reward             | -5.8487034 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 540       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 1.07e+03  |\n",
      "|    reward             | -14.82644 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 832       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 548       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -141      |\n",
      "|    reward             | 1.4826734 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | -0.0473    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -184       |\n",
      "|    reward             | 0.34629944 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -42       |\n",
      "|    reward             | -2.415951 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 55.1      |\n",
      "|    reward             | 5.0485888 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 42.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 576        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -207       |\n",
      "|    reward             | -3.2154734 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 56.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 257       |\n",
      "|    reward             | 5.370093  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 56.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -160       |\n",
      "|    reward             | 0.03019213 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 118        |\n",
      "|    reward             | -1.1561224 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12.6       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 605         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -214        |\n",
      "|    reward             | -0.94865924 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 30.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 613       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -250      |\n",
      "|    reward             | 1.1797212 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 41.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 411        |\n",
      "|    reward             | -22.785406 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 144        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 627       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 72.4      |\n",
      "|    reward             | 3.2164123 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 87          |\n",
      "|    reward             | -0.17441794 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 262         |\n",
      "|    reward             | -0.85795397 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 48.9        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 72.7       |\n",
      "|    reward             | -2.2230675 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 22.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 656       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -49.2     |\n",
      "|    reward             | 2.6728501 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 663      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -238     |\n",
      "|    reward             | 8.656925 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 86.3     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 670         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0.000219    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -187        |\n",
      "|    reward             | -0.62001467 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 27.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 55.6      |\n",
      "|    reward             | 1.1713017 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 685       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | 1.3898315 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 692       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -52.5     |\n",
      "|    reward             | -6.044222 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 699       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 67.7      |\n",
      "|    reward             | 1.8213228 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 706      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 177      |\n",
      "|    reward             | 8.957433 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 58.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 714         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.26523116 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.559       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | -0.00926   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | -0.6623605 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ppo/1_1\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 124       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.5073655 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3946387.70\n",
      "total_reward: 2946387.70\n",
      "total_cost: 357438.48\n",
      "total_trades: 81024\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015788507 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00723     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | 0.3435485   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012375185 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -1.1157341  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016662188 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00193    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.2809894   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017038994 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00886    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    reward               | 3.2505164   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01701039 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.4      |\n",
      "|    explained_variance   | 0.0063     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17         |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    reward               | 1.8685282  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 32.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02486872 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0142    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    reward               | 0.39857626 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020911664 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0215     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 1.3883617   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7870/2360990771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_ppo = agent.train_model(model=model_ppo, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=3000000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    321\u001b[0m             )\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_total_asset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_total_asset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_total_asset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36m_get_date\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m         \"\"\"\n\u001b[0;32m-> 2039\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_hashtable_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_hashtable_algo\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_object_for_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mhtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hashtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_check_object_for_strings\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# including nulls because that is the only difference between\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# StringHashTable and ObjectHashtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mndtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name=\"1\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent_con = DRLAgent(env = env_train_con)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo2 = agent_con.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "Logging to ppo/4_5\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 102        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 19         |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.44831565 |\n",
      "-----------------------------------\n",
      "day: 2892, episode: 350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5391030.00\n",
      "total_reward: 4391030.00\n",
      "total_cost: 238733.88\n",
      "total_trades: 67601\n",
      "Sharpe: 0.942\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03995688 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.8      |\n",
      "|    explained_variance   | 0.152      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 4900       |\n",
      "|    policy_gradient_loss | -0.00452   |\n",
      "|    reward               | 1.6001326  |\n",
      "|    std                  | 2.13       |\n",
      "|    value_loss           | 24.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017870178 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | 0.0781      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    reward               | -1.1760482  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015387664 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 4920        |\n",
      "|    policy_gradient_loss | -0.000752   |\n",
      "|    reward               | 0.9442785   |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 86.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 99           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0156241385 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.9        |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.85         |\n",
      "|    n_updates            | 4930         |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 0.90576816   |\n",
      "|    std                  | 2.13         |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 122        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02046115 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.9      |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.3       |\n",
      "|    n_updates            | 4940       |\n",
      "|    policy_gradient_loss | -0.00799   |\n",
      "|    reward               | 2.1014183  |\n",
      "|    std                  | 2.13       |\n",
      "|    value_loss           | 35.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012944414 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | 0.20371123  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016618852 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | -0.0972     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 4960        |\n",
      "|    policy_gradient_loss | -0.000117   |\n",
      "|    reward               | -0.58248717 |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020860018 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | 1.2361978   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018284637 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | 0.69325244  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01444217 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.2      |\n",
      "|    explained_variance   | 0.172      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 54.7       |\n",
      "|    n_updates            | 4990       |\n",
      "|    policy_gradient_loss | -0.00751   |\n",
      "|    reward               | 0.7039318  |\n",
      "|    std                  | 2.16       |\n",
      "|    value_loss           | 102        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031276677 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | -0.136      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.54        |\n",
      "|    n_updates            | 5000        |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    reward               | -0.61853516 |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023782294 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | 0.23738804  |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019568799 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 5020        |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | 0.8135659   |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024066187 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | 0.00329     |\n",
      "|    reward               | 2.5086372   |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4014855.71\n",
      "total_reward: 3014855.71\n",
      "total_cost: 143365.25\n",
      "total_trades: 62626\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02162489  |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | -0.36271545 |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016058762 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    reward               | 1.1318113   |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 99           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 371          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012315517  |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.5        |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 5060         |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | -0.040817823 |\n",
      "|    std                  | 2.18         |\n",
      "|    value_loss           | 65.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022853732 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.32        |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | -0.6092865  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007846396 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 5080        |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | -0.20216414 |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016475983 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    reward               | -8.058232   |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018229244 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | -0.000362   |\n",
      "|    reward               | 1.3306023   |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 475         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027028436 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | -0.63910174 |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 497         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017568015 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    reward               | 3.2449887   |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 517         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024454765 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 5130        |\n",
      "|    policy_gradient_loss | 0.00241     |\n",
      "|    reward               | -0.2546475  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 56.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 537         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029080423 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.76        |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | 0.33996254  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022037752 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    reward               | -0.9170337  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 578         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012773572 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | 0.075464584 |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023798432 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    reward               | -0.59715205 |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4122488.62\n",
      "total_reward: 3122488.62\n",
      "total_cost: 165835.25\n",
      "total_trades: 63558\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015110789 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | 0.8322083   |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 639         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009594912 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    reward               | 3.5054955   |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 99           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 659          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143385595 |\n",
      "|    clip_fraction        | 0.0861       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.2        |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 5200         |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | -0.5439708   |\n",
      "|    std                  | 2.23         |\n",
      "|    value_loss           | 36.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018586436 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.67        |\n",
      "|    n_updates            | 5210        |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | -1.3362074  |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 701         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021193054 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | 1.0081979   |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 722        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01730119 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.2      |\n",
      "|    explained_variance   | 0.416      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15         |\n",
      "|    n_updates            | 5230       |\n",
      "|    policy_gradient_loss | -0.00477   |\n",
      "|    reward               | -1.1901124 |\n",
      "|    std                  | 2.23       |\n",
      "|    value_loss           | 42.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 743         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026880978 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 5240        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | -3.741196   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 763         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020909593 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 0.27306888  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 784         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018344253 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | -7.131267   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 805         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017045803 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    reward               | -1.4095398  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 826         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019253522 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -1.7117196  |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 845         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016372226 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | 1.0818517   |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 866         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014890307 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | 0.00118     |\n",
      "|    reward               | 1.3309737   |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 56.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 886         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023349956 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -0.82495195 |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3501446.56\n",
      "total_reward: 2501446.56\n",
      "total_cost: 75071.27\n",
      "total_trades: 56127\n",
      "Sharpe: 0.675\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 908         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020450715 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 5320        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | 0.37607637  |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 928         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010071725 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | 2.0858967   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 949         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025297297 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.041       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    reward               | -2.3260715  |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 969         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016564425 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    reward               | 1.0734954   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 989         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02066999  |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | -0.42664486 |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1009        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01767224  |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.0533      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | -0.20748505 |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 1030        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016478991 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.93        |\n",
      "|    n_updates            | 5380        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 1.1584957   |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 1051        |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020218328 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 0.49752054  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 1072        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024138933 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | 0.000777    |\n",
      "|    reward               | -3.446968   |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 1094        |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026973711 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.056       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 5410        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    reward               | 3.0789652   |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1116        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018196374 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.5193125   |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1137        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014880851 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | 0.8494044   |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1157        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018617563 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 5440        |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 0.65889084  |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1178        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013985369 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    reward               | 0.56411886  |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3639636.09\n",
      "total_reward: 2639636.09\n",
      "total_cost: 76844.88\n",
      "total_trades: 55624\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 1199       |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01615007 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.1      |\n",
      "|    explained_variance   | 0.215      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.4       |\n",
      "|    n_updates            | 5460       |\n",
      "|    policy_gradient_loss | -0.00774   |\n",
      "|    reward               | 0.9409105  |\n",
      "|    std                  | 2.3        |\n",
      "|    value_loss           | 50         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 1220       |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01319234 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.1      |\n",
      "|    explained_variance   | 0.115      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.3       |\n",
      "|    n_updates            | 5470       |\n",
      "|    policy_gradient_loss | -0.00472   |\n",
      "|    reward               | 1.3536261  |\n",
      "|    std                  | 2.3        |\n",
      "|    value_loss           | 60         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1240        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020554554 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.09        |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | 0.42663017  |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1261        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011863872 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | 1.2506735   |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1282        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016405696 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 5500        |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | 0.87166435  |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 1302       |\n",
      "|    total_timesteps      | 129024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01936098 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.3      |\n",
      "|    explained_variance   | 0.0744     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.4       |\n",
      "|    n_updates            | 5510       |\n",
      "|    policy_gradient_loss | -0.00986   |\n",
      "|    reward               | 2.6518025  |\n",
      "|    std                  | 2.32       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 99           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1323         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014971034  |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.3        |\n",
      "|    explained_variance   | 0.213        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 5520         |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    reward               | -0.106940456 |\n",
      "|    std                  | 2.32         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 1344       |\n",
      "|    total_timesteps      | 133120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02253304 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.3      |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.3       |\n",
      "|    n_updates            | 5530       |\n",
      "|    policy_gradient_loss | -0.00572   |\n",
      "|    reward               | -1.9939486 |\n",
      "|    std                  | 2.32       |\n",
      "|    value_loss           | 45.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1364        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030191677 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | 0.00108     |\n",
      "|    reward               | -0.47303465 |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 1384       |\n",
      "|    total_timesteps      | 137216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01696361 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.4      |\n",
      "|    explained_variance   | 0.341      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 5550       |\n",
      "|    policy_gradient_loss | -0.00958   |\n",
      "|    reward               | -1.6236352 |\n",
      "|    std                  | 2.32       |\n",
      "|    value_loss           | 25.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1405        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014775265 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | -1.2005196  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1425        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019436508 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | -3.4656074  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1446        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013104226 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | 2.114402    |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1467        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016256178 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -0.7541118  |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1488        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007432441 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    reward               | -11.248899  |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 70.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3575999.94\n",
      "total_reward: 2575999.94\n",
      "total_cost: 96141.29\n",
      "total_trades: 57301\n",
      "Sharpe: 0.674\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1508        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013281932 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | 0.000908    |\n",
      "|    reward               | -0.6554034  |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1529        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025013149 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    reward               | -1.6640725  |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1549        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014087062 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 5630        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | 1.2180268   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1569        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011206886 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | 0.5907395   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1589        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017979102 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 5650        |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    reward               | 1.6553191   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1610        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026631117 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | 1.1421922   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 1630       |\n",
      "|    total_timesteps      | 161792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01646807 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.7      |\n",
      "|    explained_variance   | 0.213      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.8       |\n",
      "|    n_updates            | 5670       |\n",
      "|    policy_gradient_loss | -0.00394   |\n",
      "|    reward               | -0.3577358 |\n",
      "|    std                  | 2.36       |\n",
      "|    value_loss           | 49.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 1650       |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01668984 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.8      |\n",
      "|    explained_variance   | 0.162      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.5       |\n",
      "|    n_updates            | 5680       |\n",
      "|    policy_gradient_loss | -0.00586   |\n",
      "|    reward               | -1.163709  |\n",
      "|    std                  | 2.37       |\n",
      "|    value_loss           | 46.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1670        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027194098 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    reward               | 1.3932097   |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 99           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1689         |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015159439  |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66          |\n",
      "|    explained_variance   | 0.251        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.7         |\n",
      "|    n_updates            | 5700         |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    reward               | 0.0048585064 |\n",
      "|    std                  | 2.37         |\n",
      "|    value_loss           | 56.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1710        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012060456 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 5710        |\n",
      "|    policy_gradient_loss | 0.0017      |\n",
      "|    reward               | -0.46291277 |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1729        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011977824 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 5720        |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    reward               | 1.6426336   |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 85         |\n",
      "|    time_elapsed         | 1749       |\n",
      "|    total_timesteps      | 174080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01200805 |\n",
      "|    clip_fraction        | 0.0868     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66        |\n",
      "|    explained_variance   | 0.334      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.5       |\n",
      "|    n_updates            | 5730       |\n",
      "|    policy_gradient_loss | -0.00457   |\n",
      "|    reward               | 0.14165728 |\n",
      "|    std                  | 2.37       |\n",
      "|    value_loss           | 43.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1769        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013492812 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | 6.464595    |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3714671.92\n",
      "total_reward: 2714671.92\n",
      "total_cost: 146528.46\n",
      "total_trades: 61690\n",
      "Sharpe: 0.704\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1789        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022492267 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    reward               | 1.2787098   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1809        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014730043 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | -1.7930157  |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1829        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011865451 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | 0.00125     |\n",
      "|    reward               | -0.26669908 |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1849        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012450913 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.0918      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 5780        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | -0.437795   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 1869       |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02205021 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.1      |\n",
      "|    explained_variance   | 0.256      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.32       |\n",
      "|    n_updates            | 5790       |\n",
      "|    policy_gradient_loss | -0.00593   |\n",
      "|    reward               | -1.2551473 |\n",
      "|    std                  | 2.39       |\n",
      "|    value_loss           | 17         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1889        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020906296 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | -1.328837   |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1908        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020428108 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | 0.0019      |\n",
      "|    reward               | -1.082382   |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1928        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022909854 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.0569      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    reward               | -0.13104682 |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 1948       |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02971969 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.3      |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.6       |\n",
      "|    n_updates            | 5830       |\n",
      "|    policy_gradient_loss | -0.0068    |\n",
      "|    reward               | -0.630302  |\n",
      "|    std                  | 2.4        |\n",
      "|    value_loss           | 65.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 1968       |\n",
      "|    total_timesteps      | 196608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01759642 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.3      |\n",
      "|    explained_variance   | 0.158      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44         |\n",
      "|    n_updates            | 5840       |\n",
      "|    policy_gradient_loss | -0.0016    |\n",
      "|    reward               | -3.793129  |\n",
      "|    std                  | 2.4        |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1988        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013629412 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 5850        |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    reward               | 1.3185079   |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 62.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 2008        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020796444 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 5860        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.54249346 |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 2027        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020484198 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | -1.9115641  |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 2047       |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02548191 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.4      |\n",
      "|    explained_variance   | 0.0014     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.9       |\n",
      "|    n_updates            | 5880       |\n",
      "|    policy_gradient_loss | -0.00415   |\n",
      "|    reward               | 8.691118   |\n",
      "|    std                  | 2.41       |\n",
      "|    value_loss           | 171        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5415437.53\n",
      "total_reward: 4415437.53\n",
      "total_cost: 204204.85\n",
      "total_trades: 65496\n",
      "Sharpe: 0.803\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 99         |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 2074       |\n",
      "|    total_timesteps      | 206848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0248207  |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.5      |\n",
      "|    explained_variance   | -0.0107    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.1       |\n",
      "|    n_updates            | 5890       |\n",
      "|    policy_gradient_loss | 0.00257    |\n",
      "|    reward               | -0.8331366 |\n",
      "|    std                  | 2.42       |\n",
      "|    value_loss           | 63.1       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 2095        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024305992 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.00747     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | -0.28571025 |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 319         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 99           |\n",
      "|    iterations           | 103          |\n",
      "|    time_elapsed         | 2115         |\n",
      "|    total_timesteps      | 210944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101173315 |\n",
      "|    clip_fraction        | 0.0914       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.6        |\n",
      "|    explained_variance   | 0.193        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.5         |\n",
      "|    n_updates            | 5910         |\n",
      "|    policy_gradient_loss | -0.00973     |\n",
      "|    reward               | 7.788304     |\n",
      "|    std                  | 2.43         |\n",
      "|    value_loss           | 232          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 2135        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023849422 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.000458    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.7        |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | 0.120819435 |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 2155        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010431774 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | -0.0383     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | -3.1223829  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 2174        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016984437 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.00294     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 5940        |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    reward               | -0.9537211  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 99           |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 2194         |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127505325 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.8        |\n",
      "|    explained_variance   | 0.00549      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 245          |\n",
      "|    n_updates            | 5950         |\n",
      "|    policy_gradient_loss | -0.00889     |\n",
      "|    reward               | 0.26895973   |\n",
      "|    std                  | 2.45         |\n",
      "|    value_loss           | 299          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 2214        |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024192145 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.0491      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | -0.33601734 |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 2233        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010680938 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.0742      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.7        |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 0.36112738  |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 2253        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009803593 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 5980        |\n",
      "|    policy_gradient_loss | -0.000293   |\n",
      "|    reward               | 3.4706864   |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 80.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 2273        |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008475023 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | -0.0225     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | 0.000892    |\n",
      "|    reward               | 4.6897883   |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 112        |\n",
      "|    time_elapsed         | 2292       |\n",
      "|    total_timesteps      | 229376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01642555 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67        |\n",
      "|    explained_variance   | 0.213      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 6000       |\n",
      "|    policy_gradient_loss | -0.00841   |\n",
      "|    reward               | -0.5263287 |\n",
      "|    std                  | 2.46       |\n",
      "|    value_loss           | 37.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 2312       |\n",
      "|    total_timesteps      | 231424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01600033 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67        |\n",
      "|    explained_variance   | 0.14       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.4       |\n",
      "|    n_updates            | 6010       |\n",
      "|    policy_gradient_loss | 0.000696   |\n",
      "|    reward               | 3.2642124  |\n",
      "|    std                  | 2.46       |\n",
      "|    value_loss           | 71.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 2331        |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017965829 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.0681      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.5        |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | 2.1036289   |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 96          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4432367.14\n",
      "total_reward: 3432367.14\n",
      "total_cost: 102564.57\n",
      "total_trades: 59299\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 2351        |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017569536 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.27        |\n",
      "|    n_updates            | 6030        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -1.2065637  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 2372        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013594765 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | -2.2946703  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 2392         |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150118545 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -67.1        |\n",
      "|    explained_variance   | 0.261        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.6         |\n",
      "|    n_updates            | 6050         |\n",
      "|    policy_gradient_loss | -0.00027     |\n",
      "|    reward               | -5.8147955   |\n",
      "|    std                  | 2.47         |\n",
      "|    value_loss           | 66.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 2411        |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030848598 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    reward               | -0.19516553 |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 2431        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016706612 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | 0.7530282   |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 2450        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015975296 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    reward               | -3.435408   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 78.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 2470         |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111103095 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -67.4        |\n",
      "|    explained_variance   | 0.137        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 6090         |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    reward               | -0.3156262   |\n",
      "|    std                  | 2.49         |\n",
      "|    value_loss           | 74.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 2490        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018151019 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | -0.24128015 |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 123        |\n",
      "|    time_elapsed         | 2510       |\n",
      "|    total_timesteps      | 251904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01573791 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.4      |\n",
      "|    explained_variance   | 0.0324     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.2       |\n",
      "|    n_updates            | 6110       |\n",
      "|    policy_gradient_loss | -0.00497   |\n",
      "|    reward               | 2.766633   |\n",
      "|    std                  | 2.5        |\n",
      "|    value_loss           | 68.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 2529        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010074394 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.038       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 6120        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | 1.9818178   |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 72.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 2549        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016555851 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 6130        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 1.3885549   |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 2569       |\n",
      "|    total_timesteps      | 258048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02710294 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.5      |\n",
      "|    explained_variance   | 0.0485     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.9       |\n",
      "|    n_updates            | 6140       |\n",
      "|    policy_gradient_loss | -0.0047    |\n",
      "|    reward               | -1.0214636 |\n",
      "|    std                  | 2.51       |\n",
      "|    value_loss           | 56.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 2589        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013705935 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | -2.7092626  |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 89          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 2609        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028442642 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | 0.00253     |\n",
      "|    reward               | 3.2902784   |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4220283.31\n",
      "total_reward: 3220283.31\n",
      "total_cost: 98188.94\n",
      "total_trades: 58708\n",
      "Sharpe: 0.748\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 2629        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012633512 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | -1.8598993  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 2648        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01136012  |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    reward               | -0.29236987 |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 2668        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013587833 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | 0.0117      |\n",
      "|    reward               | -2.4093516  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 75.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 2688        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019127209 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    reward               | 2.3270965   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 2707        |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014713068 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | 1.7855897   |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 2727         |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007333269  |\n",
      "|    clip_fraction        | 0.0652       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -67.7        |\n",
      "|    explained_variance   | 0.27         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.3         |\n",
      "|    n_updates            | 6220         |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    reward               | -0.016682679 |\n",
      "|    std                  | 2.53         |\n",
      "|    value_loss           | 93.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 2747        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021323398 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | -1.5389664  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 59.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 2767        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014907412 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 6240        |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | 1.5479139   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 2787        |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016768334 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | 1.3639605   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 80.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 2806        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014450524 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.3        |\n",
      "|    n_updates            | 6260        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -0.756528   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 2826        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017420571 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | -1.5187098  |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 140        |\n",
      "|    time_elapsed         | 2846       |\n",
      "|    total_timesteps      | 286720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02011859 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68        |\n",
      "|    explained_variance   | 0.195      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.7       |\n",
      "|    n_updates            | 6280       |\n",
      "|    policy_gradient_loss | -0.00518   |\n",
      "|    reward               | 0.8387817  |\n",
      "|    std                  | 2.55       |\n",
      "|    value_loss           | 63.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 2865        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013390269 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 3.0844173   |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 86.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 2885        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018909056 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | 0.92305595  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 50.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4526526.47\n",
      "total_reward: 3526526.47\n",
      "total_cost: 122321.29\n",
      "total_trades: 60698\n",
      "Sharpe: 0.802\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 2905        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012942215 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    reward               | 1.3048807   |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 2924        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010714527 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | -0.6019326  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 75          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 145        |\n",
      "|    time_elapsed         | 2945       |\n",
      "|    total_timesteps      | 296960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01758701 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.1      |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46         |\n",
      "|    n_updates            | 6330       |\n",
      "|    policy_gradient_loss | -0.0064    |\n",
      "|    reward               | 1.2974433  |\n",
      "|    std                  | 2.56       |\n",
      "|    value_loss           | 65         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 2965        |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015110139 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 6340        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 2.601586    |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 2984        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023055974 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.2        |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | -1.4695956  |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 89.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 3004        |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013335613 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | 1.5056828   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 78.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 3024        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022363804 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | -0.127      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 6370        |\n",
      "|    policy_gradient_loss | -0.00291    |\n",
      "|    reward               | 0.9269958   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 3045        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013456857 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    reward               | -0.30475563 |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 3065        |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018169243 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | -0.0283     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.4        |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.00103    |\n",
      "|    reward               | 2.6893392   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 3086        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018479537 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.0786      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 6400        |\n",
      "|    policy_gradient_loss | 0.000261    |\n",
      "|    reward               | -3.993154   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 3107        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01698815  |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | -0.26841852 |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 154          |\n",
      "|    time_elapsed         | 3128         |\n",
      "|    total_timesteps      | 315392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109113995 |\n",
      "|    clip_fraction        | 0.068        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.3        |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 6420         |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | -0.65075326  |\n",
      "|    std                  | 2.58         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 3149         |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074402406 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.3        |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.6         |\n",
      "|    n_updates            | 6430         |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | 0.21711943   |\n",
      "|    std                  | 2.58         |\n",
      "|    value_loss           | 87.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 3170        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031916328 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.0871      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    reward               | 0.42064083  |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5266467.41\n",
      "total_reward: 4266467.41\n",
      "total_cost: 211168.97\n",
      "total_trades: 65516\n",
      "Sharpe: 0.857\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 157        |\n",
      "|    time_elapsed         | 3191       |\n",
      "|    total_timesteps      | 321536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01231306 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.5      |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 186        |\n",
      "|    n_updates            | 6450       |\n",
      "|    policy_gradient_loss | -0.00228   |\n",
      "|    reward               | -2.246658  |\n",
      "|    std                  | 2.59       |\n",
      "|    value_loss           | 420        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 3211        |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009048708 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    reward               | -11.249699  |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 3231        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012975388 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    reward               | -2.4280083  |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 3252        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019659255 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 2.0735934   |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 90.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 3273        |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016190035 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | 52.0353     |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 3293        |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013332831 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.9        |\n",
      "|    n_updates            | 6500        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | 0.21968327  |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 3314        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032488223 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | -1.5018362  |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 3334        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019182524 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 0.24400245  |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 66.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 3355        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012731609 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.0837      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.3        |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    reward               | 0.63129866  |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 98.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 3376        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012247339 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | 6.0805407   |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 167        |\n",
      "|    time_elapsed         | 3397       |\n",
      "|    total_timesteps      | 342016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01271714 |\n",
      "|    clip_fraction        | 0.0923     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.9      |\n",
      "|    explained_variance   | 0.345      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.1       |\n",
      "|    n_updates            | 6550       |\n",
      "|    policy_gradient_loss | -0.00669   |\n",
      "|    reward               | 1.5298756  |\n",
      "|    std                  | 2.63       |\n",
      "|    value_loss           | 50.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 3418        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012622351 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49          |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | 3.4543204   |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 83.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 3438        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018138867 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | -0.0102     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.2        |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | -2.4210398  |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 3459        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012184802 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -0.7579826  |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5440222.80\n",
      "total_reward: 4440222.80\n",
      "total_cost: 114987.08\n",
      "total_trades: 59799\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 3480        |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017723845 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | -1.0262669  |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 66.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 3500        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017386563 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.2        |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    reward               | 2.4601936   |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 93.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 3521        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020066839 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.0325      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.98        |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | -0.10976475 |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 3541        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009760292 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 1.1160197   |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 175        |\n",
      "|    time_elapsed         | 3561       |\n",
      "|    total_timesteps      | 358400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01858186 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.1      |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.1       |\n",
      "|    n_updates            | 6630       |\n",
      "|    policy_gradient_loss | -0.0071    |\n",
      "|    reward               | 0.56502205 |\n",
      "|    std                  | 2.65       |\n",
      "|    value_loss           | 58.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 3581        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009424476 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    reward               | -1.7901996  |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 177        |\n",
      "|    time_elapsed         | 3602       |\n",
      "|    total_timesteps      | 362496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01734401 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.2      |\n",
      "|    explained_variance   | 0.0987     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.7       |\n",
      "|    n_updates            | 6650       |\n",
      "|    policy_gradient_loss | -0.00669   |\n",
      "|    reward               | 0.85407937 |\n",
      "|    std                  | 2.66       |\n",
      "|    value_loss           | 43.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 3623        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012371382 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | -2.1040292  |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 3643        |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011909743 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.2        |\n",
      "|    n_updates            | 6670        |\n",
      "|    policy_gradient_loss | -0.00134    |\n",
      "|    reward               | 2.7763636   |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 3664        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030761473 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.28        |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | -1.4432592  |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 3685        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017996883 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.0952      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 6690        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.03815553  |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 95.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 3705        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012995301 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | 1.3311763   |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 82.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 3727        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013278386 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.000721   |\n",
      "|    reward               | 1.9218739   |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 184          |\n",
      "|    time_elapsed         | 3747         |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083538145 |\n",
      "|    clip_fraction        | 0.094        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.4        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 6720         |\n",
      "|    policy_gradient_loss | -0.00698     |\n",
      "|    reward               | -1.986189    |\n",
      "|    std                  | 2.67         |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 3768        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008612788 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 3.390041    |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 69.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4064322.40\n",
      "total_reward: 3064322.40\n",
      "total_cost: 73306.16\n",
      "total_trades: 57223\n",
      "Sharpe: 0.733\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 186        |\n",
      "|    time_elapsed         | 3789       |\n",
      "|    total_timesteps      | 380928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01400852 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.4      |\n",
      "|    explained_variance   | 0.311      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25         |\n",
      "|    n_updates            | 6740       |\n",
      "|    policy_gradient_loss | -0.000774  |\n",
      "|    reward               | 0.15021862 |\n",
      "|    std                  | 2.68       |\n",
      "|    value_loss           | 59.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 3809        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017473534 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    reward               | -1.1217511  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 3829         |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044293795 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.5        |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.3         |\n",
      "|    n_updates            | 6760         |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | 1.5026882    |\n",
      "|    std                  | 2.68         |\n",
      "|    value_loss           | 66.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 3848         |\n",
      "|    total_timesteps      | 387072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064662443 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69.5        |\n",
      "|    explained_variance   | 0.311        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 6770         |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    reward               | -5.4402747   |\n",
      "|    std                  | 2.68         |\n",
      "|    value_loss           | 63.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 3870        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013563644 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | 0.82722604  |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 3890        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016093507 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | 0.14874712  |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 192        |\n",
      "|    time_elapsed         | 3911       |\n",
      "|    total_timesteps      | 393216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01030812 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.5      |\n",
      "|    explained_variance   | 0.34       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 6800       |\n",
      "|    policy_gradient_loss | -0.00757   |\n",
      "|    reward               | -5.6867914 |\n",
      "|    std                  | 2.69       |\n",
      "|    value_loss           | 58.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 3932        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01346095  |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    reward               | -0.33400688 |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 3952        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028443493 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    reward               | 1.2820566   |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 3973        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013265435 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.0745      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.9        |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | 0.7386708   |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 80.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 3993        |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010411428 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | 0.9144053   |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 67          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 4013        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011148917 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -1.5138534  |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 198        |\n",
      "|    time_elapsed         | 4034       |\n",
      "|    total_timesteps      | 405504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01021307 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.7      |\n",
      "|    explained_variance   | 0.415      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.2       |\n",
      "|    n_updates            | 6860       |\n",
      "|    policy_gradient_loss | -0.0043    |\n",
      "|    reward               | -0.2065848 |\n",
      "|    std                  | 2.7        |\n",
      "|    value_loss           | 43.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 4054        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029105842 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    reward               | -4.963604   |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 62          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3927745.67\n",
      "total_reward: 2927745.67\n",
      "total_cost: 65647.32\n",
      "total_trades: 57090\n",
      "Sharpe: 0.728\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 4074        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014865253 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    reward               | 1.1904751   |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 4094        |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013726519 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 1.0170783   |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 4113        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013720181 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 6900        |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | -4.9588356  |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 65.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 4133        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014909865 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    reward               | 0.5465906   |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 4153       |\n",
      "|    total_timesteps      | 417792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02001932 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.9      |\n",
      "|    explained_variance   | 0.278      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.9       |\n",
      "|    n_updates            | 6920       |\n",
      "|    policy_gradient_loss | -0.00597   |\n",
      "|    reward               | 0.2387029  |\n",
      "|    std                  | 2.72       |\n",
      "|    value_loss           | 29.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 4172        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017749578 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | 4.379314    |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 4191        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014070265 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    reward               | 0.96879476  |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 4211        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017637124 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    reward               | -0.7330873  |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 4230        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022842642 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -2.5178277  |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 4250        |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007034316 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | 0.6718397   |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 4269        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010696106 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 0.27736604  |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 100       |\n",
      "|    iterations           | 211       |\n",
      "|    time_elapsed         | 4290      |\n",
      "|    total_timesteps      | 432128    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0196876 |\n",
      "|    clip_fraction        | 0.261     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.1     |\n",
      "|    explained_variance   | 0.323     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 23.3      |\n",
      "|    n_updates            | 6990      |\n",
      "|    policy_gradient_loss | -0.00851  |\n",
      "|    reward               | 1.9480382 |\n",
      "|    std                  | 2.75      |\n",
      "|    value_loss           | 31.7      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 4309        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013307704 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | -0.28296003 |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 213        |\n",
      "|    time_elapsed         | 4329       |\n",
      "|    total_timesteps      | 436224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00825192 |\n",
      "|    clip_fraction        | 0.0461     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.2      |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.9       |\n",
      "|    n_updates            | 7010       |\n",
      "|    policy_gradient_loss | -0.00601   |\n",
      "|    reward               | -0.5885434 |\n",
      "|    std                  | 2.76       |\n",
      "|    value_loss           | 58.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3769085.54\n",
      "total_reward: 2769085.54\n",
      "total_cost: 66742.18\n",
      "total_trades: 56579\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 4348        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018701635 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | -3.0678499  |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 100        |\n",
      "|    iterations           | 215        |\n",
      "|    time_elapsed         | 4367       |\n",
      "|    total_timesteps      | 440320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01800769 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.3      |\n",
      "|    explained_variance   | 0.4        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.4       |\n",
      "|    n_updates            | 7030       |\n",
      "|    policy_gradient_loss | -0.00585   |\n",
      "|    reward               | 1.3584012  |\n",
      "|    std                  | 2.76       |\n",
      "|    value_loss           | 39.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 4387        |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013243515 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.2        |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | -0.09966278 |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 78.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 4407        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010305334 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    reward               | -3.166259   |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 50          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 4426        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022109458 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 7060        |\n",
      "|    policy_gradient_loss | -0.000685   |\n",
      "|    reward               | -0.15998366 |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 4446        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017794125 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 7070        |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | -0.36975044 |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 4466        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010518861 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | 1.4837854   |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 4485        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021780912 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | -1.0371441  |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 4505        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017843496 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | -0.9707714  |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 4524        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009397128 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -2.5962534  |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 4544        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013853828 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | 4.7257767   |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 4563        |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015462161 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | 3.0850222   |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 4583        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012989569 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 7140        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 9.485062    |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 4603        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008939489 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | 0.43446302  |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 73.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3731110.15\n",
      "total_reward: 2731110.15\n",
      "total_cost: 58649.09\n",
      "total_trades: 55278\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 4622        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01078921  |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    reward               | -0.65678984 |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 4642        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017528975 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | -0.563068   |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 4662        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006108683 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    reward               | -1.9807942  |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 72.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 4682        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011701107 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | -8.341451   |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 4702        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014213273 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    reward               | -0.09949423 |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 4722         |\n",
      "|    total_timesteps      | 477184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089431945 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.7        |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 7210         |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | -2.7492497   |\n",
      "|    std                  | 2.8          |\n",
      "|    value_loss           | 55.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 4742        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0121108   |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 7220        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | -0.68445736 |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 4761        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010317918 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | -0.3905284  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 4781        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024412725 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 1.481364    |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 4801        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019922616 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 7250        |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | 0.38080746  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 67.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 4820        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020870183 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | -0.736475   |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 4840        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017394532 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 1.2900807   |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 4859        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011101536 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | -3.5858953  |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 4879        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019504488 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | -0.25833464 |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3841440.10\n",
      "total_reward: 2841440.10\n",
      "total_cost: 69524.58\n",
      "total_trades: 55618\n",
      "Sharpe: 0.715\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 242          |\n",
      "|    time_elapsed         | 4899         |\n",
      "|    total_timesteps      | 495616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0145465415 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71          |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 7300         |\n",
      "|    policy_gradient_loss | -0.00738     |\n",
      "|    reward               | -3.1528358   |\n",
      "|    std                  | 2.83         |\n",
      "|    value_loss           | 36.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 4919         |\n",
      "|    total_timesteps      | 497664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110518895 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71          |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 7310         |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    reward               | 0.47647807   |\n",
      "|    std                  | 2.83         |\n",
      "|    value_loss           | 47.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 4938        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013228134 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | 1.236187    |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 4958        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022932753 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | -0.68116605 |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 4977        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012944216 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | 1.694083    |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 247        |\n",
      "|    time_elapsed         | 4997       |\n",
      "|    total_timesteps      | 505856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01210145 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71        |\n",
      "|    explained_variance   | 0.558      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.5       |\n",
      "|    n_updates            | 7350       |\n",
      "|    policy_gradient_loss | -0.00478   |\n",
      "|    reward               | 7.284698   |\n",
      "|    std                  | 2.83       |\n",
      "|    value_loss           | 45.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 5017        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017528325 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 7360        |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    reward               | -0.6612308  |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 5036        |\n",
      "|    total_timesteps      | 509952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012988148 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    reward               | 0.19331637  |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 5055        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013879259 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | 2.2423425   |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 5075        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016242046 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 7390        |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 2.2577095   |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 5095        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012965584 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.48        |\n",
      "|    n_updates            | 7400        |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    reward               | -1.2263533  |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 5115        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016979653 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | 1.035017    |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 49.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 5134        |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010261983 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | -2.1197078  |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 5154        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012800429 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    reward               | 4.2053113   |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4002469.74\n",
      "total_reward: 3002469.74\n",
      "total_cost: 77993.46\n",
      "total_trades: 55855\n",
      "Sharpe: 0.740\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 5174        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018594678 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | 5.2388306   |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 5194        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011673702 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 7450        |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | 0.73560244  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 5214        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014922362 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | 2.1025066   |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 5234        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013302321 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.97        |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | 0.75678015  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 5254        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015306236 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 7480        |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | -0.22866914 |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 5274        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013667844 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 3.0880868   |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 262          |\n",
      "|    time_elapsed         | 5295         |\n",
      "|    total_timesteps      | 536576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.024181245  |\n",
      "|    clip_fraction        | 0.205        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.4        |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.62         |\n",
      "|    n_updates            | 7500         |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    reward               | -0.101418726 |\n",
      "|    std                  | 2.87         |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 5315         |\n",
      "|    total_timesteps      | 538624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154591575 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.5        |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 7510         |\n",
      "|    policy_gradient_loss | -0.00925     |\n",
      "|    reward               | 0.30120352   |\n",
      "|    std                  | 2.88         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 264         |\n",
      "|    time_elapsed         | 5335        |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012319069 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | -4.0099545  |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 5355        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010504032 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | -1.9298176  |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 266        |\n",
      "|    time_elapsed         | 5375       |\n",
      "|    total_timesteps      | 544768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02486677 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.6      |\n",
      "|    explained_variance   | 0.577      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.3       |\n",
      "|    n_updates            | 7540       |\n",
      "|    policy_gradient_loss | -0.00709   |\n",
      "|    reward               | 0.04247191 |\n",
      "|    std                  | 2.89       |\n",
      "|    value_loss           | 33.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 5394        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016356982 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | -1.3784106  |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 268        |\n",
      "|    time_elapsed         | 5414       |\n",
      "|    total_timesteps      | 548864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01075083 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.8      |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.4       |\n",
      "|    n_updates            | 7560       |\n",
      "|    policy_gradient_loss | -0.00692   |\n",
      "|    reward               | 0.5678363  |\n",
      "|    std                  | 2.91       |\n",
      "|    value_loss           | 71.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 5434        |\n",
      "|    total_timesteps      | 550912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020961618 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 7570        |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | -0.15040933 |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4098054.78\n",
      "total_reward: 3098054.78\n",
      "total_cost: 72153.05\n",
      "total_trades: 56263\n",
      "Sharpe: 0.747\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 270        |\n",
      "|    time_elapsed         | 5454       |\n",
      "|    total_timesteps      | 552960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01565766 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.9      |\n",
      "|    explained_variance   | 0.304      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.4       |\n",
      "|    n_updates            | 7580       |\n",
      "|    policy_gradient_loss | -0.00967   |\n",
      "|    reward               | 1.3420427  |\n",
      "|    std                  | 2.92       |\n",
      "|    value_loss           | 51.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 5474        |\n",
      "|    total_timesteps      | 555008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016469426 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | -0.5851877  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 5494        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017008081 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 7600        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -1.7665095  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 5514        |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014488833 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.8024788  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 5533        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016662885 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 7620        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -7.811233   |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 5553        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016904134 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | 0.00049     |\n",
      "|    reward               | 0.18580502  |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 5573        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008831774 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | 1.8869418   |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 5593        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011213871 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | 1.8519435   |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 278        |\n",
      "|    time_elapsed         | 5613       |\n",
      "|    total_timesteps      | 569344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00917865 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.3      |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33         |\n",
      "|    n_updates            | 7660       |\n",
      "|    policy_gradient_loss | -0.00586   |\n",
      "|    reward               | 5.3814964  |\n",
      "|    std                  | 2.96       |\n",
      "|    value_loss           | 65         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 5633        |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012721911 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | 1.3293947   |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 5664        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009773588 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | 1.036771    |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 5684        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014373182 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    reward               | 2.5629969   |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 5703        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012493553 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 7700        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | -2.1195219  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 5724        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013250458 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | 0.80870384  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3966305.52\n",
      "total_reward: 2966305.52\n",
      "total_cost: 63454.69\n",
      "total_trades: 55473\n",
      "Sharpe: 0.733\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 5745        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013771517 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | 1.1478107   |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 5766        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012273507 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 0.6069574   |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 63.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 286          |\n",
      "|    time_elapsed         | 5786         |\n",
      "|    total_timesteps      | 585728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132096335 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.6        |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 7740         |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    reward               | -1.0224203   |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 5805        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013362695 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -0.51577306 |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 288        |\n",
      "|    time_elapsed         | 5825       |\n",
      "|    total_timesteps      | 589824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01797332 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.6      |\n",
      "|    explained_variance   | 0.458      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.4       |\n",
      "|    n_updates            | 7760       |\n",
      "|    policy_gradient_loss | -0.00975   |\n",
      "|    reward               | 2.7588072  |\n",
      "|    std                  | 2.99       |\n",
      "|    value_loss           | 46.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 5845        |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011526479 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | 2.653153    |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 5865        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014775572 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    reward               | 0.8764138   |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 5885        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015120304 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | 0.025839051 |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 292          |\n",
      "|    time_elapsed         | 5904         |\n",
      "|    total_timesteps      | 598016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086626895 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.7        |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 7800         |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | 1.2771858    |\n",
      "|    std                  | 3            |\n",
      "|    value_loss           | 57.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 5924        |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015410347 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 7810        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 2.011527    |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 294          |\n",
      "|    time_elapsed         | 5944         |\n",
      "|    total_timesteps      | 602112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011141536  |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.8        |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 7820         |\n",
      "|    policy_gradient_loss | -0.00854     |\n",
      "|    reward               | -0.038936134 |\n",
      "|    std                  | 3.01         |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 295          |\n",
      "|    time_elapsed         | 5964         |\n",
      "|    total_timesteps      | 604160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075828917 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.8        |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 7830         |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | 0.8117941    |\n",
      "|    std                  | 3.01         |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 5984        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014648636 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 7840        |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    reward               | -3.0819197  |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 6004        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011524802 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | -1.5803001  |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 101       |\n",
      "|    iterations           | 298       |\n",
      "|    time_elapsed         | 6023      |\n",
      "|    total_timesteps      | 610304    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0178174 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -73       |\n",
      "|    explained_variance   | 0.395     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 15.1      |\n",
      "|    n_updates            | 7860      |\n",
      "|    policy_gradient_loss | -0.00467  |\n",
      "|    reward               | -3.220562 |\n",
      "|    std                  | 3.03      |\n",
      "|    value_loss           | 47.9      |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3659359.33\n",
      "total_reward: 2659359.33\n",
      "total_cost: 68735.15\n",
      "total_trades: 56492\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 6043        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021712923 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    reward               | 0.39182854  |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 300        |\n",
      "|    time_elapsed         | 6062       |\n",
      "|    total_timesteps      | 614400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01385485 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.1      |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.13       |\n",
      "|    n_updates            | 7880       |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    reward               | 1.3520379  |\n",
      "|    std                  | 3.04       |\n",
      "|    value_loss           | 27.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 6082        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021347925 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.9417951   |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 6102        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011673801 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 7900        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | -4.0045333  |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 6123        |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015268179 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 7910        |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -3.6256518  |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 6143        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014787145 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 0.29886445  |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 6163        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010522623 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 7930        |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | 0.5104487   |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 6183        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012860319 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    reward               | -0.52600163 |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 6203        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013212174 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 7950        |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | 0.045214318 |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 6225        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016914114 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 7960        |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | -0.7569253  |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 6244        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009260906 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 7970        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | 0.5389859   |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 6264        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013114141 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | 1.3285745   |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 6284        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02041876  |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | -0.15757021 |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 6304        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007988977 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | 0.61050385  |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3927161.19\n",
      "total_reward: 2927161.19\n",
      "total_cost: 61651.37\n",
      "total_trades: 56286\n",
      "Sharpe: 0.724\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 6324        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015555071 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 8010        |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | -7.865433   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 6344        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012966206 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | -1.4345528  |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 6364        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013409313 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 8030        |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | -4.8384066  |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 6384        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008162258 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | -1.5977569  |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 6404        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018006105 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.32        |\n",
      "|    n_updates            | 8050        |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 1.1143863   |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 318         |\n",
      "|    time_elapsed         | 6424        |\n",
      "|    total_timesteps      | 651264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018949706 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 4.771719    |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 6444        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012171557 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 8070        |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    reward               | 2.5563102   |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 320        |\n",
      "|    time_elapsed         | 6463       |\n",
      "|    total_timesteps      | 655360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01722401 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.7      |\n",
      "|    explained_variance   | 0.624      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.4       |\n",
      "|    n_updates            | 8080       |\n",
      "|    policy_gradient_loss | -0.00551   |\n",
      "|    reward               | -7.7056937 |\n",
      "|    std                  | 3.11       |\n",
      "|    value_loss           | 31.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 6483        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022050496 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 8090        |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    reward               | 0.4102869   |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 322        |\n",
      "|    time_elapsed         | 6503       |\n",
      "|    total_timesteps      | 659456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00779125 |\n",
      "|    clip_fraction        | 0.0318     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.9      |\n",
      "|    explained_variance   | 0.566      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.4       |\n",
      "|    n_updates            | 8100       |\n",
      "|    policy_gradient_loss | -0.00445   |\n",
      "|    reward               | -1.4831682 |\n",
      "|    std                  | 3.12       |\n",
      "|    value_loss           | 50.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 6523        |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018183053 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 8110        |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    reward               | -0.8723151  |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 6544        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016433498 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | -0.76365024 |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 6564        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011682416 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | 0.9467536   |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 6584        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008284952 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 8140        |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    reward               | -0.17288946 |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3907293.75\n",
      "total_reward: 2907293.75\n",
      "total_cost: 80275.43\n",
      "total_trades: 58534\n",
      "Sharpe: 0.732\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 6604        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013455572 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 8150        |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | 0.69029826  |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 6624        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012158159 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 8160        |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    reward               | 0.15853293  |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 6644        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011402665 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | -0.88041794 |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 6664        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010966668 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 8180        |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | -3.464451   |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 331          |\n",
      "|    time_elapsed         | 6684         |\n",
      "|    total_timesteps      | 677888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132491905 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.1        |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 8190         |\n",
      "|    policy_gradient_loss | -0.00901     |\n",
      "|    reward               | -1.2072808   |\n",
      "|    std                  | 3.15         |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 332        |\n",
      "|    time_elapsed         | 6704       |\n",
      "|    total_timesteps      | 679936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00949507 |\n",
      "|    clip_fraction        | 0.0869     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.2      |\n",
      "|    explained_variance   | 0.559      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.3       |\n",
      "|    n_updates            | 8200       |\n",
      "|    policy_gradient_loss | -0.00811   |\n",
      "|    reward               | 0.3376819  |\n",
      "|    std                  | 3.16       |\n",
      "|    value_loss           | 49.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 333         |\n",
      "|    time_elapsed         | 6724        |\n",
      "|    total_timesteps      | 681984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009754119 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 8210        |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | 0.86034733  |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 334        |\n",
      "|    time_elapsed         | 6744       |\n",
      "|    total_timesteps      | 684032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02163237 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.3      |\n",
      "|    explained_variance   | 0.542      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.1       |\n",
      "|    n_updates            | 8220       |\n",
      "|    policy_gradient_loss | -0.00517   |\n",
      "|    reward               | 1.024506   |\n",
      "|    std                  | 3.17       |\n",
      "|    value_loss           | 24.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 6765        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014492459 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 8230        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    reward               | -0.55265504 |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 6786        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009388188 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | -5.8057704  |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 6806        |\n",
      "|    total_timesteps      | 690176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010100465 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 8250        |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 0.18439746  |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 6827        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014229977 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 8260        |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    reward               | -0.488961   |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 6846        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008139864 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 8270        |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    reward               | -9.840917   |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 6866        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015044725 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 8280        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | 3.671087    |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4287652.03\n",
      "total_reward: 3287652.03\n",
      "total_cost: 94378.23\n",
      "total_trades: 59006\n",
      "Sharpe: 0.779\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 341        |\n",
      "|    time_elapsed         | 6886       |\n",
      "|    total_timesteps      | 698368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02596207 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.5      |\n",
      "|    explained_variance   | 0.551      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 8290       |\n",
      "|    policy_gradient_loss | -0.00872   |\n",
      "|    reward               | -1.9100075 |\n",
      "|    std                  | 3.19       |\n",
      "|    value_loss           | 25         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 6906        |\n",
      "|    total_timesteps      | 700416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019302292 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 8300        |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | 0.4066104   |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 6926        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011083929 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 8310        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | 4.452428    |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 6945        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024303742 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 8320        |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | 5.5943084   |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 6965        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019488662 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.5         |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 1.1596813   |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 6984        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015427103 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    reward               | 1.1246521   |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 347          |\n",
      "|    time_elapsed         | 7004         |\n",
      "|    total_timesteps      | 710656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096431915 |\n",
      "|    clip_fraction        | 0.0747       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.7        |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 8350         |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | -0.6915554   |\n",
      "|    std                  | 3.22         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 7024        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014802085 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    reward               | -0.9966404  |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 7043        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018226085 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 8370        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | 0.82337534  |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 7063        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007878423 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 8380        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | 2.6004798   |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 7083        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021778734 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | 0.5870589   |\n",
      "|    std                  | 3.23        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 7103        |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016007233 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | -1.5310901  |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 7123        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009483858 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | 2.6480188   |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 354        |\n",
      "|    time_elapsed         | 7143       |\n",
      "|    total_timesteps      | 724992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01239372 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75        |\n",
      "|    explained_variance   | 0.445      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 8420       |\n",
      "|    policy_gradient_loss | -0.00578   |\n",
      "|    reward               | 1.2881695  |\n",
      "|    std                  | 3.24       |\n",
      "|    value_loss           | 40.3       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3776953.48\n",
      "total_reward: 2776953.48\n",
      "total_cost: 83085.04\n",
      "total_trades: 57956\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 7162        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017330777 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 8430        |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    reward               | 0.36696738  |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 7182        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012110741 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | -0.88222307 |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 7202        |\n",
      "|    total_timesteps      | 731136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008451384 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | -1.1547062  |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 7221        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016576454 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.13        |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.4057569   |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 7241        |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012030437 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 8470        |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | -1.5440913  |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 360          |\n",
      "|    time_elapsed         | 7260         |\n",
      "|    total_timesteps      | 737280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062132217 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.2        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 8480         |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | 3.7336173    |\n",
      "|    std                  | 3.27         |\n",
      "|    value_loss           | 46.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 7280        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008773573 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 8490        |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | -0.29890788 |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 7300        |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019729149 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.83        |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.45329392  |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 363        |\n",
      "|    time_elapsed         | 7319       |\n",
      "|    total_timesteps      | 743424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01213534 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.3      |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.2       |\n",
      "|    n_updates            | 8510       |\n",
      "|    policy_gradient_loss | -0.00644   |\n",
      "|    reward               | -34.269398 |\n",
      "|    std                  | 3.28       |\n",
      "|    value_loss           | 37.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 364        |\n",
      "|    time_elapsed         | 7339       |\n",
      "|    total_timesteps      | 745472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00979506 |\n",
      "|    clip_fraction        | 0.0319     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.3      |\n",
      "|    explained_variance   | 0.528      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.7       |\n",
      "|    n_updates            | 8520       |\n",
      "|    policy_gradient_loss | -0.00265   |\n",
      "|    reward               | 0.07505061 |\n",
      "|    std                  | 3.28       |\n",
      "|    value_loss           | 50.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 7359        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014137864 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.7         |\n",
      "|    n_updates            | 8530        |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 1.4131192   |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 7379        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013118567 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.8899081   |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 367         |\n",
      "|    time_elapsed         | 7399        |\n",
      "|    total_timesteps      | 751616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014942806 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 8550        |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | 1.5201659   |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 52.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 7418        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016246252 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 1.1473782   |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2854898.17\n",
      "total_reward: 1854898.17\n",
      "total_cost: 152642.29\n",
      "total_trades: 63687\n",
      "Sharpe: 0.581\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 7438        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028734488 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    reward               | -1.0011493  |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 7457        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014834695 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 8580        |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    reward               | -2.1338387  |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 7476        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013405822 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 8590        |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    reward               | -1.4446964  |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 7496        |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021316707 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.89        |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    reward               | 1.1374974   |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 7516        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012886273 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | -0.55446297 |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 7535        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012036023 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 8620        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | -0.6415367  |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 7555        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015792657 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.27        |\n",
      "|    n_updates            | 8630        |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | -0.50734115 |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 7574        |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014958601 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.56        |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | 0.27951002  |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 377        |\n",
      "|    time_elapsed         | 7594       |\n",
      "|    total_timesteps      | 772096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01506766 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.8      |\n",
      "|    explained_variance   | 0.316      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.4       |\n",
      "|    n_updates            | 8650       |\n",
      "|    policy_gradient_loss | -0.00246   |\n",
      "|    reward               | 1.3480806  |\n",
      "|    std                  | 3.33       |\n",
      "|    value_loss           | 45.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 378          |\n",
      "|    time_elapsed         | 7614         |\n",
      "|    total_timesteps      | 774144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060839457 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.8        |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.37         |\n",
      "|    n_updates            | 8660         |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    reward               | -0.083338626 |\n",
      "|    std                  | 3.34         |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 7633        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009974409 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 8670        |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | -2.2044218  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 7653        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011694539 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 8680        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 0.30250883  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 101           |\n",
      "|    iterations           | 381           |\n",
      "|    time_elapsed         | 7673          |\n",
      "|    total_timesteps      | 780288        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.01108744    |\n",
      "|    clip_fraction        | 0.0687        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -75.8         |\n",
      "|    explained_variance   | 0.472         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.1          |\n",
      "|    n_updates            | 8690          |\n",
      "|    policy_gradient_loss | -0.00371      |\n",
      "|    reward               | -0.0033938386 |\n",
      "|    std                  | 3.34          |\n",
      "|    value_loss           | 46.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 382        |\n",
      "|    time_elapsed         | 7693       |\n",
      "|    total_timesteps      | 782336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01463581 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.9      |\n",
      "|    explained_variance   | 0.607      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.06       |\n",
      "|    n_updates            | 8700       |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    reward               | -0.6735365 |\n",
      "|    std                  | 3.34       |\n",
      "|    value_loss           | 13.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3119490.07\n",
      "total_reward: 2119490.07\n",
      "total_cost: 87633.43\n",
      "total_trades: 57508\n",
      "Sharpe: 0.624\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 383          |\n",
      "|    time_elapsed         | 7712         |\n",
      "|    total_timesteps      | 784384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108662415 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.9        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 8710         |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | 0.94903487   |\n",
      "|    std                  | 3.35         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 7732        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010542385 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 8720        |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | -1.0281359  |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 7752        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013838502 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.52        |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | 0.03734531  |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 7771        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020146258 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.64        |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 0.46717426  |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 7791        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015046578 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | 1.8225571   |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 7811        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012684381 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 8760        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.32008874 |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 7831        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018305933 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.72        |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 2.5904286   |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 7851        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018935965 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 8780        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 2.2583985   |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 7871        |\n",
      "|    total_timesteps      | 800768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023218902 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 8790        |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    reward               | 3.3309817   |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 7890        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012038214 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 8800        |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | 0.90501267  |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 7910        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011581494 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.04        |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | -0.8236392  |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 7930        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011279285 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 8820        |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | 2.092219    |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 7950        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011376504 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 8830        |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | -0.85184455 |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 7970        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018089628 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.21        |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 1.1039373   |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3111408.52\n",
      "total_reward: 2111408.52\n",
      "total_cost: 389403.27\n",
      "total_trades: 73916\n",
      "Sharpe: 0.658\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 7989        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011728611 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 8850        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.6147718  |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 8009        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015881203 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    reward               | -3.2814617  |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 8029        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021350525 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 8870        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    reward               | -4.5342546  |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 8048        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013350079 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.86        |\n",
      "|    n_updates            | 8880        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -0.8086581  |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 8068        |\n",
      "|    total_timesteps      | 821248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017022774 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.0795      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | -2.1721387  |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 8088        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020142302 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | -0.0239     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.68        |\n",
      "|    n_updates            | 8900        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -0.11790735 |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 8108        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020744307 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.0163      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 8910        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -0.5587508  |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 8128        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023194004 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 8920        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 1.3987124   |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 8148        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018752635 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | 1.9555353   |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 406         |\n",
      "|    time_elapsed         | 8168        |\n",
      "|    total_timesteps      | 831488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017648742 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | -0.0303     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.3         |\n",
      "|    n_updates            | 8940        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | 0.017515207 |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 8187        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015704455 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 8950        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 3.0364623   |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 408          |\n",
      "|    time_elapsed         | 8207         |\n",
      "|    total_timesteps      | 835584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080494685 |\n",
      "|    clip_fraction        | 0.048        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.1        |\n",
      "|    explained_variance   | 0.193        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 8960         |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    reward               | 0.75106144   |\n",
      "|    std                  | 3.48         |\n",
      "|    value_loss           | 57.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 8228        |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020489242 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.0347      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -3.4643614  |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 8249        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021968935 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.0895      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 8980        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | 1.3817078   |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 8269        |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018625967 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.0113      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 8990        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -0.36765248 |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3368379.61\n",
      "total_reward: 2368379.61\n",
      "total_cost: 420805.86\n",
      "total_trades: 75006\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 8289        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015331736 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.0233      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.77        |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.7222157  |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 8309        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020411108 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | -0.00203    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 9010        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | -0.20040596 |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 8329        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018454958 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.0332      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -0.82627994 |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 8349        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008530379 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.000494    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    reward               | 0.7062392   |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 70.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 8369        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019730259 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | -0.0144     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.49        |\n",
      "|    n_updates            | 9040        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | 0.36281586  |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 8389         |\n",
      "|    total_timesteps      | 854016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014749209  |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.5        |\n",
      "|    explained_variance   | 0.0496       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 9050         |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    reward               | -0.030349603 |\n",
      "|    std                  | 3.54         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 8410        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01383146  |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 9060        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.027506862 |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 8429        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019102149 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | -0.00394    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | -1.6917721  |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 8449        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013175781 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.0186      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 9080        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -0.04700117 |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 421          |\n",
      "|    time_elapsed         | 8469         |\n",
      "|    total_timesteps      | 862208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0156155545 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.7        |\n",
      "|    explained_variance   | 0.0579       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63           |\n",
      "|    n_updates            | 9090         |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    reward               | -0.44809598  |\n",
      "|    std                  | 3.56         |\n",
      "|    value_loss           | 63.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 8489        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016225327 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.0291      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 1.0431844   |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 92.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 8509        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017179884 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.43        |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    reward               | 0.37192604  |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 8529        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016710456 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -2.0604553  |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 8548        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018792091 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.0576      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 9130        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -6.14506    |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3412238.53\n",
      "total_reward: 2412238.53\n",
      "total_cost: 187527.08\n",
      "total_trades: 64224\n",
      "Sharpe: 0.665\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 8568        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011749582 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | -0.0592     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.28        |\n",
      "|    n_updates            | 9140        |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | -0.26239118 |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 8588        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015867516 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.59        |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.19902961  |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 8608        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011283945 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 9160        |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | 0.09026211  |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 8628        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010872275 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 9170        |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | -0.91712093 |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 8648        |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026895761 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.6         |\n",
      "|    n_updates            | 9180        |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | 0.32898062  |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 8668        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010948711 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.6112807  |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 8688        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009553738 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 9200        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | -2.0004756  |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 8708        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014243104 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    reward               | -4.1773643  |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 434        |\n",
      "|    time_elapsed         | 8728       |\n",
      "|    total_timesteps      | 888832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01649857 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.2      |\n",
      "|    explained_variance   | 0.367      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.4       |\n",
      "|    n_updates            | 9220       |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    reward               | 1.9171436  |\n",
      "|    std                  | 3.63       |\n",
      "|    value_loss           | 24         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 8748        |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008347512 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 9230        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | 0.7804517   |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 8768        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025868416 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.0905      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.71        |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 1.0270957   |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 8789        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013642936 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 9250        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -2.3411772  |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 8809        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011139646 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | 0.53256416  |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 8829        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013404705 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 9270        |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 4.815807    |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4062271.33\n",
      "total_reward: 3062271.33\n",
      "total_cost: 315673.43\n",
      "total_trades: 70357\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 8849        |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02311974  |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | -0.15       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.02        |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    reward               | -0.38106593 |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 8868        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017674241 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | -0.00228    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -1.5456421  |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 64.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 8888        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015675714 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 9300        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 3.6730793   |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 8908        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021065755 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | -0.0124     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 9310        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.5566709   |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 8928        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018543264 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | -0.00903    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 9320        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    reward               | 0.10897609  |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 80.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 8948        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00787355  |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | -0.00834    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 9330        |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | -0.98959666 |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 8969        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009601566 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.0408      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 9340        |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | 2.1881542   |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 72.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 447          |\n",
      "|    time_elapsed         | 8989         |\n",
      "|    total_timesteps      | 915456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015560446  |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.8        |\n",
      "|    explained_variance   | -0.041       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.05         |\n",
      "|    n_updates            | 9350         |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    reward               | -0.023209872 |\n",
      "|    std                  | 3.7          |\n",
      "|    value_loss           | 16.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 9010        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010046483 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    reward               | 0.48406798  |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 9030        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011553011 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 9370        |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | 3.0764382   |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 61.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 9050        |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021955788 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | -0.0325     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.42        |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    reward               | -1.0757861  |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 9071        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015813697 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | -0.00183    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -0.631367   |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 9091        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007931067 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.0232      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 9400        |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    reward               | -5.1598277  |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 78.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 9111        |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010320336 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    reward               | 2.0263147   |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2863871.14\n",
      "total_reward: 1863871.14\n",
      "total_cost: 395706.45\n",
      "total_trades: 73455\n",
      "Sharpe: 0.595\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 454        |\n",
      "|    time_elapsed         | 9131       |\n",
      "|    total_timesteps      | 929792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02407433 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.9      |\n",
      "|    explained_variance   | 0.179      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.74       |\n",
      "|    n_updates            | 9420       |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    reward               | -0.4299565 |\n",
      "|    std                  | 3.72       |\n",
      "|    value_loss           | 18.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 455        |\n",
      "|    time_elapsed         | 9151       |\n",
      "|    total_timesteps      | 931840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02081209 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79        |\n",
      "|    explained_variance   | 0.0313     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29         |\n",
      "|    n_updates            | 9430       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | 1.3547933  |\n",
      "|    std                  | 3.72       |\n",
      "|    value_loss           | 51.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 9172        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018005554 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.0949      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -3.8963735  |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 9192        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018893342 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 9450        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | -0.47372574 |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 9212        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011269457 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    reward               | -4.9881997  |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 89          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 9231        |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014445168 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 9470        |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    reward               | 0.3927601   |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 9251        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011580302 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | -8.94e-05   |\n",
      "|    reward               | -2.9695382  |\n",
      "|    std                  | 3.75        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 9271        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015144894 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.95        |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 0.053532843 |\n",
      "|    std                  | 3.75        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 9290        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012308922 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 9500        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | -0.41917843 |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 9310        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012297025 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 9510        |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | 1.301047    |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 9330        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020207617 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.0545      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.06        |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.28308347 |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 9349        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014114907 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | -0.2620369  |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 93          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 466        |\n",
      "|    time_elapsed         | 9369       |\n",
      "|    total_timesteps      | 954368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01600533 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.4      |\n",
      "|    explained_variance   | -0.0366    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.8       |\n",
      "|    n_updates            | 9540       |\n",
      "|    policy_gradient_loss | -0.00756   |\n",
      "|    reward               | -12.691563 |\n",
      "|    std                  | 3.78       |\n",
      "|    value_loss           | 81.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 9389        |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015014018 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.0565      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 0.4202505   |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4953108.29\n",
      "total_reward: 3953108.29\n",
      "total_cost: 257283.16\n",
      "total_trades: 67216\n",
      "Sharpe: 0.890\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 9408        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011702099 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | -0.00547    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 9560        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.5049819   |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 91.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 9428        |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013575377 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 9570        |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    reward               | -0.3846772  |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 55.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 9448        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015911797 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.0155      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 9580        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -0.9089842  |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 9468        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018986586 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 9590        |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | -0.03232551 |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 9487        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011093019 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | -0.9097796  |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 9508        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009426194 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 9610        |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | -2.016368   |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 474         |\n",
      "|    time_elapsed         | 9528        |\n",
      "|    total_timesteps      | 970752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020603035 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.047       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 9620        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -0.05798726 |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 9548        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018414728 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | -0.00743    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | 0.3522766   |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 9568        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009711022 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.0569      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.4        |\n",
      "|    n_updates            | 9640        |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    reward               | -4.2953267  |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 92.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 9588        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017271517 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | -0.48261386 |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 9608        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022059683 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.0306      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 9660        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | -0.34956157 |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 9628        |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017586708 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.00249     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.7        |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | -3.5292702  |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 9647        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008976566 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 9680        |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | -0.7261995  |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 63.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 9668        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017648436 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 9690        |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    reward               | 2.8294308   |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5433874.91\n",
      "total_reward: 4433874.91\n",
      "total_cost: 220408.53\n",
      "total_trades: 65633\n",
      "Sharpe: 0.917\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 9688        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019082738 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.0207      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | -0.58087593 |\n",
      "|    std                  | 3.86        |\n",
      "|    value_loss           | 72          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 9708        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012434934 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.0301      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | -9.6931095  |\n",
      "|    std                  | 3.86        |\n",
      "|    value_loss           | 75.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 484        |\n",
      "|    time_elapsed         | 9728       |\n",
      "|    total_timesteps      | 991232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01613064 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80        |\n",
      "|    explained_variance   | 0.254      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.1       |\n",
      "|    n_updates            | 9720       |\n",
      "|    policy_gradient_loss | -0.00833   |\n",
      "|    reward               | 1.7625332  |\n",
      "|    std                  | 3.86       |\n",
      "|    value_loss           | 52.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 9748        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017010694 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.0387      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.83        |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -0.4087706  |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 486        |\n",
      "|    time_elapsed         | 9768       |\n",
      "|    total_timesteps      | 995328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01097617 |\n",
      "|    clip_fraction        | 0.0959     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.1      |\n",
      "|    explained_variance   | 0.0559     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.8       |\n",
      "|    n_updates            | 9740       |\n",
      "|    policy_gradient_loss | -0.00989   |\n",
      "|    reward               | 1.3838408  |\n",
      "|    std                  | 3.87       |\n",
      "|    value_loss           | 54.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 9788        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012158706 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.00868     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -0.44709274 |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 9808        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015862986 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.07        |\n",
      "|    n_updates            | 9760        |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    reward               | 0.6314121   |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 489         |\n",
      "|    time_elapsed         | 9828        |\n",
      "|    total_timesteps      | 1001472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015699975 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 9770        |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | -0.6618529  |\n",
      "|    std                  | 3.89        |\n",
      "|    value_loss           | 65.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 490        |\n",
      "|    time_elapsed         | 9848       |\n",
      "|    total_timesteps      | 1003520    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01405185 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.2      |\n",
      "|    explained_variance   | 0.0218     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.6       |\n",
      "|    n_updates            | 9780       |\n",
      "|    policy_gradient_loss | -0.00982   |\n",
      "|    reward               | -1.1505661 |\n",
      "|    std                  | 3.89       |\n",
      "|    value_loss           | 97.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 9868        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018714728 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 4.3109083   |\n",
      "|    std                  | 3.9         |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 9888        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012785883 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 9800        |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | 1.3385333   |\n",
      "|    std                  | 3.9         |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 9908        |\n",
      "|    total_timesteps      | 1009664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011041041 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.0306      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.6        |\n",
      "|    n_updates            | 9810        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.021234432 |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 494         |\n",
      "|    time_elapsed         | 9927        |\n",
      "|    total_timesteps      | 1011712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010506033 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.0262      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.9        |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    reward               | -0.13257685 |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 495        |\n",
      "|    time_elapsed         | 9947       |\n",
      "|    total_timesteps      | 1013760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01972342 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.5      |\n",
      "|    explained_variance   | 0.2        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.97       |\n",
      "|    n_updates            | 9830       |\n",
      "|    policy_gradient_loss | -0.0095    |\n",
      "|    reward               | -2.4321773 |\n",
      "|    std                  | 3.92       |\n",
      "|    value_loss           | 14.7       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6102816.27\n",
      "total_reward: 5102816.27\n",
      "total_cost: 323758.85\n",
      "total_trades: 69324\n",
      "Sharpe: 0.905\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 9967        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016509755 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 0.056688026 |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 497         |\n",
      "|    time_elapsed         | 9987        |\n",
      "|    total_timesteps      | 1017856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011201782 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | -0.000208   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.2        |\n",
      "|    n_updates            | 9850        |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    reward               | 2.7317603   |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 498          |\n",
      "|    time_elapsed         | 10007        |\n",
      "|    total_timesteps      | 1019904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056413654 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.6        |\n",
      "|    explained_variance   | 0.13         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 9860         |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | 2.2223876    |\n",
      "|    std                  | 3.93         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 499          |\n",
      "|    time_elapsed         | 10027        |\n",
      "|    total_timesteps      | 1021952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064654117 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.6        |\n",
      "|    explained_variance   | 0.041        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.7         |\n",
      "|    n_updates            | 9870         |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | -0.54366213  |\n",
      "|    std                  | 3.94         |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 10046       |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013951609 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | 0.48606214  |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 501         |\n",
      "|    time_elapsed         | 10066       |\n",
      "|    total_timesteps      | 1026048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019319719 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.0161      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    reward               | -0.5494287  |\n",
      "|    std                  | 3.95        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 502        |\n",
      "|    time_elapsed         | 10098      |\n",
      "|    total_timesteps      | 1028096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02135476 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.6      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 77.7       |\n",
      "|    n_updates            | 9900       |\n",
      "|    policy_gradient_loss | -0.00852   |\n",
      "|    reward               | -0.3493963 |\n",
      "|    std                  | 3.95       |\n",
      "|    value_loss           | 106        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 503         |\n",
      "|    time_elapsed         | 10118       |\n",
      "|    total_timesteps      | 1030144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009149716 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 9910        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.94655836  |\n",
      "|    std                  | 3.95        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 10138       |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014002875 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.3        |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    reward               | -8.708652   |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 10157       |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015642364 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.0336      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | -3.7342067  |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 10177       |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008304743 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.1        |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -0.26520994 |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 10197       |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017898578 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.3        |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | 8.0877495   |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 508          |\n",
      "|    time_elapsed         | 10216        |\n",
      "|    total_timesteps      | 1040384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146973645 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -80.9        |\n",
      "|    explained_variance   | 0.0868       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.7         |\n",
      "|    n_updates            | 9960         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -0.24620853  |\n",
      "|    std                  | 3.98         |\n",
      "|    value_loss           | 93.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 10236       |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014348625 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.6        |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | 0.7324194   |\n",
      "|    std                  | 3.99        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5294628.10\n",
      "total_reward: 4294628.10\n",
      "total_cost: 257760.83\n",
      "total_trades: 65015\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 10256       |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015205624 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.0797      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.6        |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 0.14406642  |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 10276       |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01043359  |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | -0.75456834 |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 10296       |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024375893 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | -2.6407697  |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 513         |\n",
      "|    time_elapsed         | 10315       |\n",
      "|    total_timesteps      | 1050624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009148757 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.0694      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | -0.39696807 |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 10335       |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014250839 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.0856      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.8        |\n",
      "|    n_updates            | 10020       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | 7.2700624   |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 10355       |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017799348 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 10030       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -2.3645613  |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 516        |\n",
      "|    time_elapsed         | 10375      |\n",
      "|    total_timesteps      | 1056768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01374762 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.2      |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 56.8       |\n",
      "|    n_updates            | 10040      |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    reward               | -3.1555054 |\n",
      "|    std                  | 4.03       |\n",
      "|    value_loss           | 86.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 10395       |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008405978 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.2        |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | -5.931496   |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 10415       |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009184305 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.5        |\n",
      "|    n_updates            | 10060       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | 1.2888625   |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 10434       |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016015472 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 10070       |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | -0.4537921  |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 520        |\n",
      "|    time_elapsed         | 10455      |\n",
      "|    total_timesteps      | 1064960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01186582 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.3      |\n",
      "|    explained_variance   | 0.056      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 140        |\n",
      "|    n_updates            | 10080      |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    reward               | -1.2171061 |\n",
      "|    std                  | 4.03       |\n",
      "|    value_loss           | 203        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 521         |\n",
      "|    time_elapsed         | 10475       |\n",
      "|    total_timesteps      | 1067008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014640231 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.00909     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82          |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | -2.9713128  |\n",
      "|    std                  | 4.04        |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 10495       |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019512169 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 10100       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | 2.573168    |\n",
      "|    std                  | 4.04        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 10514       |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007821975 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.0438      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.9        |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    reward               | 2.0346146   |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 10534       |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011315064 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.1        |\n",
      "|    n_updates            | 10120       |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | -0.635214   |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 95          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4736903.44\n",
      "total_reward: 3736903.44\n",
      "total_cost: 231811.04\n",
      "total_trades: 63354\n",
      "Sharpe: 0.787\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 10553       |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010208232 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 10130       |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | 0.5331147   |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 66.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 10573       |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013990991 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 0.2709444   |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 10593       |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017029623 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.0837      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.6        |\n",
      "|    n_updates            | 10150       |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | -1.8534669  |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 99.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 528        |\n",
      "|    time_elapsed         | 10613      |\n",
      "|    total_timesteps      | 1081344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01479858 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.6      |\n",
      "|    explained_variance   | -0.00211   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.7       |\n",
      "|    n_updates            | 10160      |\n",
      "|    policy_gradient_loss | -0.00553   |\n",
      "|    reward               | 2.1493142  |\n",
      "|    std                  | 4.08       |\n",
      "|    value_loss           | 112        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 10633       |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018168334 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | -0.109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 10170       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | 0.73718476  |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 10652       |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009811495 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | -0.50024754 |\n",
      "|    std                  | 4.09        |\n",
      "|    value_loss           | 88          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 10672       |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012666326 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | 0.000398    |\n",
      "|    reward               | -1.8127024  |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 10692       |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015263401 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 10200       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | -0.7056917  |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 533         |\n",
      "|    time_elapsed         | 10711       |\n",
      "|    total_timesteps      | 1091584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021697469 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | -1.860164   |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 10731       |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015319972 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | -0.15821692 |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 10751       |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012470964 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.0903      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 10230       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | 0.8301473   |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 94.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 10771       |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015436318 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.0644      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.47        |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | 1.4728851   |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 10790       |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009961357 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 10250       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | -1.0869551  |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 82.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 538          |\n",
      "|    time_elapsed         | 10810        |\n",
      "|    total_timesteps      | 1101824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067187296 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.1        |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.9         |\n",
      "|    n_updates            | 10260        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | -2.1402001   |\n",
      "|    std                  | 4.16         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4403304.08\n",
      "total_reward: 3403304.08\n",
      "total_cost: 170077.04\n",
      "total_trades: 58789\n",
      "Sharpe: 0.777\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 539         |\n",
      "|    time_elapsed         | 10830       |\n",
      "|    total_timesteps      | 1103872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014493814 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.0616      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 10270       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | 1.1138277   |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 540         |\n",
      "|    time_elapsed         | 10850       |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010098683 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 10280       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | 0.19510016  |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 85.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 10869       |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009528374 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.0874      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.5        |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    reward               | -7.3433743  |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 542         |\n",
      "|    time_elapsed         | 10889       |\n",
      "|    total_timesteps      | 1110016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017939609 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 10300       |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | 2.9660902   |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 68.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 10909       |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017981147 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.64        |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 3.2371852   |\n",
      "|    std                  | 4.2         |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 10929       |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01636257  |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.9        |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.74804366 |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 545         |\n",
      "|    time_elapsed         | 10948       |\n",
      "|    total_timesteps      | 1116160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007675622 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.0517      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 10330       |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | -0.03426142 |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 546        |\n",
      "|    time_elapsed         | 10968      |\n",
      "|    total_timesteps      | 1118208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01752895 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.6      |\n",
      "|    explained_variance   | 0.0446     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.86       |\n",
      "|    n_updates            | 10340      |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    reward               | -0.576542  |\n",
      "|    std                  | 4.23       |\n",
      "|    value_loss           | 26.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 547         |\n",
      "|    time_elapsed         | 10988       |\n",
      "|    total_timesteps      | 1120256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013056891 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.091       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.8        |\n",
      "|    n_updates            | 10350       |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | 4.940728    |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 80.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 11008       |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009949818 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.0765      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | -2.4957469  |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 98.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 11028       |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010123929 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 10370       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | 0.75345826  |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 550          |\n",
      "|    time_elapsed         | 11048        |\n",
      "|    total_timesteps      | 1126400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115877725 |\n",
      "|    clip_fraction        | 0.0868       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.7        |\n",
      "|    explained_variance   | 0.265        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.8         |\n",
      "|    n_updates            | 10380        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    reward               | 1.6479627    |\n",
      "|    std                  | 4.25         |\n",
      "|    value_loss           | 96.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 551        |\n",
      "|    time_elapsed         | 11067      |\n",
      "|    total_timesteps      | 1128448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00804316 |\n",
      "|    clip_fraction        | 0.0716     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.8      |\n",
      "|    explained_variance   | 0.251      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 61.4       |\n",
      "|    n_updates            | 10390      |\n",
      "|    policy_gradient_loss | -0.00873   |\n",
      "|    reward               | 0.63529783 |\n",
      "|    std                  | 4.25       |\n",
      "|    value_loss           | 121        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 552         |\n",
      "|    time_elapsed         | 11087       |\n",
      "|    total_timesteps      | 1130496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012413517 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.7        |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    reward               | 2.363213    |\n",
      "|    std                  | 4.25        |\n",
      "|    value_loss           | 87.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6249223.98\n",
      "total_reward: 5249223.98\n",
      "total_cost: 223078.29\n",
      "total_trades: 61677\n",
      "Sharpe: 0.941\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 11107       |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014673949 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.0586      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.4         |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.000556   |\n",
      "|    reward               | -0.09957428 |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 11127       |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015316188 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.0326      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -0.17233744 |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 11147       |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012320358 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.0502      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.7        |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 1.6172101   |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 101        |\n",
      "|    iterations           | 556        |\n",
      "|    time_elapsed         | 11166      |\n",
      "|    total_timesteps      | 1138688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01436075 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83        |\n",
      "|    explained_variance   | 0.109      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 10440      |\n",
      "|    policy_gradient_loss | -0.0089    |\n",
      "|    reward               | -1.4462053 |\n",
      "|    std                  | 4.29       |\n",
      "|    value_loss           | 31.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 11186       |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013254724 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | -2.1649177  |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 84.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 11206       |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011973652 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.2        |\n",
      "|    n_updates            | 10460       |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | -0.6322092  |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 11225       |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008114782 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    reward               | 0.7760272   |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 91.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 11245       |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015580479 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.0812      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.46        |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 1.735412    |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 11265       |\n",
      "|    total_timesteps      | 1148928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009724779 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.7        |\n",
      "|    n_updates            | 10490       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.2097135  |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 562         |\n",
      "|    time_elapsed         | 11285       |\n",
      "|    total_timesteps      | 1150976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006122062 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36          |\n",
      "|    n_updates            | 10500       |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | 1.1450776   |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 11304       |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013051057 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.0811      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    reward               | -3.182572   |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 564         |\n",
      "|    time_elapsed         | 11324       |\n",
      "|    total_timesteps      | 1155072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008288654 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | 0.48489004  |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 11344       |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008522445 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.0756      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.6        |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | -47.14124   |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 566          |\n",
      "|    time_elapsed         | 11364        |\n",
      "|    total_timesteps      | 1159168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070005925 |\n",
      "|    clip_fraction        | 0.0584       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.5        |\n",
      "|    explained_variance   | 0.0354       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 170          |\n",
      "|    n_updates            | 10540        |\n",
      "|    policy_gradient_loss | 0.00076      |\n",
      "|    reward               | -0.49181673  |\n",
      "|    std                  | 4.36         |\n",
      "|    value_loss           | 229          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6331880.03\n",
      "total_reward: 5331880.03\n",
      "total_cost: 283024.52\n",
      "total_trades: 65866\n",
      "Sharpe: 0.877\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 567        |\n",
      "|    time_elapsed         | 11384      |\n",
      "|    total_timesteps      | 1161216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0109038  |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.5      |\n",
      "|    explained_variance   | 0.129      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.1       |\n",
      "|    n_updates            | 10550      |\n",
      "|    policy_gradient_loss | -0.00984   |\n",
      "|    reward               | -4.5291357 |\n",
      "|    std                  | 4.36       |\n",
      "|    value_loss           | 64.1       |\n",
      "----------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 102            |\n",
      "|    iterations           | 568            |\n",
      "|    time_elapsed         | 11403          |\n",
      "|    total_timesteps      | 1163264        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0137167405   |\n",
      "|    clip_fraction        | 0.129          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -83.5          |\n",
      "|    explained_variance   | 0.127          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 104            |\n",
      "|    n_updates            | 10560          |\n",
      "|    policy_gradient_loss | -0.00113       |\n",
      "|    reward               | -0.00046995413 |\n",
      "|    std                  | 4.36           |\n",
      "|    value_loss           | 192            |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 11422       |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015586147 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.0412      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 10570       |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | -5.8703847  |\n",
      "|    std                  | 4.37        |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 11442       |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016644347 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 10580       |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | -3.2283258  |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 11462       |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015037853 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.0357      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.6        |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | 1.1104536   |\n",
      "|    std                  | 4.39        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 572         |\n",
      "|    time_elapsed         | 11481       |\n",
      "|    total_timesteps      | 1171456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020999411 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.0154      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.1        |\n",
      "|    n_updates            | 10600       |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    reward               | -12.442865  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 11501       |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019934077 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.0767      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55          |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    reward               | 0.30765587  |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 11521       |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013199469 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.072       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.4        |\n",
      "|    n_updates            | 10620       |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | -0.6962762  |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 11541       |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011761807 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.0766      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 185         |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -0.24179691 |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 576          |\n",
      "|    time_elapsed         | 11561        |\n",
      "|    total_timesteps      | 1179648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069976696 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.9        |\n",
      "|    explained_variance   | 0.122        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 140          |\n",
      "|    n_updates            | 10640        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -6.9439735   |\n",
      "|    std                  | 4.43         |\n",
      "|    value_loss           | 282          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 11580       |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011981825 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 10650       |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 3.486779    |\n",
      "|    std                  | 4.44        |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 11600       |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009722851 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.059       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | 0.50583935  |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 579         |\n",
      "|    time_elapsed         | 11620       |\n",
      "|    total_timesteps      | 1185792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005224755 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 10670       |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | 1.5268519   |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 580          |\n",
      "|    time_elapsed         | 11639        |\n",
      "|    total_timesteps      | 1187840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148787955 |\n",
      "|    clip_fraction        | 0.0968       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.1        |\n",
      "|    explained_variance   | 0.0599       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.3         |\n",
      "|    n_updates            | 10680        |\n",
      "|    policy_gradient_loss | -0.00735     |\n",
      "|    reward               | -2.1151788   |\n",
      "|    std                  | 4.46         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6987564.35\n",
      "total_reward: 5987564.35\n",
      "total_cost: 295233.77\n",
      "total_trades: 65804\n",
      "Sharpe: 0.846\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 11659       |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010108608 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.0895      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.6        |\n",
      "|    n_updates            | 10690       |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    reward               | 0.6582946   |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 582          |\n",
      "|    time_elapsed         | 11679        |\n",
      "|    total_timesteps      | 1191936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005429658  |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.2        |\n",
      "|    explained_variance   | 0.0141       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 10700        |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    reward               | -0.053152837 |\n",
      "|    std                  | 4.47         |\n",
      "|    value_loss           | 280          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 11699       |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012813259 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.2       |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.4        |\n",
      "|    n_updates            | 10710       |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 0.5580629   |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 11719       |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014577294 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.0649      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.29        |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 1.0432184   |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 11738       |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008350323 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.0193      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.3        |\n",
      "|    n_updates            | 10730       |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | 0.8443966   |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 220         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 586         |\n",
      "|    time_elapsed         | 11760       |\n",
      "|    total_timesteps      | 1200128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012275072 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.0073      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 245         |\n",
      "|    n_updates            | 10740       |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    reward               | 2.4862561   |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 312         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 11780       |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015142279 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 10750       |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | 4.3621573   |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 59.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 11799       |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012883514 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.00763     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.305237    |\n",
      "|    std                  | 4.5         |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 11819       |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013084437 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.029       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95          |\n",
      "|    n_updates            | 10770       |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | -8.538148   |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 307         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 11839       |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017664824 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.04        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.3        |\n",
      "|    n_updates            | 10780       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 2.2151303   |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 591          |\n",
      "|    time_elapsed         | 11859        |\n",
      "|    total_timesteps      | 1210368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070264726 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.6        |\n",
      "|    explained_variance   | 0.017        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67           |\n",
      "|    n_updates            | 10790        |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    reward               | 0.87819165   |\n",
      "|    std                  | 4.53         |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 11879       |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013261425 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.0331      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.7        |\n",
      "|    n_updates            | 10800       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 0.1356609   |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 11899       |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008261856 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.0405      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | -1.1082793  |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 309         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 11919       |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014483709 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.0911      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 10820       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -4.1919985  |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5914930.62\n",
      "total_reward: 4914930.62\n",
      "total_cost: 317333.96\n",
      "total_trades: 66855\n",
      "Sharpe: 0.858\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 11939       |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015789252 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.0534      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -3.2420485  |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 596         |\n",
      "|    time_elapsed         | 11958       |\n",
      "|    total_timesteps      | 1220608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013478264 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.0288      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.7        |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -2.2655606  |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 11978       |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018497154 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 10850       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    reward               | 1.6003183   |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 11998       |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010484726 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.9        |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    reward               | 0.99643385  |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 599         |\n",
      "|    time_elapsed         | 12017       |\n",
      "|    total_timesteps      | 1226752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009158108 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 10870       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | 1.9391212   |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 12037       |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005196379 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62          |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    reward               | 3.3404684   |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 601         |\n",
      "|    time_elapsed         | 12057       |\n",
      "|    total_timesteps      | 1230848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015105425 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 10890       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | -1.6637675  |\n",
      "|    std                  | 4.59        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 12077       |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010926481 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    reward               | 1.5057799   |\n",
      "|    std                  | 4.59        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 603          |\n",
      "|    time_elapsed         | 12096        |\n",
      "|    total_timesteps      | 1234944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056071845 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85          |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 10910        |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    reward               | -2.576353    |\n",
      "|    std                  | 4.59         |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 604        |\n",
      "|    time_elapsed         | 12117      |\n",
      "|    total_timesteps      | 1236992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01684715 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.1      |\n",
      "|    explained_variance   | 0.278      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.1       |\n",
      "|    n_updates            | 10920      |\n",
      "|    policy_gradient_loss | -0.00626   |\n",
      "|    reward               | 10.536878  |\n",
      "|    std                  | 4.6        |\n",
      "|    value_loss           | 47.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 12136       |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009737164 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.0531      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 10930       |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | 1.6576375   |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 606          |\n",
      "|    time_elapsed         | 12157        |\n",
      "|    total_timesteps      | 1241088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073234118 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.1        |\n",
      "|    explained_variance   | 0.179        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 10940        |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    reward               | -1.3289217   |\n",
      "|    std                  | 4.61         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 12177       |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011847681 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 10950       |\n",
      "|    policy_gradient_loss | -0.00154    |\n",
      "|    reward               | 0.6267117   |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 12197       |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012080289 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.22        |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 1.0474087   |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5326982.56\n",
      "total_reward: 4326982.56\n",
      "total_cost: 242569.85\n",
      "total_trades: 62988\n",
      "Sharpe: 0.855\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 609          |\n",
      "|    time_elapsed         | 12217        |\n",
      "|    total_timesteps      | 1247232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075677773 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.2        |\n",
      "|    explained_variance   | 0.14         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.4         |\n",
      "|    n_updates            | 10970        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -1.0650818   |\n",
      "|    std                  | 4.63         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 12238        |\n",
      "|    total_timesteps      | 1249280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134899225 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.2        |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.6         |\n",
      "|    n_updates            | 10980        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    reward               | 6.082396     |\n",
      "|    std                  | 4.63         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 611         |\n",
      "|    time_elapsed         | 12258       |\n",
      "|    total_timesteps      | 1251328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016116692 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.0802      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 10990       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -0.95280975 |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 12278       |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015839895 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.0215      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 4.494892    |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 613         |\n",
      "|    time_elapsed         | 12298       |\n",
      "|    total_timesteps      | 1255424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015923295 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.0229      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | 8.52843     |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 12318       |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010359956 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.0126      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    reward               | 0.60731447  |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 12337       |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010199288 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | 2.268039    |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 616          |\n",
      "|    time_elapsed         | 12359        |\n",
      "|    total_timesteps      | 1261568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055183033 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.6        |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 158          |\n",
      "|    n_updates            | 11040        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 1.2109234    |\n",
      "|    std                  | 4.69         |\n",
      "|    value_loss           | 237          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 12380       |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009035708 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 11050       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | 4.5463505   |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 305         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 618          |\n",
      "|    time_elapsed         | 12401        |\n",
      "|    total_timesteps      | 1265664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093977675 |\n",
      "|    clip_fraction        | 0.0861       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.7        |\n",
      "|    explained_variance   | 0.115        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 11060        |\n",
      "|    policy_gradient_loss | -0.00793     |\n",
      "|    reward               | -3.4739263   |\n",
      "|    std                  | 4.7          |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 12420       |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00800366  |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.0828      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 11070       |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | -0.44205135 |\n",
      "|    std                  | 4.71        |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 620          |\n",
      "|    time_elapsed         | 12439        |\n",
      "|    total_timesteps      | 1269760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046051536 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.7        |\n",
      "|    explained_variance   | 0.119        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 143          |\n",
      "|    n_updates            | 11080        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -7.7630825   |\n",
      "|    std                  | 4.71         |\n",
      "|    value_loss           | 297          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 621         |\n",
      "|    time_elapsed         | 12458       |\n",
      "|    total_timesteps      | 1271808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014531729 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | -0.0429     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.9        |\n",
      "|    n_updates            | 11090       |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    reward               | 0.46963987  |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 12477       |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011394665 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.0923      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.2        |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    reward               | 0.431884    |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6442545.95\n",
      "total_reward: 5442545.95\n",
      "total_cost: 274670.22\n",
      "total_trades: 63093\n",
      "Sharpe: 0.824\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 12496       |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011044929 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.9       |\n",
      "|    explained_variance   | 0.0542      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 11110       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.5644625   |\n",
      "|    std                  | 4.74        |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 12515       |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007777565 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.9       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 11120       |\n",
      "|    policy_gradient_loss | -0.00719    |\n",
      "|    reward               | -1.1214372  |\n",
      "|    std                  | 4.75        |\n",
      "|    value_loss           | 269         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 625         |\n",
      "|    time_elapsed         | 12534       |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016282758 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.0058239  |\n",
      "|    std                  | 4.75        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 12554       |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010790038 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.0414      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.07928297 |\n",
      "|    std                  | 4.75        |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 12574       |\n",
      "|    total_timesteps      | 1284096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010331526 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 11150       |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | 5.0007625   |\n",
      "|    std                  | 4.76        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 12595       |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009634554 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.0542      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 11160       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | 4.353285    |\n",
      "|    std                  | 4.77        |\n",
      "|    value_loss           | 67.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 12616       |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011992902 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99          |\n",
      "|    n_updates            | 11170       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | -1.0259286  |\n",
      "|    std                  | 4.77        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 630         |\n",
      "|    time_elapsed         | 12636       |\n",
      "|    total_timesteps      | 1290240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008373113 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.2        |\n",
      "|    n_updates            | 11180       |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    reward               | 13.55279    |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 12656       |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012949778 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.08466872  |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 632          |\n",
      "|    time_elapsed         | 12677        |\n",
      "|    total_timesteps      | 1294336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132906735 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.2        |\n",
      "|    explained_variance   | 0.288        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.67         |\n",
      "|    n_updates            | 11200        |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    reward               | 0.24396256   |\n",
      "|    std                  | 4.79         |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 633          |\n",
      "|    time_elapsed         | 12697        |\n",
      "|    total_timesteps      | 1296384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105179865 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.3        |\n",
      "|    explained_variance   | 0.171        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.4         |\n",
      "|    n_updates            | 11210        |\n",
      "|    policy_gradient_loss | -0.00993     |\n",
      "|    reward               | -0.0275351   |\n",
      "|    std                  | 4.8          |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 634          |\n",
      "|    time_elapsed         | 12716        |\n",
      "|    total_timesteps      | 1298432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058981106 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.3        |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.5         |\n",
      "|    n_updates            | 11220        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | -1.8253629   |\n",
      "|    std                  | 4.8          |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 635        |\n",
      "|    time_elapsed         | 12735      |\n",
      "|    total_timesteps      | 1300480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02280033 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.4      |\n",
      "|    explained_variance   | 0.0463     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.2       |\n",
      "|    n_updates            | 11230      |\n",
      "|    policy_gradient_loss | -0.00748   |\n",
      "|    reward               | 2.2097626  |\n",
      "|    std                  | 4.82       |\n",
      "|    value_loss           | 34.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 12754       |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008562361 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 11240       |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    reward               | 0.45311993  |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 637          |\n",
      "|    time_elapsed         | 12773        |\n",
      "|    total_timesteps      | 1304576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051071253 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.5        |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 11250        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | -1.782662    |\n",
      "|    std                  | 4.83         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5293808.59\n",
      "total_reward: 4293808.59\n",
      "total_cost: 257179.28\n",
      "total_trades: 62631\n",
      "Sharpe: 0.884\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 12793       |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021525707 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 11260       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    reward               | 3.7304194   |\n",
      "|    std                  | 4.84        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 12812       |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011062937 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    reward               | 0.0161496   |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 96.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 640         |\n",
      "|    time_elapsed         | 12832       |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004709219 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 11280       |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    reward               | 1.2360996   |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 12851       |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017878775 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | -0.0253     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 11290       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.1771048  |\n",
      "|    std                  | 4.88        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 12871       |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012651973 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.06        |\n",
      "|    n_updates            | 11300       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | 3.7221603   |\n",
      "|    std                  | 4.9         |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 12890       |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010577638 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | -0.00216    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 11310       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.38323084  |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 12909       |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011025595 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.0392      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.2        |\n",
      "|    n_updates            | 11320       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | 0.10003412  |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 12928       |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014254916 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 11330       |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    reward               | -3.2538533  |\n",
      "|    std                  | 4.93        |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 12947       |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009543546 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.0637      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 11340       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -0.43574125 |\n",
      "|    std                  | 4.95        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 12966       |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008011573 |\n",
      "|    clip_fraction        | 0.0519      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.0674      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.7        |\n",
      "|    n_updates            | 11350       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | 0.90614367  |\n",
      "|    std                  | 4.96        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 648          |\n",
      "|    time_elapsed         | 12985        |\n",
      "|    total_timesteps      | 1327104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076813498 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.3        |\n",
      "|    explained_variance   | 0.0325       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89.8         |\n",
      "|    n_updates            | 11360        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | 3.7273464    |\n",
      "|    std                  | 4.97         |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 13004       |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011522677 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 11370       |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    reward               | -2.5583458  |\n",
      "|    std                  | 4.99        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 650         |\n",
      "|    time_elapsed         | 13023       |\n",
      "|    total_timesteps      | 1331200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013067574 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 11380       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 1.0100396   |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 13042       |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008414406 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | -0.0136     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.5        |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    reward               | 6.355318    |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6208701.09\n",
      "total_reward: 5208701.09\n",
      "total_cost: 265026.31\n",
      "total_trades: 63202\n",
      "Sharpe: 0.836\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 13060       |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012543971 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 11400       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    reward               | 2.4436386   |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 13080       |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010339626 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 2.8462043   |\n",
      "|    std                  | 5.03        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 13099       |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014077311 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.0157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.1        |\n",
      "|    n_updates            | 11420       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 22.236712   |\n",
      "|    std                  | 5.04        |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 13118       |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010689909 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.00254     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87          |\n",
      "|    n_updates            | 11430       |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    reward               | -1.6691171  |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 13137       |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012175423 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 11440       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 1.6123732   |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 13156       |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010832077 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.0807      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.5        |\n",
      "|    n_updates            | 11450       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.28848618  |\n",
      "|    std                  | 5.07        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 13175       |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010107536 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73          |\n",
      "|    n_updates            | 11460       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | -2.722003   |\n",
      "|    std                  | 5.07        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 13194       |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012240946 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 11470       |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | -0.40353006 |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 660          |\n",
      "|    time_elapsed         | 13213        |\n",
      "|    total_timesteps      | 1351680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072314255 |\n",
      "|    clip_fraction        | 0.0526       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.9        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 11480        |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | -0.98198223  |\n",
      "|    std                  | 5.08         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 13232       |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010622787 |\n",
      "|    clip_fraction        | 0.0749      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.0378      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.5        |\n",
      "|    n_updates            | 11490       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 2.342554    |\n",
      "|    std                  | 5.09        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 13251       |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014948564 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 11500       |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | 0.3940866   |\n",
      "|    std                  | 5.09        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 663          |\n",
      "|    time_elapsed         | 13270        |\n",
      "|    total_timesteps      | 1357824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109216515 |\n",
      "|    clip_fraction        | 0.0747       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88          |\n",
      "|    explained_variance   | 0.226        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 11510        |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    reward               | -0.39604345  |\n",
      "|    std                  | 5.1          |\n",
      "|    value_loss           | 63.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 13289       |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004916315 |\n",
      "|    clip_fraction        | 0.0278      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.2        |\n",
      "|    n_updates            | 11520       |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 0.5189713   |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 665         |\n",
      "|    time_elapsed         | 13308       |\n",
      "|    total_timesteps      | 1361920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015451085 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 11530       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.488025    |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 86.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5451761.43\n",
      "total_reward: 4451761.43\n",
      "total_cost: 288946.21\n",
      "total_trades: 64416\n",
      "Sharpe: 0.824\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 13327       |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010828417 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.57        |\n",
      "|    n_updates            | 11540       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    reward               | 0.87464845  |\n",
      "|    std                  | 5.12        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 667          |\n",
      "|    time_elapsed         | 13346        |\n",
      "|    total_timesteps      | 1366016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059661176 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.2        |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.2         |\n",
      "|    n_updates            | 11550        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | 0.40662572   |\n",
      "|    std                  | 5.13         |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 13365       |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004340183 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 11560       |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    reward               | 4.10113     |\n",
      "|    std                  | 5.13        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 669         |\n",
      "|    time_elapsed         | 13384       |\n",
      "|    total_timesteps      | 1370112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013146738 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    reward               | 0.9386115   |\n",
      "|    std                  | 5.14        |\n",
      "|    value_loss           | 55.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 13403       |\n",
      "|    total_timesteps      | 1372160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009002811 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 11580       |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    reward               | 0.5171204   |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 13422       |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007537756 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 11590       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | -0.42560312 |\n",
      "|    std                  | 5.16        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 672          |\n",
      "|    time_elapsed         | 13441        |\n",
      "|    total_timesteps      | 1376256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066110264 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.4        |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.7         |\n",
      "|    n_updates            | 11600        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    reward               | -0.2875935   |\n",
      "|    std                  | 5.17         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 13460       |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022676792 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.35        |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -1.2273126  |\n",
      "|    std                  | 5.18        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 674          |\n",
      "|    time_elapsed         | 13479        |\n",
      "|    total_timesteps      | 1380352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041933074 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.5        |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.4         |\n",
      "|    n_updates            | 11620        |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    reward               | 0.9264648    |\n",
      "|    std                  | 5.19         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 13498       |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008107461 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 11630       |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 2.782559    |\n",
      "|    std                  | 5.19        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 13517       |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009892115 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 11640       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.9771574   |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 677         |\n",
      "|    time_elapsed         | 13536       |\n",
      "|    total_timesteps      | 1386496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007991392 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 11650       |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -1.2161939  |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 13555       |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007249944 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.3        |\n",
      "|    n_updates            | 11660       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | -3.0742085  |\n",
      "|    std                  | 5.21        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 13574       |\n",
      "|    total_timesteps      | 1390592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010150938 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.5        |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 3.6756732   |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6650327.20\n",
      "total_reward: 5650327.20\n",
      "total_cost: 288585.05\n",
      "total_trades: 64048\n",
      "Sharpe: 0.840\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 13593       |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010321345 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | -1.9669855  |\n",
      "|    std                  | 5.23        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 13613       |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009859882 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.9811983   |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 682         |\n",
      "|    time_elapsed         | 13632       |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008584894 |\n",
      "|    clip_fraction        | 0.0309      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | 4.2219043   |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 13651       |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011545779 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | -0.0554     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 11710       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | 6.119406    |\n",
      "|    std                  | 5.27        |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 684          |\n",
      "|    time_elapsed         | 13670        |\n",
      "|    total_timesteps      | 1400832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076050144 |\n",
      "|    clip_fraction        | 0.0562       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.9        |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.7         |\n",
      "|    n_updates            | 11720        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    reward               | 0.8810004    |\n",
      "|    std                  | 5.27         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 13689       |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007076109 |\n",
      "|    clip_fraction        | 0.0299      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.4        |\n",
      "|    n_updates            | 11730       |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | -1.514487   |\n",
      "|    std                  | 5.28        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 102       |\n",
      "|    iterations           | 686       |\n",
      "|    time_elapsed         | 13708     |\n",
      "|    total_timesteps      | 1404928   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0097881 |\n",
      "|    clip_fraction        | 0.0782    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -89       |\n",
      "|    explained_variance   | -0.00708  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 42.3      |\n",
      "|    n_updates            | 11740     |\n",
      "|    policy_gradient_loss | -0.00624  |\n",
      "|    reward               | 4.0698824 |\n",
      "|    std                  | 5.29      |\n",
      "|    value_loss           | 115       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 13727       |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008554594 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | -0.11985517 |\n",
      "|    std                  | 5.29        |\n",
      "|    value_loss           | 96.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 688          |\n",
      "|    time_elapsed         | 13746        |\n",
      "|    total_timesteps      | 1409024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076293447 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89          |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50           |\n",
      "|    n_updates            | 11760        |\n",
      "|    policy_gradient_loss | -0.00781     |\n",
      "|    reward               | 1.7401406    |\n",
      "|    std                  | 5.3          |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 689         |\n",
      "|    time_elapsed         | 13765       |\n",
      "|    total_timesteps      | 1411072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009556484 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.0389      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 11770       |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    reward               | 1.8202296   |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 13784       |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013496416 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 11780       |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    reward               | -4.5452933  |\n",
      "|    std                  | 5.31        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 13803       |\n",
      "|    total_timesteps      | 1415168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007239634 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.5        |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | -0.6712987  |\n",
      "|    std                  | 5.32        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 13822       |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010095494 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 11800       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 2.223192    |\n",
      "|    std                  | 5.33        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 693        |\n",
      "|    time_elapsed         | 13841      |\n",
      "|    total_timesteps      | 1419264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01546585 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.2      |\n",
      "|    explained_variance   | -0.0171    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 11810      |\n",
      "|    policy_gradient_loss | -0.00827   |\n",
      "|    reward               | 0.22464037 |\n",
      "|    std                  | 5.34       |\n",
      "|    value_loss           | 47.3       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5944021.68\n",
      "total_reward: 4944021.68\n",
      "total_cost: 290103.39\n",
      "total_trades: 63612\n",
      "Sharpe: 0.859\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 694         |\n",
      "|    time_elapsed         | 13860       |\n",
      "|    total_timesteps      | 1421312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009251482 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -0.4305817  |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 98.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 695          |\n",
      "|    time_elapsed         | 13879        |\n",
      "|    total_timesteps      | 1423360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009639615  |\n",
      "|    clip_fraction        | 0.053        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.4        |\n",
      "|    explained_variance   | 0.354        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 182          |\n",
      "|    n_updates            | 11830        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    reward               | -0.106437884 |\n",
      "|    std                  | 5.36         |\n",
      "|    value_loss           | 225          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 13898       |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010037729 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.1        |\n",
      "|    n_updates            | 11840       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | -0.74323076 |\n",
      "|    std                  | 5.37        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 13917       |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011892686 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.0481      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.25        |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -0.9683187  |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 698          |\n",
      "|    time_elapsed         | 13936        |\n",
      "|    total_timesteps      | 1429504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051659895 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.5        |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.4         |\n",
      "|    n_updates            | 11860        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | 0.9486116    |\n",
      "|    std                  | 5.38         |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 699          |\n",
      "|    time_elapsed         | 13955        |\n",
      "|    total_timesteps      | 1431552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068040513 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.5        |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61           |\n",
      "|    n_updates            | 11870        |\n",
      "|    policy_gradient_loss | -0.00703     |\n",
      "|    reward               | 0.057897955  |\n",
      "|    std                  | 5.38         |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 13974       |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010572569 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | -0.242      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 11880       |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | -0.73269665 |\n",
      "|    std                  | 5.39        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 701          |\n",
      "|    time_elapsed         | 13994        |\n",
      "|    total_timesteps      | 1435648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075967917 |\n",
      "|    clip_fraction        | 0.0543       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.6        |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 11890        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    reward               | -4.6460943   |\n",
      "|    std                  | 5.4          |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 14013       |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008649537 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.1        |\n",
      "|    n_updates            | 11900       |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    reward               | 11.506059   |\n",
      "|    std                  | 5.4         |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 14032       |\n",
      "|    total_timesteps      | 1439744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012216972 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.2        |\n",
      "|    n_updates            | 11910       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    reward               | 1.5757155   |\n",
      "|    std                  | 5.41        |\n",
      "|    value_loss           | 81.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 704         |\n",
      "|    time_elapsed         | 14051       |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011346316 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 11920       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -2.502521   |\n",
      "|    std                  | 5.41        |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 705          |\n",
      "|    time_elapsed         | 14070        |\n",
      "|    total_timesteps      | 1443840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056084646 |\n",
      "|    clip_fraction        | 0.0316       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.7        |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.1         |\n",
      "|    n_updates            | 11930        |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    reward               | 0.42576322   |\n",
      "|    std                  | 5.41         |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 706          |\n",
      "|    time_elapsed         | 14090        |\n",
      "|    total_timesteps      | 1445888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032523228 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.7        |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.7         |\n",
      "|    n_updates            | 11940        |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    reward               | 0.5126477    |\n",
      "|    std                  | 5.41         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 14109       |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016886188 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | -0.0227     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 11950       |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | 0.28997585  |\n",
      "|    std                  | 5.42        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5769757.58\n",
      "total_reward: 4769757.58\n",
      "total_cost: 289553.72\n",
      "total_trades: 62341\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 14128       |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007043325 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.6        |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | 0.51906383  |\n",
      "|    std                  | 5.42        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 14148       |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009008838 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.8        |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 3.3060174   |\n",
      "|    std                  | 5.43        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 14166       |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012018437 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 11980       |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    reward               | 1.3155689   |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 14186       |\n",
      "|    total_timesteps      | 1456128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008086556 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.5        |\n",
      "|    n_updates            | 11990       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | -0.5231509  |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 14205        |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026465915 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.8        |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.3         |\n",
      "|    n_updates            | 12000        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | -0.23692271  |\n",
      "|    std                  | 5.44         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 713         |\n",
      "|    time_elapsed         | 14224       |\n",
      "|    total_timesteps      | 1460224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009114686 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.1        |\n",
      "|    n_updates            | 12010       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -2.0379188  |\n",
      "|    std                  | 5.45        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 14243       |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012868839 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -2.1995337  |\n",
      "|    std                  | 5.47        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 14262        |\n",
      "|    total_timesteps      | 1464320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091783665 |\n",
      "|    clip_fraction        | 0.0883       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90          |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 12030        |\n",
      "|    policy_gradient_loss | -0.00899     |\n",
      "|    reward               | 0.769305     |\n",
      "|    std                  | 5.49         |\n",
      "|    value_loss           | 94.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 14282       |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008387486 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.4        |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | -8.6847315  |\n",
      "|    std                  | 5.5         |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 14301       |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011338247 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 2.2630847   |\n",
      "|    std                  | 5.5         |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 718         |\n",
      "|    time_elapsed         | 14320       |\n",
      "|    total_timesteps      | 1470464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006418797 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.6        |\n",
      "|    n_updates            | 12060       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | -1.5778565  |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 14339       |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007707653 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 12070       |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 2.2056847   |\n",
      "|    std                  | 5.52        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 14358       |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014394212 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.8        |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.39161032 |\n",
      "|    std                  | 5.52        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 721        |\n",
      "|    time_elapsed         | 14377      |\n",
      "|    total_timesteps      | 1476608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01719572 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.3      |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 12090      |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    reward               | 1.9936666  |\n",
      "|    std                  | 5.55       |\n",
      "|    value_loss           | 30.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5678692.57\n",
      "total_reward: 4678692.57\n",
      "total_cost: 294515.99\n",
      "total_trades: 62936\n",
      "Sharpe: 0.828\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 14396       |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009694298 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    reward               | -2.9329605  |\n",
      "|    std                  | 5.55        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 723         |\n",
      "|    time_elapsed         | 14415       |\n",
      "|    total_timesteps      | 1480704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009820612 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.8        |\n",
      "|    n_updates            | 12110       |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    reward               | -0.12840976 |\n",
      "|    std                  | 5.55        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 14435       |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014788187 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 12120       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 2.668796    |\n",
      "|    std                  | 5.57        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 14454       |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013886143 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 12130       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 1.1364871   |\n",
      "|    std                  | 5.59        |\n",
      "|    value_loss           | 96.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 726         |\n",
      "|    time_elapsed         | 14473       |\n",
      "|    total_timesteps      | 1486848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012887957 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72          |\n",
      "|    n_updates            | 12140       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | 1.7613344   |\n",
      "|    std                  | 5.59        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 727          |\n",
      "|    time_elapsed         | 14492        |\n",
      "|    total_timesteps      | 1488896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120702125 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.6        |\n",
      "|    explained_variance   | -0.0517      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.2         |\n",
      "|    n_updates            | 12150        |\n",
      "|    policy_gradient_loss | -0.00683     |\n",
      "|    reward               | -0.35300964  |\n",
      "|    std                  | 5.59         |\n",
      "|    value_loss           | 58.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 14512       |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014173937 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | 0.48407042  |\n",
      "|    std                  | 5.61        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 14531       |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010795062 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | -1.6678067  |\n",
      "|    std                  | 5.61        |\n",
      "|    value_loss           | 71          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 14551       |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009273351 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.7        |\n",
      "|    n_updates            | 12180       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | -0.9817981  |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 14570       |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018535508 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 12190       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.5216855  |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 732          |\n",
      "|    time_elapsed         | 14589        |\n",
      "|    total_timesteps      | 1499136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110592805 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.9        |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 12200        |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    reward               | 0.14430588   |\n",
      "|    std                  | 5.65         |\n",
      "|    value_loss           | 74.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 733         |\n",
      "|    time_elapsed         | 14608       |\n",
      "|    total_timesteps      | 1501184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014036825 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.00794     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.6        |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | -4.226465   |\n",
      "|    std                  | 5.66        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 14627       |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014238796 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 12220       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    reward               | -5.064831   |\n",
      "|    std                  | 5.67        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 14646       |\n",
      "|    total_timesteps      | 1505280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011157867 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 12230       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 0.14624047  |\n",
      "|    std                  | 5.69        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4304811.93\n",
      "total_reward: 3304811.93\n",
      "total_cost: 277144.30\n",
      "total_trades: 63203\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 14666       |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010491969 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 12240       |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | -0.14137149 |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 737         |\n",
      "|    time_elapsed         | 14685       |\n",
      "|    total_timesteps      | 1509376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00822608  |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 12250       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    reward               | -0.52990377 |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 72.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 14704       |\n",
      "|    total_timesteps      | 1511424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015735906 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 12260       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | -1.9527687  |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 14725       |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008250235 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 12270       |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    reward               | -0.56746393 |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 62.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 14744        |\n",
      "|    total_timesteps      | 1515520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072619785 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.2        |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 12280        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | 1.0666193    |\n",
      "|    std                  | 5.71         |\n",
      "|    value_loss           | 67.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 14763       |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010878174 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 12290       |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    reward               | -2.4857733  |\n",
      "|    std                  | 5.72        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 742        |\n",
      "|    time_elapsed         | 14782      |\n",
      "|    total_timesteps      | 1519616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01567857 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.3      |\n",
      "|    explained_variance   | 0.379      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.2       |\n",
      "|    n_updates            | 12300      |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    reward               | 1.2550396  |\n",
      "|    std                  | 5.73       |\n",
      "|    value_loss           | 48         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 743         |\n",
      "|    time_elapsed         | 14801       |\n",
      "|    total_timesteps      | 1521664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011997972 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 12310       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -4.4389615  |\n",
      "|    std                  | 5.73        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 14820       |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007201553 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.6        |\n",
      "|    n_updates            | 12320       |\n",
      "|    policy_gradient_loss | 0.000319    |\n",
      "|    reward               | 0.16228725  |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 14839       |\n",
      "|    total_timesteps      | 1525760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013331865 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.0744      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.15        |\n",
      "|    n_updates            | 12330       |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    reward               | 0.030551953 |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 14858       |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007068097 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | -0.3399774  |\n",
      "|    std                  | 5.75        |\n",
      "|    value_loss           | 66.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 14877       |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016252447 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.0595      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 12350       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 0.5452603   |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 99.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 748         |\n",
      "|    time_elapsed         | 14896       |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016512964 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 12360       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | -0.2858437  |\n",
      "|    std                  | 5.77        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 749          |\n",
      "|    time_elapsed         | 14915        |\n",
      "|    total_timesteps      | 1533952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060098357 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.5        |\n",
      "|    explained_variance   | 0.348        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 12370        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    reward               | -4.709803    |\n",
      "|    std                  | 5.77         |\n",
      "|    value_loss           | 70.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 14934       |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005880978 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 12380       |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    reward               | -1.0114895  |\n",
      "|    std                  | 5.77        |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3676003.64\n",
      "total_reward: 2676003.64\n",
      "total_cost: 330936.55\n",
      "total_trades: 65284\n",
      "Sharpe: 0.718\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 14952       |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008187104 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.0902      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 12390       |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | 0.13154146  |\n",
      "|    std                  | 5.77        |\n",
      "|    value_loss           | 71.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 752         |\n",
      "|    time_elapsed         | 14972       |\n",
      "|    total_timesteps      | 1540096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012675026 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 12400       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 0.5403645   |\n",
      "|    std                  | 5.78        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 14991       |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014255198 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 12410       |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | 0.5183887   |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 71.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 15011       |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008721253 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 12420       |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    reward               | 1.3273101   |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 755        |\n",
      "|    time_elapsed         | 15031      |\n",
      "|    total_timesteps      | 1546240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01088956 |\n",
      "|    clip_fraction        | 0.0809     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.6      |\n",
      "|    explained_variance   | 0.102      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.7       |\n",
      "|    n_updates            | 12430      |\n",
      "|    policy_gradient_loss | -0.00734   |\n",
      "|    reward               | 2.007439   |\n",
      "|    std                  | 5.79       |\n",
      "|    value_loss           | 23.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 756          |\n",
      "|    time_elapsed         | 15051        |\n",
      "|    total_timesteps      | 1548288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009379173  |\n",
      "|    clip_fraction        | 0.0792       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.6        |\n",
      "|    explained_variance   | 0.119        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.1         |\n",
      "|    n_updates            | 12440        |\n",
      "|    policy_gradient_loss | -0.00935     |\n",
      "|    reward               | -0.099742375 |\n",
      "|    std                  | 5.8          |\n",
      "|    value_loss           | 94.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 757         |\n",
      "|    time_elapsed         | 15070       |\n",
      "|    total_timesteps      | 1550336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012058416 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 12450       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 1.3091985   |\n",
      "|    std                  | 5.8         |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 758        |\n",
      "|    time_elapsed         | 15091      |\n",
      "|    total_timesteps      | 1552384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01037042 |\n",
      "|    clip_fraction        | 0.0815     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.7      |\n",
      "|    explained_variance   | 0.159      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.7       |\n",
      "|    n_updates            | 12460      |\n",
      "|    policy_gradient_loss | -0.00922   |\n",
      "|    reward               | -1.4830737 |\n",
      "|    std                  | 5.81       |\n",
      "|    value_loss           | 43.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 15112       |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009213055 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 12470       |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    reward               | 0.83616143  |\n",
      "|    std                  | 5.82        |\n",
      "|    value_loss           | 51.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 15132       |\n",
      "|    total_timesteps      | 1556480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015040985 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 12480       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.021120815 |\n",
      "|    std                  | 5.83        |\n",
      "|    value_loss           | 67.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 761          |\n",
      "|    time_elapsed         | 15152        |\n",
      "|    total_timesteps      | 1558528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012108583  |\n",
      "|    clip_fraction        | 0.0922       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.9        |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 12490        |\n",
      "|    policy_gradient_loss | -0.00864     |\n",
      "|    reward               | -0.056008562 |\n",
      "|    std                  | 5.85         |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 762         |\n",
      "|    time_elapsed         | 15172       |\n",
      "|    total_timesteps      | 1560576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018204533 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.0513      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 12500       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 4.664442    |\n",
      "|    std                  | 5.88        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 763        |\n",
      "|    time_elapsed         | 15192      |\n",
      "|    total_timesteps      | 1562624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01405636 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.1      |\n",
      "|    explained_variance   | 0.474      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.7       |\n",
      "|    n_updates            | 12510      |\n",
      "|    policy_gradient_loss | -0.00852   |\n",
      "|    reward               | -3.7048063 |\n",
      "|    std                  | 5.88       |\n",
      "|    value_loss           | 50.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 15212       |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010895437 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 12520       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | -0.56391144 |\n",
      "|    std                  | 5.89        |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3969227.52\n",
      "total_reward: 2969227.52\n",
      "total_cost: 326718.02\n",
      "total_trades: 65954\n",
      "Sharpe: 0.759\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 765         |\n",
      "|    time_elapsed         | 15231       |\n",
      "|    total_timesteps      | 1566720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011664188 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 12530       |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    reward               | 0.10382243  |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 15250       |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007865232 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 0.14444777  |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 767         |\n",
      "|    time_elapsed         | 15269       |\n",
      "|    total_timesteps      | 1570816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010485577 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 12550       |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    reward               | 21.900206   |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 15288       |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015017316 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 12560       |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    reward               | -1.632717   |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 15307       |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015235048 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 12570       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 1.8231595   |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 770         |\n",
      "|    time_elapsed         | 15326       |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009937711 |\n",
      "|    clip_fraction        | 0.0881      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -0.39016715 |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 69.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 15344       |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010816464 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 12590       |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | -6.1280413  |\n",
      "|    std                  | 5.93        |\n",
      "|    value_loss           | 91.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 15363       |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011401206 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.67        |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | 0.2551136   |\n",
      "|    std                  | 5.94        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 15382       |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008903155 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 12610       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | -0.22667527 |\n",
      "|    std                  | 5.95        |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 774         |\n",
      "|    time_elapsed         | 15401       |\n",
      "|    total_timesteps      | 1585152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008648165 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 12620       |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | -2.8697934  |\n",
      "|    std                  | 5.95        |\n",
      "|    value_loss           | 88          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 15420       |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009294104 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 12630       |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    reward               | 0.20503578  |\n",
      "|    std                  | 5.96        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 15440       |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011561582 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 12640       |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    reward               | 0.1511474   |\n",
      "|    std                  | 5.96        |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 777         |\n",
      "|    time_elapsed         | 15474       |\n",
      "|    total_timesteps      | 1591296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008802259 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 12650       |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | 1.0356363   |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 98.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 15493       |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008366405 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 12660       |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    reward               | -3.3943565  |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 75.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5175641.43\n",
      "total_reward: 4175641.43\n",
      "total_cost: 318304.92\n",
      "total_trades: 66259\n",
      "Sharpe: 0.885\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 15512       |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012196043 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.016       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 12670       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -0.28980914 |\n",
      "|    std                  | 5.98        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 15531       |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011214891 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 12680       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | 1.5400015   |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 15550       |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004576289 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 12690       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | 1.0768975   |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 782         |\n",
      "|    time_elapsed         | 15569       |\n",
      "|    total_timesteps      | 1601536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012246793 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.0884      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.52        |\n",
      "|    n_updates            | 12700       |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | -2.3783393  |\n",
      "|    std                  | 6.02        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 15589       |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013734583 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.36        |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 0.1377699   |\n",
      "|    std                  | 6.04        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 784         |\n",
      "|    time_elapsed         | 15609       |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013711658 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 12720       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 0.6395526   |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 15628       |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014513725 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 12730       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | -0.8067485  |\n",
      "|    std                  | 6.07        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 15647       |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013371618 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.24        |\n",
      "|    n_updates            | 12740       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 1.2968808   |\n",
      "|    std                  | 6.07        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 787         |\n",
      "|    time_elapsed         | 15667       |\n",
      "|    total_timesteps      | 1611776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012739018 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 12750       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -1.0920107  |\n",
      "|    std                  | 6.07        |\n",
      "|    value_loss           | 65          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 15686       |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010862294 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 12760       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | 3.2973375   |\n",
      "|    std                  | 6.08        |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 789        |\n",
      "|    time_elapsed         | 15705      |\n",
      "|    total_timesteps      | 1615872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0167083  |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.1      |\n",
      "|    explained_variance   | 0.388      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.1       |\n",
      "|    n_updates            | 12770      |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    reward               | -2.3355308 |\n",
      "|    std                  | 6.1        |\n",
      "|    value_loss           | 24.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 15725       |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011023238 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 12780       |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | 0.6543122   |\n",
      "|    std                  | 6.12        |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 15744       |\n",
      "|    total_timesteps      | 1619968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011375476 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 12790       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -3.4324968  |\n",
      "|    std                  | 6.12        |\n",
      "|    value_loss           | 93.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 792          |\n",
      "|    time_elapsed         | 15763        |\n",
      "|    total_timesteps      | 1622016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127829835 |\n",
      "|    clip_fraction        | 0.0857       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.2        |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 12800        |\n",
      "|    policy_gradient_loss | -0.00952     |\n",
      "|    reward               | 2.4481251    |\n",
      "|    std                  | 6.12         |\n",
      "|    value_loss           | 47.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4766380.27\n",
      "total_reward: 3766380.27\n",
      "total_cost: 310704.61\n",
      "total_trades: 65125\n",
      "Sharpe: 0.831\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 15782       |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012818274 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 12810       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -1.0091772  |\n",
      "|    std                  | 6.14        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 15802       |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008020615 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 12820       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.10536338 |\n",
      "|    std                  | 6.16        |\n",
      "|    value_loss           | 86.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 15821       |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012622632 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 12830       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | -0.6630184  |\n",
      "|    std                  | 6.17        |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 796         |\n",
      "|    time_elapsed         | 15840       |\n",
      "|    total_timesteps      | 1630208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010611532 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.46        |\n",
      "|    n_updates            | 12840       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    reward               | -0.5625571  |\n",
      "|    std                  | 6.18        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 15859       |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009744496 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 12850       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.18891828 |\n",
      "|    std                  | 6.18        |\n",
      "|    value_loss           | 71.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 15878       |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010802641 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 12860       |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | 1.0162759   |\n",
      "|    std                  | 6.2         |\n",
      "|    value_loss           | 69.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 15898       |\n",
      "|    total_timesteps      | 1636352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011282137 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 12870       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | 2.2520528   |\n",
      "|    std                  | 6.21        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 15917       |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01168944  |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 12880       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.25272658 |\n",
      "|    std                  | 6.22        |\n",
      "|    value_loss           | 48          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 801         |\n",
      "|    time_elapsed         | 15936       |\n",
      "|    total_timesteps      | 1640448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009396797 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 12890       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | -3.1958358  |\n",
      "|    std                  | 6.22        |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 15955       |\n",
      "|    total_timesteps      | 1642496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007276621 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.6        |\n",
      "|    n_updates            | 12900       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 0.8038687   |\n",
      "|    std                  | 6.23        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 15975       |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014575288 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.089       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 12910       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | -0.543968   |\n",
      "|    std                  | 6.24        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 804         |\n",
      "|    time_elapsed         | 15993       |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010675017 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 12920       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 2.6594887   |\n",
      "|    std                  | 6.25        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 16013       |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012110796 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 12930       |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | 1.0847006   |\n",
      "|    std                  | 6.25        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 806         |\n",
      "|    time_elapsed         | 16032       |\n",
      "|    total_timesteps      | 1650688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017424993 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.0048      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 12940       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | 3.681618    |\n",
      "|    std                  | 6.27        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4374646.31\n",
      "total_reward: 3374646.31\n",
      "total_cost: 294147.49\n",
      "total_trades: 63800\n",
      "Sharpe: 0.796\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 807          |\n",
      "|    time_elapsed         | 16051        |\n",
      "|    total_timesteps      | 1652736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011340098  |\n",
      "|    clip_fraction        | 0.0935       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.9        |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 12950        |\n",
      "|    policy_gradient_loss | -0.00983     |\n",
      "|    reward               | -0.101508945 |\n",
      "|    std                  | 6.27         |\n",
      "|    value_loss           | 47.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 16070       |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008338129 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 12960       |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    reward               | -0.14496173 |\n",
      "|    std                  | 6.28        |\n",
      "|    value_loss           | 66.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 809          |\n",
      "|    time_elapsed         | 16089        |\n",
      "|    total_timesteps      | 1656832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048964457 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94          |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.3         |\n",
      "|    n_updates            | 12970        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    reward               | 0.6072686    |\n",
      "|    std                  | 6.28         |\n",
      "|    value_loss           | 75.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 16109       |\n",
      "|    total_timesteps      | 1658880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005401853 |\n",
      "|    clip_fraction        | 0.0224      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.88        |\n",
      "|    n_updates            | 12980       |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | 0.6776959   |\n",
      "|    std                  | 6.29        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 811         |\n",
      "|    time_elapsed         | 16129       |\n",
      "|    total_timesteps      | 1660928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010717008 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 12990       |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    reward               | -0.63058144 |\n",
      "|    std                  | 6.29        |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 812          |\n",
      "|    time_elapsed         | 16148        |\n",
      "|    total_timesteps      | 1662976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065472643 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94          |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 13000        |\n",
      "|    policy_gradient_loss | -0.00781     |\n",
      "|    reward               | 0.9652006    |\n",
      "|    std                  | 6.3          |\n",
      "|    value_loss           | 65.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 16169       |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015261546 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 13010       |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    reward               | -0.4254125  |\n",
      "|    std                  | 6.31        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 16190       |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012241585 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.0447      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 13020       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 2.44935     |\n",
      "|    std                  | 6.31        |\n",
      "|    value_loss           | 69.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 16209       |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013749709 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.9        |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -1.3700182  |\n",
      "|    std                  | 6.31        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 816          |\n",
      "|    time_elapsed         | 16230        |\n",
      "|    total_timesteps      | 1671168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068069566 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.4         |\n",
      "|    n_updates            | 13040        |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    reward               | -1.4372145   |\n",
      "|    std                  | 6.31         |\n",
      "|    value_loss           | 72.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 16249       |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009498877 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.0878      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.4        |\n",
      "|    n_updates            | 13050       |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | -1.6163235  |\n",
      "|    std                  | 6.32        |\n",
      "|    value_loss           | 98.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 16268       |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012688491 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.0876      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.1        |\n",
      "|    n_updates            | 13060       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 0.31581345  |\n",
      "|    std                  | 6.33        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 819          |\n",
      "|    time_elapsed         | 16287        |\n",
      "|    total_timesteps      | 1677312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072972947 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.2        |\n",
      "|    explained_variance   | 0.168        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.2         |\n",
      "|    n_updates            | 13070        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | 4.1321464    |\n",
      "|    std                  | 6.34         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 16306       |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013547124 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.38845307 |\n",
      "|    std                  | 6.36        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5500809.48\n",
      "total_reward: 4500809.48\n",
      "total_cost: 292929.11\n",
      "total_trades: 63065\n",
      "Sharpe: 0.822\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 821         |\n",
      "|    time_elapsed         | 16325       |\n",
      "|    total_timesteps      | 1681408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014136083 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.091       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 13090       |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | 0.3181362   |\n",
      "|    std                  | 6.37        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 16344       |\n",
      "|    total_timesteps      | 1683456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007824973 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.6        |\n",
      "|    n_updates            | 13100       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | 3.6507664   |\n",
      "|    std                  | 6.38        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 823         |\n",
      "|    time_elapsed         | 16363       |\n",
      "|    total_timesteps      | 1685504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015087448 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 13110       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | -6.0626583  |\n",
      "|    std                  | 6.39        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 16382       |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009102601 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.4        |\n",
      "|    n_updates            | 13120       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | -1.4974419  |\n",
      "|    std                  | 6.4         |\n",
      "|    value_loss           | 99.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 16401       |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009607429 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.0698      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 13130       |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    reward               | -1.5733733  |\n",
      "|    std                  | 6.41        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 826        |\n",
      "|    time_elapsed         | 16420      |\n",
      "|    total_timesteps      | 1691648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00709753 |\n",
      "|    clip_fraction        | 0.0323     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.5      |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 75.9       |\n",
      "|    n_updates            | 13140      |\n",
      "|    policy_gradient_loss | -0.00222   |\n",
      "|    reward               | -0.5889009 |\n",
      "|    std                  | 6.41       |\n",
      "|    value_loss           | 115        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 16439       |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013193537 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    reward               | 1.5639029   |\n",
      "|    std                  | 6.43        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 828         |\n",
      "|    time_elapsed         | 16458       |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008570234 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 13160       |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | -1.3867632  |\n",
      "|    std                  | 6.43        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 829          |\n",
      "|    time_elapsed         | 16477        |\n",
      "|    total_timesteps      | 1697792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053233383 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.6        |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.9         |\n",
      "|    n_updates            | 13170        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | 27.18444     |\n",
      "|    std                  | 6.44         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 16496       |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010488626 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 13180       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -2.7279315  |\n",
      "|    std                  | 6.45        |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 831         |\n",
      "|    time_elapsed         | 16515       |\n",
      "|    total_timesteps      | 1701888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010224426 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.0857      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 13190       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 2.479112    |\n",
      "|    std                  | 6.46        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 832         |\n",
      "|    time_elapsed         | 16534       |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009828879 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 13200       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 9.285259    |\n",
      "|    std                  | 6.47        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 833         |\n",
      "|    time_elapsed         | 16554       |\n",
      "|    total_timesteps      | 1705984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009262213 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.094       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.7        |\n",
      "|    n_updates            | 13210       |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    reward               | -0.9176586  |\n",
      "|    std                  | 6.48        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 16573       |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011640079 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 13220       |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | -3.3574543  |\n",
      "|    std                  | 6.5         |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5158984.58\n",
      "total_reward: 4158984.58\n",
      "total_cost: 318019.38\n",
      "total_trades: 64361\n",
      "Sharpe: 0.908\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 835         |\n",
      "|    time_elapsed         | 16592       |\n",
      "|    total_timesteps      | 1710080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009249765 |\n",
      "|    clip_fraction        | 0.0517      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.0491      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 13230       |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    reward               | 0.17060229  |\n",
      "|    std                  | 6.5         |\n",
      "|    value_loss           | 93.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 16611       |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019024784 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.0713      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 13240       |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | -0.86430496 |\n",
      "|    std                  | 6.52        |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 16630       |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009340503 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 13250       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 5.053509    |\n",
      "|    std                  | 6.52        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 16649       |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008574729 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.0822      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 13260       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | 2.865544    |\n",
      "|    std                  | 6.53        |\n",
      "|    value_loss           | 94.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 16670       |\n",
      "|    total_timesteps      | 1718272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009612892 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.0269      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 13270       |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    reward               | 9.20486     |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 840          |\n",
      "|    time_elapsed         | 16689        |\n",
      "|    total_timesteps      | 1720320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075360937 |\n",
      "|    clip_fraction        | 0.0553       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.2        |\n",
      "|    explained_variance   | 0.141        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 13280        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | 2.4854825    |\n",
      "|    std                  | 6.56         |\n",
      "|    value_loss           | 52.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 16711       |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008264756 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.0875      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 13290       |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 0.6482166   |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 97.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 16730       |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014189193 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.0274      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.8        |\n",
      "|    n_updates            | 13300       |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    reward               | -3.0392215  |\n",
      "|    std                  | 6.58        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 843         |\n",
      "|    time_elapsed         | 16749       |\n",
      "|    total_timesteps      | 1726464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005653938 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.0376      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 13310       |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    reward               | -2.254326   |\n",
      "|    std                  | 6.59        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 16769       |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014757915 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | -0.024      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 13320       |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    reward               | -2.6728237  |\n",
      "|    std                  | 6.6         |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 845         |\n",
      "|    time_elapsed         | 16789       |\n",
      "|    total_timesteps      | 1730560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009978848 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.0751      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 13330       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -0.6719594  |\n",
      "|    std                  | 6.62        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 846          |\n",
      "|    time_elapsed         | 16808        |\n",
      "|    total_timesteps      | 1732608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037603793 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.5        |\n",
      "|    explained_variance   | 0.0533       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 13340        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | 8.121698     |\n",
      "|    std                  | 6.63         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 16827       |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009481754 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 13350       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 2.0848415   |\n",
      "|    std                  | 6.66        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 848         |\n",
      "|    time_elapsed         | 16846       |\n",
      "|    total_timesteps      | 1736704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007716894 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.0982      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    reward               | 2.2841222   |\n",
      "|    std                  | 6.67        |\n",
      "|    value_loss           | 89.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5899755.74\n",
      "total_reward: 4899755.74\n",
      "total_cost: 286642.41\n",
      "total_trades: 62311\n",
      "Sharpe: 0.941\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 849         |\n",
      "|    time_elapsed         | 16866       |\n",
      "|    total_timesteps      | 1738752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009787231 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.0421      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.8        |\n",
      "|    n_updates            | 13370       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -2.1483438  |\n",
      "|    std                  | 6.68        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 850         |\n",
      "|    time_elapsed         | 16885       |\n",
      "|    total_timesteps      | 1740800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013037773 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.0302      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 13380       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    reward               | -5.4114447  |\n",
      "|    std                  | 6.69        |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 16904       |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016317926 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.42        |\n",
      "|    n_updates            | 13390       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 0.8999879   |\n",
      "|    std                  | 6.72        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 852          |\n",
      "|    time_elapsed         | 16923        |\n",
      "|    total_timesteps      | 1744896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088761095 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.9        |\n",
      "|    explained_variance   | 0.0992       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.6         |\n",
      "|    n_updates            | 13400        |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    reward               | -1.7402252   |\n",
      "|    std                  | 6.72         |\n",
      "|    value_loss           | 97.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 853          |\n",
      "|    time_elapsed         | 16942        |\n",
      "|    total_timesteps      | 1746944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074675484 |\n",
      "|    clip_fraction        | 0.0446       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.9        |\n",
      "|    explained_variance   | 0.0398       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.1         |\n",
      "|    n_updates            | 13410        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    reward               | 5.033061     |\n",
      "|    std                  | 6.73         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 16961       |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005954331 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.0943      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 13420       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -0.43742532 |\n",
      "|    std                  | 6.73        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 855         |\n",
      "|    time_elapsed         | 16980       |\n",
      "|    total_timesteps      | 1751040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009178511 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.0823      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.40813428 |\n",
      "|    std                  | 6.74        |\n",
      "|    value_loss           | 81.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 856          |\n",
      "|    time_elapsed         | 16999        |\n",
      "|    total_timesteps      | 1753088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058134915 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96          |\n",
      "|    explained_variance   | 0.13         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.2         |\n",
      "|    n_updates            | 13440        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    reward               | -20.285713   |\n",
      "|    std                  | 6.75         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 17018       |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005751765 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.8        |\n",
      "|    n_updates            | 13450       |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | 4.604223    |\n",
      "|    std                  | 6.75        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 17037       |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012268072 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 13460       |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | 1.6760918   |\n",
      "|    std                  | 6.77        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 859          |\n",
      "|    time_elapsed         | 17056        |\n",
      "|    total_timesteps      | 1759232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073271245 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.1        |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.7         |\n",
      "|    n_updates            | 13470        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | -0.82683575  |\n",
      "|    std                  | 6.78         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 860         |\n",
      "|    time_elapsed         | 17076       |\n",
      "|    total_timesteps      | 1761280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005675437 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.6        |\n",
      "|    n_updates            | 13480       |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    reward               | 3.7802365   |\n",
      "|    std                  | 6.79        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 17094       |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012580684 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.34        |\n",
      "|    n_updates            | 13490       |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    reward               | 0.22993863  |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 17113       |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005834002 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.0939      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 13500       |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    reward               | -3.064326   |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 96.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 863          |\n",
      "|    time_elapsed         | 17132        |\n",
      "|    total_timesteps      | 1767424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066854833 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.2        |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.2         |\n",
      "|    n_updates            | 13510        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | 1.9340348    |\n",
      "|    std                  | 6.8          |\n",
      "|    value_loss           | 77.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5839334.88\n",
      "total_reward: 4839334.88\n",
      "total_cost: 209796.46\n",
      "total_trades: 57006\n",
      "Sharpe: 0.941\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 864         |\n",
      "|    time_elapsed         | 17151       |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009182845 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 13520       |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    reward               | 1.1060913   |\n",
      "|    std                  | 6.81        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 865         |\n",
      "|    time_elapsed         | 17170       |\n",
      "|    total_timesteps      | 1771520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016303096 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.0702      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 13530       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -2.3217015  |\n",
      "|    std                  | 6.82        |\n",
      "|    value_loss           | 70.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 17189       |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007857041 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.9        |\n",
      "|    n_updates            | 13540       |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | 0.7915958   |\n",
      "|    std                  | 6.82        |\n",
      "|    value_loss           | 85.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 867        |\n",
      "|    time_elapsed         | 17208      |\n",
      "|    total_timesteps      | 1775616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00926641 |\n",
      "|    clip_fraction        | 0.0418     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.3      |\n",
      "|    explained_variance   | 0.0971     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 79.4       |\n",
      "|    n_updates            | 13550      |\n",
      "|    policy_gradient_loss | -0.0049    |\n",
      "|    reward               | 1.6822035  |\n",
      "|    std                  | 6.82       |\n",
      "|    value_loss           | 111        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 17227       |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018264418 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.15        |\n",
      "|    n_updates            | 13560       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -1.9721146  |\n",
      "|    std                  | 6.84        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 17246       |\n",
      "|    total_timesteps      | 1779712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013517182 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.0856      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -0.5307395  |\n",
      "|    std                  | 6.85        |\n",
      "|    value_loss           | 83.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 870         |\n",
      "|    time_elapsed         | 17266       |\n",
      "|    total_timesteps      | 1781760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009047978 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.8        |\n",
      "|    n_updates            | 13580       |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    reward               | -2.6060066  |\n",
      "|    std                  | 6.86        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 17285       |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008314114 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 13590       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | 2.6877425   |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 872          |\n",
      "|    time_elapsed         | 17305        |\n",
      "|    total_timesteps      | 1785856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070507205 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.5        |\n",
      "|    explained_variance   | 0.0767       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.2         |\n",
      "|    n_updates            | 13600        |\n",
      "|    policy_gradient_loss | -0.00746     |\n",
      "|    reward               | 1.6799084    |\n",
      "|    std                  | 6.87         |\n",
      "|    value_loss           | 65.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 17324       |\n",
      "|    total_timesteps      | 1787904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010334897 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | -1.2173562  |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 17344       |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012816189 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.00342     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.3        |\n",
      "|    n_updates            | 13620       |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    reward               | 1.6279597   |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 875         |\n",
      "|    time_elapsed         | 17363       |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015861396 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.0558      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 13630       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | -1.0549737  |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 17383       |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011901453 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.6        |\n",
      "|    n_updates            | 13640       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 0.6681404   |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 877        |\n",
      "|    time_elapsed         | 17402      |\n",
      "|    total_timesteps      | 1796096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00817555 |\n",
      "|    clip_fraction        | 0.0518     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.6      |\n",
      "|    explained_variance   | 0.195      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 72.4       |\n",
      "|    n_updates            | 13650      |\n",
      "|    policy_gradient_loss | -0.00661   |\n",
      "|    reward               | 2.7400224  |\n",
      "|    std                  | 6.9        |\n",
      "|    value_loss           | 89.2       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5284903.34\n",
      "total_reward: 4284903.34\n",
      "total_cost: 267961.45\n",
      "total_trades: 59809\n",
      "Sharpe: 0.910\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 17421       |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011890516 |\n",
      "|    clip_fraction        | 0.0764      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 13660       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | -3.577101   |\n",
      "|    std                  | 6.91        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 879          |\n",
      "|    time_elapsed         | 17440        |\n",
      "|    total_timesteps      | 1800192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065462478 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.6        |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.1         |\n",
      "|    n_updates            | 13670        |\n",
      "|    policy_gradient_loss | -0.00854     |\n",
      "|    reward               | 0.56717515   |\n",
      "|    std                  | 6.91         |\n",
      "|    value_loss           | 67.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 880          |\n",
      "|    time_elapsed         | 17459        |\n",
      "|    total_timesteps      | 1802240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042040297 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.0883       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.7         |\n",
      "|    n_updates            | 13680        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | 4.73986      |\n",
      "|    std                  | 6.92         |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 881        |\n",
      "|    time_elapsed         | 17478      |\n",
      "|    total_timesteps      | 1804288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00854974 |\n",
      "|    clip_fraction        | 0.0352     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.7      |\n",
      "|    explained_variance   | 0.137      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.5       |\n",
      "|    n_updates            | 13690      |\n",
      "|    policy_gradient_loss | -0.00423   |\n",
      "|    reward               | -5.2655067 |\n",
      "|    std                  | 6.92       |\n",
      "|    value_loss           | 63.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 17498       |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009275104 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 13700       |\n",
      "|    policy_gradient_loss | -0.00719    |\n",
      "|    reward               | -1.6605473  |\n",
      "|    std                  | 6.93        |\n",
      "|    value_loss           | 63.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 17517       |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007734022 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 13710       |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | 1.0511007   |\n",
      "|    std                  | 6.95        |\n",
      "|    value_loss           | 83.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 884         |\n",
      "|    time_elapsed         | 17536       |\n",
      "|    total_timesteps      | 1810432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007175644 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 13720       |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    reward               | 2.6761842   |\n",
      "|    std                  | 6.95        |\n",
      "|    value_loss           | 95.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 17555       |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015855609 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 13730       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | 3.6133637   |\n",
      "|    std                  | 6.96        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 886        |\n",
      "|    time_elapsed         | 17574      |\n",
      "|    total_timesteps      | 1814528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00477834 |\n",
      "|    clip_fraction        | 0.0158     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.9      |\n",
      "|    explained_variance   | 0.47       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35         |\n",
      "|    n_updates            | 13740      |\n",
      "|    policy_gradient_loss | -0.0052    |\n",
      "|    reward               | -2.016587  |\n",
      "|    std                  | 6.96       |\n",
      "|    value_loss           | 59.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 887          |\n",
      "|    time_elapsed         | 17594        |\n",
      "|    total_timesteps      | 1816576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053025754 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.6         |\n",
      "|    n_updates            | 13750        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    reward               | 4.413955     |\n",
      "|    std                  | 6.96         |\n",
      "|    value_loss           | 91.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 888          |\n",
      "|    time_elapsed         | 17613        |\n",
      "|    total_timesteps      | 1818624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045122444 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 13760        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | 2.548589     |\n",
      "|    std                  | 6.97         |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 889         |\n",
      "|    time_elapsed         | 17632       |\n",
      "|    total_timesteps      | 1820672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007281979 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 13770       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -2.4156778  |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 890          |\n",
      "|    time_elapsed         | 17651        |\n",
      "|    total_timesteps      | 1822720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066874856 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 13780        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -0.5131159   |\n",
      "|    std                  | 6.98         |\n",
      "|    value_loss           | 47.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 17670       |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003383899 |\n",
      "|    clip_fraction        | 0.00459     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 13790       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    reward               | 0.12599555  |\n",
      "|    std                  | 6.99        |\n",
      "|    value_loss           | 57.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4937076.97\n",
      "total_reward: 3937076.97\n",
      "total_cost: 147262.03\n",
      "total_trades: 51941\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 892         |\n",
      "|    time_elapsed         | 17690       |\n",
      "|    total_timesteps      | 1826816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018831931 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 13800       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | 0.5638712   |\n",
      "|    std                  | 7.01        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 17709       |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007106783 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.4        |\n",
      "|    n_updates            | 13810       |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | -0.5174781  |\n",
      "|    std                  | 7.01        |\n",
      "|    value_loss           | 67.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 894         |\n",
      "|    time_elapsed         | 17728       |\n",
      "|    total_timesteps      | 1830912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008224575 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.3        |\n",
      "|    n_updates            | 13820       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 1.6176603   |\n",
      "|    std                  | 7.01        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 17747       |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009237903 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 13830       |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | -0.21227993 |\n",
      "|    std                  | 7.03        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 896         |\n",
      "|    time_elapsed         | 17766       |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007808836 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 13840       |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | 0.08078621  |\n",
      "|    std                  | 7.04        |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 17784       |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006255799 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.9        |\n",
      "|    n_updates            | 13850       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -20.930859  |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 96.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 898          |\n",
      "|    time_elapsed         | 17804        |\n",
      "|    total_timesteps      | 1839104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073235678 |\n",
      "|    clip_fraction        | 0.0447       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.3        |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 13860        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | 4.283497     |\n",
      "|    std                  | 7.06         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 899         |\n",
      "|    time_elapsed         | 17822       |\n",
      "|    total_timesteps      | 1841152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016348101 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 13870       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.043208696 |\n",
      "|    std                  | 7.09        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 900          |\n",
      "|    time_elapsed         | 17842        |\n",
      "|    total_timesteps      | 1843200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043921405 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.4        |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.5         |\n",
      "|    n_updates            | 13880        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | 1.1024635    |\n",
      "|    std                  | 7.09         |\n",
      "|    value_loss           | 78.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 901         |\n",
      "|    time_elapsed         | 17860       |\n",
      "|    total_timesteps      | 1845248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010190321 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.1        |\n",
      "|    n_updates            | 13890       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | 3.5317497   |\n",
      "|    std                  | 7.1         |\n",
      "|    value_loss           | 92.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 902          |\n",
      "|    time_elapsed         | 17879        |\n",
      "|    total_timesteps      | 1847296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077156774 |\n",
      "|    clip_fraction        | 0.046        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.5        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 13900        |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    reward               | 0.13677894   |\n",
      "|    std                  | 7.1          |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 903          |\n",
      "|    time_elapsed         | 17898        |\n",
      "|    total_timesteps      | 1849344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060384166 |\n",
      "|    clip_fraction        | 0.0447       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.5        |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 13910        |\n",
      "|    policy_gradient_loss | -0.00741     |\n",
      "|    reward               | -1.0248107   |\n",
      "|    std                  | 7.12         |\n",
      "|    value_loss           | 61.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 103           |\n",
      "|    iterations           | 904           |\n",
      "|    time_elapsed         | 17918         |\n",
      "|    total_timesteps      | 1851392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0039626183  |\n",
      "|    clip_fraction        | 0.0101        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -97.5         |\n",
      "|    explained_variance   | 0.396         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 58            |\n",
      "|    n_updates            | 13920         |\n",
      "|    policy_gradient_loss | -0.00494      |\n",
      "|    reward               | -0.0023333319 |\n",
      "|    std                  | 7.13          |\n",
      "|    value_loss           | 70.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 905          |\n",
      "|    time_elapsed         | 17937        |\n",
      "|    total_timesteps      | 1853440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042678965 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.6        |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 13930        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | -1.2297078   |\n",
      "|    std                  | 7.13         |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4829570.54\n",
      "total_reward: 3829570.54\n",
      "total_cost: 109112.15\n",
      "total_trades: 50662\n",
      "Sharpe: 0.876\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 17955       |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009506736 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 13940       |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | 0.43028814  |\n",
      "|    std                  | 7.15        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 907          |\n",
      "|    time_elapsed         | 17974        |\n",
      "|    total_timesteps      | 1857536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069114547 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.7        |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 13950        |\n",
      "|    policy_gradient_loss | -0.00703     |\n",
      "|    reward               | 1.6592264    |\n",
      "|    std                  | 7.16         |\n",
      "|    value_loss           | 81.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 908        |\n",
      "|    time_elapsed         | 17993      |\n",
      "|    total_timesteps      | 1859584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01169043 |\n",
      "|    clip_fraction        | 0.0603     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.7      |\n",
      "|    explained_variance   | 0.363      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.5       |\n",
      "|    n_updates            | 13960      |\n",
      "|    policy_gradient_loss | -0.00516   |\n",
      "|    reward               | 3.778492   |\n",
      "|    std                  | 7.16       |\n",
      "|    value_loss           | 84.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 909         |\n",
      "|    time_elapsed         | 18012       |\n",
      "|    total_timesteps      | 1861632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010164893 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.7       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 13970       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | -0.39126244 |\n",
      "|    std                  | 7.17        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 910          |\n",
      "|    time_elapsed         | 18031        |\n",
      "|    total_timesteps      | 1863680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074836016 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.7        |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.7         |\n",
      "|    n_updates            | 13980        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | -0.5911854   |\n",
      "|    std                  | 7.18         |\n",
      "|    value_loss           | 77.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 911          |\n",
      "|    time_elapsed         | 18050        |\n",
      "|    total_timesteps      | 1865728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060041295 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.8        |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.2         |\n",
      "|    n_updates            | 13990        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | 0.044786014  |\n",
      "|    std                  | 7.19         |\n",
      "|    value_loss           | 99.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 912          |\n",
      "|    time_elapsed         | 18069        |\n",
      "|    total_timesteps      | 1867776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075425077 |\n",
      "|    clip_fraction        | 0.0518       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.8        |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 14000        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | 1.8382542    |\n",
      "|    std                  | 7.2          |\n",
      "|    value_loss           | 56           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 913          |\n",
      "|    time_elapsed         | 18089        |\n",
      "|    total_timesteps      | 1869824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077742077 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.9        |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45           |\n",
      "|    n_updates            | 14010        |\n",
      "|    policy_gradient_loss | -0.00793     |\n",
      "|    reward               | 0.34200087   |\n",
      "|    std                  | 7.22         |\n",
      "|    value_loss           | 68.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 914         |\n",
      "|    time_elapsed         | 18108       |\n",
      "|    total_timesteps      | 1871872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009184257 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 14020       |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | 0.78502476  |\n",
      "|    std                  | 7.22        |\n",
      "|    value_loss           | 83.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 18127        |\n",
      "|    total_timesteps      | 1873920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025208988 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.9        |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.5         |\n",
      "|    n_updates            | 14030        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | 5.1447515    |\n",
      "|    std                  | 7.22         |\n",
      "|    value_loss           | 71.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 18146       |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009860311 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.28        |\n",
      "|    n_updates            | 14040       |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    reward               | 0.25638154  |\n",
      "|    std                  | 7.24        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 917          |\n",
      "|    time_elapsed         | 18164        |\n",
      "|    total_timesteps      | 1878016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098626595 |\n",
      "|    clip_fraction        | 0.0735       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.2         |\n",
      "|    n_updates            | 14050        |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | 0.7249417    |\n",
      "|    std                  | 7.25         |\n",
      "|    value_loss           | 56.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 918          |\n",
      "|    time_elapsed         | 18183        |\n",
      "|    total_timesteps      | 1880064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046033384 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.1        |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 14060        |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | 3.4886074    |\n",
      "|    std                  | 7.26         |\n",
      "|    value_loss           | 64.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 18202       |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007597909 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 14070       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | -2.1973493  |\n",
      "|    std                  | 7.28        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3528341.63\n",
      "total_reward: 2528341.63\n",
      "total_cost: 81117.37\n",
      "total_trades: 48365\n",
      "Sharpe: 0.721\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 18222       |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009190293 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 14080       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    reward               | 0.87219     |\n",
      "|    std                  | 7.28        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 921          |\n",
      "|    time_elapsed         | 18241        |\n",
      "|    total_timesteps      | 1886208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047460017 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.2        |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 14090        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -2.8539987   |\n",
      "|    std                  | 7.29         |\n",
      "|    value_loss           | 57.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 18260       |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012025308 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 14100       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    reward               | -3.7086492  |\n",
      "|    std                  | 7.29        |\n",
      "|    value_loss           | 62.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 923         |\n",
      "|    time_elapsed         | 18279       |\n",
      "|    total_timesteps      | 1890304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009846939 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.2         |\n",
      "|    n_updates            | 14110       |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | 0.53125226  |\n",
      "|    std                  | 7.31        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 18298       |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006227972 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 14120       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | -3.185918   |\n",
      "|    std                  | 7.31        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 18316       |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006049187 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 14130       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | -0.28717884 |\n",
      "|    std                  | 7.32        |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 926        |\n",
      "|    time_elapsed         | 18335      |\n",
      "|    total_timesteps      | 1896448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00754401 |\n",
      "|    clip_fraction        | 0.0391     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.3      |\n",
      "|    explained_variance   | 0.234      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 14140      |\n",
      "|    policy_gradient_loss | -0.00762   |\n",
      "|    reward               | 2.6319516  |\n",
      "|    std                  | 7.33       |\n",
      "|    value_loss           | 39.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 927        |\n",
      "|    time_elapsed         | 18354      |\n",
      "|    total_timesteps      | 1898496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00911043 |\n",
      "|    clip_fraction        | 0.0807     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.4      |\n",
      "|    explained_variance   | 0.255      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.5       |\n",
      "|    n_updates            | 14150      |\n",
      "|    policy_gradient_loss | -0.00836   |\n",
      "|    reward               | 2.3894436  |\n",
      "|    std                  | 7.34       |\n",
      "|    value_loss           | 74.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 928         |\n",
      "|    time_elapsed         | 18373       |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005003565 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 14160       |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    reward               | -0.90222603 |\n",
      "|    std                  | 7.35        |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 929          |\n",
      "|    time_elapsed         | 18392        |\n",
      "|    total_timesteps      | 1902592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077165784 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.4        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 14170        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | 1.2308474    |\n",
      "|    std                  | 7.34         |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 18412       |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013220741 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 14180       |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | 1.3566803   |\n",
      "|    std                  | 7.35        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 931         |\n",
      "|    time_elapsed         | 18432       |\n",
      "|    total_timesteps      | 1906688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007039165 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 14190       |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | -0.9206971  |\n",
      "|    std                  | 7.36        |\n",
      "|    value_loss           | 49.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 932          |\n",
      "|    time_elapsed         | 18452        |\n",
      "|    total_timesteps      | 1908736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044846185 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.5        |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 14200        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    reward               | -3.1646252   |\n",
      "|    std                  | 7.36         |\n",
      "|    value_loss           | 82.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 933        |\n",
      "|    time_elapsed         | 18471      |\n",
      "|    total_timesteps      | 1910784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01068118 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.5      |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.6       |\n",
      "|    n_updates            | 14210      |\n",
      "|    policy_gradient_loss | -0.00474   |\n",
      "|    reward               | -0.8644061 |\n",
      "|    std                  | 7.36       |\n",
      "|    value_loss           | 30         |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4675433.37\n",
      "total_reward: 3675433.37\n",
      "total_cost: 111760.38\n",
      "total_trades: 51567\n",
      "Sharpe: 0.876\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 18491       |\n",
      "|    total_timesteps      | 1912832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010297758 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.9        |\n",
      "|    n_updates            | 14220       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.36822584  |\n",
      "|    std                  | 7.37        |\n",
      "|    value_loss           | 93          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 935          |\n",
      "|    time_elapsed         | 18510        |\n",
      "|    total_timesteps      | 1914880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043975753 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.5        |\n",
      "|    explained_variance   | 0.359        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42           |\n",
      "|    n_updates            | 14230        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -0.90419555  |\n",
      "|    std                  | 7.38         |\n",
      "|    value_loss           | 88.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 936         |\n",
      "|    time_elapsed         | 18529       |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011874316 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 14240       |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | -6.1408954  |\n",
      "|    std                  | 7.38        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 18549       |\n",
      "|    total_timesteps      | 1918976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008634309 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.88        |\n",
      "|    n_updates            | 14250       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | -0.40371227 |\n",
      "|    std                  | 7.39        |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 938          |\n",
      "|    time_elapsed         | 18568        |\n",
      "|    total_timesteps      | 1921024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062896702 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.6        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 14260        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 0.1414647    |\n",
      "|    std                  | 7.4          |\n",
      "|    value_loss           | 68           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 18589       |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005377002 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 14270       |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | 1.1512809   |\n",
      "|    std                  | 7.4         |\n",
      "|    value_loss           | 74          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 18608       |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012023987 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.77        |\n",
      "|    n_updates            | 14280       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 0.4573076   |\n",
      "|    std                  | 7.42        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 18628       |\n",
      "|    total_timesteps      | 1927168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007557871 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 14290       |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | 0.06980866  |\n",
      "|    std                  | 7.43        |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 18648       |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004146791 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 14300       |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | 4.063214    |\n",
      "|    std                  | 7.44        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 943         |\n",
      "|    time_elapsed         | 18669       |\n",
      "|    total_timesteps      | 1931264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009163531 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 14310       |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    reward               | -0.67695516 |\n",
      "|    std                  | 7.45        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 944         |\n",
      "|    time_elapsed         | 18689       |\n",
      "|    total_timesteps      | 1933312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008469089 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 14320       |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | 0.31116623  |\n",
      "|    std                  | 7.46        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 103       |\n",
      "|    iterations           | 945       |\n",
      "|    time_elapsed         | 18708     |\n",
      "|    total_timesteps      | 1935360   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0095805 |\n",
      "|    clip_fraction        | 0.0452    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -98.9     |\n",
      "|    explained_variance   | 0.379     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 46.6      |\n",
      "|    n_updates            | 14330     |\n",
      "|    policy_gradient_loss | -0.00656  |\n",
      "|    reward               | -6.301094 |\n",
      "|    std                  | 7.47      |\n",
      "|    value_loss           | 71.6      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 946          |\n",
      "|    time_elapsed         | 18727        |\n",
      "|    total_timesteps      | 1937408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076050977 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99          |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 14340        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | -1.9949154   |\n",
      "|    std                  | 7.48         |\n",
      "|    value_loss           | 64.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 947          |\n",
      "|    time_elapsed         | 18746        |\n",
      "|    total_timesteps      | 1939456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008388699  |\n",
      "|    clip_fraction        | 0.0553       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99          |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 14350        |\n",
      "|    policy_gradient_loss | -0.00903     |\n",
      "|    reward               | -0.073048525 |\n",
      "|    std                  | 7.49         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4208659.19\n",
      "total_reward: 3208659.19\n",
      "total_cost: 130887.57\n",
      "total_trades: 53876\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 948         |\n",
      "|    time_elapsed         | 18765       |\n",
      "|    total_timesteps      | 1941504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009944122 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 14360       |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | 0.27282998  |\n",
      "|    std                  | 7.5         |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 949          |\n",
      "|    time_elapsed         | 18784        |\n",
      "|    total_timesteps      | 1943552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075347293 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.3         |\n",
      "|    n_updates            | 14370        |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    reward               | -1.2689081   |\n",
      "|    std                  | 7.52         |\n",
      "|    value_loss           | 78.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 950          |\n",
      "|    time_elapsed         | 18802        |\n",
      "|    total_timesteps      | 1945600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062173395 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 14380        |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    reward               | -5.6781745   |\n",
      "|    std                  | 7.52         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 18822       |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007356516 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 14390       |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | 2.8358657   |\n",
      "|    std                  | 7.53        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 952          |\n",
      "|    time_elapsed         | 18842        |\n",
      "|    total_timesteps      | 1949696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043680505 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.2        |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 14400        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    reward               | 7.022777     |\n",
      "|    std                  | 7.54         |\n",
      "|    value_loss           | 68.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 953         |\n",
      "|    time_elapsed         | 18861       |\n",
      "|    total_timesteps      | 1951744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008719666 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 14410       |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | -1.2259775  |\n",
      "|    std                  | 7.55        |\n",
      "|    value_loss           | 49.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 18880       |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010222861 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    reward               | 0.84490025  |\n",
      "|    std                  | 7.56        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 955         |\n",
      "|    time_elapsed         | 18898       |\n",
      "|    total_timesteps      | 1955840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010977111 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 14430       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.3269398   |\n",
      "|    std                  | 7.57        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 18917       |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004157956 |\n",
      "|    clip_fraction        | 0.00869     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 14440       |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    reward               | -1.3724471  |\n",
      "|    std                  | 7.57        |\n",
      "|    value_loss           | 70.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 957         |\n",
      "|    time_elapsed         | 18936       |\n",
      "|    total_timesteps      | 1959936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011977018 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.95        |\n",
      "|    n_updates            | 14450       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    reward               | 2.7293882   |\n",
      "|    std                  | 7.58        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 958         |\n",
      "|    time_elapsed         | 18955       |\n",
      "|    total_timesteps      | 1961984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005271403 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 14460       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | -0.49424422 |\n",
      "|    std                  | 7.59        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 959         |\n",
      "|    time_elapsed         | 18974       |\n",
      "|    total_timesteps      | 1964032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006002888 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | -3.8020313  |\n",
      "|    std                  | 7.59        |\n",
      "|    value_loss           | 68.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 960          |\n",
      "|    time_elapsed         | 18993        |\n",
      "|    total_timesteps      | 1966080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041848123 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.4        |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 14480        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | -0.13576452  |\n",
      "|    std                  | 7.59         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 19012       |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014305592 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 14490       |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | 1.5285901   |\n",
      "|    std                  | 7.59        |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3783797.73\n",
      "total_reward: 2783797.73\n",
      "total_cost: 197000.70\n",
      "total_trades: 58504\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 962         |\n",
      "|    time_elapsed         | 19031       |\n",
      "|    total_timesteps      | 1970176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006474712 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 14500       |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    reward               | -0.1710868  |\n",
      "|    std                  | 7.59        |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 19050       |\n",
      "|    total_timesteps      | 1972224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008887245 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 14510       |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | 1.2468631   |\n",
      "|    std                  | 7.6         |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 19069       |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013218971 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.47        |\n",
      "|    n_updates            | 14520       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | -0.46927512 |\n",
      "|    std                  | 7.62        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 965         |\n",
      "|    time_elapsed         | 19088       |\n",
      "|    total_timesteps      | 1976320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011002382 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 14530       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -0.11454757 |\n",
      "|    std                  | 7.64        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 966          |\n",
      "|    time_elapsed         | 19108        |\n",
      "|    total_timesteps      | 1978368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042232363 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.6        |\n",
      "|    explained_variance   | 0.141        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.5         |\n",
      "|    n_updates            | 14540        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | -4.482289    |\n",
      "|    std                  | 7.66         |\n",
      "|    value_loss           | 88.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 967          |\n",
      "|    time_elapsed         | 19127        |\n",
      "|    total_timesteps      | 1980416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069504087 |\n",
      "|    clip_fraction        | 0.0413       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.7        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 14550        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | 0.7996475    |\n",
      "|    std                  | 7.67         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 19146       |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010147696 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    reward               | -0.5828409  |\n",
      "|    std                  | 7.68        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 969          |\n",
      "|    time_elapsed         | 19165        |\n",
      "|    total_timesteps      | 1984512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053250175 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.7        |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 14570        |\n",
      "|    policy_gradient_loss | -0.00722     |\n",
      "|    reward               | -11.522793   |\n",
      "|    std                  | 7.68         |\n",
      "|    value_loss           | 67.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 970         |\n",
      "|    time_elapsed         | 19184       |\n",
      "|    total_timesteps      | 1986560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004459666 |\n",
      "|    clip_fraction        | 0.00532     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 14580       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -6.5489564  |\n",
      "|    std                  | 7.68        |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 19203       |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009907024 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 14590       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -1.5895962  |\n",
      "|    std                  | 7.69        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 972         |\n",
      "|    time_elapsed         | 19222       |\n",
      "|    total_timesteps      | 1990656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011589809 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 14600       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 1.4436535   |\n",
      "|    std                  | 7.69        |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 973          |\n",
      "|    time_elapsed         | 19241        |\n",
      "|    total_timesteps      | 1992704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053353645 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 14610        |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | -11.328995   |\n",
      "|    std                  | 7.7          |\n",
      "|    value_loss           | 68.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 974          |\n",
      "|    time_elapsed         | 19260        |\n",
      "|    total_timesteps      | 1994752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008698726  |\n",
      "|    clip_fraction        | 0.083        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 14620        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    reward               | -0.008239262 |\n",
      "|    std                  | 7.71         |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 975          |\n",
      "|    time_elapsed         | 19279        |\n",
      "|    total_timesteps      | 1996800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082212    |\n",
      "|    clip_fraction        | 0.0705       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.9        |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 14630        |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    reward               | -0.027636414 |\n",
      "|    std                  | 7.73         |\n",
      "|    value_loss           | 58.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 19299       |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007506986 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.6        |\n",
      "|    n_updates            | 14640       |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | -12.736823  |\n",
      "|    std                  | 7.74        |\n",
      "|    value_loss           | 82.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4934502.04\n",
      "total_reward: 3934502.04\n",
      "total_cost: 196161.65\n",
      "total_trades: 57012\n",
      "Sharpe: 0.897\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 977         |\n",
      "|    time_elapsed         | 19318       |\n",
      "|    total_timesteps      | 2000896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010508694 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 14650       |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    reward               | 0.8037529   |\n",
      "|    std                  | 7.76        |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 978          |\n",
      "|    time_elapsed         | 19337        |\n",
      "|    total_timesteps      | 2002944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091941655 |\n",
      "|    clip_fraction        | 0.0732       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.8         |\n",
      "|    n_updates            | 14660        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    reward               | 1.2377101    |\n",
      "|    std                  | 7.78         |\n",
      "|    value_loss           | 48           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 19356       |\n",
      "|    total_timesteps      | 2004992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009553503 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 14670       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    reward               | 0.0412798   |\n",
      "|    std                  | 7.79        |\n",
      "|    value_loss           | 71.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 980         |\n",
      "|    time_elapsed         | 19375       |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008653021 |\n",
      "|    clip_fraction        | 0.0435      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.8        |\n",
      "|    n_updates            | 14680       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | 0.95266783  |\n",
      "|    std                  | 7.81        |\n",
      "|    value_loss           | 94.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 19394       |\n",
      "|    total_timesteps      | 2009088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012019429 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 14690       |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    reward               | 0.35787693  |\n",
      "|    std                  | 7.83        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 103           |\n",
      "|    iterations           | 982           |\n",
      "|    time_elapsed         | 19413         |\n",
      "|    total_timesteps      | 2011136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007764206   |\n",
      "|    clip_fraction        | 0.0316        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -100          |\n",
      "|    explained_variance   | 0.58          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.5          |\n",
      "|    n_updates            | 14700         |\n",
      "|    policy_gradient_loss | -0.00561      |\n",
      "|    reward               | -0.0058304276 |\n",
      "|    std                  | 7.83          |\n",
      "|    value_loss           | 56.4          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 983        |\n",
      "|    time_elapsed         | 19432      |\n",
      "|    total_timesteps      | 2013184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00942615 |\n",
      "|    clip_fraction        | 0.0711     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -100       |\n",
      "|    explained_variance   | 0.227      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.1       |\n",
      "|    n_updates            | 14710      |\n",
      "|    policy_gradient_loss | -0.00731   |\n",
      "|    reward               | 1.2543811  |\n",
      "|    std                  | 7.85       |\n",
      "|    value_loss           | 99.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 984        |\n",
      "|    time_elapsed         | 19452      |\n",
      "|    total_timesteps      | 2015232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00986016 |\n",
      "|    clip_fraction        | 0.0851     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -100       |\n",
      "|    explained_variance   | 0.228      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.7       |\n",
      "|    n_updates            | 14720      |\n",
      "|    policy_gradient_loss | -0.00419   |\n",
      "|    reward               | 0.32279325 |\n",
      "|    std                  | 7.86       |\n",
      "|    value_loss           | 46.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 985          |\n",
      "|    time_elapsed         | 19471        |\n",
      "|    total_timesteps      | 2017280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065147346 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.317        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52           |\n",
      "|    n_updates            | 14730        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    reward               | -0.54001194  |\n",
      "|    std                  | 7.87         |\n",
      "|    value_loss           | 59.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 986         |\n",
      "|    time_elapsed         | 19489       |\n",
      "|    total_timesteps      | 2019328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00546363  |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 14740       |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | -0.03878798 |\n",
      "|    std                  | 7.87        |\n",
      "|    value_loss           | 65.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 987         |\n",
      "|    time_elapsed         | 19508       |\n",
      "|    total_timesteps      | 2021376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01077142  |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 14750       |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    reward               | -0.48839378 |\n",
      "|    std                  | 7.88        |\n",
      "|    value_loss           | 75.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 988        |\n",
      "|    time_elapsed         | 19527      |\n",
      "|    total_timesteps      | 2023424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01654762 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -100       |\n",
      "|    explained_variance   | 0.295      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.73       |\n",
      "|    n_updates            | 14760      |\n",
      "|    policy_gradient_loss | -0.00848   |\n",
      "|    reward               | 1.2938377  |\n",
      "|    std                  | 7.89       |\n",
      "|    value_loss           | 17         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 989         |\n",
      "|    time_elapsed         | 19547       |\n",
      "|    total_timesteps      | 2025472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007703312 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 14770       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 0.28036043  |\n",
      "|    std                  | 7.91        |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 990          |\n",
      "|    time_elapsed         | 19566        |\n",
      "|    total_timesteps      | 2027520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009502444  |\n",
      "|    clip_fraction        | 0.0973       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29           |\n",
      "|    n_updates            | 14780        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    reward               | -0.036769077 |\n",
      "|    std                  | 7.94         |\n",
      "|    value_loss           | 73.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5040435.36\n",
      "total_reward: 4040435.36\n",
      "total_cost: 192677.69\n",
      "total_trades: 57216\n",
      "Sharpe: 0.864\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 991          |\n",
      "|    time_elapsed         | 19585        |\n",
      "|    total_timesteps      | 2029568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009057613  |\n",
      "|    clip_fraction        | 0.0831       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 14790        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | -0.055329416 |\n",
      "|    std                  | 7.95         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 992          |\n",
      "|    time_elapsed         | 19604        |\n",
      "|    total_timesteps      | 2031616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100647155 |\n",
      "|    clip_fraction        | 0.0762       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.8         |\n",
      "|    n_updates            | 14800        |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    reward               | -2.8038094   |\n",
      "|    std                  | 7.95         |\n",
      "|    value_loss           | 56.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 993          |\n",
      "|    time_elapsed         | 19623        |\n",
      "|    total_timesteps      | 2033664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062481426 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 14810        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    reward               | 3.430791     |\n",
      "|    std                  | 7.96         |\n",
      "|    value_loss           | 65.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 994         |\n",
      "|    time_elapsed         | 19642       |\n",
      "|    total_timesteps      | 2035712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009827644 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 14820       |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | -1.0315601  |\n",
      "|    std                  | 7.97        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 19661       |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009977266 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 14830       |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | -2.8001761  |\n",
      "|    std                  | 7.97        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 996          |\n",
      "|    time_elapsed         | 19680        |\n",
      "|    total_timesteps      | 2039808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027366702 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 14840        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | 0.6383801    |\n",
      "|    std                  | 7.97         |\n",
      "|    value_loss           | 63.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 997          |\n",
      "|    time_elapsed         | 19699        |\n",
      "|    total_timesteps      | 2041856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036346354 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.1         |\n",
      "|    n_updates            | 14850        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | -14.700619   |\n",
      "|    std                  | 7.98         |\n",
      "|    value_loss           | 68.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 19718       |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012257728 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 14860       |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    reward               | -4.715883   |\n",
      "|    std                  | 8           |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 19737       |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004388267 |\n",
      "|    clip_fraction        | 0.0304      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    reward               | -1.0903596  |\n",
      "|    std                  | 8           |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1000        |\n",
      "|    time_elapsed         | 19756       |\n",
      "|    total_timesteps      | 2048000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005193681 |\n",
      "|    clip_fraction        | 0.0252      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.2        |\n",
      "|    n_updates            | 14880       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | -0.52412194 |\n",
      "|    std                  | 8.01        |\n",
      "|    value_loss           | 88.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1001         |\n",
      "|    time_elapsed         | 19776        |\n",
      "|    total_timesteps      | 2050048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070334477 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 14890        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | -0.060446464 |\n",
      "|    std                  | 8.01         |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 1002       |\n",
      "|    time_elapsed         | 19796      |\n",
      "|    total_timesteps      | 2052096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01589463 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.435      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.7       |\n",
      "|    n_updates            | 14900      |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    reward               | -1.119866  |\n",
      "|    std                  | 8.04       |\n",
      "|    value_loss           | 53.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1003         |\n",
      "|    time_elapsed         | 19815        |\n",
      "|    total_timesteps      | 2054144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057057007 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 14910        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | -0.70435256  |\n",
      "|    std                  | 8.05         |\n",
      "|    value_loss           | 54.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 1004       |\n",
      "|    time_elapsed         | 19834      |\n",
      "|    total_timesteps      | 2056192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00575128 |\n",
      "|    clip_fraction        | 0.043      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.318      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.4       |\n",
      "|    n_updates            | 14920      |\n",
      "|    policy_gradient_loss | -0.00408   |\n",
      "|    reward               | 0.21374416 |\n",
      "|    std                  | 8.06       |\n",
      "|    value_loss           | 97.3       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5004156.17\n",
      "total_reward: 4004156.17\n",
      "total_cost: 230558.25\n",
      "total_trades: 58849\n",
      "Sharpe: 0.904\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 19853       |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013095565 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 14930       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 1.6031888   |\n",
      "|    std                  | 8.07        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1006        |\n",
      "|    time_elapsed         | 19874       |\n",
      "|    total_timesteps      | 2060288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005029219 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 14940       |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | -1.1753155  |\n",
      "|    std                  | 8.08        |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 19893        |\n",
      "|    total_timesteps      | 2062336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061350046 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.8         |\n",
      "|    n_updates            | 14950        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | 6.3303165    |\n",
      "|    std                  | 8.08         |\n",
      "|    value_loss           | 93.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1008         |\n",
      "|    time_elapsed         | 19913        |\n",
      "|    total_timesteps      | 2064384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073813577 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.5          |\n",
      "|    n_updates            | 14960        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | -1.0755081   |\n",
      "|    std                  | 8.09         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1009        |\n",
      "|    time_elapsed         | 19932       |\n",
      "|    total_timesteps      | 2066432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011800684 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60          |\n",
      "|    n_updates            | 14970       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.9942613  |\n",
      "|    std                  | 8.11        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 1010       |\n",
      "|    time_elapsed         | 19950      |\n",
      "|    total_timesteps      | 2068480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00953943 |\n",
      "|    clip_fraction        | 0.062      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.553      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.8       |\n",
      "|    n_updates            | 14980      |\n",
      "|    policy_gradient_loss | -0.00759   |\n",
      "|    reward               | 15.201112  |\n",
      "|    std                  | 8.12       |\n",
      "|    value_loss           | 67         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1011         |\n",
      "|    time_elapsed         | 19970        |\n",
      "|    total_timesteps      | 2070528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040564155 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 14990        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -0.6138245   |\n",
      "|    std                  | 8.13         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 19989       |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015433315 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7           |\n",
      "|    n_updates            | 15000       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | -1.6974783  |\n",
      "|    std                  | 8.13        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1013        |\n",
      "|    time_elapsed         | 20008       |\n",
      "|    total_timesteps      | 2074624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008165009 |\n",
      "|    clip_fraction        | 0.0628      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 15010       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | -2.0156462  |\n",
      "|    std                  | 8.14        |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1014         |\n",
      "|    time_elapsed         | 20027        |\n",
      "|    total_timesteps      | 2076672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072304197 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 15020        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | 1.1822649    |\n",
      "|    std                  | 8.15         |\n",
      "|    value_loss           | 59.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 20046       |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013101429 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 15030       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | 0.08144471  |\n",
      "|    std                  | 8.15        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1016        |\n",
      "|    time_elapsed         | 20065       |\n",
      "|    total_timesteps      | 2080768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009830216 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 15040       |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | -0.37036324 |\n",
      "|    std                  | 8.17        |\n",
      "|    value_loss           | 52.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1017        |\n",
      "|    time_elapsed         | 20084       |\n",
      "|    total_timesteps      | 2082816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005362317 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 15050       |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | 3.5471144   |\n",
      "|    std                  | 8.17        |\n",
      "|    value_loss           | 62.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1018        |\n",
      "|    time_elapsed         | 20103       |\n",
      "|    total_timesteps      | 2084864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008807113 |\n",
      "|    clip_fraction        | 0.0349      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 15060       |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | -1.2459285  |\n",
      "|    std                  | 8.18        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3505983.65\n",
      "total_reward: 2505983.65\n",
      "total_cost: 265610.91\n",
      "total_trades: 61334\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 20123       |\n",
      "|    total_timesteps      | 2086912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009916347 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.3         |\n",
      "|    n_updates            | 15070       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | 1.4914222   |\n",
      "|    std                  | 8.19        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1020         |\n",
      "|    time_elapsed         | 20142        |\n",
      "|    total_timesteps      | 2088960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026197126 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 15080        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | -0.062072176 |\n",
      "|    std                  | 8.2          |\n",
      "|    value_loss           | 65.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1021         |\n",
      "|    time_elapsed         | 20161        |\n",
      "|    total_timesteps      | 2091008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070167286 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 15090        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | 1.0327728    |\n",
      "|    std                  | 8.2          |\n",
      "|    value_loss           | 56.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1022         |\n",
      "|    time_elapsed         | 20180        |\n",
      "|    total_timesteps      | 2093056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114986375 |\n",
      "|    clip_fraction        | 0.0838       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 15100        |\n",
      "|    policy_gradient_loss | -0.00923     |\n",
      "|    reward               | 1.6134216    |\n",
      "|    std                  | 8.23         |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 20199       |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010141323 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 15110       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.078530036 |\n",
      "|    std                  | 8.23        |\n",
      "|    value_loss           | 82.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1024        |\n",
      "|    time_elapsed         | 20218       |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008290233 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 15120       |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    reward               | 1.7660002   |\n",
      "|    std                  | 8.24        |\n",
      "|    value_loss           | 73.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 20237       |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008011809 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 15130       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | 2.7177007   |\n",
      "|    std                  | 8.26        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1026         |\n",
      "|    time_elapsed         | 20256        |\n",
      "|    total_timesteps      | 2101248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077794874 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 15140        |\n",
      "|    policy_gradient_loss | -0.00965     |\n",
      "|    reward               | 0.31928787   |\n",
      "|    std                  | 8.28         |\n",
      "|    value_loss           | 50.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1027         |\n",
      "|    time_elapsed         | 20276        |\n",
      "|    total_timesteps      | 2103296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058325054 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40           |\n",
      "|    n_updates            | 15150        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | 2.2252367    |\n",
      "|    std                  | 8.29         |\n",
      "|    value_loss           | 66.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1028         |\n",
      "|    time_elapsed         | 20295        |\n",
      "|    total_timesteps      | 2105344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058532683 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.7         |\n",
      "|    n_updates            | 15160        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    reward               | -0.11117425  |\n",
      "|    std                  | 8.3          |\n",
      "|    value_loss           | 54.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 20314       |\n",
      "|    total_timesteps      | 2107392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016052797 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 15170       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 0.44363526  |\n",
      "|    std                  | 8.3         |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1030         |\n",
      "|    time_elapsed         | 20333        |\n",
      "|    total_timesteps      | 2109440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043461435 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 15180        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | 0.5617191    |\n",
      "|    std                  | 8.3          |\n",
      "|    value_loss           | 59.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1031         |\n",
      "|    time_elapsed         | 20352        |\n",
      "|    total_timesteps      | 2111488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041287793 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 15190        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | -0.5970466   |\n",
      "|    std                  | 8.31         |\n",
      "|    value_loss           | 70.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1032         |\n",
      "|    time_elapsed         | 20371        |\n",
      "|    total_timesteps      | 2113536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072760116 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 15200        |\n",
      "|    policy_gradient_loss | -0.00749     |\n",
      "|    reward               | 1.1271586    |\n",
      "|    std                  | 8.31         |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3970069.20\n",
      "total_reward: 2970069.20\n",
      "total_cost: 257810.91\n",
      "total_trades: 61157\n",
      "Sharpe: 0.780\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 20390       |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010815561 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 15210       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | 2.036235    |\n",
      "|    std                  | 8.31        |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1034        |\n",
      "|    time_elapsed         | 20409       |\n",
      "|    total_timesteps      | 2117632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005262101 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 15220       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | 3.1547604   |\n",
      "|    std                  | 8.32        |\n",
      "|    value_loss           | 68.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 103           |\n",
      "|    iterations           | 1035          |\n",
      "|    time_elapsed         | 20428         |\n",
      "|    total_timesteps      | 2119680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008215756   |\n",
      "|    clip_fraction        | 0.0461        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -102          |\n",
      "|    explained_variance   | 0.604         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.3          |\n",
      "|    n_updates            | 15230         |\n",
      "|    policy_gradient_loss | -0.00615      |\n",
      "|    reward               | -0.0042398074 |\n",
      "|    std                  | 8.34          |\n",
      "|    value_loss           | 64.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1036         |\n",
      "|    time_elapsed         | 20447        |\n",
      "|    total_timesteps      | 2121728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123490635 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.67         |\n",
      "|    n_updates            | 15240        |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    reward               | 0.37060618   |\n",
      "|    std                  | 8.37         |\n",
      "|    value_loss           | 17.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 1037       |\n",
      "|    time_elapsed         | 20466      |\n",
      "|    total_timesteps      | 2123776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00548197 |\n",
      "|    clip_fraction        | 0.0236     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -102       |\n",
      "|    explained_variance   | 0.564      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.5       |\n",
      "|    n_updates            | 15250      |\n",
      "|    policy_gradient_loss | -0.00536   |\n",
      "|    reward               | 0.1522802  |\n",
      "|    std                  | 8.37       |\n",
      "|    value_loss           | 64.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1038        |\n",
      "|    time_elapsed         | 20485       |\n",
      "|    total_timesteps      | 2125824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002974689 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 15260       |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    reward               | -0.35193053 |\n",
      "|    std                  | 8.38        |\n",
      "|    value_loss           | 76.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1039        |\n",
      "|    time_elapsed         | 20504       |\n",
      "|    total_timesteps      | 2127872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012733968 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 15270       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.8231093   |\n",
      "|    std                  | 8.38        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1040        |\n",
      "|    time_elapsed         | 20524       |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006546491 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.9        |\n",
      "|    n_updates            | 15280       |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | -1.6347506  |\n",
      "|    std                  | 8.39        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1041        |\n",
      "|    time_elapsed         | 20543       |\n",
      "|    total_timesteps      | 2131968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009435009 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 15290       |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    reward               | 2.0737488   |\n",
      "|    std                  | 8.39        |\n",
      "|    value_loss           | 61.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 20562       |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010655006 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 15300       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | -1.0632832  |\n",
      "|    std                  | 8.41        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 20581       |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008537155 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 15310       |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | 0.46031892  |\n",
      "|    std                  | 8.43        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1044         |\n",
      "|    time_elapsed         | 20600        |\n",
      "|    total_timesteps      | 2138112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058705695 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 15320        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | 1.5826945    |\n",
      "|    std                  | 8.44         |\n",
      "|    value_loss           | 62.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1045        |\n",
      "|    time_elapsed         | 20619       |\n",
      "|    total_timesteps      | 2140160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007925576 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 15330       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | 0.6982697   |\n",
      "|    std                  | 8.45        |\n",
      "|    value_loss           | 67.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 20638       |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011989921 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 15340       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.65077436 |\n",
      "|    std                  | 8.44        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4345860.29\n",
      "total_reward: 3345860.29\n",
      "total_cost: 353957.32\n",
      "total_trades: 68885\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1047         |\n",
      "|    time_elapsed         | 20658        |\n",
      "|    total_timesteps      | 2144256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065886835 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.1         |\n",
      "|    n_updates            | 15350        |\n",
      "|    policy_gradient_loss | -0.00791     |\n",
      "|    reward               | -2.1952474   |\n",
      "|    std                  | 8.45         |\n",
      "|    value_loss           | 78.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1048         |\n",
      "|    time_elapsed         | 20677        |\n",
      "|    total_timesteps      | 2146304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064096246 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.6         |\n",
      "|    n_updates            | 15360        |\n",
      "|    policy_gradient_loss | -0.00676     |\n",
      "|    reward               | -1.0704433   |\n",
      "|    std                  | 8.45         |\n",
      "|    value_loss           | 82.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1049        |\n",
      "|    time_elapsed         | 20696       |\n",
      "|    total_timesteps      | 2148352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010717522 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 15370       |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    reward               | -2.842374   |\n",
      "|    std                  | 8.47        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1050         |\n",
      "|    time_elapsed         | 20715        |\n",
      "|    total_timesteps      | 2150400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087731695 |\n",
      "|    clip_fraction        | 0.0491       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.9         |\n",
      "|    n_updates            | 15380        |\n",
      "|    policy_gradient_loss | -0.00968     |\n",
      "|    reward               | -0.7270168   |\n",
      "|    std                  | 8.49         |\n",
      "|    value_loss           | 66.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1051        |\n",
      "|    time_elapsed         | 20735       |\n",
      "|    total_timesteps      | 2152448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009109835 |\n",
      "|    clip_fraction        | 0.0564      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.4        |\n",
      "|    n_updates            | 15390       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.88026583  |\n",
      "|    std                  | 8.51        |\n",
      "|    value_loss           | 89.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 20754       |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005352459 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.2        |\n",
      "|    n_updates            | 15400       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | -0.44175783 |\n",
      "|    std                  | 8.51        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 20774       |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012903192 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.00149     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 15410       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.8442255   |\n",
      "|    std                  | 8.54        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1054         |\n",
      "|    time_elapsed         | 20793        |\n",
      "|    total_timesteps      | 2158592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004755414  |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.2         |\n",
      "|    n_updates            | 15420        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    reward               | -0.015253633 |\n",
      "|    std                  | 8.55         |\n",
      "|    value_loss           | 86.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1055        |\n",
      "|    time_elapsed         | 20812       |\n",
      "|    total_timesteps      | 2160640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007885965 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.8        |\n",
      "|    n_updates            | 15430       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 8.553192    |\n",
      "|    std                  | 8.55        |\n",
      "|    value_loss           | 93.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 20832       |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011524353 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 15440       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | -2.9722338  |\n",
      "|    std                  | 8.57        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1057         |\n",
      "|    time_elapsed         | 20851        |\n",
      "|    total_timesteps      | 2164736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072427616 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.0717       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.4         |\n",
      "|    n_updates            | 15450        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | -0.51725423  |\n",
      "|    std                  | 8.59         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1058         |\n",
      "|    time_elapsed         | 20870        |\n",
      "|    total_timesteps      | 2166784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029276474 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.9         |\n",
      "|    n_updates            | 15460        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | -20.675833   |\n",
      "|    std                  | 8.59         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1059        |\n",
      "|    time_elapsed         | 20890       |\n",
      "|    total_timesteps      | 2168832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005737176 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 15470       |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    reward               | -0.3023523  |\n",
      "|    std                  | 8.59        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1060        |\n",
      "|    time_elapsed         | 20909       |\n",
      "|    total_timesteps      | 2170880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014408971 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.07        |\n",
      "|    n_updates            | 15480       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.5690966   |\n",
      "|    std                  | 8.62        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4599633.62\n",
      "total_reward: 3599633.62\n",
      "total_cost: 302625.21\n",
      "total_trades: 64498\n",
      "Sharpe: 0.822\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 20929       |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010308366 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.7        |\n",
      "|    n_updates            | 15490       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    reward               | -0.03871428 |\n",
      "|    std                  | 8.63        |\n",
      "|    value_loss           | 79.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 20948       |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004314894 |\n",
      "|    clip_fraction        | 0.0199      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.8        |\n",
      "|    n_updates            | 15500       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -2.7979841  |\n",
      "|    std                  | 8.64        |\n",
      "|    value_loss           | 73          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1063        |\n",
      "|    time_elapsed         | 20968       |\n",
      "|    total_timesteps      | 2177024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011428546 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.13        |\n",
      "|    n_updates            | 15510       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -2.3990943  |\n",
      "|    std                  | 8.65        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 20987       |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006858466 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 15520       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -1.3690177  |\n",
      "|    std                  | 8.68        |\n",
      "|    value_loss           | 71.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1065         |\n",
      "|    time_elapsed         | 21006        |\n",
      "|    total_timesteps      | 2181120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067254584 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.1         |\n",
      "|    n_updates            | 15530        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    reward               | -5.6392913   |\n",
      "|    std                  | 8.69         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1066         |\n",
      "|    time_elapsed         | 21025        |\n",
      "|    total_timesteps      | 2183168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080787465 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.7         |\n",
      "|    n_updates            | 15540        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    reward               | -3.4051185   |\n",
      "|    std                  | 8.7          |\n",
      "|    value_loss           | 49.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1067        |\n",
      "|    time_elapsed         | 21045       |\n",
      "|    total_timesteps      | 2185216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010240335 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 15550       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -1.160274   |\n",
      "|    std                  | 8.71        |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1068        |\n",
      "|    time_elapsed         | 21064       |\n",
      "|    total_timesteps      | 2187264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007194007 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 15560       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -2.482436   |\n",
      "|    std                  | 8.72        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1069        |\n",
      "|    time_elapsed         | 21084       |\n",
      "|    total_timesteps      | 2189312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007380327 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.3        |\n",
      "|    n_updates            | 15570       |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | 0.31558698  |\n",
      "|    std                  | 8.75        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1070         |\n",
      "|    time_elapsed         | 21103        |\n",
      "|    total_timesteps      | 2191360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146007165 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 15580        |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    reward               | 0.8940906    |\n",
      "|    std                  | 8.78         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1071         |\n",
      "|    time_elapsed         | 21122        |\n",
      "|    total_timesteps      | 2193408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060310126 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 15590        |\n",
      "|    policy_gradient_loss | -0.00801     |\n",
      "|    reward               | -0.34701878  |\n",
      "|    std                  | 8.79         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1072         |\n",
      "|    time_elapsed         | 21141        |\n",
      "|    total_timesteps      | 2195456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042306264 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.1         |\n",
      "|    n_updates            | 15600        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | 3.5205522    |\n",
      "|    std                  | 8.8          |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 103       |\n",
      "|    iterations           | 1073      |\n",
      "|    time_elapsed         | 21161     |\n",
      "|    total_timesteps      | 2197504   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0097577 |\n",
      "|    clip_fraction        | 0.0901    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -104      |\n",
      "|    explained_variance   | 0.637     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 23.7      |\n",
      "|    n_updates            | 15610     |\n",
      "|    policy_gradient_loss | -0.0124   |\n",
      "|    reward               | 1.985874  |\n",
      "|    std                  | 8.82      |\n",
      "|    value_loss           | 42.8      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1074        |\n",
      "|    time_elapsed         | 21180       |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007277119 |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 15620       |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | 2.0354545   |\n",
      "|    std                  | 8.83        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5196850.64\n",
      "total_reward: 4196850.64\n",
      "total_cost: 312286.07\n",
      "total_trades: 65163\n",
      "Sharpe: 0.830\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1075         |\n",
      "|    time_elapsed         | 21199        |\n",
      "|    total_timesteps      | 2201600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057094404 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 15630        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    reward               | 0.6630608    |\n",
      "|    std                  | 8.84         |\n",
      "|    value_loss           | 93.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1076        |\n",
      "|    time_elapsed         | 21219       |\n",
      "|    total_timesteps      | 2203648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008615935 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.6        |\n",
      "|    n_updates            | 15640       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.98642576 |\n",
      "|    std                  | 8.85        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 21238       |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015453375 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 15650       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -0.9475198  |\n",
      "|    std                  | 8.88        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1078         |\n",
      "|    time_elapsed         | 21258        |\n",
      "|    total_timesteps      | 2207744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077453926 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.6         |\n",
      "|    n_updates            | 15660        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    reward               | 0.06349728   |\n",
      "|    std                  | 8.88         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1079         |\n",
      "|    time_elapsed         | 21277        |\n",
      "|    total_timesteps      | 2209792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040274565 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.2         |\n",
      "|    n_updates            | 15670        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    reward               | -0.7900051   |\n",
      "|    std                  | 8.89         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1080         |\n",
      "|    time_elapsed         | 21296        |\n",
      "|    total_timesteps      | 2211840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01305623   |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 15680        |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | -0.055488907 |\n",
      "|    std                  | 8.92         |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1081         |\n",
      "|    time_elapsed         | 21316        |\n",
      "|    total_timesteps      | 2213888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064367116 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 15690        |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    reward               | -0.9885133   |\n",
      "|    std                  | 8.94         |\n",
      "|    value_loss           | 87.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1082         |\n",
      "|    time_elapsed         | 21336        |\n",
      "|    total_timesteps      | 2215936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018149432 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.9         |\n",
      "|    n_updates            | 15700        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | 5.059928     |\n",
      "|    std                  | 8.94         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1083         |\n",
      "|    time_elapsed         | 21357        |\n",
      "|    total_timesteps      | 2217984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067691132 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.4         |\n",
      "|    n_updates            | 15710        |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    reward               | -0.69687784  |\n",
      "|    std                  | 8.95         |\n",
      "|    value_loss           | 80.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1084        |\n",
      "|    time_elapsed         | 21376       |\n",
      "|    total_timesteps      | 2220032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009940218 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.77        |\n",
      "|    n_updates            | 15720       |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    reward               | 0.13618581  |\n",
      "|    std                  | 8.97        |\n",
      "|    value_loss           | 81.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 21394       |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003933952 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.5        |\n",
      "|    n_updates            | 15730       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | 0.43640754  |\n",
      "|    std                  | 8.97        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 21413       |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013443203 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 15740       |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | -6.3973866  |\n",
      "|    std                  | 8.99        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 21432       |\n",
      "|    total_timesteps      | 2226176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012400058 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0429      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 15750       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | 0.37473977  |\n",
      "|    std                  | 9.04        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1088        |\n",
      "|    time_elapsed         | 21451       |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005484353 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.8        |\n",
      "|    n_updates            | 15760       |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    reward               | -2.403613   |\n",
      "|    std                  | 9.05        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1089         |\n",
      "|    time_elapsed         | 21469        |\n",
      "|    total_timesteps      | 2230272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050617615 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.8         |\n",
      "|    n_updates            | 15770        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | -4.362472    |\n",
      "|    std                  | 9.05         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5210482.68\n",
      "total_reward: 4210482.68\n",
      "total_cost: 344248.95\n",
      "total_trades: 67730\n",
      "Sharpe: 0.859\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1090        |\n",
      "|    time_elapsed         | 21488       |\n",
      "|    total_timesteps      | 2232320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011581477 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 15780       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | -1.564879   |\n",
      "|    std                  | 9.07        |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 21507       |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008254397 |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 15790       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    reward               | 0.62730557  |\n",
      "|    std                  | 9.09        |\n",
      "|    value_loss           | 99.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1092         |\n",
      "|    time_elapsed         | 21526        |\n",
      "|    total_timesteps      | 2236416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037624887 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.7         |\n",
      "|    n_updates            | 15800        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | -1.6715046   |\n",
      "|    std                  | 9.1          |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1093        |\n",
      "|    time_elapsed         | 21544       |\n",
      "|    total_timesteps      | 2238464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003891679 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49          |\n",
      "|    n_updates            | 15810       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | -1.5091251  |\n",
      "|    std                  | 9.1         |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1094        |\n",
      "|    time_elapsed         | 21563       |\n",
      "|    total_timesteps      | 2240512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013646757 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 15820       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 3.069182    |\n",
      "|    std                  | 9.13        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1095         |\n",
      "|    time_elapsed         | 21581        |\n",
      "|    total_timesteps      | 2242560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033095265 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.4         |\n",
      "|    n_updates            | 15830        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -0.37046945  |\n",
      "|    std                  | 9.14         |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1096         |\n",
      "|    time_elapsed         | 21600        |\n",
      "|    total_timesteps      | 2244608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015747622 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.7         |\n",
      "|    n_updates            | 15840        |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    reward               | -5.3380404   |\n",
      "|    std                  | 9.15         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1097         |\n",
      "|    time_elapsed         | 21621        |\n",
      "|    total_timesteps      | 2246656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078835385 |\n",
      "|    clip_fraction        | 0.0679       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.144        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 15850        |\n",
      "|    policy_gradient_loss | -0.00858     |\n",
      "|    reward               | -0.6856777   |\n",
      "|    std                  | 9.17         |\n",
      "|    value_loss           | 55.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1098         |\n",
      "|    time_elapsed         | 21640        |\n",
      "|    total_timesteps      | 2248704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054875207 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 15860        |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    reward               | -0.92744136  |\n",
      "|    std                  | 9.18         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1099        |\n",
      "|    time_elapsed         | 21658       |\n",
      "|    total_timesteps      | 2250752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003959121 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 15870       |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | 13.539819   |\n",
      "|    std                  | 9.19        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1100         |\n",
      "|    time_elapsed         | 21677        |\n",
      "|    total_timesteps      | 2252800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039688027 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79           |\n",
      "|    n_updates            | 15880        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | 1.3675588    |\n",
      "|    std                  | 9.19         |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 21695       |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015718106 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 15890       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | 7.1538777   |\n",
      "|    std                  | 9.21        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1102         |\n",
      "|    time_elapsed         | 21714        |\n",
      "|    total_timesteps      | 2256896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046656183 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.6         |\n",
      "|    n_updates            | 15900        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 0.1660623    |\n",
      "|    std                  | 9.22         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1103        |\n",
      "|    time_elapsed         | 21733       |\n",
      "|    total_timesteps      | 2258944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004588736 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 15910       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | 1.308788    |\n",
      "|    std                  | 9.23        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4260841.96\n",
      "total_reward: 3260841.96\n",
      "total_cost: 265357.89\n",
      "total_trades: 63059\n",
      "Sharpe: 0.740\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1104        |\n",
      "|    time_elapsed         | 21751       |\n",
      "|    total_timesteps      | 2260992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010242875 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 15920       |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | 4.728081    |\n",
      "|    std                  | 9.24        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 21770       |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008031175 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 15930       |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | -2.880827   |\n",
      "|    std                  | 9.25        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1106        |\n",
      "|    time_elapsed         | 21788       |\n",
      "|    total_timesteps      | 2265088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006064219 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 15940       |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    reward               | -1.0012428  |\n",
      "|    std                  | 9.26        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1107         |\n",
      "|    time_elapsed         | 21807        |\n",
      "|    total_timesteps      | 2267136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075907186 |\n",
      "|    clip_fraction        | 0.0407       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55           |\n",
      "|    n_updates            | 15950        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | 0.21717142   |\n",
      "|    std                  | 9.28         |\n",
      "|    value_loss           | 67.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1108        |\n",
      "|    time_elapsed         | 21826       |\n",
      "|    total_timesteps      | 2269184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008492729 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 15960       |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    reward               | 1.2050505   |\n",
      "|    std                  | 9.29        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1109         |\n",
      "|    time_elapsed         | 21844        |\n",
      "|    total_timesteps      | 2271232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073331613 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.8         |\n",
      "|    n_updates            | 15970        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    reward               | 0.8601502    |\n",
      "|    std                  | 9.3          |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1110         |\n",
      "|    time_elapsed         | 21863        |\n",
      "|    total_timesteps      | 2273280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021660407 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 15980        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | 3.059269     |\n",
      "|    std                  | 9.3          |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1111        |\n",
      "|    time_elapsed         | 21882       |\n",
      "|    total_timesteps      | 2275328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012853199 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 15990       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -1.5402975  |\n",
      "|    std                  | 9.34        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1112        |\n",
      "|    time_elapsed         | 21901       |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004913763 |\n",
      "|    clip_fraction        | 0.0145      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.1        |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | -0.1089158  |\n",
      "|    std                  | 9.35        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1113         |\n",
      "|    time_elapsed         | 21920        |\n",
      "|    total_timesteps      | 2279424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057519055 |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.1         |\n",
      "|    n_updates            | 16010        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | 3.2338977    |\n",
      "|    std                  | 9.37         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1114         |\n",
      "|    time_elapsed         | 21938        |\n",
      "|    total_timesteps      | 2281472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052814824 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 16020        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | -0.07086866  |\n",
      "|    std                  | 9.38         |\n",
      "|    value_loss           | 62.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 21957       |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007199094 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 16030       |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    reward               | -1.3273278  |\n",
      "|    std                  | 9.39        |\n",
      "|    value_loss           | 76.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1116         |\n",
      "|    time_elapsed         | 21976        |\n",
      "|    total_timesteps      | 2285568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024634674 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.6         |\n",
      "|    n_updates            | 16040        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 2.12317      |\n",
      "|    std                  | 9.4          |\n",
      "|    value_loss           | 97.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1117         |\n",
      "|    time_elapsed         | 21995        |\n",
      "|    total_timesteps      | 2287616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087662265 |\n",
      "|    clip_fraction        | 0.0636       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.3         |\n",
      "|    n_updates            | 16050        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | 1.995494     |\n",
      "|    std                  | 9.42         |\n",
      "|    value_loss           | 93.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6062079.38\n",
      "total_reward: 5062079.38\n",
      "total_cost: 267088.07\n",
      "total_trades: 62271\n",
      "Sharpe: 0.932\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1118        |\n",
      "|    time_elapsed         | 22033       |\n",
      "|    total_timesteps      | 2289664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011838382 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.92        |\n",
      "|    n_updates            | 16060       |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    reward               | 0.048022255 |\n",
      "|    std                  | 9.46        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1119        |\n",
      "|    time_elapsed         | 22051       |\n",
      "|    total_timesteps      | 2291712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009636312 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 16070       |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    reward               | 0.4387408   |\n",
      "|    std                  | 9.47        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1120         |\n",
      "|    time_elapsed         | 22070        |\n",
      "|    total_timesteps      | 2293760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064192074 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.287        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 16080        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | 1.4656982    |\n",
      "|    std                  | 9.49         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 1121       |\n",
      "|    time_elapsed         | 22089      |\n",
      "|    total_timesteps      | 2295808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01339265 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -106       |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18         |\n",
      "|    n_updates            | 16090      |\n",
      "|    policy_gradient_loss | -0.00986   |\n",
      "|    reward               | -1.1795182 |\n",
      "|    std                  | 9.51       |\n",
      "|    value_loss           | 46.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 1122       |\n",
      "|    time_elapsed         | 22108      |\n",
      "|    total_timesteps      | 2297856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0093478  |\n",
      "|    clip_fraction        | 0.0682     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -106       |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.6       |\n",
      "|    n_updates            | 16100      |\n",
      "|    policy_gradient_loss | -0.00915   |\n",
      "|    reward               | -1.4813021 |\n",
      "|    std                  | 9.53       |\n",
      "|    value_loss           | 106        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1123         |\n",
      "|    time_elapsed         | 22127        |\n",
      "|    total_timesteps      | 2299904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073395986 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 16110        |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    reward               | 24.152864    |\n",
      "|    std                  | 9.54         |\n",
      "|    value_loss           | 99.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1124        |\n",
      "|    time_elapsed         | 22146       |\n",
      "|    total_timesteps      | 2301952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004714084 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 16120       |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | 2.1290748   |\n",
      "|    std                  | 9.54        |\n",
      "|    value_loss           | 98.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1125         |\n",
      "|    time_elapsed         | 22164        |\n",
      "|    total_timesteps      | 2304000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070216972 |\n",
      "|    clip_fraction        | 0.0373       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.77         |\n",
      "|    n_updates            | 16130        |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    reward               | 1.5133936    |\n",
      "|    std                  | 9.54         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1126        |\n",
      "|    time_elapsed         | 22183       |\n",
      "|    total_timesteps      | 2306048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004020228 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 16140       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 0.8515556   |\n",
      "|    std                  | 9.56        |\n",
      "|    value_loss           | 80.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1127         |\n",
      "|    time_elapsed         | 22202        |\n",
      "|    total_timesteps      | 2308096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026231897 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.1         |\n",
      "|    n_updates            | 16150        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | -1.0345044   |\n",
      "|    std                  | 9.56         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1128        |\n",
      "|    time_elapsed         | 22220       |\n",
      "|    total_timesteps      | 2310144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012780857 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 16160       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 4.5685077   |\n",
      "|    std                  | 9.58        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1129         |\n",
      "|    time_elapsed         | 22239        |\n",
      "|    total_timesteps      | 2312192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029814774 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 16170        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | -4.4119987   |\n",
      "|    std                  | 9.59         |\n",
      "|    value_loss           | 89.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1130         |\n",
      "|    time_elapsed         | 22257        |\n",
      "|    total_timesteps      | 2314240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060321735 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.9         |\n",
      "|    n_updates            | 16180        |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    reward               | -1.7256527   |\n",
      "|    std                  | 9.61         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1131        |\n",
      "|    time_elapsed         | 22276       |\n",
      "|    total_timesteps      | 2316288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006963009 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 16190       |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | -3.0897243  |\n",
      "|    std                  | 9.62        |\n",
      "|    value_loss           | 69.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4949961.42\n",
      "total_reward: 3949961.42\n",
      "total_cost: 218788.23\n",
      "total_trades: 59891\n",
      "Sharpe: 0.808\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1132        |\n",
      "|    time_elapsed         | 22295       |\n",
      "|    total_timesteps      | 2318336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009001103 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.9        |\n",
      "|    n_updates            | 16200       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 0.61032045  |\n",
      "|    std                  | 9.64        |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1133         |\n",
      "|    time_elapsed         | 22314        |\n",
      "|    total_timesteps      | 2320384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026142783 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.3         |\n",
      "|    n_updates            | 16210        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | 0.30674148   |\n",
      "|    std                  | 9.66         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1134         |\n",
      "|    time_elapsed         | 22334        |\n",
      "|    total_timesteps      | 2322432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070519038 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.7         |\n",
      "|    n_updates            | 16220        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    reward               | -1.7715975   |\n",
      "|    std                  | 9.67         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 22355       |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012665939 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 16230       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | -3.017602   |\n",
      "|    std                  | 9.7         |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1136         |\n",
      "|    time_elapsed         | 22373        |\n",
      "|    total_timesteps      | 2326528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021383122 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.6         |\n",
      "|    n_updates            | 16240        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    reward               | 1.1944834    |\n",
      "|    std                  | 9.7          |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 1137         |\n",
      "|    time_elapsed         | 22392        |\n",
      "|    total_timesteps      | 2328576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053977612 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.2         |\n",
      "|    n_updates            | 16250        |\n",
      "|    policy_gradient_loss | -0.00754     |\n",
      "|    reward               | -0.29577526  |\n",
      "|    std                  | 9.71         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 1138       |\n",
      "|    time_elapsed         | 22410      |\n",
      "|    total_timesteps      | 2330624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00919294 |\n",
      "|    clip_fraction        | 0.0468     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.568      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48.2       |\n",
      "|    n_updates            | 16260      |\n",
      "|    policy_gradient_loss | -0.00711   |\n",
      "|    reward               | 2.6014967  |\n",
      "|    std                  | 9.72       |\n",
      "|    value_loss           | 70.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 22429       |\n",
      "|    total_timesteps      | 2332672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008554823 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.7        |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    reward               | 1.0469657   |\n",
      "|    std                  | 9.74        |\n",
      "|    value_loss           | 85.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 22448       |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004879785 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.5        |\n",
      "|    n_updates            | 16280       |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | -1.5424317  |\n",
      "|    std                  | 9.74        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1141        |\n",
      "|    time_elapsed         | 22466       |\n",
      "|    total_timesteps      | 2336768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007906262 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.8        |\n",
      "|    n_updates            | 16290       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 1.4427841   |\n",
      "|    std                  | 9.75        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 22485       |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009348674 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 16300       |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    reward               | -3.7611263  |\n",
      "|    std                  | 9.78        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1143        |\n",
      "|    time_elapsed         | 22504       |\n",
      "|    total_timesteps      | 2340864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005790136 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.0721      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.5        |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -0.46026734 |\n",
      "|    std                  | 9.78        |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 22522       |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003260333 |\n",
      "|    clip_fraction        | 0.00591     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.6        |\n",
      "|    n_updates            | 16320       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | 4.8250995   |\n",
      "|    std                  | 9.79        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1145        |\n",
      "|    time_elapsed         | 22541       |\n",
      "|    total_timesteps      | 2344960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010788422 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 16330       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -2.0639365  |\n",
      "|    std                  | 9.8         |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4602844.65\n",
      "total_reward: 3602844.65\n",
      "total_cost: 274496.86\n",
      "total_trades: 63245\n",
      "Sharpe: 0.751\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1146        |\n",
      "|    time_elapsed         | 22560       |\n",
      "|    total_timesteps      | 2347008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00649287  |\n",
      "|    clip_fraction        | 0.0386      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | -0.36933908 |\n",
      "|    std                  | 9.81        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1147         |\n",
      "|    time_elapsed         | 22579        |\n",
      "|    total_timesteps      | 2349056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066959527 |\n",
      "|    clip_fraction        | 0.0451       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.8         |\n",
      "|    n_updates            | 16350        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    reward               | 20.386755    |\n",
      "|    std                  | 9.83         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1148         |\n",
      "|    time_elapsed         | 22598        |\n",
      "|    total_timesteps      | 2351104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044603646 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.7         |\n",
      "|    n_updates            | 16360        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | 3.461189     |\n",
      "|    std                  | 9.85         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1149        |\n",
      "|    time_elapsed         | 22616       |\n",
      "|    total_timesteps      | 2353152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008967233 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    reward               | 0.6964955   |\n",
      "|    std                  | 9.87        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1150         |\n",
      "|    time_elapsed         | 22635        |\n",
      "|    total_timesteps      | 2355200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035642907 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.2         |\n",
      "|    n_updates            | 16380        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | 0.6297256    |\n",
      "|    std                  | 9.89         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1151         |\n",
      "|    time_elapsed         | 22653        |\n",
      "|    total_timesteps      | 2357248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022536027 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 16390        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    reward               | -6.476291    |\n",
      "|    std                  | 9.9          |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 22672       |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009789415 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 16400       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 8.047333    |\n",
      "|    std                  | 9.93        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1153         |\n",
      "|    time_elapsed         | 22691        |\n",
      "|    total_timesteps      | 2361344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031817383 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.3         |\n",
      "|    n_updates            | 16410        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | -7.9703383   |\n",
      "|    std                  | 9.93         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1154        |\n",
      "|    time_elapsed         | 22710       |\n",
      "|    total_timesteps      | 2363392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005791624 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.9        |\n",
      "|    n_updates            | 16420       |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | -15.522752  |\n",
      "|    std                  | 9.94        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1155        |\n",
      "|    time_elapsed         | 22729       |\n",
      "|    total_timesteps      | 2365440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005357624 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 16430       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | -1.2112739  |\n",
      "|    std                  | 9.94        |\n",
      "|    value_loss           | 99.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 22748       |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007986282 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 16440       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | 0.862139    |\n",
      "|    std                  | 9.97        |\n",
      "|    value_loss           | 76.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1157         |\n",
      "|    time_elapsed         | 22767        |\n",
      "|    total_timesteps      | 2369536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049697286 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.7         |\n",
      "|    n_updates            | 16450        |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    reward               | 0.55491304   |\n",
      "|    std                  | 9.99         |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1158         |\n",
      "|    time_elapsed         | 22785        |\n",
      "|    total_timesteps      | 2371584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016571532 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 16460        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | 1.3888925    |\n",
      "|    std                  | 9.99         |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 22804       |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013141928 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 16470       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | 0.8870361   |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3902446.59\n",
      "total_reward: 2902446.59\n",
      "total_cost: 244675.31\n",
      "total_trades: 61298\n",
      "Sharpe: 0.666\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 22823       |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005680982 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44          |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 0.028792236 |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1161         |\n",
      "|    time_elapsed         | 22842        |\n",
      "|    total_timesteps      | 2377728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012769836 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.6         |\n",
      "|    n_updates            | 16490        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | 3.7035298    |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1162         |\n",
      "|    time_elapsed         | 22860        |\n",
      "|    total_timesteps      | 2379776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072632087 |\n",
      "|    clip_fraction        | 0.0454       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.3         |\n",
      "|    n_updates            | 16500        |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    reward               | 4.588598     |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 55.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1163        |\n",
      "|    time_elapsed         | 22879       |\n",
      "|    total_timesteps      | 2381824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007994715 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 16510       |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    reward               | 0.2924434   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 76.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1164         |\n",
      "|    time_elapsed         | 22898        |\n",
      "|    total_timesteps      | 2383872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023801737 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.4         |\n",
      "|    n_updates            | 16520        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | -0.15579274  |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1165         |\n",
      "|    time_elapsed         | 22916        |\n",
      "|    total_timesteps      | 2385920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021966707 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.9         |\n",
      "|    n_updates            | 16530        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | 2.4875262    |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1166        |\n",
      "|    time_elapsed         | 22935       |\n",
      "|    total_timesteps      | 2387968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012706978 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.16        |\n",
      "|    n_updates            | 16540       |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -0.65151507 |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1167         |\n",
      "|    time_elapsed         | 22954        |\n",
      "|    total_timesteps      | 2390016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032265084 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.7         |\n",
      "|    n_updates            | 16550        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | -0.6071118   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1168        |\n",
      "|    time_elapsed         | 22973       |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002761682 |\n",
      "|    clip_fraction        | 0.00444     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.3        |\n",
      "|    n_updates            | 16560       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 2.023592    |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 22992       |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008943807 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 16570       |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    reward               | 4.4089136   |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1170         |\n",
      "|    time_elapsed         | 23012        |\n",
      "|    total_timesteps      | 2396160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072517116 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.8         |\n",
      "|    n_updates            | 16580        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    reward               | 2.3116746    |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 80.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 23031       |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006110974 |\n",
      "|    clip_fraction        | 0.0322      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 16590       |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | -19.286436  |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1172        |\n",
      "|    time_elapsed         | 23049       |\n",
      "|    total_timesteps      | 2400256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005598071 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 16600       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 1.6382791   |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 23068       |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006854674 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 16610       |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    reward               | 2.9668572   |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4074397.68\n",
      "total_reward: 3074397.68\n",
      "total_cost: 218910.95\n",
      "total_trades: 58786\n",
      "Sharpe: 0.723\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1174         |\n",
      "|    time_elapsed         | 23087        |\n",
      "|    total_timesteps      | 2404352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028243563 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.8         |\n",
      "|    n_updates            | 16620        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -0.36350232  |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 88.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1175         |\n",
      "|    time_elapsed         | 23106        |\n",
      "|    total_timesteps      | 2406400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054392843 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 16630        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    reward               | -5.924116    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 80.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1176        |\n",
      "|    time_elapsed         | 23125       |\n",
      "|    total_timesteps      | 2408448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011589822 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.82        |\n",
      "|    n_updates            | 16640       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 0.19337988  |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1177         |\n",
      "|    time_elapsed         | 23144        |\n",
      "|    total_timesteps      | 2410496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033362966 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 16650        |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    reward               | 0.31273353   |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 70           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1178         |\n",
      "|    time_elapsed         | 23163        |\n",
      "|    total_timesteps      | 2412544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017908113 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 16660        |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    reward               | -7.1893706   |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 81           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1179         |\n",
      "|    time_elapsed         | 23182        |\n",
      "|    total_timesteps      | 2414592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057214256 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 16670        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 2.7877557    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 53.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1180         |\n",
      "|    time_elapsed         | 23200        |\n",
      "|    total_timesteps      | 2416640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075789043 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 16680        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    reward               | 0.16637257   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 79.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1181         |\n",
      "|    time_elapsed         | 23219        |\n",
      "|    total_timesteps      | 2418688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032769593 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.4         |\n",
      "|    n_updates            | 16690        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | 0.35526213   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1182        |\n",
      "|    time_elapsed         | 23238       |\n",
      "|    total_timesteps      | 2420736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002089085 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 16700       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -1.1281546  |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 23257       |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009708187 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.0537      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.28        |\n",
      "|    n_updates            | 16710       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -2.8846529  |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1184         |\n",
      "|    time_elapsed         | 23275        |\n",
      "|    total_timesteps      | 2424832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043637627 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.4         |\n",
      "|    n_updates            | 16720        |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    reward               | -0.051441107 |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1185         |\n",
      "|    time_elapsed         | 23294        |\n",
      "|    total_timesteps      | 2426880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058200806 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 16730        |\n",
      "|    policy_gradient_loss | -0.00733     |\n",
      "|    reward               | -2.1848104   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 99           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1186         |\n",
      "|    time_elapsed         | 23313        |\n",
      "|    total_timesteps      | 2428928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067256587 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 16740        |\n",
      "|    policy_gradient_loss | -0.00846     |\n",
      "|    reward               | -1.3930107   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1187        |\n",
      "|    time_elapsed         | 23331       |\n",
      "|    total_timesteps      | 2430976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006182424 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 16750       |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    reward               | -1.125191   |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4579098.61\n",
      "total_reward: 3579098.61\n",
      "total_cost: 202117.38\n",
      "total_trades: 58018\n",
      "Sharpe: 0.809\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 23351       |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006074971 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 16760       |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -1.514328   |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1189         |\n",
      "|    time_elapsed         | 23369        |\n",
      "|    total_timesteps      | 2435072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046330877 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.1         |\n",
      "|    n_updates            | 16770        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    reward               | -0.24504153  |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 23388       |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011631214 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 16780       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.48123956  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1191         |\n",
      "|    time_elapsed         | 23407        |\n",
      "|    total_timesteps      | 2439168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033117514 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57           |\n",
      "|    n_updates            | 16790        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | -1.9066228   |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1192         |\n",
      "|    time_elapsed         | 23426        |\n",
      "|    total_timesteps      | 2441216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054518576 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.1         |\n",
      "|    n_updates            | 16800        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    reward               | -2.8554506   |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1193       |\n",
      "|    time_elapsed         | 23445      |\n",
      "|    total_timesteps      | 2443264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00686107 |\n",
      "|    clip_fraction        | 0.0385     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -109       |\n",
      "|    explained_variance   | 0.602      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 16810      |\n",
      "|    policy_gradient_loss | -0.00744   |\n",
      "|    reward               | 0.7864911  |\n",
      "|    std                  | 10.5       |\n",
      "|    value_loss           | 42.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1194         |\n",
      "|    time_elapsed         | 23464        |\n",
      "|    total_timesteps      | 2445312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047206683 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.7         |\n",
      "|    n_updates            | 16820        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | -2.2185268   |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 72.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1195         |\n",
      "|    time_elapsed         | 23483        |\n",
      "|    total_timesteps      | 2447360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059002377 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 16830        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    reward               | 5.3180747    |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 73.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1196        |\n",
      "|    time_elapsed         | 23501       |\n",
      "|    total_timesteps      | 2449408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009007923 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 16840       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | -1.4938011  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 23520       |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008837091 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.21        |\n",
      "|    n_updates            | 16850       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | -0.7930986  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1198        |\n",
      "|    time_elapsed         | 23539       |\n",
      "|    total_timesteps      | 2453504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002333426 |\n",
      "|    clip_fraction        | 0.00464     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.6        |\n",
      "|    n_updates            | 16860       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | -0.70021474 |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 95.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1199         |\n",
      "|    time_elapsed         | 23558        |\n",
      "|    total_timesteps      | 2455552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045326054 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 16870        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -17.89151    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1200        |\n",
      "|    time_elapsed         | 23577       |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009703267 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.39        |\n",
      "|    n_updates            | 16880       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 1.5734512   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1201        |\n",
      "|    time_elapsed         | 23596       |\n",
      "|    total_timesteps      | 2459648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006008711 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.1        |\n",
      "|    n_updates            | 16890       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | 2.0456612   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 67.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1202        |\n",
      "|    time_elapsed         | 23614       |\n",
      "|    total_timesteps      | 2461696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006208174 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 16900       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | -2.7772222  |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 78.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4559881.63\n",
      "total_reward: 3559881.63\n",
      "total_cost: 186714.72\n",
      "total_trades: 57527\n",
      "Sharpe: 0.763\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1203         |\n",
      "|    time_elapsed         | 23633        |\n",
      "|    total_timesteps      | 2463744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070345025 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 16910        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    reward               | 10.173916    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 51.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1204        |\n",
      "|    time_elapsed         | 23652       |\n",
      "|    total_timesteps      | 2465792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010355678 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 16920       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.8281772   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1205       |\n",
      "|    time_elapsed         | 23670      |\n",
      "|    total_timesteps      | 2467840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00526586 |\n",
      "|    clip_fraction        | 0.0125     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -109       |\n",
      "|    explained_variance   | 0.799      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.5       |\n",
      "|    n_updates            | 16930      |\n",
      "|    policy_gradient_loss | -0.00449   |\n",
      "|    reward               | 0.18708403 |\n",
      "|    std                  | 10.7       |\n",
      "|    value_loss           | 87.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1206        |\n",
      "|    time_elapsed         | 23689       |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003557167 |\n",
      "|    clip_fraction        | 0.00557     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47          |\n",
      "|    n_updates            | 16940       |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    reward               | 1.4795535   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 80.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1207        |\n",
      "|    time_elapsed         | 23708       |\n",
      "|    total_timesteps      | 2471936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012430768 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 2.2176893   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1208         |\n",
      "|    time_elapsed         | 23727        |\n",
      "|    total_timesteps      | 2473984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033035455 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 16960        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | -1.0935115   |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 72.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1209        |\n",
      "|    time_elapsed         | 23746       |\n",
      "|    total_timesteps      | 2476032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004482514 |\n",
      "|    clip_fraction        | 0.011       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 16970       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -5.367334   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 85.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1210         |\n",
      "|    time_elapsed         | 23765        |\n",
      "|    total_timesteps      | 2478080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054154736 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 16980        |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    reward               | -4.045863    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1211         |\n",
      "|    time_elapsed         | 23784        |\n",
      "|    total_timesteps      | 2480128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053869463 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.3         |\n",
      "|    n_updates            | 16990        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | 0.076665066  |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 74.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1212         |\n",
      "|    time_elapsed         | 23803        |\n",
      "|    total_timesteps      | 2482176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059212176 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.8         |\n",
      "|    n_updates            | 17000        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    reward               | 14.331244    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1213         |\n",
      "|    time_elapsed         | 23822        |\n",
      "|    total_timesteps      | 2484224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021701357 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.5         |\n",
      "|    n_updates            | 17010        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | -0.5582517   |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 97.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1214        |\n",
      "|    time_elapsed         | 23841       |\n",
      "|    total_timesteps      | 2486272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011658503 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 17020       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 2.7403982   |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 104           |\n",
      "|    iterations           | 1215          |\n",
      "|    time_elapsed         | 23860         |\n",
      "|    total_timesteps      | 2488320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0034076055  |\n",
      "|    clip_fraction        | 0.00869       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -109          |\n",
      "|    explained_variance   | 0.84          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31            |\n",
      "|    n_updates            | 17030         |\n",
      "|    policy_gradient_loss | -0.00452      |\n",
      "|    reward               | -0.0069337315 |\n",
      "|    std                  | 10.8          |\n",
      "|    value_loss           | 75.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1216         |\n",
      "|    time_elapsed         | 23879        |\n",
      "|    total_timesteps      | 2490368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025184737 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 17040        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | 0.08470721   |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 86.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3758798.92\n",
      "total_reward: 2758798.92\n",
      "total_cost: 168723.74\n",
      "total_trades: 55666\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 23897       |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009120525 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 17050       |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | 1.4259458   |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1218         |\n",
      "|    time_elapsed         | 23916        |\n",
      "|    total_timesteps      | 2494464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056182668 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 17060        |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    reward               | 3.7336733    |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 65.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1219        |\n",
      "|    time_elapsed         | 23935       |\n",
      "|    total_timesteps      | 2496512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005556044 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 17070       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -1.9421563  |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 77.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1220         |\n",
      "|    time_elapsed         | 23955        |\n",
      "|    total_timesteps      | 2498560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057761976 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 17080        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | -7.3741517   |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 47.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1221       |\n",
      "|    time_elapsed         | 23974      |\n",
      "|    total_timesteps      | 2500608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00945529 |\n",
      "|    clip_fraction        | 0.0883     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -110       |\n",
      "|    explained_variance   | 0.803      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.8       |\n",
      "|    n_updates            | 17090      |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    reward               | -0.838383  |\n",
      "|    std                  | 10.9       |\n",
      "|    value_loss           | 44.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1222        |\n",
      "|    time_elapsed         | 23993       |\n",
      "|    total_timesteps      | 2502656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00561407  |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.3        |\n",
      "|    n_updates            | 17100       |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    reward               | -0.25034207 |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1223         |\n",
      "|    time_elapsed         | 24012        |\n",
      "|    total_timesteps      | 2504704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031376453 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.9         |\n",
      "|    n_updates            | 17110        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | -2.248233    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1224        |\n",
      "|    time_elapsed         | 24031       |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013148213 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 17120       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.71973324 |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1225         |\n",
      "|    time_elapsed         | 24050        |\n",
      "|    total_timesteps      | 2508800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008024205 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.9         |\n",
      "|    n_updates            | 17130        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    reward               | 0.2513405    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 97.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1226        |\n",
      "|    time_elapsed         | 24069       |\n",
      "|    total_timesteps      | 2510848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002895657 |\n",
      "|    clip_fraction        | 0.00327     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 17140       |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    reward               | -4.670328   |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1227        |\n",
      "|    time_elapsed         | 24088       |\n",
      "|    total_timesteps      | 2512896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006486884 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 17150       |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | 0.34224585  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1228         |\n",
      "|    time_elapsed         | 24107        |\n",
      "|    total_timesteps      | 2514944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022787112 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 17160        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | 4.221098     |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 70.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1229         |\n",
      "|    time_elapsed         | 24126        |\n",
      "|    total_timesteps      | 2516992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035086898 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.2         |\n",
      "|    n_updates            | 17170        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | 0.16761258   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 82.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1230         |\n",
      "|    time_elapsed         | 24145        |\n",
      "|    total_timesteps      | 2519040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031235355 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 17180        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | -2.2244484   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4102447.59\n",
      "total_reward: 3102447.59\n",
      "total_cost: 148057.67\n",
      "total_trades: 54245\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1231        |\n",
      "|    time_elapsed         | 24164       |\n",
      "|    total_timesteps      | 2521088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007999893 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.51        |\n",
      "|    n_updates            | 17190       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | 3.0489926   |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1232         |\n",
      "|    time_elapsed         | 24183        |\n",
      "|    total_timesteps      | 2523136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016191875 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 17200        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 0.36585534   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 88.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1233         |\n",
      "|    time_elapsed         | 24201        |\n",
      "|    total_timesteps      | 2525184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040876474 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.5         |\n",
      "|    n_updates            | 17210        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    reward               | -3.4119334   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1234         |\n",
      "|    time_elapsed         | 24220        |\n",
      "|    total_timesteps      | 2527232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061769458 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 17220        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    reward               | -0.52309114  |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1235         |\n",
      "|    time_elapsed         | 24239        |\n",
      "|    total_timesteps      | 2529280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045632822 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 17230        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -1.5683426   |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 84           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1236         |\n",
      "|    time_elapsed         | 24258        |\n",
      "|    total_timesteps      | 2531328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009376611 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.1         |\n",
      "|    n_updates            | 17240        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | 1.658239     |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1237         |\n",
      "|    time_elapsed         | 24276        |\n",
      "|    total_timesteps      | 2533376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021201414 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 17250        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | 1.8069685    |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 96.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1238        |\n",
      "|    time_elapsed         | 24296       |\n",
      "|    total_timesteps      | 2535424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011217751 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 17260       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -1.392398   |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1239        |\n",
      "|    time_elapsed         | 24315       |\n",
      "|    total_timesteps      | 2537472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006755174 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 17270       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 0.21774934  |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1240        |\n",
      "|    time_elapsed         | 24333       |\n",
      "|    total_timesteps      | 2539520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005349067 |\n",
      "|    clip_fraction        | 0.0267      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.9        |\n",
      "|    n_updates            | 17280       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 0.162823    |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1241         |\n",
      "|    time_elapsed         | 24352        |\n",
      "|    total_timesteps      | 2541568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077352044 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 17290        |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    reward               | 4.2700677    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 35.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1242        |\n",
      "|    time_elapsed         | 24371       |\n",
      "|    total_timesteps      | 2543616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007691622 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 17300       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 3.8788545   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 90.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1243         |\n",
      "|    time_elapsed         | 24390        |\n",
      "|    total_timesteps      | 2545664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025049224 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.9         |\n",
      "|    n_updates            | 17310        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | -11.47043    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1244         |\n",
      "|    time_elapsed         | 24410        |\n",
      "|    total_timesteps      | 2547712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025809496 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 17320        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -1.366882    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 54.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4172970.75\n",
      "total_reward: 3172970.75\n",
      "total_cost: 161782.25\n",
      "total_trades: 55000\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1245        |\n",
      "|    time_elapsed         | 24428       |\n",
      "|    total_timesteps      | 2549760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008885772 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 17330       |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    reward               | 1.8003498   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1246       |\n",
      "|    time_elapsed         | 24447      |\n",
      "|    total_timesteps      | 2551808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00544966 |\n",
      "|    clip_fraction        | 0.015      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.791      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.7       |\n",
      "|    n_updates            | 17340      |\n",
      "|    policy_gradient_loss | -0.0069    |\n",
      "|    reward               | -1.1835511 |\n",
      "|    std                  | 11.2       |\n",
      "|    value_loss           | 83.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1247         |\n",
      "|    time_elapsed         | 24466        |\n",
      "|    total_timesteps      | 2553856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024567235 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.8         |\n",
      "|    n_updates            | 17350        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | -3.9362068   |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 85.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1248        |\n",
      "|    time_elapsed         | 24485       |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011750371 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 17360       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    reward               | -0.18197781 |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1249         |\n",
      "|    time_elapsed         | 24504        |\n",
      "|    total_timesteps      | 2557952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035567903 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.9         |\n",
      "|    n_updates            | 17370        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | 1.1334265    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 80.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1250        |\n",
      "|    time_elapsed         | 24523       |\n",
      "|    total_timesteps      | 2560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004317737 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.1        |\n",
      "|    n_updates            | 17380       |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | 2.491088    |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 96          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1251         |\n",
      "|    time_elapsed         | 24542        |\n",
      "|    total_timesteps      | 2562048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045414725 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 17390        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | 5.879339     |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 49.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1252        |\n",
      "|    time_elapsed         | 24561       |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007397767 |\n",
      "|    clip_fraction        | 0.0368      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.6        |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | 2.3071525   |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 76.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1253         |\n",
      "|    time_elapsed         | 24580        |\n",
      "|    total_timesteps      | 2566144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032251119 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 17410        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | -1.5962014   |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1254        |\n",
      "|    time_elapsed         | 24598       |\n",
      "|    total_timesteps      | 2568192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002976321 |\n",
      "|    clip_fraction        | 0.00234     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 17420       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    reward               | 1.3296139   |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 97          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1255         |\n",
      "|    time_elapsed         | 24618        |\n",
      "|    total_timesteps      | 2570240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067287963 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.73         |\n",
      "|    n_updates            | 17430        |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    reward               | -0.2787758   |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1256         |\n",
      "|    time_elapsed         | 24636        |\n",
      "|    total_timesteps      | 2572288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067404183 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 17440        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    reward               | -0.16993491  |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 75.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1257         |\n",
      "|    time_elapsed         | 24655        |\n",
      "|    total_timesteps      | 2574336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029142795 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.2         |\n",
      "|    n_updates            | 17450        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | -8.660083    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 74.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1258       |\n",
      "|    time_elapsed         | 24674      |\n",
      "|    total_timesteps      | 2576384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0070744  |\n",
      "|    clip_fraction        | 0.024      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.687      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.7       |\n",
      "|    n_updates            | 17460      |\n",
      "|    policy_gradient_loss | -0.00771   |\n",
      "|    reward               | 0.86560315 |\n",
      "|    std                  | 11.4       |\n",
      "|    value_loss           | 30.2       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4041633.64\n",
      "total_reward: 3041633.64\n",
      "total_cost: 149221.45\n",
      "total_trades: 54350\n",
      "Sharpe: 0.698\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 24693       |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006656477 |\n",
      "|    clip_fraction        | 0.0265      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 17470       |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | 0.37280932  |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1260         |\n",
      "|    time_elapsed         | 24712        |\n",
      "|    total_timesteps      | 2580480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042618047 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.1         |\n",
      "|    n_updates            | 17480        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | 37.097816    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 83.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 24730       |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005147079 |\n",
      "|    clip_fraction        | 0.0102      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 17490       |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | -1.6314003  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 24749       |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008814011 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.04        |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    reward               | 5.2016053   |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1263        |\n",
      "|    time_elapsed         | 24768       |\n",
      "|    total_timesteps      | 2586624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004054294 |\n",
      "|    clip_fraction        | 0.00933     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 17510       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 0.59412986  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1264        |\n",
      "|    time_elapsed         | 24787       |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004762667 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.9        |\n",
      "|    n_updates            | 17520       |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | -10.586465  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 88.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1265        |\n",
      "|    time_elapsed         | 24806       |\n",
      "|    total_timesteps      | 2590720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012374697 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 17530       |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    reward               | 0.62441754  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1266        |\n",
      "|    time_elapsed         | 24825       |\n",
      "|    total_timesteps      | 2592768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002817074 |\n",
      "|    clip_fraction        | 0.0085      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 17540       |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | 2.924174    |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 72.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1267        |\n",
      "|    time_elapsed         | 24844       |\n",
      "|    total_timesteps      | 2594816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002810579 |\n",
      "|    clip_fraction        | 0.00288     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 17550       |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | -4.4576993  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 70.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1268         |\n",
      "|    time_elapsed         | 24863        |\n",
      "|    total_timesteps      | 2596864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040134685 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 17560        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | -1.0862885   |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1269        |\n",
      "|    time_elapsed         | 24883       |\n",
      "|    total_timesteps      | 2598912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008828761 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.37        |\n",
      "|    n_updates            | 17570       |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    reward               | -0.7967088  |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1270        |\n",
      "|    time_elapsed         | 24901       |\n",
      "|    total_timesteps      | 2600960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004191561 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 17580       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | 1.318065    |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 99.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1271         |\n",
      "|    time_elapsed         | 24921        |\n",
      "|    total_timesteps      | 2603008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072675087 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.4         |\n",
      "|    n_updates            | 17590        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | 2.5264523    |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 72.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1272        |\n",
      "|    time_elapsed         | 24939       |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012988163 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.89        |\n",
      "|    n_updates            | 17600       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 1.0582801   |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4736303.06\n",
      "total_reward: 3736303.06\n",
      "total_cost: 206191.16\n",
      "total_trades: 58656\n",
      "Sharpe: 0.784\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1273         |\n",
      "|    time_elapsed         | 24958        |\n",
      "|    total_timesteps      | 2607104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070349155 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.7         |\n",
      "|    n_updates            | 17610        |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    reward               | 1.355223     |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 67.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1274         |\n",
      "|    time_elapsed         | 24977        |\n",
      "|    total_timesteps      | 2609152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048538316 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 17620        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    reward               | -0.43878886  |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 95.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1275        |\n",
      "|    time_elapsed         | 24996       |\n",
      "|    total_timesteps      | 2611200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005063978 |\n",
      "|    clip_fraction        | 0.00864     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 17630       |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 2.5384526   |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1276       |\n",
      "|    time_elapsed         | 25016      |\n",
      "|    total_timesteps      | 2613248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00930413 |\n",
      "|    clip_fraction        | 0.0507     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -112       |\n",
      "|    explained_variance   | 0.754      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.3       |\n",
      "|    n_updates            | 17640      |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    reward               | 0.93207914 |\n",
      "|    std                  | 11.8       |\n",
      "|    value_loss           | 51.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1277        |\n",
      "|    time_elapsed         | 25034       |\n",
      "|    total_timesteps      | 2615296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003587334 |\n",
      "|    clip_fraction        | 0.0101      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 17650       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | 0.6056546   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1278        |\n",
      "|    time_elapsed         | 25053       |\n",
      "|    total_timesteps      | 2617344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005875229 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.1        |\n",
      "|    n_updates            | 17660       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 1.415502    |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 96.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1279         |\n",
      "|    time_elapsed         | 25073        |\n",
      "|    total_timesteps      | 2619392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013566669  |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 17670        |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    reward               | -0.009853049 |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1280         |\n",
      "|    time_elapsed         | 25092        |\n",
      "|    total_timesteps      | 2621440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014805649 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29           |\n",
      "|    n_updates            | 17680        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | 0.22317468   |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 75.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1281        |\n",
      "|    time_elapsed         | 25111       |\n",
      "|    total_timesteps      | 2623488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005410305 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 17690       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | 1.4404529   |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1282        |\n",
      "|    time_elapsed         | 25130       |\n",
      "|    total_timesteps      | 2625536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009489542 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.0206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 17700       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 1.9012682   |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1283       |\n",
      "|    time_elapsed         | 25149      |\n",
      "|    total_timesteps      | 2627584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00574978 |\n",
      "|    clip_fraction        | 0.0282     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -112       |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.2       |\n",
      "|    n_updates            | 17710      |\n",
      "|    policy_gradient_loss | -0.00651   |\n",
      "|    reward               | -2.92453   |\n",
      "|    std                  | 11.9       |\n",
      "|    value_loss           | 134        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1284         |\n",
      "|    time_elapsed         | 25168        |\n",
      "|    total_timesteps      | 2629632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032154797 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.6         |\n",
      "|    n_updates            | 17720        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | -16.621628   |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1285         |\n",
      "|    time_elapsed         | 25187        |\n",
      "|    total_timesteps      | 2631680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024410186 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 17730        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 3.229987     |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 80.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1286        |\n",
      "|    time_elapsed         | 25207       |\n",
      "|    total_timesteps      | 2633728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007091915 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 17740       |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | 1.5846007   |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4518036.40\n",
      "total_reward: 3518036.40\n",
      "total_cost: 192131.13\n",
      "total_trades: 57186\n",
      "Sharpe: 0.761\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1287         |\n",
      "|    time_elapsed         | 25226        |\n",
      "|    total_timesteps      | 2635776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039161304 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.8         |\n",
      "|    n_updates            | 17750        |\n",
      "|    policy_gradient_loss | -0.0072      |\n",
      "|    reward               | 0.38952386   |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1288         |\n",
      "|    time_elapsed         | 25245        |\n",
      "|    total_timesteps      | 2637824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014691572 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.8         |\n",
      "|    n_updates            | 17760        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | 5.3693886    |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 92.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 25264       |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009589913 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.52        |\n",
      "|    n_updates            | 17770       |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    reward               | -0.3725138  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1290        |\n",
      "|    time_elapsed         | 25283       |\n",
      "|    total_timesteps      | 2641920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001620193 |\n",
      "|    clip_fraction        | 0.00659     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 17780       |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    reward               | -0.8053048  |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 82.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1291         |\n",
      "|    time_elapsed         | 25302        |\n",
      "|    total_timesteps      | 2643968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056788353 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.3         |\n",
      "|    n_updates            | 17790        |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    reward               | 3.3813305    |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 76.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1292        |\n",
      "|    time_elapsed         | 25321       |\n",
      "|    total_timesteps      | 2646016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006566095 |\n",
      "|    clip_fraction        | 0.024       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 17800       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 1.6396751   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 25340       |\n",
      "|    total_timesteps      | 2648064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006929134 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 17810       |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | -3.5981991  |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 51.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1294         |\n",
      "|    time_elapsed         | 25359        |\n",
      "|    total_timesteps      | 2650112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034561418 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.6         |\n",
      "|    n_updates            | 17820        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | 0.16739091   |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 104           |\n",
      "|    iterations           | 1295          |\n",
      "|    time_elapsed         | 25378         |\n",
      "|    total_timesteps      | 2652160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068251777 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -113          |\n",
      "|    explained_variance   | 0.802         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 36            |\n",
      "|    n_updates            | 17830         |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    reward               | -2.0115514    |\n",
      "|    std                  | 12            |\n",
      "|    value_loss           | 73.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1296         |\n",
      "|    time_elapsed         | 25397        |\n",
      "|    total_timesteps      | 2654208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064985626 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.79         |\n",
      "|    n_updates            | 17840        |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    reward               | -1.6675193   |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1297        |\n",
      "|    time_elapsed         | 25416       |\n",
      "|    total_timesteps      | 2656256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006785304 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 17850       |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | 3.2160947   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 63.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1298       |\n",
      "|    time_elapsed         | 25435      |\n",
      "|    total_timesteps      | 2658304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00395177 |\n",
      "|    clip_fraction        | 0.00981    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -113       |\n",
      "|    explained_variance   | 0.761      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.7       |\n",
      "|    n_updates            | 17860      |\n",
      "|    policy_gradient_loss | -0.00536   |\n",
      "|    reward               | 2.733923   |\n",
      "|    std                  | 12         |\n",
      "|    value_loss           | 86.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1299        |\n",
      "|    time_elapsed         | 25454       |\n",
      "|    total_timesteps      | 2660352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007512306 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 17870       |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    reward               | -1.056065   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1300        |\n",
      "|    time_elapsed         | 25473       |\n",
      "|    total_timesteps      | 2662400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007187846 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.3        |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | -0.7037143  |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 99.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1301         |\n",
      "|    time_elapsed         | 25492        |\n",
      "|    total_timesteps      | 2664448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023774782 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 17890        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -23.022692   |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4893432.35\n",
      "total_reward: 3893432.35\n",
      "total_cost: 198715.21\n",
      "total_trades: 57825\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 104           |\n",
      "|    iterations           | 1302          |\n",
      "|    time_elapsed         | 25511         |\n",
      "|    total_timesteps      | 2666496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071971305 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -113          |\n",
      "|    explained_variance   | 0.472         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 49.5          |\n",
      "|    n_updates            | 17900         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | 0.27464595    |\n",
      "|    std                  | 12.1          |\n",
      "|    value_loss           | 144           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1303        |\n",
      "|    time_elapsed         | 25531       |\n",
      "|    total_timesteps      | 2668544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011588042 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.22        |\n",
      "|    n_updates            | 17910       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    reward               | 0.033447746 |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1304        |\n",
      "|    time_elapsed         | 25550       |\n",
      "|    total_timesteps      | 2670592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002786203 |\n",
      "|    clip_fraction        | 0.00645     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 17920       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | -1.2863313  |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1305         |\n",
      "|    time_elapsed         | 25568        |\n",
      "|    total_timesteps      | 2672640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056755035 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 17930        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | 1.5795823    |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 25588       |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004805262 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 17940       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | -1.273907   |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1307         |\n",
      "|    time_elapsed         | 25606        |\n",
      "|    total_timesteps      | 2676736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047683544 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.766        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.4         |\n",
      "|    n_updates            | 17950        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | 4.7424374    |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 87.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1308         |\n",
      "|    time_elapsed         | 25626        |\n",
      "|    total_timesteps      | 2678784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019411555 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.7         |\n",
      "|    n_updates            | 17960        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -6.0087347   |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1309        |\n",
      "|    time_elapsed         | 25645       |\n",
      "|    total_timesteps      | 2680832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007927912 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 17970       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | -0.71237355 |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 56.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 25664       |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010666465 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 17980       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.96895915  |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1311         |\n",
      "|    time_elapsed         | 25682        |\n",
      "|    total_timesteps      | 2684928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039539747 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.4         |\n",
      "|    n_updates            | 17990        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    reward               | -0.4267787   |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 104           |\n",
      "|    iterations           | 1312          |\n",
      "|    time_elapsed         | 25701         |\n",
      "|    total_timesteps      | 2686976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043245114 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -113          |\n",
      "|    explained_variance   | 0.628         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 64.8          |\n",
      "|    n_updates            | 18000         |\n",
      "|    policy_gradient_loss | -0.000947     |\n",
      "|    reward               | 2.3312788     |\n",
      "|    std                  | 12.3          |\n",
      "|    value_loss           | 108           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1313       |\n",
      "|    time_elapsed         | 25720      |\n",
      "|    total_timesteps      | 2689024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01049681 |\n",
      "|    clip_fraction        | 0.0856     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -113       |\n",
      "|    explained_variance   | 0.42       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.7        |\n",
      "|    n_updates            | 18010      |\n",
      "|    policy_gradient_loss | -0.00661   |\n",
      "|    reward               | -0.7104567 |\n",
      "|    std                  | 12.3       |\n",
      "|    value_loss           | 25.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1314         |\n",
      "|    time_elapsed         | 25739        |\n",
      "|    total_timesteps      | 2691072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034586722 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.5         |\n",
      "|    n_updates            | 18020        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | 1.8937873    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 88.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1315        |\n",
      "|    time_elapsed         | 25758       |\n",
      "|    total_timesteps      | 2693120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002387507 |\n",
      "|    clip_fraction        | 0.00479     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 18030       |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | -1.5153501  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 74.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4477653.11\n",
      "total_reward: 3477653.11\n",
      "total_cost: 194944.30\n",
      "total_trades: 58832\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1316        |\n",
      "|    time_elapsed         | 25777       |\n",
      "|    total_timesteps      | 2695168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009974286 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 18040       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    reward               | -2.942025   |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1317         |\n",
      "|    time_elapsed         | 25796        |\n",
      "|    total_timesteps      | 2697216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052795745 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 18050        |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    reward               | -1.8049148   |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 69.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1318         |\n",
      "|    time_elapsed         | 25816        |\n",
      "|    total_timesteps      | 2699264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018687558 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 18060        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | -0.18825811  |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 88.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1319         |\n",
      "|    time_elapsed         | 25834        |\n",
      "|    total_timesteps      | 2701312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015689211 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.4         |\n",
      "|    n_updates            | 18070        |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    reward               | 1.0952519    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 92.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1320        |\n",
      "|    time_elapsed         | 25853       |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011268939 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 18080       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | -2.351414   |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 104           |\n",
      "|    iterations           | 1321          |\n",
      "|    time_elapsed         | 25873         |\n",
      "|    total_timesteps      | 2705408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063687714 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.828         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46.3          |\n",
      "|    n_updates            | 18090         |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    reward               | 1.5726632     |\n",
      "|    std                  | 12.4          |\n",
      "|    value_loss           | 82.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1322         |\n",
      "|    time_elapsed         | 25892        |\n",
      "|    total_timesteps      | 2707456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029584984 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.7         |\n",
      "|    n_updates            | 18100        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -2.0959845   |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1323         |\n",
      "|    time_elapsed         | 25911        |\n",
      "|    total_timesteps      | 2709504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060273437 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 18110        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    reward               | -0.79365903  |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1324        |\n",
      "|    time_elapsed         | 25930       |\n",
      "|    total_timesteps      | 2711552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004354769 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 18120       |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | -0.48344725 |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 63.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1325        |\n",
      "|    time_elapsed         | 25949       |\n",
      "|    total_timesteps      | 2713600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003274301 |\n",
      "|    clip_fraction        | 0.00903     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 18130       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | -12.808691  |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 91.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1326         |\n",
      "|    time_elapsed         | 25968        |\n",
      "|    total_timesteps      | 2715648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016620767 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.3         |\n",
      "|    n_updates            | 18140        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | 1.1640732    |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 25987       |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010989301 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.78        |\n",
      "|    n_updates            | 18150       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -1.3534129  |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1328        |\n",
      "|    time_elapsed         | 26006       |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005878452 |\n",
      "|    clip_fraction        | 0.026       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.4        |\n",
      "|    n_updates            | 18160       |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 0.8206348   |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 82.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1329         |\n",
      "|    time_elapsed         | 26026        |\n",
      "|    total_timesteps      | 2721792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022179042 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67           |\n",
      "|    n_updates            | 18170        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 2.9458654    |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 98.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3944076.91\n",
      "total_reward: 2944076.91\n",
      "total_cost: 172464.33\n",
      "total_trades: 55883\n",
      "Sharpe: 0.669\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 26045       |\n",
      "|    total_timesteps      | 2723840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008755218 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.77        |\n",
      "|    n_updates            | 18180       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -3.0545056  |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1331         |\n",
      "|    time_elapsed         | 26064        |\n",
      "|    total_timesteps      | 2725888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038579996 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.9         |\n",
      "|    n_updates            | 18190        |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    reward               | 0.6880103    |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 76           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1332         |\n",
      "|    time_elapsed         | 26082        |\n",
      "|    total_timesteps      | 2727936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028833786 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 18200        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | 0.40583125   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 82.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1333         |\n",
      "|    time_elapsed         | 26101        |\n",
      "|    total_timesteps      | 2729984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029111123 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 18210        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | 1.659366     |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 51.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1334        |\n",
      "|    time_elapsed         | 26120       |\n",
      "|    total_timesteps      | 2732032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006198552 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.78        |\n",
      "|    n_updates            | 18220       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | -1.2277951  |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1335         |\n",
      "|    time_elapsed         | 26139        |\n",
      "|    total_timesteps      | 2734080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034576894 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 18230        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 0.30518043   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 76.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1336         |\n",
      "|    time_elapsed         | 26158        |\n",
      "|    total_timesteps      | 2736128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020439131 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64           |\n",
      "|    n_updates            | 18240        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 1.269858     |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 26177       |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006823031 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 18250       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | -1.7496486  |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1338         |\n",
      "|    time_elapsed         | 26196        |\n",
      "|    total_timesteps      | 2740224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018395531 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.1         |\n",
      "|    n_updates            | 18260        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | -1.5735754   |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1339         |\n",
      "|    time_elapsed         | 26215        |\n",
      "|    total_timesteps      | 2742272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012586534 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.4         |\n",
      "|    n_updates            | 18270        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | -2.8166695   |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1340        |\n",
      "|    time_elapsed         | 26233       |\n",
      "|    total_timesteps      | 2744320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005170277 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 18280       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | 2.1294973   |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1341        |\n",
      "|    time_elapsed         | 26252       |\n",
      "|    total_timesteps      | 2746368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003389229 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.8        |\n",
      "|    n_updates            | 18290       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | -0.43412006 |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1342         |\n",
      "|    time_elapsed         | 26271        |\n",
      "|    total_timesteps      | 2748416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065274513 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.3         |\n",
      "|    n_updates            | 18300        |\n",
      "|    policy_gradient_loss | -0.00892     |\n",
      "|    reward               | 0.32055092   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 94.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1343         |\n",
      "|    time_elapsed         | 26289        |\n",
      "|    total_timesteps      | 2750464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007235069 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 18310        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    reward               | -1.4694954   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 87.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4046440.62\n",
      "total_reward: 3046440.62\n",
      "total_cost: 143640.29\n",
      "total_trades: 54041\n",
      "Sharpe: 0.708\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 26308       |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010826888 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.15        |\n",
      "|    n_updates            | 18320       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    reward               | -0.41795984 |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1345        |\n",
      "|    time_elapsed         | 26328       |\n",
      "|    total_timesteps      | 2754560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004864827 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 18330       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | -0.04547916 |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 56.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 104           |\n",
      "|    iterations           | 1346          |\n",
      "|    time_elapsed         | 26346         |\n",
      "|    total_timesteps      | 2756608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070036645 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.799         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55.2          |\n",
      "|    n_updates            | 18340         |\n",
      "|    policy_gradient_loss | -0.00218      |\n",
      "|    reward               | -4.430817     |\n",
      "|    std                  | 12.9          |\n",
      "|    value_loss           | 83.2          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1347       |\n",
      "|    time_elapsed         | 26366      |\n",
      "|    total_timesteps      | 2758656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00708137 |\n",
      "|    clip_fraction        | 0.0439     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.581      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.2       |\n",
      "|    n_updates            | 18350      |\n",
      "|    policy_gradient_loss | -0.00703   |\n",
      "|    reward               | 0.18497361 |\n",
      "|    std                  | 12.9       |\n",
      "|    value_loss           | 33.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1348        |\n",
      "|    time_elapsed         | 26385       |\n",
      "|    total_timesteps      | 2760704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005651476 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 18360       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | -0.16582276 |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1349         |\n",
      "|    time_elapsed         | 26404        |\n",
      "|    total_timesteps      | 2762752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023332033 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56           |\n",
      "|    n_updates            | 18370        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | -12.15068    |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1350        |\n",
      "|    time_elapsed         | 26423       |\n",
      "|    total_timesteps      | 2764800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001032345 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 18380       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    reward               | -2.653282   |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 79.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1351        |\n",
      "|    time_elapsed         | 26442       |\n",
      "|    total_timesteps      | 2766848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008470217 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 18390       |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    reward               | -0.5189313  |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1352         |\n",
      "|    time_elapsed         | 26461        |\n",
      "|    total_timesteps      | 2768896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011451982 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.2         |\n",
      "|    n_updates            | 18400        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | -0.40738988  |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 76.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1353       |\n",
      "|    time_elapsed         | 26480      |\n",
      "|    total_timesteps      | 2770944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00198314 |\n",
      "|    clip_fraction        | 0.00112    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.825      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.4       |\n",
      "|    n_updates            | 18410      |\n",
      "|    policy_gradient_loss | -0.0034    |\n",
      "|    reward               | 0.3438478  |\n",
      "|    std                  | 13         |\n",
      "|    value_loss           | 74.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1354         |\n",
      "|    time_elapsed         | 26499        |\n",
      "|    total_timesteps      | 2772992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058821915 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 18420        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    reward               | -0.42821404  |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1355         |\n",
      "|    time_elapsed         | 26518        |\n",
      "|    total_timesteps      | 2775040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051661516 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.854        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.5         |\n",
      "|    n_updates            | 18430        |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    reward               | -0.43971682  |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 61.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 26537       |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001723284 |\n",
      "|    clip_fraction        | 0.00142     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 18440       |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    reward               | -1.2940181  |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 97.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1357         |\n",
      "|    time_elapsed         | 26556        |\n",
      "|    total_timesteps      | 2779136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012944546 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 18450        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | -2.6116605   |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4348824.95\n",
      "total_reward: 3348824.95\n",
      "total_cost: 138653.34\n",
      "total_trades: 53037\n",
      "Sharpe: 0.702\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1358        |\n",
      "|    time_elapsed         | 26576       |\n",
      "|    total_timesteps      | 2781184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008746864 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.55        |\n",
      "|    n_updates            | 18460       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 1.7470756   |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1359         |\n",
      "|    time_elapsed         | 26595        |\n",
      "|    total_timesteps      | 2783232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030767866 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 18470        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -0.48520058  |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1360         |\n",
      "|    time_elapsed         | 26613        |\n",
      "|    total_timesteps      | 2785280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005181172 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 18480        |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    reward               | -0.007667808 |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1361         |\n",
      "|    time_elapsed         | 26633        |\n",
      "|    total_timesteps      | 2787328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097614415 |\n",
      "|    clip_fraction        | 0.073        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 18490        |\n",
      "|    policy_gradient_loss | -0.00942     |\n",
      "|    reward               | -3.327092    |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1362         |\n",
      "|    time_elapsed         | 26652        |\n",
      "|    total_timesteps      | 2789376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028255475 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 18500        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | 1.8342957    |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 96.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1363         |\n",
      "|    time_elapsed         | 26671        |\n",
      "|    total_timesteps      | 2791424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007932575 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.7         |\n",
      "|    n_updates            | 18510        |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    reward               | 0.007056256  |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1364         |\n",
      "|    time_elapsed         | 26690        |\n",
      "|    total_timesteps      | 2793472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032427418 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 18520        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 1.9546776    |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1365        |\n",
      "|    time_elapsed         | 26709       |\n",
      "|    total_timesteps      | 2795520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007952603 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 18530       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | 0.92805994  |\n",
      "|    std                  | 13.1        |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1366         |\n",
      "|    time_elapsed         | 26728        |\n",
      "|    total_timesteps      | 2797568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020343342 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 18540        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | -0.6811589   |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 95           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1367         |\n",
      "|    time_elapsed         | 26746        |\n",
      "|    total_timesteps      | 2799616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018098431 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.6         |\n",
      "|    n_updates            | 18550        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | 2.4161174    |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 98.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1368        |\n",
      "|    time_elapsed         | 26765       |\n",
      "|    total_timesteps      | 2801664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008979417 |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.98        |\n",
      "|    n_updates            | 18560       |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | -0.2751758  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1369         |\n",
      "|    time_elapsed         | 26784        |\n",
      "|    total_timesteps      | 2803712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014495517 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.2         |\n",
      "|    n_updates            | 18570        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | -0.63142854  |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1370         |\n",
      "|    time_elapsed         | 26803        |\n",
      "|    total_timesteps      | 2805760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026744232 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 18580        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | 1.86408      |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1371       |\n",
      "|    time_elapsed         | 26822      |\n",
      "|    total_timesteps      | 2807808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.008981   |\n",
      "|    clip_fraction        | 0.0542     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.271      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16         |\n",
      "|    n_updates            | 18590      |\n",
      "|    policy_gradient_loss | -0.00848   |\n",
      "|    reward               | 0.70137507 |\n",
      "|    std                  | 13.2       |\n",
      "|    value_loss           | 37.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4387670.65\n",
      "total_reward: 3387670.65\n",
      "total_cost: 157566.98\n",
      "total_trades: 55441\n",
      "Sharpe: 0.747\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1372       |\n",
      "|    time_elapsed         | 26841      |\n",
      "|    total_timesteps      | 2809856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00462434 |\n",
      "|    clip_fraction        | 0.0174     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.599      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 96.6       |\n",
      "|    n_updates            | 18600      |\n",
      "|    policy_gradient_loss | -0.00526   |\n",
      "|    reward               | -2.1722298 |\n",
      "|    std                  | 13.3       |\n",
      "|    value_loss           | 116        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1373         |\n",
      "|    time_elapsed         | 26860        |\n",
      "|    total_timesteps      | 2811904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020999114 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 18610        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -0.76063335  |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 99.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1374        |\n",
      "|    time_elapsed         | 26879       |\n",
      "|    total_timesteps      | 2813952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007406365 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 18620       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | -0.34727654 |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1375        |\n",
      "|    time_elapsed         | 26898       |\n",
      "|    total_timesteps      | 2816000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008848126 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 18630       |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | -2.5831616  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1376         |\n",
      "|    time_elapsed         | 26917        |\n",
      "|    total_timesteps      | 2818048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031924723 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.5         |\n",
      "|    n_updates            | 18640        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | 0.30722198   |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1377        |\n",
      "|    time_elapsed         | 26936       |\n",
      "|    total_timesteps      | 2820096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001575797 |\n",
      "|    clip_fraction        | 0.00332     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.8        |\n",
      "|    n_updates            | 18650       |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    reward               | -3.7101836  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 26955       |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009433642 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.19        |\n",
      "|    n_updates            | 18660       |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | -1.1094697  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1379         |\n",
      "|    time_elapsed         | 26974        |\n",
      "|    total_timesteps      | 2824192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062529077 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 18670        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | -0.96054584  |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 70.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1380         |\n",
      "|    time_elapsed         | 26993        |\n",
      "|    total_timesteps      | 2826240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021110747 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 18680        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | -3.1323855   |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 99.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1381        |\n",
      "|    time_elapsed         | 27012       |\n",
      "|    total_timesteps      | 2828288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005529331 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 18690       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | -3.090671   |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1382         |\n",
      "|    time_elapsed         | 27031        |\n",
      "|    total_timesteps      | 2830336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038178382 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.2         |\n",
      "|    n_updates            | 18700        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | -0.4135708   |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 58.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1383         |\n",
      "|    time_elapsed         | 27050        |\n",
      "|    total_timesteps      | 2832384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013422468 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.2         |\n",
      "|    n_updates            | 18710        |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    reward               | 0.5132419    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1384         |\n",
      "|    time_elapsed         | 27069        |\n",
      "|    total_timesteps      | 2834432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006388034 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 18720        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | 1.5577716    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 86.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1385        |\n",
      "|    time_elapsed         | 27088       |\n",
      "|    total_timesteps      | 2836480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007622122 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 18730       |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | -1.6752625  |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3937663.96\n",
      "total_reward: 2937663.96\n",
      "total_cost: 154327.37\n",
      "total_trades: 54803\n",
      "Sharpe: 0.644\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1386         |\n",
      "|    time_elapsed         | 27107        |\n",
      "|    total_timesteps      | 2838528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007837416 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 18740        |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | -0.69557863  |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1387        |\n",
      "|    time_elapsed         | 27126       |\n",
      "|    total_timesteps      | 2840576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002219117 |\n",
      "|    clip_fraction        | 0.00679     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.6        |\n",
      "|    n_updates            | 18750       |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | -0.39973196 |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1388         |\n",
      "|    time_elapsed         | 27145        |\n",
      "|    total_timesteps      | 2842624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058775907 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 18760        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | 0.04625502   |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1389        |\n",
      "|    time_elapsed         | 27164       |\n",
      "|    total_timesteps      | 2844672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003153609 |\n",
      "|    clip_fraction        | 0.00327     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 18770       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | 0.44695815  |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1390         |\n",
      "|    time_elapsed         | 27183        |\n",
      "|    total_timesteps      | 2846720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014982439 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 18780        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | -0.41567954  |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 91.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1391         |\n",
      "|    time_elapsed         | 27203        |\n",
      "|    total_timesteps      | 2848768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017760966 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.3         |\n",
      "|    n_updates            | 18790        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | -0.4078024   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1392        |\n",
      "|    time_elapsed         | 27222       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009236436 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 18800       |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    reward               | 1.2859975   |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1393         |\n",
      "|    time_elapsed         | 27240        |\n",
      "|    total_timesteps      | 2852864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027677887 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.4         |\n",
      "|    n_updates            | 18810        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | 0.48499805   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 85.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1394        |\n",
      "|    time_elapsed         | 27259       |\n",
      "|    total_timesteps      | 2854912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002969887 |\n",
      "|    clip_fraction        | 0.00889     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 18820       |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    reward               | -0.21793464 |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 82          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1395        |\n",
      "|    time_elapsed         | 27279       |\n",
      "|    total_timesteps      | 2856960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009758603 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 18830       |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | 4.41352     |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1396         |\n",
      "|    time_elapsed         | 27298        |\n",
      "|    total_timesteps      | 2859008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028199959 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 18840        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | 0.23230745   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 95.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1397        |\n",
      "|    time_elapsed         | 27317       |\n",
      "|    total_timesteps      | 2861056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002987345 |\n",
      "|    clip_fraction        | 0.00557     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 18850       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | 0.38476697  |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 78.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1398         |\n",
      "|    time_elapsed         | 27336        |\n",
      "|    total_timesteps      | 2863104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012921551 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.3         |\n",
      "|    n_updates            | 18860        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | 1.1612773    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 67.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1399        |\n",
      "|    time_elapsed         | 27356       |\n",
      "|    total_timesteps      | 2865152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009955775 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 18870       |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    reward               | 0.5980298   |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4200282.37\n",
      "total_reward: 3200282.37\n",
      "total_cost: 147625.76\n",
      "total_trades: 54372\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1400         |\n",
      "|    time_elapsed         | 27374        |\n",
      "|    total_timesteps      | 2867200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006075796 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.1         |\n",
      "|    n_updates            | 18880        |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    reward               | 0.5070579    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 104           |\n",
      "|    iterations           | 1401          |\n",
      "|    time_elapsed         | 27393         |\n",
      "|    total_timesteps      | 2869248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084930577 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.82          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43.6          |\n",
      "|    n_updates            | 18890         |\n",
      "|    policy_gradient_loss | -0.0024       |\n",
      "|    reward               | 1.5065978     |\n",
      "|    std                  | 13.5          |\n",
      "|    value_loss           | 121           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1402         |\n",
      "|    time_elapsed         | 27412        |\n",
      "|    total_timesteps      | 2871296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043497253 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 18900        |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    reward               | -3.1304185   |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1403         |\n",
      "|    time_elapsed         | 27432        |\n",
      "|    total_timesteps      | 2873344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041732206 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 18910        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -1.0658284   |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 92.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1404         |\n",
      "|    time_elapsed         | 27451        |\n",
      "|    total_timesteps      | 2875392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027565397 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.842        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.1         |\n",
      "|    n_updates            | 18920        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | -5.077768    |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 76.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1405         |\n",
      "|    time_elapsed         | 27470        |\n",
      "|    total_timesteps      | 2877440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026210772 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 18930        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | 2.7709982    |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1406       |\n",
      "|    time_elapsed         | 27489      |\n",
      "|    total_timesteps      | 2879488    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00969255 |\n",
      "|    clip_fraction        | 0.0779     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -116       |\n",
      "|    explained_variance   | 0.843      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.4       |\n",
      "|    n_updates            | 18940      |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | 0.15762389 |\n",
      "|    std                  | 13.6       |\n",
      "|    value_loss           | 47.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1407         |\n",
      "|    time_elapsed         | 27508        |\n",
      "|    total_timesteps      | 2881536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055641215 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 18950        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    reward               | 0.20390347   |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 64           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1408        |\n",
      "|    time_elapsed         | 27528       |\n",
      "|    total_timesteps      | 2883584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005235456 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 18960       |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    reward               | -3.3165834  |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 66.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1409        |\n",
      "|    time_elapsed         | 27547       |\n",
      "|    total_timesteps      | 2885632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010127818 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.35        |\n",
      "|    n_updates            | 18970       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.46660653  |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 27566       |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005928204 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.4        |\n",
      "|    n_updates            | 18980       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | -0.45881343 |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 71.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1411         |\n",
      "|    time_elapsed         | 27585        |\n",
      "|    total_timesteps      | 2889728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019471871 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.3         |\n",
      "|    n_updates            | 18990        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -2.2835004   |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 70.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1412        |\n",
      "|    time_elapsed         | 27604       |\n",
      "|    total_timesteps      | 2891776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008469275 |\n",
      "|    clip_fraction        | 0.0255      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 19000       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    reward               | -6.1688905  |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1413        |\n",
      "|    time_elapsed         | 27623       |\n",
      "|    total_timesteps      | 2893824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005724556 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 19010       |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    reward               | 0.7932495   |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1414         |\n",
      "|    time_elapsed         | 27642        |\n",
      "|    total_timesteps      | 2895872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053540505 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.4         |\n",
      "|    n_updates            | 19020        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | 5.484258     |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4520995.12\n",
      "total_reward: 3520995.12\n",
      "total_cost: 126308.90\n",
      "total_trades: 52833\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1415         |\n",
      "|    time_elapsed         | 27661        |\n",
      "|    total_timesteps      | 2897920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025077232 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28           |\n",
      "|    n_updates            | 19030        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -1.015421    |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 78.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 27680       |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008719891 |\n",
      "|    clip_fraction        | 0.0504      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.99        |\n",
      "|    n_updates            | 19040       |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    reward               | 0.33062533  |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1417        |\n",
      "|    time_elapsed         | 27699       |\n",
      "|    total_timesteps      | 2902016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002382643 |\n",
      "|    clip_fraction        | 0.0022      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 19050       |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | -4.5624404  |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 90.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1418         |\n",
      "|    time_elapsed         | 27718        |\n",
      "|    total_timesteps      | 2904064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001521012  |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.3         |\n",
      "|    n_updates            | 19060        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | -0.087019645 |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 94.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1419         |\n",
      "|    time_elapsed         | 27737        |\n",
      "|    total_timesteps      | 2906112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053572147 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 19070        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | 0.036939487  |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1420         |\n",
      "|    time_elapsed         | 27756        |\n",
      "|    total_timesteps      | 2908160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029875247 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.2         |\n",
      "|    n_updates            | 19080        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | 1.7965156    |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 87.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1421         |\n",
      "|    time_elapsed         | 27775        |\n",
      "|    total_timesteps      | 2910208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047861333 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.9         |\n",
      "|    n_updates            | 19090        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | -0.64144605  |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 83.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1422        |\n",
      "|    time_elapsed         | 27794       |\n",
      "|    total_timesteps      | 2912256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003905256 |\n",
      "|    clip_fraction        | 0.00581     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 19100       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | 3.0176926   |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1423         |\n",
      "|    time_elapsed         | 27813        |\n",
      "|    total_timesteps      | 2914304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071473145 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 19110        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    reward               | -0.51870805  |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 56.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1424         |\n",
      "|    time_elapsed         | 27832        |\n",
      "|    total_timesteps      | 2916352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018977344 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60           |\n",
      "|    n_updates            | 19120        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | 2.6118715    |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1425         |\n",
      "|    time_elapsed         | 27851        |\n",
      "|    total_timesteps      | 2918400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015847473 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.3         |\n",
      "|    n_updates            | 19130        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 0.36093783   |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1426        |\n",
      "|    time_elapsed         | 27870       |\n",
      "|    total_timesteps      | 2920448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009278167 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 19140       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -0.8962145  |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1427         |\n",
      "|    time_elapsed         | 27889        |\n",
      "|    total_timesteps      | 2922496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037099877 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.8         |\n",
      "|    n_updates            | 19150        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | -0.14249356  |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 75.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1428         |\n",
      "|    time_elapsed         | 27908        |\n",
      "|    total_timesteps      | 2924544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019551236 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.842        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.4         |\n",
      "|    n_updates            | 19160        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | -5.918078    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 78.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4858845.44\n",
      "total_reward: 3858845.44\n",
      "total_cost: 139646.65\n",
      "total_trades: 53270\n",
      "Sharpe: 0.760\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1429         |\n",
      "|    time_elapsed         | 27926        |\n",
      "|    total_timesteps      | 2926592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062513547 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.307        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 19170        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | -5.655334    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 57.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1430        |\n",
      "|    time_elapsed         | 27946       |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007239356 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.2        |\n",
      "|    n_updates            | 19180       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | 0.68816394  |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 87.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1431         |\n",
      "|    time_elapsed         | 27964        |\n",
      "|    total_timesteps      | 2930688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022933888 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.7         |\n",
      "|    n_updates            | 19190        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | 0.32664216   |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 82           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1432        |\n",
      "|    time_elapsed         | 27983       |\n",
      "|    total_timesteps      | 2932736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002331102 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 19200       |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    reward               | 0.6807422   |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1433        |\n",
      "|    time_elapsed         | 28002       |\n",
      "|    total_timesteps      | 2934784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010993677 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.2         |\n",
      "|    n_updates            | 19210       |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | 4.001604    |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1434         |\n",
      "|    time_elapsed         | 28021        |\n",
      "|    total_timesteps      | 2936832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028938083 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.3         |\n",
      "|    n_updates            | 19220        |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    reward               | 0.7103446    |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 82.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1435         |\n",
      "|    time_elapsed         | 28040        |\n",
      "|    total_timesteps      | 2938880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019517125 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.5         |\n",
      "|    n_updates            | 19230        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -0.87686574  |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1436        |\n",
      "|    time_elapsed         | 28059       |\n",
      "|    total_timesteps      | 2940928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007783611 |\n",
      "|    clip_fraction        | 0.0295      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 19240       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | 3.3798494   |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1437         |\n",
      "|    time_elapsed         | 28078        |\n",
      "|    total_timesteps      | 2942976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067266105 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.7         |\n",
      "|    n_updates            | 19250        |\n",
      "|    policy_gradient_loss | -0.00788     |\n",
      "|    reward               | -0.6383534   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 77.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1438         |\n",
      "|    time_elapsed         | 28098        |\n",
      "|    total_timesteps      | 2945024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043337233 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.2         |\n",
      "|    n_updates            | 19260        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    reward               | -10.7578     |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1439        |\n",
      "|    time_elapsed         | 28117       |\n",
      "|    total_timesteps      | 2947072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006104367 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.1        |\n",
      "|    n_updates            | 19270       |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    reward               | -2.058336   |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 80.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 28136       |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009717291 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 19280       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.64122915  |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1441       |\n",
      "|    time_elapsed         | 28155      |\n",
      "|    total_timesteps      | 2951168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00840288 |\n",
      "|    clip_fraction        | 0.0517     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -118       |\n",
      "|    explained_variance   | 0.608      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.5       |\n",
      "|    n_updates            | 19290      |\n",
      "|    policy_gradient_loss | -0.00956   |\n",
      "|    reward               | 0.35051328 |\n",
      "|    std                  | 14.4       |\n",
      "|    value_loss           | 109        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1442         |\n",
      "|    time_elapsed         | 28174        |\n",
      "|    total_timesteps      | 2953216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045100613 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.4         |\n",
      "|    n_updates            | 19300        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | -1.7087616   |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 83.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4875310.05\n",
      "total_reward: 3875310.05\n",
      "total_cost: 148354.58\n",
      "total_trades: 54785\n",
      "Sharpe: 0.816\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1443       |\n",
      "|    time_elapsed         | 28193      |\n",
      "|    total_timesteps      | 2955264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00564052 |\n",
      "|    clip_fraction        | 0.019      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -118       |\n",
      "|    explained_variance   | 0.474      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.1       |\n",
      "|    n_updates            | 19310      |\n",
      "|    policy_gradient_loss | -0.00662   |\n",
      "|    reward               | -4.743998  |\n",
      "|    std                  | 14.4       |\n",
      "|    value_loss           | 34         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1444         |\n",
      "|    time_elapsed         | 28212        |\n",
      "|    total_timesteps      | 2957312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041936664 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50           |\n",
      "|    n_updates            | 19320        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    reward               | 1.8988814    |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 87.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1445         |\n",
      "|    time_elapsed         | 28231        |\n",
      "|    total_timesteps      | 2959360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040715956 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.9         |\n",
      "|    n_updates            | 19330        |\n",
      "|    policy_gradient_loss | -0.00744     |\n",
      "|    reward               | 4.0371084    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1446        |\n",
      "|    time_elapsed         | 28250       |\n",
      "|    total_timesteps      | 2961408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003594299 |\n",
      "|    clip_fraction        | 0.00464     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 19340       |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    reward               | -0.47963938 |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1447         |\n",
      "|    time_elapsed         | 28269        |\n",
      "|    total_timesteps      | 2963456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068997387 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 19350        |\n",
      "|    policy_gradient_loss | -0.0091      |\n",
      "|    reward               | 0.8932511    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1448         |\n",
      "|    time_elapsed         | 28288        |\n",
      "|    total_timesteps      | 2965504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059410036 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.1         |\n",
      "|    n_updates            | 19360        |\n",
      "|    policy_gradient_loss | -0.00851     |\n",
      "|    reward               | 0.60019827   |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 96.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1449         |\n",
      "|    time_elapsed         | 28307        |\n",
      "|    total_timesteps      | 2967552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026688287 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.1         |\n",
      "|    n_updates            | 19370        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | 0.6462368    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 81.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1450         |\n",
      "|    time_elapsed         | 28326        |\n",
      "|    total_timesteps      | 2969600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050751064 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.61         |\n",
      "|    n_updates            | 19380        |\n",
      "|    policy_gradient_loss | -0.00806     |\n",
      "|    reward               | 3.9350173    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1451        |\n",
      "|    time_elapsed         | 28345       |\n",
      "|    total_timesteps      | 2971648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007723705 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 19390       |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | 1.2792902   |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 74.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1452         |\n",
      "|    time_elapsed         | 28364        |\n",
      "|    total_timesteps      | 2973696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027079429 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 19400        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | 0.42792925   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 74.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1453        |\n",
      "|    time_elapsed         | 28383       |\n",
      "|    total_timesteps      | 2975744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004355667 |\n",
      "|    clip_fraction        | 0.00732     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 19410       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    reward               | 1.8615419   |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1454        |\n",
      "|    time_elapsed         | 28402       |\n",
      "|    total_timesteps      | 2977792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007275588 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 19420       |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    reward               | -1.0695149  |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1455        |\n",
      "|    time_elapsed         | 28421       |\n",
      "|    total_timesteps      | 2979840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002595714 |\n",
      "|    clip_fraction        | 0.00776     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 19430       |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    reward               | 1.1827701   |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1456         |\n",
      "|    time_elapsed         | 28439        |\n",
      "|    total_timesteps      | 2981888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038444106 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.8         |\n",
      "|    n_updates            | 19440        |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    reward               | 0.8628515    |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 71.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3868097.29\n",
      "total_reward: 2868097.29\n",
      "total_cost: 146741.70\n",
      "total_trades: 55399\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1457       |\n",
      "|    time_elapsed         | 28458      |\n",
      "|    total_timesteps      | 2983936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01081357 |\n",
      "|    clip_fraction        | 0.0875     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -118       |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.52       |\n",
      "|    n_updates            | 19450      |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    reward               | 1.2716907  |\n",
      "|    std                  | 14.7       |\n",
      "|    value_loss           | 15.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1458         |\n",
      "|    time_elapsed         | 28477        |\n",
      "|    total_timesteps      | 2985984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030965847 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 19460        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | 1.3891338    |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 67.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 28497       |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005519123 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 19470       |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | -0.65011686 |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 91.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1460       |\n",
      "|    time_elapsed         | 28516      |\n",
      "|    total_timesteps      | 2990080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00541445 |\n",
      "|    clip_fraction        | 0.0175     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -118       |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.8       |\n",
      "|    n_updates            | 19480      |\n",
      "|    policy_gradient_loss | -0.00564   |\n",
      "|    reward               | -4.0925074 |\n",
      "|    std                  | 14.7       |\n",
      "|    value_loss           | 24.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1461         |\n",
      "|    time_elapsed         | 28535        |\n",
      "|    total_timesteps      | 2992128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070857937 |\n",
      "|    clip_fraction        | 0.0366       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.4         |\n",
      "|    n_updates            | 19490        |\n",
      "|    policy_gradient_loss | -0.00837     |\n",
      "|    reward               | 1.4775455    |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1462         |\n",
      "|    time_elapsed         | 28554        |\n",
      "|    total_timesteps      | 2994176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044394173 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 19500        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    reward               | 15.899616    |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 95.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1463         |\n",
      "|    time_elapsed         | 28573        |\n",
      "|    total_timesteps      | 2996224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059947036 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 19510        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | 0.92429507   |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 41.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1464         |\n",
      "|    time_elapsed         | 28592        |\n",
      "|    total_timesteps      | 2998272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072076377 |\n",
      "|    clip_fraction        | 0.0389       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 19520        |\n",
      "|    policy_gradient_loss | -0.00875     |\n",
      "|    reward               | 1.4119672    |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1465         |\n",
      "|    time_elapsed         | 28611        |\n",
      "|    total_timesteps      | 3000320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055876207 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 19530        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    reward               | 1.0149753    |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 84.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1466        |\n",
      "|    time_elapsed         | 28629       |\n",
      "|    total_timesteps      | 3002368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002818475 |\n",
      "|    clip_fraction        | 0.0085      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 19540       |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | 8.624154    |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 62.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1467         |\n",
      "|    time_elapsed         | 28648        |\n",
      "|    total_timesteps      | 3004416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070391037 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 19550        |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    reward               | -0.561148    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1468         |\n",
      "|    time_elapsed         | 28667        |\n",
      "|    total_timesteps      | 3006464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060327603 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 19560        |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    reward               | -1.2087883   |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 55.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1469         |\n",
      "|    time_elapsed         | 28686        |\n",
      "|    total_timesteps      | 3008512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034279577 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 19570        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | 3.0015354    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 93.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1470        |\n",
      "|    time_elapsed         | 28705       |\n",
      "|    total_timesteps      | 3010560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008066238 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 19580       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | 1.0317651   |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4299704.79\n",
      "total_reward: 3299704.79\n",
      "total_cost: 119639.69\n",
      "total_trades: 51991\n",
      "Sharpe: 0.771\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1471         |\n",
      "|    time_elapsed         | 28723        |\n",
      "|    total_timesteps      | 3012608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064406483 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 19590        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | -0.24064806  |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1472        |\n",
      "|    time_elapsed         | 28742       |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004101235 |\n",
      "|    clip_fraction        | 0.0101      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 19600       |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    reward               | 1.8313468   |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1473         |\n",
      "|    time_elapsed         | 28761        |\n",
      "|    total_timesteps      | 3016704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031132717 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 19610        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | -1.1028253   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 64.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1474        |\n",
      "|    time_elapsed         | 28780       |\n",
      "|    total_timesteps      | 3018752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007079942 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 19620       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | -2.4308054  |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1475        |\n",
      "|    time_elapsed         | 28799       |\n",
      "|    total_timesteps      | 3020800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005759067 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 19630       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | -0.45054936 |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 87.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1476         |\n",
      "|    time_elapsed         | 28819        |\n",
      "|    total_timesteps      | 3022848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042022113 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.3         |\n",
      "|    n_updates            | 19640        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 4.786098     |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1477         |\n",
      "|    time_elapsed         | 28838        |\n",
      "|    total_timesteps      | 3024896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073888483 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 19650        |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    reward               | 1.171223     |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1478        |\n",
      "|    time_elapsed         | 28857       |\n",
      "|    total_timesteps      | 3026944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007861681 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 19660       |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    reward               | -2.2294774  |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1479        |\n",
      "|    time_elapsed         | 28876       |\n",
      "|    total_timesteps      | 3028992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003102912 |\n",
      "|    clip_fraction        | 0.00464     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 19670       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | 0.24476454  |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 67.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1480         |\n",
      "|    time_elapsed         | 28895        |\n",
      "|    total_timesteps      | 3031040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045731384 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.1         |\n",
      "|    n_updates            | 19680        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -0.51163995  |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 70           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1481         |\n",
      "|    time_elapsed         | 28914        |\n",
      "|    total_timesteps      | 3033088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099187605 |\n",
      "|    clip_fraction        | 0.0767       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.27         |\n",
      "|    n_updates            | 19690        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    reward               | -1.9198505   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1482         |\n",
      "|    time_elapsed         | 28933        |\n",
      "|    total_timesteps      | 3035136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045642992 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 19700        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 3.4058514    |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 59           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1483         |\n",
      "|    time_elapsed         | 28952        |\n",
      "|    total_timesteps      | 3037184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061291335 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 19710        |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    reward               | 1.9545627    |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 58.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1484         |\n",
      "|    time_elapsed         | 28971        |\n",
      "|    total_timesteps      | 3039232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052099503 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.83         |\n",
      "|    n_updates            | 19720        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    reward               | -3.1069434   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3911394.64\n",
      "total_reward: 2911394.64\n",
      "total_cost: 171041.61\n",
      "total_trades: 57337\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1485        |\n",
      "|    time_elapsed         | 28990       |\n",
      "|    total_timesteps      | 3041280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005318139 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 19730       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | 1.0626996   |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1486        |\n",
      "|    time_elapsed         | 29009       |\n",
      "|    total_timesteps      | 3043328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005186038 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 19740       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | 2.2502446   |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1487        |\n",
      "|    time_elapsed         | 29028       |\n",
      "|    total_timesteps      | 3045376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001732772 |\n",
      "|    clip_fraction        | 0.00562     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 19750       |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    reward               | -1.4550953  |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 29047       |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009293921 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 19760       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.62063134  |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1489        |\n",
      "|    time_elapsed         | 29066       |\n",
      "|    total_timesteps      | 3049472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00463859  |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 19770       |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | -0.15015607 |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1490         |\n",
      "|    time_elapsed         | 29084        |\n",
      "|    total_timesteps      | 3051520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020602297 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.5         |\n",
      "|    n_updates            | 19780        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | -4.1795516   |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 64.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1491        |\n",
      "|    time_elapsed         | 29103       |\n",
      "|    total_timesteps      | 3053568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007956986 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.44        |\n",
      "|    n_updates            | 19790       |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    reward               | -3.7232642  |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1492         |\n",
      "|    time_elapsed         | 29122        |\n",
      "|    total_timesteps      | 3055616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017682253 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 19800        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | 0.025343774  |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 62.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1493        |\n",
      "|    time_elapsed         | 29141       |\n",
      "|    total_timesteps      | 3057664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003475336 |\n",
      "|    clip_fraction        | 0.00771     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 19810       |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | 0.6616895   |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1494         |\n",
      "|    time_elapsed         | 29160        |\n",
      "|    total_timesteps      | 3059712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032249412 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.204        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 19820        |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | 0.31528237   |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 51.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1495         |\n",
      "|    time_elapsed         | 29179        |\n",
      "|    total_timesteps      | 3061760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029547145 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 19830        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -0.94964707  |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1496         |\n",
      "|    time_elapsed         | 29198        |\n",
      "|    total_timesteps      | 3063808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047264504 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 19840        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    reward               | -0.038136516 |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 52.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1497         |\n",
      "|    time_elapsed         | 29217        |\n",
      "|    total_timesteps      | 3065856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035770964 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 19850        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    reward               | -1.4071755   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 53.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1498        |\n",
      "|    time_elapsed         | 29236       |\n",
      "|    total_timesteps      | 3067904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009115256 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.99        |\n",
      "|    n_updates            | 19860       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | 0.29430526  |\n",
      "|    std                  | 15.5        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4212643.32\n",
      "total_reward: 3212643.32\n",
      "total_cost: 148464.68\n",
      "total_trades: 55381\n",
      "Sharpe: 0.777\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1499        |\n",
      "|    time_elapsed         | 29254       |\n",
      "|    total_timesteps      | 3069952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003488225 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 19870       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | -1.0761987  |\n",
      "|    std                  | 15.5        |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1500        |\n",
      "|    time_elapsed         | 29273       |\n",
      "|    total_timesteps      | 3072000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006412565 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 19880       |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 2.891399    |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1501         |\n",
      "|    time_elapsed         | 29292        |\n",
      "|    total_timesteps      | 3074048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039079334 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 19890        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | -3.5955896   |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1502         |\n",
      "|    time_elapsed         | 29312        |\n",
      "|    total_timesteps      | 3076096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066153174 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 19900        |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    reward               | -0.7287173   |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 40.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1503         |\n",
      "|    time_elapsed         | 29331        |\n",
      "|    total_timesteps      | 3078144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050253095 |\n",
      "|    clip_fraction        | 0.0447       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 19910        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    reward               | -0.077258825 |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 55.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1504         |\n",
      "|    time_elapsed         | 29350        |\n",
      "|    total_timesteps      | 3080192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014914087 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 19920        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | 1.6552155    |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 66.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1505        |\n",
      "|    time_elapsed         | 29369       |\n",
      "|    total_timesteps      | 3082240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010343459 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.663629   |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1506         |\n",
      "|    time_elapsed         | 29388        |\n",
      "|    total_timesteps      | 3084288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004733215  |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 19940        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | -0.018248124 |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 57.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1507         |\n",
      "|    time_elapsed         | 29406        |\n",
      "|    total_timesteps      | 3086336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036842271 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 19950        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | -3.4146492   |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 57.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1508        |\n",
      "|    time_elapsed         | 29425       |\n",
      "|    total_timesteps      | 3088384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007829401 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 19960       |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | -4.835272   |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1509         |\n",
      "|    time_elapsed         | 29444        |\n",
      "|    total_timesteps      | 3090432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068641994 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 19970        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    reward               | 1.5457802    |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1510         |\n",
      "|    time_elapsed         | 29463        |\n",
      "|    total_timesteps      | 3092480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039984393 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 19980        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | -0.34852618  |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 66.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1511         |\n",
      "|    time_elapsed         | 29482        |\n",
      "|    total_timesteps      | 3094528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037856053 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 19990        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    reward               | 0.95809907   |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 56.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1512        |\n",
      "|    time_elapsed         | 29501       |\n",
      "|    total_timesteps      | 3096576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004913365 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 20000       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | -1.0018162  |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3969831.27\n",
      "total_reward: 2969831.27\n",
      "total_cost: 153757.52\n",
      "total_trades: 55798\n",
      "Sharpe: 0.765\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1513         |\n",
      "|    time_elapsed         | 29519        |\n",
      "|    total_timesteps      | 3098624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037478483 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 20010        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    reward               | 0.19008294   |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1514        |\n",
      "|    time_elapsed         | 29538       |\n",
      "|    total_timesteps      | 3100672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006725153 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 20020       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | -0.5359051  |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1515        |\n",
      "|    time_elapsed         | 29557       |\n",
      "|    total_timesteps      | 3102720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008259991 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.38        |\n",
      "|    n_updates            | 20030       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | 0.9905493   |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1516        |\n",
      "|    time_elapsed         | 29577       |\n",
      "|    total_timesteps      | 3104768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006108354 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 20040       |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | 2.4852402   |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1517         |\n",
      "|    time_elapsed         | 29595        |\n",
      "|    total_timesteps      | 3106816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041966485 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.261        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 20050        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    reward               | 5.553718     |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 76.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1518         |\n",
      "|    time_elapsed         | 29614        |\n",
      "|    total_timesteps      | 3108864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058391234 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.15         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 20060        |\n",
      "|    policy_gradient_loss | -0.00761     |\n",
      "|    reward               | -3.9033413   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 56.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1519        |\n",
      "|    time_elapsed         | 29634       |\n",
      "|    total_timesteps      | 3110912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005808755 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 20070       |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | -0.8740982  |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 62.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1520        |\n",
      "|    time_elapsed         | 29653       |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006547607 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 20080       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | -0.7284723  |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1521         |\n",
      "|    time_elapsed         | 29671        |\n",
      "|    total_timesteps      | 3115008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033749081 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.1         |\n",
      "|    n_updates            | 20090        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | 1.382025     |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 58.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1522         |\n",
      "|    time_elapsed         | 29690        |\n",
      "|    total_timesteps      | 3117056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009779535  |\n",
      "|    clip_fraction        | 0.0784       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.98         |\n",
      "|    n_updates            | 20100        |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    reward               | -0.018622749 |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1523         |\n",
      "|    time_elapsed         | 29709        |\n",
      "|    total_timesteps      | 3119104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067066853 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 20110        |\n",
      "|    policy_gradient_loss | -0.00784     |\n",
      "|    reward               | 0.40209907   |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 54.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1524        |\n",
      "|    time_elapsed         | 29728       |\n",
      "|    total_timesteps      | 3121152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002992595 |\n",
      "|    clip_fraction        | 0.00527     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.5        |\n",
      "|    n_updates            | 20120       |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | -9.317828   |\n",
      "|    std                  | 16          |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1525        |\n",
      "|    time_elapsed         | 29748       |\n",
      "|    total_timesteps      | 3123200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011877538 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 20130       |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | 2.717274    |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1526         |\n",
      "|    time_elapsed         | 29767        |\n",
      "|    total_timesteps      | 3125248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007922886  |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 20140        |\n",
      "|    policy_gradient_loss | -0.00822     |\n",
      "|    reward               | -0.021986384 |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1527       |\n",
      "|    time_elapsed         | 29786      |\n",
      "|    total_timesteps      | 3127296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00328267 |\n",
      "|    clip_fraction        | 0.00869    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -121       |\n",
      "|    explained_variance   | 0.654      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.1       |\n",
      "|    n_updates            | 20150      |\n",
      "|    policy_gradient_loss | -0.00425   |\n",
      "|    reward               | 5.219735   |\n",
      "|    std                  | 16.1       |\n",
      "|    value_loss           | 65.4       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4078519.99\n",
      "total_reward: 3078519.99\n",
      "total_cost: 158979.59\n",
      "total_trades: 55945\n",
      "Sharpe: 0.772\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1528         |\n",
      "|    time_elapsed         | 29805        |\n",
      "|    total_timesteps      | 3129344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012608849 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 20160        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | -3.521615    |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 49.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1529        |\n",
      "|    time_elapsed         | 29824       |\n",
      "|    total_timesteps      | 3131392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011110344 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.12        |\n",
      "|    n_updates            | 20170       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | -2.2030988  |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1530         |\n",
      "|    time_elapsed         | 29843        |\n",
      "|    total_timesteps      | 3133440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053844983 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 20180        |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    reward               | 1.91761      |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 83.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1531         |\n",
      "|    time_elapsed         | 29862        |\n",
      "|    total_timesteps      | 3135488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037624387 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 20190        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 5.888039     |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 73.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1532        |\n",
      "|    time_elapsed         | 29881       |\n",
      "|    total_timesteps      | 3137536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006450154 |\n",
      "|    clip_fraction        | 0.0226      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 20200       |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | 3.0551648   |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1533         |\n",
      "|    time_elapsed         | 29900        |\n",
      "|    total_timesteps      | 3139584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068547195 |\n",
      "|    clip_fraction        | 0.0371       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.19         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.8         |\n",
      "|    n_updates            | 20210        |\n",
      "|    policy_gradient_loss | -0.00894     |\n",
      "|    reward               | 0.81543505   |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 85.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1534         |\n",
      "|    time_elapsed         | 29919        |\n",
      "|    total_timesteps      | 3141632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026419736 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.8         |\n",
      "|    n_updates            | 20220        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | 1.6508411    |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 56.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1535        |\n",
      "|    time_elapsed         | 29938       |\n",
      "|    total_timesteps      | 3143680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002934114 |\n",
      "|    clip_fraction        | 0.00415     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 20230       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | -8.784652   |\n",
      "|    std                  | 16.3        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1536         |\n",
      "|    time_elapsed         | 29957        |\n",
      "|    total_timesteps      | 3145728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067019276 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 20240        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    reward               | 0.37860098   |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1537        |\n",
      "|    time_elapsed         | 29976       |\n",
      "|    total_timesteps      | 3147776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004090597 |\n",
      "|    clip_fraction        | 0.00991     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 20250       |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | 0.25414103  |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1538        |\n",
      "|    time_elapsed         | 29996       |\n",
      "|    total_timesteps      | 3149824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005222721 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 20260       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | 1.8886585   |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 1539       |\n",
      "|    time_elapsed         | 30015      |\n",
      "|    total_timesteps      | 3151872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00908544 |\n",
      "|    clip_fraction        | 0.0465     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -121       |\n",
      "|    explained_variance   | 0.609      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.55       |\n",
      "|    n_updates            | 20270      |\n",
      "|    policy_gradient_loss | -0.00822   |\n",
      "|    reward               | 0.3672941  |\n",
      "|    std                  | 16.4       |\n",
      "|    value_loss           | 19.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1540         |\n",
      "|    time_elapsed         | 30034        |\n",
      "|    total_timesteps      | 3153920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038981633 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 20280        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    reward               | -2.3838127   |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 53.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1541        |\n",
      "|    time_elapsed         | 30081       |\n",
      "|    total_timesteps      | 3155968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005505724 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 20290       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -1.3237631  |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4008688.50\n",
      "total_reward: 3008688.50\n",
      "total_cost: 118990.95\n",
      "total_trades: 52607\n",
      "Sharpe: 0.731\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1542         |\n",
      "|    time_elapsed         | 30101        |\n",
      "|    total_timesteps      | 3158016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061173756 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 20300        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    reward               | -3.526354    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1543         |\n",
      "|    time_elapsed         | 30120        |\n",
      "|    total_timesteps      | 3160064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006451999  |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.812        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 20310        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    reward               | -0.039372187 |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1544         |\n",
      "|    time_elapsed         | 30138        |\n",
      "|    total_timesteps      | 3162112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023235483 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 20320        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 1.0930512    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 62.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1545         |\n",
      "|    time_elapsed         | 30158        |\n",
      "|    total_timesteps      | 3164160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036218907 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 20330        |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    reward               | 0.5676243    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1546        |\n",
      "|    time_elapsed         | 30177       |\n",
      "|    total_timesteps      | 3166208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008236924 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.63        |\n",
      "|    n_updates            | 20340       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 1.2001925   |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1547        |\n",
      "|    time_elapsed         | 30197       |\n",
      "|    total_timesteps      | 3168256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003732196 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.8        |\n",
      "|    n_updates            | 20350       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | 1.647497    |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1548        |\n",
      "|    time_elapsed         | 30215       |\n",
      "|    total_timesteps      | 3170304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003211422 |\n",
      "|    clip_fraction        | 0.00332     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 20360       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | -0.50358516 |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1549        |\n",
      "|    time_elapsed         | 30234       |\n",
      "|    total_timesteps      | 3172352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007665523 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 20370       |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    reward               | 0.58384824  |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1550         |\n",
      "|    time_elapsed         | 30254        |\n",
      "|    total_timesteps      | 3174400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051883813 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 20380        |\n",
      "|    policy_gradient_loss | -0.00733     |\n",
      "|    reward               | -0.3785002   |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1551        |\n",
      "|    time_elapsed         | 30273       |\n",
      "|    total_timesteps      | 3176448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006942143 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.1        |\n",
      "|    n_updates            | 20390       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -11.065521  |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 52.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1552         |\n",
      "|    time_elapsed         | 30292        |\n",
      "|    total_timesteps      | 3178496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032178005 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 20400        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | -0.46436426  |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1553         |\n",
      "|    time_elapsed         | 30311        |\n",
      "|    total_timesteps      | 3180544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097892005 |\n",
      "|    clip_fraction        | 0.0751       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 20410        |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    reward               | 1.9870607    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 19.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1554         |\n",
      "|    time_elapsed         | 30330        |\n",
      "|    total_timesteps      | 3182592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021728324 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 20420        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    reward               | -0.132518    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 49.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1555         |\n",
      "|    time_elapsed         | 30349        |\n",
      "|    total_timesteps      | 3184640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016923907 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 20430        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | -1.6534458   |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 56.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4250887.55\n",
      "total_reward: 3250887.55\n",
      "total_cost: 126201.75\n",
      "total_trades: 52849\n",
      "Sharpe: 0.784\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1556        |\n",
      "|    time_elapsed         | 30368       |\n",
      "|    total_timesteps      | 3186688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004950458 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.6         |\n",
      "|    n_updates            | 20440       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    reward               | -4.6058974  |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1557         |\n",
      "|    time_elapsed         | 30388        |\n",
      "|    total_timesteps      | 3188736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040586228 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 20450        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | -3.7364342   |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1558         |\n",
      "|    time_elapsed         | 30406        |\n",
      "|    total_timesteps      | 3190784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036764261 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 20460        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -0.4303571   |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 60.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1559       |\n",
      "|    time_elapsed         | 30425      |\n",
      "|    total_timesteps      | 3192832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00246177 |\n",
      "|    clip_fraction        | 0.00269    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -122       |\n",
      "|    explained_variance   | -0.0193    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.1       |\n",
      "|    n_updates            | 20470      |\n",
      "|    policy_gradient_loss | -0.00377   |\n",
      "|    reward               | -2.211973  |\n",
      "|    std                  | 16.9       |\n",
      "|    value_loss           | 69         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1560         |\n",
      "|    time_elapsed         | 30445        |\n",
      "|    total_timesteps      | 3194880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075803036 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.265        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.6         |\n",
      "|    n_updates            | 20480        |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    reward               | 2.4318616    |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 56.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1561         |\n",
      "|    time_elapsed         | 30464        |\n",
      "|    total_timesteps      | 3196928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034042809 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 20490        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    reward               | 0.25242063   |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 69.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1562         |\n",
      "|    time_elapsed         | 30483        |\n",
      "|    total_timesteps      | 3198976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031213635 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 20500        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | -0.80102605  |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1563        |\n",
      "|    time_elapsed         | 30503       |\n",
      "|    total_timesteps      | 3201024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009761156 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.34        |\n",
      "|    n_updates            | 20510       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.8072935   |\n",
      "|    std                  | 17.1        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1564        |\n",
      "|    time_elapsed         | 30522       |\n",
      "|    total_timesteps      | 3203072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004970907 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 20520       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | 0.4347043   |\n",
      "|    std                  | 17.1        |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1565         |\n",
      "|    time_elapsed         | 30540        |\n",
      "|    total_timesteps      | 3205120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014156401 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 20530        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -3.3282967   |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 65.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1566        |\n",
      "|    time_elapsed         | 30559       |\n",
      "|    total_timesteps      | 3207168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00393611  |\n",
      "|    clip_fraction        | 0.00713     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 20540       |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | -0.75597674 |\n",
      "|    std                  | 17.1        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 1567       |\n",
      "|    time_elapsed         | 30578      |\n",
      "|    total_timesteps      | 3209216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00543366 |\n",
      "|    clip_fraction        | 0.0187     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -123       |\n",
      "|    explained_variance   | 0.651      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.1       |\n",
      "|    n_updates            | 20550      |\n",
      "|    policy_gradient_loss | -0.00498   |\n",
      "|    reward               | -1.5730166 |\n",
      "|    std                  | 17.2       |\n",
      "|    value_loss           | 30         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1568        |\n",
      "|    time_elapsed         | 30597       |\n",
      "|    total_timesteps      | 3211264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003853452 |\n",
      "|    clip_fraction        | 0.00864     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 20560       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | -1.4702079  |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1569         |\n",
      "|    time_elapsed         | 30616        |\n",
      "|    total_timesteps      | 3213312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027209274 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 20570        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | -0.27333954  |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 62.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4033407.28\n",
      "total_reward: 3033407.28\n",
      "total_cost: 119259.68\n",
      "total_trades: 53068\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1570        |\n",
      "|    time_elapsed         | 30635       |\n",
      "|    total_timesteps      | 3215360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009605009 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.58        |\n",
      "|    n_updates            | 20580       |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | -1.7382472  |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1571        |\n",
      "|    time_elapsed         | 30654       |\n",
      "|    total_timesteps      | 3217408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006505517 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 20590       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 0.94517297  |\n",
      "|    std                  | 17.3        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1572         |\n",
      "|    time_elapsed         | 30673        |\n",
      "|    total_timesteps      | 3219456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025647548 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.2         |\n",
      "|    n_updates            | 20600        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | 2.0487552    |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 65.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1573         |\n",
      "|    time_elapsed         | 30692        |\n",
      "|    total_timesteps      | 3221504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040135793 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 20610        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | -0.8315911   |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1574         |\n",
      "|    time_elapsed         | 30711        |\n",
      "|    total_timesteps      | 3223552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061625307 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 20620        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | 0.90888834   |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1575         |\n",
      "|    time_elapsed         | 30730        |\n",
      "|    total_timesteps      | 3225600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039823796 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 20630        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | 0.104006544  |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 51.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1576        |\n",
      "|    time_elapsed         | 30750       |\n",
      "|    total_timesteps      | 3227648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005684071 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 20640       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 0.954782    |\n",
      "|    std                  | 17.4        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1577        |\n",
      "|    time_elapsed         | 30769       |\n",
      "|    total_timesteps      | 3229696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004415744 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 20650       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | 1.2748579   |\n",
      "|    std                  | 17.4        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1578         |\n",
      "|    time_elapsed         | 30787        |\n",
      "|    total_timesteps      | 3231744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044816835 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.271        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 20660        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | -1.6020405   |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 76.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1579         |\n",
      "|    time_elapsed         | 30806        |\n",
      "|    total_timesteps      | 3233792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013302672 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.6         |\n",
      "|    n_updates            | 20670        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | 4.182864     |\n",
      "|    std                  | 17.5         |\n",
      "|    value_loss           | 81.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1580         |\n",
      "|    time_elapsed         | 30825        |\n",
      "|    total_timesteps      | 3235840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028243857 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 20680        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | 1.4088638    |\n",
      "|    std                  | 17.5         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1581        |\n",
      "|    time_elapsed         | 30843       |\n",
      "|    total_timesteps      | 3237888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008386869 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 20690       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 2.2558322   |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1582        |\n",
      "|    time_elapsed         | 30863       |\n",
      "|    total_timesteps      | 3239936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002549746 |\n",
      "|    clip_fraction        | 0.0043      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 20700       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | -0.3494563  |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1583         |\n",
      "|    time_elapsed         | 30882        |\n",
      "|    total_timesteps      | 3241984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064050066 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.294        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 20710        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    reward               | -1.6935465   |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 47.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4020723.32\n",
      "total_reward: 3020723.32\n",
      "total_cost: 127318.55\n",
      "total_trades: 54493\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1584         |\n",
      "|    time_elapsed         | 30902        |\n",
      "|    total_timesteps      | 3244032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052029076 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.307        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 20720        |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    reward               | -0.044923373 |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1585        |\n",
      "|    time_elapsed         | 30921       |\n",
      "|    total_timesteps      | 3246080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004613894 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 20730       |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | 0.8757298   |\n",
      "|    std                  | 17.7        |\n",
      "|    value_loss           | 68.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1586         |\n",
      "|    time_elapsed         | 30939        |\n",
      "|    total_timesteps      | 3248128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041439375 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 20740        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | -3.2780397   |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 63.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1587        |\n",
      "|    time_elapsed         | 30958       |\n",
      "|    total_timesteps      | 3250176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007611336 |\n",
      "|    clip_fraction        | 0.0362      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.88        |\n",
      "|    n_updates            | 20750       |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | 1.8841239   |\n",
      "|    std                  | 17.7        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1588         |\n",
      "|    time_elapsed         | 30978        |\n",
      "|    total_timesteps      | 3252224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059022354 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 20760        |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    reward               | -0.9373296   |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 51.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1589         |\n",
      "|    time_elapsed         | 30997        |\n",
      "|    total_timesteps      | 3254272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040298533 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 20770        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    reward               | 0.2770379    |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1590        |\n",
      "|    time_elapsed         | 31016       |\n",
      "|    total_timesteps      | 3256320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004943857 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 20780       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | -0.710927   |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1591        |\n",
      "|    time_elapsed         | 31035       |\n",
      "|    total_timesteps      | 3258368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006436843 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 20790       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | -2.3019137  |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1592         |\n",
      "|    time_elapsed         | 31054        |\n",
      "|    total_timesteps      | 3260416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053554513 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.6         |\n",
      "|    n_updates            | 20800        |\n",
      "|    policy_gradient_loss | -0.00784     |\n",
      "|    reward               | -0.17164735  |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 74.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1593         |\n",
      "|    time_elapsed         | 31073        |\n",
      "|    total_timesteps      | 3262464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014249582 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 20810        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | 4.3006153    |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 55.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1594        |\n",
      "|    time_elapsed         | 31092       |\n",
      "|    total_timesteps      | 3264512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007839523 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.09        |\n",
      "|    n_updates            | 20820       |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    reward               | -0.44127706 |\n",
      "|    std                  | 17.9        |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1595        |\n",
      "|    time_elapsed         | 31112       |\n",
      "|    total_timesteps      | 3266560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004937595 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 20830       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | -0.26752943 |\n",
      "|    std                  | 17.9        |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1596        |\n",
      "|    time_elapsed         | 31131       |\n",
      "|    total_timesteps      | 3268608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004261189 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 20840       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | -0.1691695  |\n",
      "|    std                  | 18          |\n",
      "|    value_loss           | 65.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1597        |\n",
      "|    time_elapsed         | 31150       |\n",
      "|    total_timesteps      | 3270656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007367531 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 20850       |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | -4.1975846  |\n",
      "|    std                  | 18          |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3566641.90\n",
      "total_reward: 2566641.90\n",
      "total_cost: 123489.53\n",
      "total_trades: 53628\n",
      "Sharpe: 0.697\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1598         |\n",
      "|    time_elapsed         | 31169        |\n",
      "|    total_timesteps      | 3272704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020801686 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.16         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 20860        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | 1.6011436    |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 60.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 104          |\n",
      "|    iterations           | 1599         |\n",
      "|    time_elapsed         | 31189        |\n",
      "|    total_timesteps      | 3274752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031624357 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 20870        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | -4.9682035   |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1600        |\n",
      "|    time_elapsed         | 31208       |\n",
      "|    total_timesteps      | 3276800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006002535 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 20880       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | -1.6807986  |\n",
      "|    std                  | 18          |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 1601        |\n",
      "|    time_elapsed         | 31227       |\n",
      "|    total_timesteps      | 3278848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005412127 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 20890       |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | -1.4094329  |\n",
      "|    std                  | 18.1        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1602         |\n",
      "|    time_elapsed         | 31246        |\n",
      "|    total_timesteps      | 3280896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051929615 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 20900        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    reward               | 0.017003087  |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 53.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1603         |\n",
      "|    time_elapsed         | 31265        |\n",
      "|    total_timesteps      | 3282944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033622803 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.8         |\n",
      "|    n_updates            | 20910        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | 3.2661405    |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 57.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1604         |\n",
      "|    time_elapsed         | 31285        |\n",
      "|    total_timesteps      | 3284992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058433698 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 20920        |\n",
      "|    policy_gradient_loss | -0.00725     |\n",
      "|    reward               | 2.6796472    |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1605         |\n",
      "|    time_elapsed         | 31304        |\n",
      "|    total_timesteps      | 3287040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045647663 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 20930        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | 0.506002     |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 67.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1606        |\n",
      "|    time_elapsed         | 31322       |\n",
      "|    total_timesteps      | 3289088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004229287 |\n",
      "|    clip_fraction        | 0.00947     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 20940       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | 0.21271756  |\n",
      "|    std                  | 18.1        |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1607         |\n",
      "|    time_elapsed         | 31341        |\n",
      "|    total_timesteps      | 3291136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033639679 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 20950        |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    reward               | -0.055445105 |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1608         |\n",
      "|    time_elapsed         | 31360        |\n",
      "|    total_timesteps      | 3293184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050360747 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 20960        |\n",
      "|    policy_gradient_loss | -0.00768     |\n",
      "|    reward               | -2.1235652   |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1609         |\n",
      "|    time_elapsed         | 31379        |\n",
      "|    total_timesteps      | 3295232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021832343 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.8         |\n",
      "|    n_updates            | 20970        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | 1.149517     |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 70.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1610         |\n",
      "|    time_elapsed         | 31399        |\n",
      "|    total_timesteps      | 3297280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031253486 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 20980        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -5.111938    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 68.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1611        |\n",
      "|    time_elapsed         | 31418       |\n",
      "|    total_timesteps      | 3299328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009014966 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.92        |\n",
      "|    n_updates            | 20990       |\n",
      "|    policy_gradient_loss | -0.00956    |\n",
      "|    reward               | 2.9501665   |\n",
      "|    std                  | 18.3        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4036846.12\n",
      "total_reward: 3036846.12\n",
      "total_cost: 153133.38\n",
      "total_trades: 56341\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1612        |\n",
      "|    time_elapsed         | 31437       |\n",
      "|    total_timesteps      | 3301376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003996202 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 21000       |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | 0.44937995  |\n",
      "|    std                  | 18.3        |\n",
      "|    value_loss           | 61.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1613        |\n",
      "|    time_elapsed         | 31456       |\n",
      "|    total_timesteps      | 3303424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003791713 |\n",
      "|    clip_fraction        | 0.0264      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 21010       |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    reward               | -18.114956  |\n",
      "|    std                  | 18.3        |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1614         |\n",
      "|    time_elapsed         | 31475        |\n",
      "|    total_timesteps      | 3305472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047876826 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 21020        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | 1.6711628    |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 55.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1615        |\n",
      "|    time_elapsed         | 31495       |\n",
      "|    total_timesteps      | 3307520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004983657 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 21030       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -0.94743854 |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1616        |\n",
      "|    time_elapsed         | 31513       |\n",
      "|    total_timesteps      | 3309568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003941501 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 21040       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | 5.613475    |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 64          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1617         |\n",
      "|    time_elapsed         | 31532        |\n",
      "|    total_timesteps      | 3311616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045441194 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48           |\n",
      "|    n_updates            | 21050        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | 0.12510201   |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 70.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1618         |\n",
      "|    time_elapsed         | 31551        |\n",
      "|    total_timesteps      | 3313664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085873045 |\n",
      "|    clip_fraction        | 0.0537       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.15         |\n",
      "|    n_updates            | 21060        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    reward               | 3.3815758    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1619         |\n",
      "|    time_elapsed         | 31570        |\n",
      "|    total_timesteps      | 3315712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023372378 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 21070        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | 2.178554     |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 61.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1620         |\n",
      "|    time_elapsed         | 31589        |\n",
      "|    total_timesteps      | 3317760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042392006 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 21080        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | -1.6639693   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 58           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1621        |\n",
      "|    time_elapsed         | 31608       |\n",
      "|    total_timesteps      | 3319808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003993762 |\n",
      "|    clip_fraction        | 0.0083      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 21090       |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    reward               | 0.026720513 |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1622         |\n",
      "|    time_elapsed         | 31627        |\n",
      "|    total_timesteps      | 3321856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019725696 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 21100        |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    reward               | -2.641323    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 49.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1623         |\n",
      "|    time_elapsed         | 31646        |\n",
      "|    total_timesteps      | 3323904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036850648 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 21110        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 1.3582971    |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 60.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1624         |\n",
      "|    time_elapsed         | 31665        |\n",
      "|    total_timesteps      | 3325952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045214137 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 21120        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    reward               | 0.3854892    |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1625         |\n",
      "|    time_elapsed         | 31684        |\n",
      "|    total_timesteps      | 3328000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044193338 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 21130        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | 1.4291346    |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4114499.50\n",
      "total_reward: 3114499.50\n",
      "total_cost: 152411.25\n",
      "total_trades: 55940\n",
      "Sharpe: 0.776\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1626         |\n",
      "|    time_elapsed         | 31703        |\n",
      "|    total_timesteps      | 3330048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034137154 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.7         |\n",
      "|    n_updates            | 21140        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | -1.5202543   |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 63.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1627         |\n",
      "|    time_elapsed         | 31722        |\n",
      "|    total_timesteps      | 3332096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052718995 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 21150        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | 2.3084655    |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 62.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1628        |\n",
      "|    time_elapsed         | 31741       |\n",
      "|    total_timesteps      | 3334144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008585417 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.65        |\n",
      "|    n_updates            | 21160       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | -0.77283496 |\n",
      "|    std                  | 18.7        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1629         |\n",
      "|    time_elapsed         | 31761        |\n",
      "|    total_timesteps      | 3336192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035776803 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 21170        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | 1.6346949    |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 69           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1630        |\n",
      "|    time_elapsed         | 31780       |\n",
      "|    total_timesteps      | 3338240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004747932 |\n",
      "|    clip_fraction        | 0.0295      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 21180       |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | -0.7570953  |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1631         |\n",
      "|    time_elapsed         | 31799        |\n",
      "|    total_timesteps      | 3340288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012063291 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 21190        |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    reward               | -2.864438    |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 45.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1632         |\n",
      "|    time_elapsed         | 31819        |\n",
      "|    total_timesteps      | 3342336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066881357 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.2         |\n",
      "|    n_updates            | 21200        |\n",
      "|    policy_gradient_loss | -0.00743     |\n",
      "|    reward               | 0.228967     |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1633         |\n",
      "|    time_elapsed         | 31838        |\n",
      "|    total_timesteps      | 3344384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048648217 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 21210        |\n",
      "|    policy_gradient_loss | -0.00698     |\n",
      "|    reward               | 0.54263806   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 58.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1634         |\n",
      "|    time_elapsed         | 31857        |\n",
      "|    total_timesteps      | 3346432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031143716 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 21220        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 0.28615433   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 54.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1635         |\n",
      "|    time_elapsed         | 31876        |\n",
      "|    total_timesteps      | 3348480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064469706 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 21230        |\n",
      "|    policy_gradient_loss | -0.00732     |\n",
      "|    reward               | -5.0083427   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1636         |\n",
      "|    time_elapsed         | 31895        |\n",
      "|    total_timesteps      | 3350528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021726242 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 21240        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | -1.2208307   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 62.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1637         |\n",
      "|    time_elapsed         | 31914        |\n",
      "|    total_timesteps      | 3352576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036078729 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 21250        |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    reward               | -0.14966129  |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1638         |\n",
      "|    time_elapsed         | 31933        |\n",
      "|    total_timesteps      | 3354624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041445782 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 21260        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | 1.4181271    |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1639         |\n",
      "|    time_elapsed         | 31952        |\n",
      "|    total_timesteps      | 3356672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050714617 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 21270        |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    reward               | 0.16956969   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 40.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1640         |\n",
      "|    time_elapsed         | 31971        |\n",
      "|    total_timesteps      | 3358720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035640663 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 21280        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    reward               | 5.7071323    |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 57.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4081246.42\n",
      "total_reward: 3081246.42\n",
      "total_cost: 107673.56\n",
      "total_trades: 53228\n",
      "Sharpe: 0.756\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1641         |\n",
      "|    time_elapsed         | 31990        |\n",
      "|    total_timesteps      | 3360768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015645372 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 21290        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 0.122849375  |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 68           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1642         |\n",
      "|    time_elapsed         | 32009        |\n",
      "|    total_timesteps      | 3362816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097211525 |\n",
      "|    clip_fraction        | 0.0527       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.71         |\n",
      "|    n_updates            | 21300        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    reward               | 0.13791281   |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1643         |\n",
      "|    time_elapsed         | 32028        |\n",
      "|    total_timesteps      | 3364864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031002436 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 21310        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    reward               | 0.21928807   |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1644         |\n",
      "|    time_elapsed         | 32047        |\n",
      "|    total_timesteps      | 3366912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024299675 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 21320        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | 2.1393282    |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 58.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1645         |\n",
      "|    time_elapsed         | 32067        |\n",
      "|    total_timesteps      | 3368960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047134715 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 21330        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    reward               | -0.7158869   |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1646        |\n",
      "|    time_elapsed         | 32086       |\n",
      "|    total_timesteps      | 3371008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005603447 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 21340       |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    reward               | -1.7820487  |\n",
      "|    std                  | 19.4        |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1647        |\n",
      "|    time_elapsed         | 32105       |\n",
      "|    total_timesteps      | 3373056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006244808 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 21350       |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | -0.5065661  |\n",
      "|    std                  | 19.4        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1648         |\n",
      "|    time_elapsed         | 32124        |\n",
      "|    total_timesteps      | 3375104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044795256 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 21360        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    reward               | 3.8651693    |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1649         |\n",
      "|    time_elapsed         | 32143        |\n",
      "|    total_timesteps      | 3377152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027341428 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 21370        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | 0.2552246    |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 1650       |\n",
      "|    time_elapsed         | 32162      |\n",
      "|    total_timesteps      | 3379200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00159415 |\n",
      "|    clip_fraction        | 0.00298    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -126       |\n",
      "|    explained_variance   | 0.678      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.3       |\n",
      "|    n_updates            | 21380      |\n",
      "|    policy_gradient_loss | -0.00346   |\n",
      "|    reward               | 0.08739531 |\n",
      "|    std                  | 19.5       |\n",
      "|    value_loss           | 61.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1651         |\n",
      "|    time_elapsed         | 32181        |\n",
      "|    total_timesteps      | 3381248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034885933 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.7         |\n",
      "|    n_updates            | 21390        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 1.3485934    |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 61.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1652         |\n",
      "|    time_elapsed         | 32200        |\n",
      "|    total_timesteps      | 3383296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082604075 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 21400        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    reward               | -0.36578506  |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1653        |\n",
      "|    time_elapsed         | 32219       |\n",
      "|    total_timesteps      | 3385344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004915752 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 21410       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    reward               | -0.37672213 |\n",
      "|    std                  | 19.6        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1654         |\n",
      "|    time_elapsed         | 32238        |\n",
      "|    total_timesteps      | 3387392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004843797  |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.168        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 21420        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | -0.041071806 |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 79.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3672313.05\n",
      "total_reward: 2672313.05\n",
      "total_cost: 171395.15\n",
      "total_trades: 58620\n",
      "Sharpe: 0.704\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1655         |\n",
      "|    time_elapsed         | 32257        |\n",
      "|    total_timesteps      | 3389440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036514034 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 21430        |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | -0.007248918 |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1656        |\n",
      "|    time_elapsed         | 32276       |\n",
      "|    total_timesteps      | 3391488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006035923 |\n",
      "|    clip_fraction        | 0.0223      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 21440       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | 4.20633     |\n",
      "|    std                  | 19.7        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1657         |\n",
      "|    time_elapsed         | 32296        |\n",
      "|    total_timesteps      | 3393536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023314646 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 21450        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 1.4400514    |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 50.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1658         |\n",
      "|    time_elapsed         | 32315        |\n",
      "|    total_timesteps      | 3395584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025398587 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 21460        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -0.34500548  |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 54           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1659         |\n",
      "|    time_elapsed         | 32333        |\n",
      "|    total_timesteps      | 3397632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077024787 |\n",
      "|    clip_fraction        | 0.0498       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.199        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.14         |\n",
      "|    n_updates            | 21470        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    reward               | -1.1792301   |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 15.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1660         |\n",
      "|    time_elapsed         | 32352        |\n",
      "|    total_timesteps      | 3399680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040094173 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 21480        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | -1.3131471   |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1661         |\n",
      "|    time_elapsed         | 32371        |\n",
      "|    total_timesteps      | 3401728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039425013 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.2         |\n",
      "|    n_updates            | 21490        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 4.014778     |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1662         |\n",
      "|    time_elapsed         | 32390        |\n",
      "|    total_timesteps      | 3403776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037123016 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 21500        |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    reward               | -2.0800042   |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1663         |\n",
      "|    time_elapsed         | 32409        |\n",
      "|    total_timesteps      | 3405824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055381497 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 21510        |\n",
      "|    policy_gradient_loss | -0.00798     |\n",
      "|    reward               | 1.3403906    |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1664         |\n",
      "|    time_elapsed         | 32428        |\n",
      "|    total_timesteps      | 3407872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022573122 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.316        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.8         |\n",
      "|    n_updates            | 21520        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | -4.777797    |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 72.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1665         |\n",
      "|    time_elapsed         | 32447        |\n",
      "|    total_timesteps      | 3409920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034970287 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 21530        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | 0.5284773    |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1666        |\n",
      "|    time_elapsed         | 32466       |\n",
      "|    total_timesteps      | 3411968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007612416 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.94        |\n",
      "|    n_updates            | 21540       |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    reward               | 2.0314248   |\n",
      "|    std                  | 20          |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1667         |\n",
      "|    time_elapsed         | 32485        |\n",
      "|    total_timesteps      | 3414016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034570354 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 21550        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | -1.0373181   |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 58.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1668         |\n",
      "|    time_elapsed         | 32503        |\n",
      "|    total_timesteps      | 3416064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004848368 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 21560        |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    reward               | 0.61764485   |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 65.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3657486.99\n",
      "total_reward: 2657486.99\n",
      "total_cost: 115438.10\n",
      "total_trades: 54388\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1669        |\n",
      "|    time_elapsed         | 32522       |\n",
      "|    total_timesteps      | 3418112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002723514 |\n",
      "|    clip_fraction        | 0.00293     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 21570       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | 0.07045834  |\n",
      "|    std                  | 20.1        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1670        |\n",
      "|    time_elapsed         | 32541       |\n",
      "|    total_timesteps      | 3420160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004906043 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 21580       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | -2.454356   |\n",
      "|    std                  | 20.2        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1671         |\n",
      "|    time_elapsed         | 32560        |\n",
      "|    total_timesteps      | 3422208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006450431 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 21590        |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    reward               | -0.91470623  |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 56.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1672         |\n",
      "|    time_elapsed         | 32579        |\n",
      "|    total_timesteps      | 3424256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030514821 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 21600        |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    reward               | -0.20864418  |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1673         |\n",
      "|    time_elapsed         | 32598        |\n",
      "|    total_timesteps      | 3426304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028271151 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 21610        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    reward               | 0.53689355   |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1674         |\n",
      "|    time_elapsed         | 32617        |\n",
      "|    total_timesteps      | 3428352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028200606 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 21620        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | 0.3670279    |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 51.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1675          |\n",
      "|    time_elapsed         | 32636         |\n",
      "|    total_timesteps      | 3430400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086173974 |\n",
      "|    clip_fraction        | 0.00103       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.695         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.1          |\n",
      "|    n_updates            | 21630         |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    reward               | -3.9640522    |\n",
      "|    std                  | 20.3          |\n",
      "|    value_loss           | 48.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1676         |\n",
      "|    time_elapsed         | 32655        |\n",
      "|    total_timesteps      | 3432448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073745814 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.33         |\n",
      "|    n_updates            | 21640        |\n",
      "|    policy_gradient_loss | -0.00892     |\n",
      "|    reward               | -1.7597119   |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1677         |\n",
      "|    time_elapsed         | 32674        |\n",
      "|    total_timesteps      | 3434496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017573049 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 21650        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | -0.29147047  |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1678         |\n",
      "|    time_elapsed         | 32693        |\n",
      "|    total_timesteps      | 3436544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022620584 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 21660        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | -0.28799307  |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 50.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1679        |\n",
      "|    time_elapsed         | 32712       |\n",
      "|    total_timesteps      | 3438592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003959616 |\n",
      "|    clip_fraction        | 0.00918     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 21670       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    reward               | 4.8265796   |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1680         |\n",
      "|    time_elapsed         | 32731        |\n",
      "|    total_timesteps      | 3440640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056379642 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 21680        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | 2.8677773    |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1681        |\n",
      "|    time_elapsed         | 32750       |\n",
      "|    total_timesteps      | 3442688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002633545 |\n",
      "|    clip_fraction        | 0.00728     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 21690       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    reward               | -0.6202854  |\n",
      "|    std                  | 20.5        |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1682         |\n",
      "|    time_elapsed         | 32769        |\n",
      "|    total_timesteps      | 3444736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019564247 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 21700        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -0.8410562   |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4069696.17\n",
      "total_reward: 3069696.17\n",
      "total_cost: 167662.87\n",
      "total_trades: 57864\n",
      "Sharpe: 0.777\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 1683       |\n",
      "|    time_elapsed         | 32788      |\n",
      "|    total_timesteps      | 3446784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01024426 |\n",
      "|    clip_fraction        | 0.0688     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -128       |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.84       |\n",
      "|    n_updates            | 21710      |\n",
      "|    policy_gradient_loss | -0.00871   |\n",
      "|    reward               | -1.9499172 |\n",
      "|    std                  | 20.6       |\n",
      "|    value_loss           | 16.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1684         |\n",
      "|    time_elapsed         | 32807        |\n",
      "|    total_timesteps      | 3448832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064169727 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 21720        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    reward               | -0.42056015  |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1685         |\n",
      "|    time_elapsed         | 32826        |\n",
      "|    total_timesteps      | 3450880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020645186 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 21730        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 5.570943     |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 52.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1686         |\n",
      "|    time_elapsed         | 32845        |\n",
      "|    total_timesteps      | 3452928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005877037  |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 21740        |\n",
      "|    policy_gradient_loss | -0.00885     |\n",
      "|    reward               | -0.068041325 |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1687         |\n",
      "|    time_elapsed         | 32864        |\n",
      "|    total_timesteps      | 3454976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046652406 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.15         |\n",
      "|    n_updates            | 21750        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | 5.497897     |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1688         |\n",
      "|    time_elapsed         | 32883        |\n",
      "|    total_timesteps      | 3457024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029441917 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 21760        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    reward               | 0.70041484   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1689         |\n",
      "|    time_elapsed         | 32902        |\n",
      "|    total_timesteps      | 3459072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018137263 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 21770        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | -4.324203    |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1690         |\n",
      "|    time_elapsed         | 32921        |\n",
      "|    total_timesteps      | 3461120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035665177 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.83         |\n",
      "|    n_updates            | 21780        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | 1.8971523    |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1691         |\n",
      "|    time_elapsed         | 32940        |\n",
      "|    total_timesteps      | 3463168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022122785 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 21790        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | 0.24526203   |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1692         |\n",
      "|    time_elapsed         | 32959        |\n",
      "|    total_timesteps      | 3465216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034994325 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 21800        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | 0.06398012   |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 53.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1693        |\n",
      "|    time_elapsed         | 32978       |\n",
      "|    total_timesteps      | 3467264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005809606 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 21810       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | -6.078704   |\n",
      "|    std                  | 20.9        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1694         |\n",
      "|    time_elapsed         | 32997        |\n",
      "|    total_timesteps      | 3469312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030470605 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 21820        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | 1.9373608    |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1695        |\n",
      "|    time_elapsed         | 33016       |\n",
      "|    total_timesteps      | 3471360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004206173 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 21830       |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | -5.18045    |\n",
      "|    std                  | 20.9        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1696         |\n",
      "|    time_elapsed         | 33035        |\n",
      "|    total_timesteps      | 3473408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031097499 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 21840        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | -0.057025313 |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4177426.90\n",
      "total_reward: 3177426.90\n",
      "total_cost: 127043.84\n",
      "total_trades: 54209\n",
      "Sharpe: 0.761\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1697         |\n",
      "|    time_elapsed         | 33054        |\n",
      "|    total_timesteps      | 3475456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033689942 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 21850        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | -0.112699255 |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1698        |\n",
      "|    time_elapsed         | 33073       |\n",
      "|    total_timesteps      | 3477504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004395397 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.5        |\n",
      "|    n_updates            | 21860       |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    reward               | 0.103636846 |\n",
      "|    std                  | 21          |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1699        |\n",
      "|    time_elapsed         | 33092       |\n",
      "|    total_timesteps      | 3479552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001590412 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 21870       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    reward               | -1.243011   |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1700        |\n",
      "|    time_elapsed         | 33111       |\n",
      "|    total_timesteps      | 3481600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007433379 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.03        |\n",
      "|    n_updates            | 21880       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | 0.3098537   |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1701         |\n",
      "|    time_elapsed         | 33130        |\n",
      "|    total_timesteps      | 3483648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025915601 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 21890        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -0.19376974  |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 46.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1702         |\n",
      "|    time_elapsed         | 33149        |\n",
      "|    total_timesteps      | 3485696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020422093 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 21900        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | -4.2429624   |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 56.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1703         |\n",
      "|    time_elapsed         | 33168        |\n",
      "|    total_timesteps      | 3487744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035136857 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 21910        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | -1.3832678   |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1704         |\n",
      "|    time_elapsed         | 33187        |\n",
      "|    total_timesteps      | 3489792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041758656 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 21920        |\n",
      "|    policy_gradient_loss | -0.00762     |\n",
      "|    reward               | 1.5840878    |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1705         |\n",
      "|    time_elapsed         | 33206        |\n",
      "|    total_timesteps      | 3491840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041397056 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 21930        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | 9.9091       |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 51.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1706         |\n",
      "|    time_elapsed         | 33225        |\n",
      "|    total_timesteps      | 3493888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012486326 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 21940        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | -0.5971448   |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 71.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1707         |\n",
      "|    time_elapsed         | 33244        |\n",
      "|    total_timesteps      | 3495936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056494884 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.27         |\n",
      "|    n_updates            | 21950        |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    reward               | -1.28353     |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 1708       |\n",
      "|    time_elapsed         | 33263      |\n",
      "|    total_timesteps      | 3497984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00210949 |\n",
      "|    clip_fraction        | 0.00244    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -129       |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.4       |\n",
      "|    n_updates            | 21960      |\n",
      "|    policy_gradient_loss | -0.00352   |\n",
      "|    reward               | -5.214362  |\n",
      "|    std                  | 21.4       |\n",
      "|    value_loss           | 48.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1709        |\n",
      "|    time_elapsed         | 33282       |\n",
      "|    total_timesteps      | 3500032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002001738 |\n",
      "|    clip_fraction        | 0.00107     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 21970       |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    reward               | 3.6335576   |\n",
      "|    std                  | 21.4        |\n",
      "|    value_loss           | 72.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1710         |\n",
      "|    time_elapsed         | 33301        |\n",
      "|    total_timesteps      | 3502080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046111722 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 21980        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -2.0326488   |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4044946.04\n",
      "total_reward: 3044946.04\n",
      "total_cost: 135057.50\n",
      "total_trades: 55622\n",
      "Sharpe: 0.757\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1711         |\n",
      "|    time_elapsed         | 33321        |\n",
      "|    total_timesteps      | 3504128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077648424 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 21990        |\n",
      "|    policy_gradient_loss | -0.00738     |\n",
      "|    reward               | -2.2773159   |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 51.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1712        |\n",
      "|    time_elapsed         | 33340       |\n",
      "|    total_timesteps      | 3506176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002748033 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 22000       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | -1.5963484  |\n",
      "|    std                  | 21.5        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1713        |\n",
      "|    time_elapsed         | 33359       |\n",
      "|    total_timesteps      | 3508224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003636273 |\n",
      "|    clip_fraction        | 0.00537     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 22010       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | -1.3491011  |\n",
      "|    std                  | 21.5        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1714         |\n",
      "|    time_elapsed         | 33378        |\n",
      "|    total_timesteps      | 3510272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025990107 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.5         |\n",
      "|    n_updates            | 22020        |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    reward               | 2.0785723    |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1715         |\n",
      "|    time_elapsed         | 33397        |\n",
      "|    total_timesteps      | 3512320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023430944 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 22030        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -1.3802795   |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 54.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1716         |\n",
      "|    time_elapsed         | 33416        |\n",
      "|    total_timesteps      | 3514368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016512881 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 22040        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 0.5788974    |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1717        |\n",
      "|    time_elapsed         | 33435       |\n",
      "|    total_timesteps      | 3516416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009835174 |\n",
      "|    clip_fraction        | 0.0684      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.66        |\n",
      "|    n_updates            | 22050       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.029141622 |\n",
      "|    std                  | 21.6        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1718         |\n",
      "|    time_elapsed         | 33454        |\n",
      "|    total_timesteps      | 3518464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024131825 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 22060        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | 0.6527504    |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 50.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1719        |\n",
      "|    time_elapsed         | 33473       |\n",
      "|    total_timesteps      | 3520512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002017151 |\n",
      "|    clip_fraction        | 0.00229     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 22070       |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    reward               | 5.1671076   |\n",
      "|    std                  | 21.6        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1720         |\n",
      "|    time_elapsed         | 33492        |\n",
      "|    total_timesteps      | 3522560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019115503 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 22080        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | 1.0775318    |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1721         |\n",
      "|    time_elapsed         | 33511        |\n",
      "|    total_timesteps      | 3524608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055189375 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 22090        |\n",
      "|    policy_gradient_loss | -0.00857     |\n",
      "|    reward               | 0.4870756    |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1722         |\n",
      "|    time_elapsed         | 33530        |\n",
      "|    total_timesteps      | 3526656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026431298 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 22100        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | 0.023098962  |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1723         |\n",
      "|    time_elapsed         | 33549        |\n",
      "|    total_timesteps      | 3528704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014771036 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 22110        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -3.181225    |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 55.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1724        |\n",
      "|    time_elapsed         | 33568       |\n",
      "|    total_timesteps      | 3530752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005452469 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.31        |\n",
      "|    n_updates            | 22120       |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | 0.027727582 |\n",
      "|    std                  | 21.8        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3901672.28\n",
      "total_reward: 2901672.28\n",
      "total_cost: 120872.22\n",
      "total_trades: 54408\n",
      "Sharpe: 0.751\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1725         |\n",
      "|    time_elapsed         | 33587        |\n",
      "|    total_timesteps      | 3532800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040304298 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 22130        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | 0.1296097    |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1726        |\n",
      "|    time_elapsed         | 33606       |\n",
      "|    total_timesteps      | 3534848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004216059 |\n",
      "|    clip_fraction        | 0.00835     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 22140       |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | -1.7772682  |\n",
      "|    std                  | 21.8        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1727         |\n",
      "|    time_elapsed         | 33625        |\n",
      "|    total_timesteps      | 3536896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043030474 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 22150        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    reward               | -3.2210095   |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1728        |\n",
      "|    time_elapsed         | 33644       |\n",
      "|    total_timesteps      | 3538944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005667162 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 22160       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 0.11969319  |\n",
      "|    std                  | 21.9        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1729         |\n",
      "|    time_elapsed         | 33663        |\n",
      "|    total_timesteps      | 3540992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026991284 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 22170        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | 3.6509182    |\n",
      "|    std                  | 21.9         |\n",
      "|    value_loss           | 62.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1730         |\n",
      "|    time_elapsed         | 33682        |\n",
      "|    total_timesteps      | 3543040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018829925 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.8         |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | 0.099106655  |\n",
      "|    std                  | 21.9         |\n",
      "|    value_loss           | 86.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1731         |\n",
      "|    time_elapsed         | 33700        |\n",
      "|    total_timesteps      | 3545088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064968276 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.41         |\n",
      "|    n_updates            | 22190        |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    reward               | 0.16794416   |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 16.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1732         |\n",
      "|    time_elapsed         | 33720        |\n",
      "|    total_timesteps      | 3547136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013568833 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.7         |\n",
      "|    n_updates            | 22200        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | 1.0070431    |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 61.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1733         |\n",
      "|    time_elapsed         | 33739        |\n",
      "|    total_timesteps      | 3549184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015767554 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 22210        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | -5.730669    |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1734          |\n",
      "|    time_elapsed         | 33758         |\n",
      "|    total_timesteps      | 3551232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077786704 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.697         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.1          |\n",
      "|    n_updates            | 22220         |\n",
      "|    policy_gradient_loss | -0.00201      |\n",
      "|    reward               | -4.5537353    |\n",
      "|    std                  | 22            |\n",
      "|    value_loss           | 34.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1735         |\n",
      "|    time_elapsed         | 33777        |\n",
      "|    total_timesteps      | 3553280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066404073 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 22230        |\n",
      "|    policy_gradient_loss | -0.00737     |\n",
      "|    reward               | -1.9292407   |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 40.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1736         |\n",
      "|    time_elapsed         | 33797        |\n",
      "|    total_timesteps      | 3555328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022306014 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 22240        |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | -0.1456618   |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 63.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1737         |\n",
      "|    time_elapsed         | 33816        |\n",
      "|    total_timesteps      | 3557376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022933893 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 22250        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    reward               | -0.75086015  |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1738         |\n",
      "|    time_elapsed         | 33835        |\n",
      "|    total_timesteps      | 3559424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067690825 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 22260        |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    reward               | 0.84551316   |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3867086.34\n",
      "total_reward: 2867086.34\n",
      "total_cost: 108061.47\n",
      "total_trades: 53079\n",
      "Sharpe: 0.742\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1739         |\n",
      "|    time_elapsed         | 33853        |\n",
      "|    total_timesteps      | 3561472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033123535 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 22270        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    reward               | -0.18612106  |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 52.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1740         |\n",
      "|    time_elapsed         | 33873        |\n",
      "|    total_timesteps      | 3563520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014065587 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 22280        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | -0.20118774  |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 67.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1741         |\n",
      "|    time_elapsed         | 33892        |\n",
      "|    total_timesteps      | 3565568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047059534 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.42         |\n",
      "|    n_updates            | 22290        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    reward               | -1.9104834   |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 20.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1742         |\n",
      "|    time_elapsed         | 33911        |\n",
      "|    total_timesteps      | 3567616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039855903 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 22300        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | -1.2779716   |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 57.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1743          |\n",
      "|    time_elapsed         | 33930         |\n",
      "|    total_timesteps      | 3569664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061510183 |\n",
      "|    clip_fraction        | 0.00103       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.588         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22            |\n",
      "|    n_updates            | 22310         |\n",
      "|    policy_gradient_loss | -0.00196      |\n",
      "|    reward               | 2.0979657     |\n",
      "|    std                  | 22.3          |\n",
      "|    value_loss           | 58.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1744         |\n",
      "|    time_elapsed         | 33949        |\n",
      "|    total_timesteps      | 3571712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026501603 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 22320        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | 4.5260406    |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1745         |\n",
      "|    time_elapsed         | 33967        |\n",
      "|    total_timesteps      | 3573760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016376679 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 22330        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | -0.6491294   |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1746        |\n",
      "|    time_elapsed         | 33986       |\n",
      "|    total_timesteps      | 3575808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004048352 |\n",
      "|    clip_fraction        | 0.0063      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 22340       |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | 0.73217314  |\n",
      "|    std                  | 22.4        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1747         |\n",
      "|    time_elapsed         | 34005        |\n",
      "|    total_timesteps      | 3577856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018112916 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 22350        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | 0.9865217    |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 51.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1748        |\n",
      "|    time_elapsed         | 34024       |\n",
      "|    total_timesteps      | 3579904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003381444 |\n",
      "|    clip_fraction        | 0.00884     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 22360       |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 0.96601677  |\n",
      "|    std                  | 22.4        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1749        |\n",
      "|    time_elapsed         | 34044       |\n",
      "|    total_timesteps      | 3581952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003807732 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 22370       |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | 0.07062071  |\n",
      "|    std                  | 22.4        |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1750          |\n",
      "|    time_elapsed         | 34063         |\n",
      "|    total_timesteps      | 3584000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090868725 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.698         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.7          |\n",
      "|    n_updates            | 22380         |\n",
      "|    policy_gradient_loss | -0.00272      |\n",
      "|    reward               | 0.10068484    |\n",
      "|    std                  | 22.5          |\n",
      "|    value_loss           | 48.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1751         |\n",
      "|    time_elapsed         | 34082        |\n",
      "|    total_timesteps      | 3586048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020811867 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 22390        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | -2.3090804   |\n",
      "|    std                  | 22.5         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1752         |\n",
      "|    time_elapsed         | 34101        |\n",
      "|    total_timesteps      | 3588096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038503713 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 22400        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    reward               | 0.72142464   |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1753         |\n",
      "|    time_elapsed         | 34120        |\n",
      "|    total_timesteps      | 3590144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028373576 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 22410        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | 21.100935    |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 46.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3712908.84\n",
      "total_reward: 2712908.84\n",
      "total_cost: 123565.83\n",
      "total_trades: 54755\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1754         |\n",
      "|    time_elapsed         | 34139        |\n",
      "|    total_timesteps      | 3592192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038859798 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 22420        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | -1.4090395   |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 51.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1755        |\n",
      "|    time_elapsed         | 34158       |\n",
      "|    total_timesteps      | 3594240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006437963 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 22430       |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | 1.6429703   |\n",
      "|    std                  | 22.6        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1756         |\n",
      "|    time_elapsed         | 34177        |\n",
      "|    total_timesteps      | 3596288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020633275 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 22440        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | 0.05081157   |\n",
      "|    std                  | 22.7         |\n",
      "|    value_loss           | 52           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1757         |\n",
      "|    time_elapsed         | 34196        |\n",
      "|    total_timesteps      | 3598336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010831857 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 22450        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | -3.5088801   |\n",
      "|    std                  | 22.7         |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1758         |\n",
      "|    time_elapsed         | 34215        |\n",
      "|    total_timesteps      | 3600384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062158727 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.09         |\n",
      "|    n_updates            | 22460        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | 2.013193     |\n",
      "|    std                  | 22.7         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1759         |\n",
      "|    time_elapsed         | 34234        |\n",
      "|    total_timesteps      | 3602432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026193499 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 22470        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | -0.40061387  |\n",
      "|    std                  | 22.7         |\n",
      "|    value_loss           | 37.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1760         |\n",
      "|    time_elapsed         | 34253        |\n",
      "|    total_timesteps      | 3604480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024121664 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 22480        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | 2.2410307    |\n",
      "|    std                  | 22.8         |\n",
      "|    value_loss           | 53.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1761         |\n",
      "|    time_elapsed         | 34272        |\n",
      "|    total_timesteps      | 3606528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030509913 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 22490        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | 2.3851001    |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 56.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1762         |\n",
      "|    time_elapsed         | 34291        |\n",
      "|    total_timesteps      | 3608576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077618244 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 22500        |\n",
      "|    policy_gradient_loss | -0.00992     |\n",
      "|    reward               | 1.2772412    |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1763         |\n",
      "|    time_elapsed         | 34310        |\n",
      "|    total_timesteps      | 3610624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010578817 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 22510        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 1.3936634    |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 44.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1764         |\n",
      "|    time_elapsed         | 34330        |\n",
      "|    total_timesteps      | 3612672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008326982 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 22520        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 0.9683314    |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1765         |\n",
      "|    time_elapsed         | 34349        |\n",
      "|    total_timesteps      | 3614720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064171217 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.58         |\n",
      "|    n_updates            | 22530        |\n",
      "|    policy_gradient_loss | -0.00998     |\n",
      "|    reward               | 0.6896668    |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 15.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1766        |\n",
      "|    time_elapsed         | 34368       |\n",
      "|    total_timesteps      | 3616768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005225518 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 22540       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | 0.6900559   |\n",
      "|    std                  | 23.1        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1767         |\n",
      "|    time_elapsed         | 34387        |\n",
      "|    total_timesteps      | 3618816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007107267 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 22550        |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    reward               | -1.1183175   |\n",
      "|    std                  | 23.1         |\n",
      "|    value_loss           | 50.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3878695.82\n",
      "total_reward: 2878695.82\n",
      "total_cost: 217946.65\n",
      "total_trades: 62363\n",
      "Sharpe: 0.761\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1768         |\n",
      "|    time_elapsed         | 34407        |\n",
      "|    total_timesteps      | 3620864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045444346 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 22560        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    reward               | -0.5452546   |\n",
      "|    std                  | 23.1         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1769        |\n",
      "|    time_elapsed         | 34426       |\n",
      "|    total_timesteps      | 3622912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002856405 |\n",
      "|    clip_fraction        | 0.00479     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 22570       |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    reward               | -2.6992645  |\n",
      "|    std                  | 23.1        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1770         |\n",
      "|    time_elapsed         | 34445        |\n",
      "|    total_timesteps      | 3624960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026677898 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 22580        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | 0.006659566  |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1771         |\n",
      "|    time_elapsed         | 34464        |\n",
      "|    total_timesteps      | 3627008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017466176 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 22590        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 0.58514947   |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1772         |\n",
      "|    time_elapsed         | 34483        |\n",
      "|    total_timesteps      | 3629056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052999575 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.25         |\n",
      "|    n_updates            | 22600        |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    reward               | -1.0906942   |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1773         |\n",
      "|    time_elapsed         | 34502        |\n",
      "|    total_timesteps      | 3631104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023751447 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 22610        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | -1.341198    |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1774         |\n",
      "|    time_elapsed         | 34521        |\n",
      "|    total_timesteps      | 3633152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031192012 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 22620        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    reward               | 1.0685031    |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1775         |\n",
      "|    time_elapsed         | 34541        |\n",
      "|    total_timesteps      | 3635200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045211245 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 22630        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    reward               | 2.1587005    |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1776         |\n",
      "|    time_elapsed         | 34561        |\n",
      "|    total_timesteps      | 3637248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048630917 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 22640        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    reward               | -1.9490427   |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1777        |\n",
      "|    time_elapsed         | 34580       |\n",
      "|    total_timesteps      | 3639296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002466456 |\n",
      "|    clip_fraction        | 0.00522     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 22650       |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    reward               | 0.3379057   |\n",
      "|    std                  | 23.3        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1778         |\n",
      "|    time_elapsed         | 34599        |\n",
      "|    total_timesteps      | 3641344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009504901 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 22660        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | 2.30646      |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1779        |\n",
      "|    time_elapsed         | 34618       |\n",
      "|    total_timesteps      | 3643392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003903173 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 22670       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -0.668321   |\n",
      "|    std                  | 23.3        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1780         |\n",
      "|    time_elapsed         | 34638        |\n",
      "|    total_timesteps      | 3645440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020146214 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 22680        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.40477365   |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 53.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1781          |\n",
      "|    time_elapsed         | 34657         |\n",
      "|    total_timesteps      | 3647488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049841194 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.747         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.8          |\n",
      "|    n_updates            | 22690         |\n",
      "|    policy_gradient_loss | -0.00216      |\n",
      "|    reward               | -4.295605     |\n",
      "|    std                  | 23.4          |\n",
      "|    value_loss           | 50            |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3733957.75\n",
      "total_reward: 2733957.75\n",
      "total_cost: 117328.08\n",
      "total_trades: 54550\n",
      "Sharpe: 0.719\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1782         |\n",
      "|    time_elapsed         | 34676        |\n",
      "|    total_timesteps      | 3649536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038364222 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 22700        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    reward               | 1.3810062    |\n",
      "|    std                  | 23.4         |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1783         |\n",
      "|    time_elapsed         | 34695        |\n",
      "|    total_timesteps      | 3651584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057244003 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 22710        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | 0.65168166   |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1784        |\n",
      "|    time_elapsed         | 34714       |\n",
      "|    total_timesteps      | 3653632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001521471 |\n",
      "|    clip_fraction        | 0.002       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 22720       |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | -1.6250997  |\n",
      "|    std                  | 23.5        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1785         |\n",
      "|    time_elapsed         | 34733        |\n",
      "|    total_timesteps      | 3655680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013133462 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 22730        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -0.39092252  |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1786         |\n",
      "|    time_elapsed         | 34752        |\n",
      "|    total_timesteps      | 3657728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074097947 |\n",
      "|    clip_fraction        | 0.042        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 22740        |\n",
      "|    policy_gradient_loss | -0.00837     |\n",
      "|    reward               | 0.2678647    |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1787         |\n",
      "|    time_elapsed         | 34771        |\n",
      "|    total_timesteps      | 3659776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031958986 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 22750        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | 1.7690091    |\n",
      "|    std                  | 23.6         |\n",
      "|    value_loss           | 46.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1788         |\n",
      "|    time_elapsed         | 34791        |\n",
      "|    total_timesteps      | 3661824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007996489 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 22760        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    reward               | 1.2514085    |\n",
      "|    std                  | 23.6         |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1789        |\n",
      "|    time_elapsed         | 34810       |\n",
      "|    total_timesteps      | 3663872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006907992 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 22770       |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | 0.508431    |\n",
      "|    std                  | 23.6        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1790         |\n",
      "|    time_elapsed         | 34830        |\n",
      "|    total_timesteps      | 3665920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012839116 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 22780        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | 0.5933139    |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1791         |\n",
      "|    time_elapsed         | 34849        |\n",
      "|    total_timesteps      | 3667968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018929392 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 22790        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | 2.931436     |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1792         |\n",
      "|    time_elapsed         | 34867        |\n",
      "|    total_timesteps      | 3670016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007240905 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 22800        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | -1.2358353   |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1793        |\n",
      "|    time_elapsed         | 34886       |\n",
      "|    total_timesteps      | 3672064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004641517 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 22810       |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | -1.3425475  |\n",
      "|    std                  | 23.8        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1794          |\n",
      "|    time_elapsed         | 34905         |\n",
      "|    total_timesteps      | 3674112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.001268603   |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.713         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.8          |\n",
      "|    n_updates            | 22820         |\n",
      "|    policy_gradient_loss | -0.00339      |\n",
      "|    reward               | -0.0051813642 |\n",
      "|    std                  | 23.8          |\n",
      "|    value_loss           | 44.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1795          |\n",
      "|    time_elapsed         | 34924         |\n",
      "|    total_timesteps      | 3676160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080067816 |\n",
      "|    clip_fraction        | 0.00215       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.772         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.6          |\n",
      "|    n_updates            | 22830         |\n",
      "|    policy_gradient_loss | -0.00168      |\n",
      "|    reward               | 4.571427      |\n",
      "|    std                  | 23.7          |\n",
      "|    value_loss           | 46.9          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3944112.56\n",
      "total_reward: 2944112.56\n",
      "total_cost: 176775.23\n",
      "total_trades: 59285\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1796         |\n",
      "|    time_elapsed         | 34943        |\n",
      "|    total_timesteps      | 3678208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061715916 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.83         |\n",
      "|    n_updates            | 22840        |\n",
      "|    policy_gradient_loss | -0.00835     |\n",
      "|    reward               | 2.611175     |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 16.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1797         |\n",
      "|    time_elapsed         | 34962        |\n",
      "|    total_timesteps      | 3680256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024376682 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 22850        |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    reward               | -0.42284945  |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1798         |\n",
      "|    time_elapsed         | 34980        |\n",
      "|    total_timesteps      | 3682304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009726028 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 22860        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 3.109717     |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1799        |\n",
      "|    time_elapsed         | 34999       |\n",
      "|    total_timesteps      | 3684352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006273183 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 22870       |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | 1.6553615   |\n",
      "|    std                  | 23.8        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1800         |\n",
      "|    time_elapsed         | 35019        |\n",
      "|    total_timesteps      | 3686400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025662903 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 22880        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | 0.2096832    |\n",
      "|    std                  | 23.9         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1801         |\n",
      "|    time_elapsed         | 35038        |\n",
      "|    total_timesteps      | 3688448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009497324 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 22890        |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | -1.3868645   |\n",
      "|    std                  | 23.9         |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1802         |\n",
      "|    time_elapsed         | 35057        |\n",
      "|    total_timesteps      | 3690496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004680666  |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 22900        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    reward               | -0.043388054 |\n",
      "|    std                  | 24           |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1803        |\n",
      "|    time_elapsed         | 35076       |\n",
      "|    total_timesteps      | 3692544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011374528 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 22910       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -3.3619518  |\n",
      "|    std                  | 24.1        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1804         |\n",
      "|    time_elapsed         | 35095        |\n",
      "|    total_timesteps      | 3694592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042018853 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 22920        |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    reward               | -0.30982918  |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1805         |\n",
      "|    time_elapsed         | 35114        |\n",
      "|    total_timesteps      | 3696640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022358065 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 22930        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | -18.17211    |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1806        |\n",
      "|    time_elapsed         | 35133       |\n",
      "|    total_timesteps      | 3698688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004865731 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 22940       |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | 0.375631    |\n",
      "|    std                  | 24.2        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1807        |\n",
      "|    time_elapsed         | 35152       |\n",
      "|    total_timesteps      | 3700736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003632226 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 22950       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | -1.1795135  |\n",
      "|    std                  | 24.3        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1808         |\n",
      "|    time_elapsed         | 35171        |\n",
      "|    total_timesteps      | 3702784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014505369 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 22960        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | -5.990066    |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1809        |\n",
      "|    time_elapsed         | 35191       |\n",
      "|    total_timesteps      | 3704832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002443767 |\n",
      "|    clip_fraction        | 0.00371     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 22970       |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | 0.39820576  |\n",
      "|    std                  | 24.3        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3195316.88\n",
      "total_reward: 2195316.88\n",
      "total_cost: 142047.37\n",
      "total_trades: 57313\n",
      "Sharpe: 0.650\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1810         |\n",
      "|    time_elapsed         | 35210        |\n",
      "|    total_timesteps      | 3706880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055357534 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.21         |\n",
      "|    n_updates            | 22980        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | 0.6794239    |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1811         |\n",
      "|    time_elapsed         | 35229        |\n",
      "|    total_timesteps      | 3708928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028421376 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 22990        |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    reward               | 1.3561238    |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1812          |\n",
      "|    time_elapsed         | 35248         |\n",
      "|    total_timesteps      | 3710976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089559867 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.506         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.8          |\n",
      "|    n_updates            | 23000         |\n",
      "|    policy_gradient_loss | -0.00263      |\n",
      "|    reward               | 1.5801957     |\n",
      "|    std                  | 24.4          |\n",
      "|    value_loss           | 63.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1813         |\n",
      "|    time_elapsed         | 35267        |\n",
      "|    total_timesteps      | 3713024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071472665 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.9          |\n",
      "|    n_updates            | 23010        |\n",
      "|    policy_gradient_loss | -0.00772     |\n",
      "|    reward               | -0.04931172  |\n",
      "|    std                  | 24.5         |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1814         |\n",
      "|    time_elapsed         | 35286        |\n",
      "|    total_timesteps      | 3715072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022405642 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 23020        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | -0.72645944  |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1815         |\n",
      "|    time_elapsed         | 35305        |\n",
      "|    total_timesteps      | 3717120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023822086 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.7         |\n",
      "|    n_updates            | 23030        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | -7.6796546   |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 56.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1816        |\n",
      "|    time_elapsed         | 35324       |\n",
      "|    total_timesteps      | 3719168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00504482  |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 23040       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | -0.71370625 |\n",
      "|    std                  | 24.7        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1817         |\n",
      "|    time_elapsed         | 35343        |\n",
      "|    total_timesteps      | 3721216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022356915 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 23050        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | 0.5282153    |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1818         |\n",
      "|    time_elapsed         | 35362        |\n",
      "|    total_timesteps      | 3723264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027553127 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 23060        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | -3.8506024   |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 45.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1819         |\n",
      "|    time_elapsed         | 35381        |\n",
      "|    total_timesteps      | 3725312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013884064 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 23070        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -0.26917428  |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1820         |\n",
      "|    time_elapsed         | 35400        |\n",
      "|    total_timesteps      | 3727360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042926464 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.99         |\n",
      "|    n_updates            | 23080        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    reward               | 0.43402255   |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 15.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1821         |\n",
      "|    time_elapsed         | 35419        |\n",
      "|    total_timesteps      | 3729408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037979726 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29           |\n",
      "|    n_updates            | 23090        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | 0.70668954   |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 1822       |\n",
      "|    time_elapsed         | 35439      |\n",
      "|    total_timesteps      | 3731456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00249562 |\n",
      "|    clip_fraction        | 0.00737    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -133       |\n",
      "|    explained_variance   | 0.777      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.5       |\n",
      "|    n_updates            | 23100      |\n",
      "|    policy_gradient_loss | -0.00502   |\n",
      "|    reward               | 0.50581414 |\n",
      "|    std                  | 24.9       |\n",
      "|    value_loss           | 39.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1823         |\n",
      "|    time_elapsed         | 35458        |\n",
      "|    total_timesteps      | 3733504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023555341 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.52         |\n",
      "|    n_updates            | 23110        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -2.7899466   |\n",
      "|    std                  | 24.9         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4083890.93\n",
      "total_reward: 3083890.93\n",
      "total_cost: 201257.46\n",
      "total_trades: 61457\n",
      "Sharpe: 0.774\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1824         |\n",
      "|    time_elapsed         | 35477        |\n",
      "|    total_timesteps      | 3735552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051343148 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 23120        |\n",
      "|    policy_gradient_loss | -0.00875     |\n",
      "|    reward               | 1.5178047    |\n",
      "|    std                  | 24.9         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1825         |\n",
      "|    time_elapsed         | 35496        |\n",
      "|    total_timesteps      | 3737600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014395602 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.311        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 23130        |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | 9.706131     |\n",
      "|    std                  | 24.9         |\n",
      "|    value_loss           | 58.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1826         |\n",
      "|    time_elapsed         | 35515        |\n",
      "|    total_timesteps      | 3739648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031731199 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 23140        |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | 0.16298744   |\n",
      "|    std                  | 25           |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1827         |\n",
      "|    time_elapsed         | 35535        |\n",
      "|    total_timesteps      | 3741696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065917885 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 23150        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | 0.3474149    |\n",
      "|    std                  | 25           |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1828        |\n",
      "|    time_elapsed         | 35554       |\n",
      "|    total_timesteps      | 3743744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002970635 |\n",
      "|    clip_fraction        | 0.00566     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 23160       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -2.0422237  |\n",
      "|    std                  | 25.1        |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1829        |\n",
      "|    time_elapsed         | 35573       |\n",
      "|    total_timesteps      | 3745792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001001448 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 23170       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | 1.4031249   |\n",
      "|    std                  | 25.1        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1830        |\n",
      "|    time_elapsed         | 35592       |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008736602 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.72        |\n",
      "|    n_updates            | 23180       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | 0.38056862  |\n",
      "|    std                  | 25.2        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1831         |\n",
      "|    time_elapsed         | 35612        |\n",
      "|    total_timesteps      | 3749888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030896347 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 23190        |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    reward               | 1.3643059    |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1832         |\n",
      "|    time_elapsed         | 35631        |\n",
      "|    total_timesteps      | 3751936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012100508 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 23200        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | 0.24147904   |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 47.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1833         |\n",
      "|    time_elapsed         | 35650        |\n",
      "|    total_timesteps      | 3753984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036620824 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 23210        |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    reward               | 1.0187765    |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1834         |\n",
      "|    time_elapsed         | 35669        |\n",
      "|    total_timesteps      | 3756032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070400243 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 23220        |\n",
      "|    policy_gradient_loss | -0.00808     |\n",
      "|    reward               | -1.2053653   |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1835         |\n",
      "|    time_elapsed         | 35688        |\n",
      "|    total_timesteps      | 3758080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013607789 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 23230        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | -2.7160733   |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1836        |\n",
      "|    time_elapsed         | 35707       |\n",
      "|    total_timesteps      | 3760128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003163639 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 23240       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | -0.29497203 |\n",
      "|    std                  | 25.3        |\n",
      "|    value_loss           | 89.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 1837       |\n",
      "|    time_elapsed         | 35726      |\n",
      "|    total_timesteps      | 3762176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01249337 |\n",
      "|    clip_fraction        | 0.0765     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -134       |\n",
      "|    explained_variance   | 0.158      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.48       |\n",
      "|    n_updates            | 23250      |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    reward               | -1.3807111 |\n",
      "|    std                  | 25.4       |\n",
      "|    value_loss           | 23.1       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5190912.31\n",
      "total_reward: 4190912.31\n",
      "total_cost: 195609.98\n",
      "total_trades: 61101\n",
      "Sharpe: 0.881\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1838        |\n",
      "|    time_elapsed         | 35745       |\n",
      "|    total_timesteps      | 3764224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003936357 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.8        |\n",
      "|    n_updates            | 23260       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | 1.5639215   |\n",
      "|    std                  | 25.4        |\n",
      "|    value_loss           | 77.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1839         |\n",
      "|    time_elapsed         | 35764        |\n",
      "|    total_timesteps      | 3766272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020606292 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.1         |\n",
      "|    n_updates            | 23270        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | 0.86819124   |\n",
      "|    std                  | 25.5         |\n",
      "|    value_loss           | 69           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1840         |\n",
      "|    time_elapsed         | 35783        |\n",
      "|    total_timesteps      | 3768320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037045744 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 23280        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    reward               | 2.081444     |\n",
      "|    std                  | 25.5         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1841         |\n",
      "|    time_elapsed         | 35802        |\n",
      "|    total_timesteps      | 3770368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069077564 |\n",
      "|    clip_fraction        | 0.0346       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.24         |\n",
      "|    n_updates            | 23290        |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | 0.16463436   |\n",
      "|    std                  | 25.5         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1842         |\n",
      "|    time_elapsed         | 35821        |\n",
      "|    total_timesteps      | 3772416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018586579 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.9         |\n",
      "|    n_updates            | 23300        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | -3.6073987   |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 69           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1843         |\n",
      "|    time_elapsed         | 35841        |\n",
      "|    total_timesteps      | 3774464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006950662 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 23310        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | -3.2965417   |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 56.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1844        |\n",
      "|    time_elapsed         | 35860       |\n",
      "|    total_timesteps      | 3776512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009733244 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.24        |\n",
      "|    n_updates            | 23320       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 1.1174699   |\n",
      "|    std                  | 25.7        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1845         |\n",
      "|    time_elapsed         | 35879        |\n",
      "|    total_timesteps      | 3778560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023635319 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.6         |\n",
      "|    n_updates            | 23330        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | 0.3892801    |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 68.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1846         |\n",
      "|    time_elapsed         | 35898        |\n",
      "|    total_timesteps      | 3780608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024177188 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 23340        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 3.0503736    |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 57.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1847        |\n",
      "|    time_elapsed         | 35917       |\n",
      "|    total_timesteps      | 3782656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00541667  |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.09        |\n",
      "|    n_updates            | 23350       |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | 0.009371584 |\n",
      "|    std                  | 25.8        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1848         |\n",
      "|    time_elapsed         | 35936        |\n",
      "|    total_timesteps      | 3784704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059495335 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 23360        |\n",
      "|    policy_gradient_loss | -0.00753     |\n",
      "|    reward               | -1.3199016   |\n",
      "|    std                  | 25.8         |\n",
      "|    value_loss           | 47           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1849        |\n",
      "|    time_elapsed         | 35956       |\n",
      "|    total_timesteps      | 3786752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001933805 |\n",
      "|    clip_fraction        | 0.0061      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 23370       |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | -2.2787633  |\n",
      "|    std                  | 25.9        |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1850         |\n",
      "|    time_elapsed         | 35975        |\n",
      "|    total_timesteps      | 3788800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018118359 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 23380        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | 0.7790121    |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1851         |\n",
      "|    time_elapsed         | 35994        |\n",
      "|    total_timesteps      | 3790848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072228555 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 23390        |\n",
      "|    policy_gradient_loss | -0.00838     |\n",
      "|    reward               | 0.72092897   |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3665948.15\n",
      "total_reward: 2665948.15\n",
      "total_cost: 133616.23\n",
      "total_trades: 56669\n",
      "Sharpe: 0.701\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1852         |\n",
      "|    time_elapsed         | 36013        |\n",
      "|    total_timesteps      | 3792896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025234069 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.68         |\n",
      "|    n_updates            | 23400        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | 1.5223185    |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 57.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1853         |\n",
      "|    time_elapsed         | 36032        |\n",
      "|    total_timesteps      | 3794944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011774362 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 23410        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 1.7555053    |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1854         |\n",
      "|    time_elapsed         | 36051        |\n",
      "|    total_timesteps      | 3796992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054002544 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.77         |\n",
      "|    n_updates            | 23420        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    reward               | -0.5757789   |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 14.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1855         |\n",
      "|    time_elapsed         | 36069        |\n",
      "|    total_timesteps      | 3799040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031052805 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 23430        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | 0.13826084   |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1856         |\n",
      "|    time_elapsed         | 36088        |\n",
      "|    total_timesteps      | 3801088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023079866 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.1         |\n",
      "|    n_updates            | 23440        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | -1.4446405   |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 62.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1857        |\n",
      "|    time_elapsed         | 36107       |\n",
      "|    total_timesteps      | 3803136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004756594 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 23450       |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | 1.5220878   |\n",
      "|    std                  | 26          |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1858         |\n",
      "|    time_elapsed         | 36126        |\n",
      "|    total_timesteps      | 3805184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053848783 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.3         |\n",
      "|    n_updates            | 23460        |\n",
      "|    policy_gradient_loss | -0.00691     |\n",
      "|    reward               | 2.7229636    |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 37.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1859         |\n",
      "|    time_elapsed         | 36145        |\n",
      "|    total_timesteps      | 3807232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021433868 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 23470        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | -0.32308495  |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1860         |\n",
      "|    time_elapsed         | 36164        |\n",
      "|    total_timesteps      | 3809280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017371923 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 23480        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 0.17340542   |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 61           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1861        |\n",
      "|    time_elapsed         | 36183       |\n",
      "|    total_timesteps      | 3811328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005730901 |\n",
      "|    clip_fraction        | 0.0223      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.64        |\n",
      "|    n_updates            | 23490       |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    reward               | 0.78265375  |\n",
      "|    std                  | 26.3        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1862         |\n",
      "|    time_elapsed         | 36202        |\n",
      "|    total_timesteps      | 3813376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029899734 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 23500        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    reward               | 0.28724298   |\n",
      "|    std                  | 26.3         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1863         |\n",
      "|    time_elapsed         | 36222        |\n",
      "|    total_timesteps      | 3815424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018776498 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 23510        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -1.0808003   |\n",
      "|    std                  | 26.4         |\n",
      "|    value_loss           | 57.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1864         |\n",
      "|    time_elapsed         | 36241        |\n",
      "|    total_timesteps      | 3817472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029170485 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.48         |\n",
      "|    n_updates            | 23520        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | -0.35007322  |\n",
      "|    std                  | 26.4         |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1865        |\n",
      "|    time_elapsed         | 36260       |\n",
      "|    total_timesteps      | 3819520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005099858 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.28        |\n",
      "|    n_updates            | 23530       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | 0.23599498  |\n",
      "|    std                  | 26.5        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1866         |\n",
      "|    time_elapsed         | 36279        |\n",
      "|    total_timesteps      | 3821568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019903814 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 23540        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | 16.088993    |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4066818.37\n",
      "total_reward: 3066818.37\n",
      "total_cost: 190389.60\n",
      "total_trades: 60336\n",
      "Sharpe: 0.780\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1867         |\n",
      "|    time_elapsed         | 36298        |\n",
      "|    total_timesteps      | 3823616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020865728 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.277        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 23550        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    reward               | -2.0718248   |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1868        |\n",
      "|    time_elapsed         | 36317       |\n",
      "|    total_timesteps      | 3825664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006001468 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 23560       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | 2.040113    |\n",
      "|    std                  | 26.7        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1869         |\n",
      "|    time_elapsed         | 36336        |\n",
      "|    total_timesteps      | 3827712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027973815 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 23570        |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    reward               | -0.19225651  |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1870          |\n",
      "|    time_elapsed         | 36356         |\n",
      "|    total_timesteps      | 3829760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096663716 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.342         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.9          |\n",
      "|    n_updates            | 23580         |\n",
      "|    policy_gradient_loss | -0.00308      |\n",
      "|    reward               | -7.7895713    |\n",
      "|    std                  | 26.8          |\n",
      "|    value_loss           | 57.7          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1871        |\n",
      "|    time_elapsed         | 36375       |\n",
      "|    total_timesteps      | 3831808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004838518 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.94        |\n",
      "|    n_updates            | 23590       |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | -0.3324761  |\n",
      "|    std                  | 26.9        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1872        |\n",
      "|    time_elapsed         | 36395       |\n",
      "|    total_timesteps      | 3833856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005292412 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 23600       |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | 0.19393623  |\n",
      "|    std                  | 27          |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1873          |\n",
      "|    time_elapsed         | 36413         |\n",
      "|    total_timesteps      | 3835904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071574136 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.659         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.1          |\n",
      "|    n_updates            | 23610         |\n",
      "|    policy_gradient_loss | -0.00199      |\n",
      "|    reward               | 2.9818544     |\n",
      "|    std                  | 27            |\n",
      "|    value_loss           | 46.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1874        |\n",
      "|    time_elapsed         | 36432       |\n",
      "|    total_timesteps      | 3837952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001787375 |\n",
      "|    clip_fraction        | 0.00239     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 23620       |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | 2.1369667   |\n",
      "|    std                  | 27          |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1875         |\n",
      "|    time_elapsed         | 36451        |\n",
      "|    total_timesteps      | 3840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059847143 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 23630        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | 0.24084662   |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1876         |\n",
      "|    time_elapsed         | 36470        |\n",
      "|    total_timesteps      | 3842048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021791123 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 23640        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | 0.6504993    |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 69.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1877         |\n",
      "|    time_elapsed         | 36489        |\n",
      "|    total_timesteps      | 3844096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012441586 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 23650        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | 1.7952557    |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1878        |\n",
      "|    time_elapsed         | 36509       |\n",
      "|    total_timesteps      | 3846144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009293259 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.95        |\n",
      "|    n_updates            | 23660       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 2.283539    |\n",
      "|    std                  | 27.2        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1879         |\n",
      "|    time_elapsed         | 36528        |\n",
      "|    total_timesteps      | 3848192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028809423 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.75         |\n",
      "|    n_updates            | 23670        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | -0.27964437  |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1880         |\n",
      "|    time_elapsed         | 36547        |\n",
      "|    total_timesteps      | 3850240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016803584 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 23680        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | -2.6232033   |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3802270.45\n",
      "total_reward: 2802270.45\n",
      "total_cost: 220426.33\n",
      "total_trades: 63336\n",
      "Sharpe: 0.748\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1881         |\n",
      "|    time_elapsed         | 36566        |\n",
      "|    total_timesteps      | 3852288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025907918 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 23690        |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    reward               | 0.9756838    |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1882         |\n",
      "|    time_elapsed         | 36585        |\n",
      "|    total_timesteps      | 3854336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043950775 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    reward               | -4.2654395   |\n",
      "|    std                  | 27.4         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1883         |\n",
      "|    time_elapsed         | 36605        |\n",
      "|    total_timesteps      | 3856384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038637458 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 23710        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | 0.10642763   |\n",
      "|    std                  | 27.4         |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1884          |\n",
      "|    time_elapsed         | 36624         |\n",
      "|    total_timesteps      | 3858432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054248306 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.635         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.1          |\n",
      "|    n_updates            | 23720         |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    reward               | 3.8233738     |\n",
      "|    std                  | 27.4          |\n",
      "|    value_loss           | 50.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1885         |\n",
      "|    time_elapsed         | 36643        |\n",
      "|    total_timesteps      | 3860480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077005723 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.32         |\n",
      "|    n_updates            | 23730        |\n",
      "|    policy_gradient_loss | -0.00897     |\n",
      "|    reward               | -0.8133698   |\n",
      "|    std                  | 27.4         |\n",
      "|    value_loss           | 13.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1886         |\n",
      "|    time_elapsed         | 36662        |\n",
      "|    total_timesteps      | 3862528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017659386 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 23740        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | -0.14338504  |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1887         |\n",
      "|    time_elapsed         | 36681        |\n",
      "|    total_timesteps      | 3864576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004662855 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 23750        |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    reward               | 2.3186636    |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1888         |\n",
      "|    time_elapsed         | 36700        |\n",
      "|    total_timesteps      | 3866624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038668253 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 23760        |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    reward               | 2.1582575    |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1889         |\n",
      "|    time_elapsed         | 36719        |\n",
      "|    total_timesteps      | 3868672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022144364 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 23770        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | -0.037232082 |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1890         |\n",
      "|    time_elapsed         | 36738        |\n",
      "|    total_timesteps      | 3870720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016610783 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 23780        |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    reward               | 2.389632     |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 44.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1891         |\n",
      "|    time_elapsed         | 36757        |\n",
      "|    total_timesteps      | 3872768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034401754 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 23790        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    reward               | -0.55542976  |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1892         |\n",
      "|    time_elapsed         | 36777        |\n",
      "|    total_timesteps      | 3874816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057807425 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 23800        |\n",
      "|    policy_gradient_loss | -0.00881     |\n",
      "|    reward               | 2.647607     |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1893        |\n",
      "|    time_elapsed         | 36796       |\n",
      "|    total_timesteps      | 3876864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004737809 |\n",
      "|    clip_fraction        | 0.022       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 23810       |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    reward               | 1.0921024   |\n",
      "|    std                  | 27.7        |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1894         |\n",
      "|    time_elapsed         | 36815        |\n",
      "|    total_timesteps      | 3878912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010430829 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 23820        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | 7.160534     |\n",
      "|    std                  | 27.7         |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3440726.43\n",
      "total_reward: 2440726.43\n",
      "total_cost: 118470.36\n",
      "total_trades: 55495\n",
      "Sharpe: 0.674\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1895         |\n",
      "|    time_elapsed         | 36834        |\n",
      "|    total_timesteps      | 3880960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029401237 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 23830        |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    reward               | -1.1237463   |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1896        |\n",
      "|    time_elapsed         | 36853       |\n",
      "|    total_timesteps      | 3883008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005887402 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 23840       |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | 0.15531982  |\n",
      "|    std                  | 27.8        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1897          |\n",
      "|    time_elapsed         | 36872         |\n",
      "|    total_timesteps      | 3885056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061864627 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.673         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.7          |\n",
      "|    n_updates            | 23850         |\n",
      "|    policy_gradient_loss | -0.0018       |\n",
      "|    reward               | -5.761599     |\n",
      "|    std                  | 27.9          |\n",
      "|    value_loss           | 47.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1898         |\n",
      "|    time_elapsed         | 36891        |\n",
      "|    total_timesteps      | 3887104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009623568 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 23860        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | 0.42480046   |\n",
      "|    std                  | 27.9         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1899        |\n",
      "|    time_elapsed         | 36911       |\n",
      "|    total_timesteps      | 3889152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005580279 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 23870       |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    reward               | -1.6439066  |\n",
      "|    std                  | 28          |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1900        |\n",
      "|    time_elapsed         | 36930       |\n",
      "|    total_timesteps      | 3891200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003152135 |\n",
      "|    clip_fraction        | 0.00747     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 23880       |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | 1.0244106   |\n",
      "|    std                  | 28.1        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1901         |\n",
      "|    time_elapsed         | 36949        |\n",
      "|    total_timesteps      | 3893248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015087237 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 23890        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | -0.85564166  |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 52.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1902         |\n",
      "|    time_elapsed         | 36968        |\n",
      "|    total_timesteps      | 3895296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064401357 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.44         |\n",
      "|    n_updates            | 23900        |\n",
      "|    policy_gradient_loss | -0.00844     |\n",
      "|    reward               | 3.371419     |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1903         |\n",
      "|    time_elapsed         | 36988        |\n",
      "|    total_timesteps      | 3897344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034758183 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 23910        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | -0.09648685  |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1904         |\n",
      "|    time_elapsed         | 37007        |\n",
      "|    total_timesteps      | 3899392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010540142 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 23920        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | -2.8295023   |\n",
      "|    std                  | 28.2         |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1905          |\n",
      "|    time_elapsed         | 37026         |\n",
      "|    total_timesteps      | 3901440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092827075 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.603         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.3          |\n",
      "|    n_updates            | 23930         |\n",
      "|    policy_gradient_loss | -0.00218      |\n",
      "|    reward               | -3.3421385    |\n",
      "|    std                  | 28.2          |\n",
      "|    value_loss           | 33.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1906        |\n",
      "|    time_elapsed         | 37045       |\n",
      "|    total_timesteps      | 3903488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004049981 |\n",
      "|    clip_fraction        | 0.00845     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 23940       |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | 2.6516206   |\n",
      "|    std                  | 28.3        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1907          |\n",
      "|    time_elapsed         | 37064         |\n",
      "|    total_timesteps      | 3905536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067434163 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.513         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.5          |\n",
      "|    n_updates            | 23950         |\n",
      "|    policy_gradient_loss | -0.00134      |\n",
      "|    reward               | -18.669353    |\n",
      "|    std                  | 28.3          |\n",
      "|    value_loss           | 57.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1908        |\n",
      "|    time_elapsed         | 37083       |\n",
      "|    total_timesteps      | 3907584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000629938 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 23960       |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    reward               | -0.08531034 |\n",
      "|    std                  | 28.3        |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3777694.12\n",
      "total_reward: 2777694.12\n",
      "total_cost: 124720.29\n",
      "total_trades: 56242\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1909        |\n",
      "|    time_elapsed         | 37102       |\n",
      "|    total_timesteps      | 3909632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005808857 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.5         |\n",
      "|    n_updates            | 23970       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    reward               | -1.113593   |\n",
      "|    std                  | 28.4        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1910         |\n",
      "|    time_elapsed         | 37121        |\n",
      "|    total_timesteps      | 3911680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038857362 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 23980        |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    reward               | 0.24062306   |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1911         |\n",
      "|    time_elapsed         | 37140        |\n",
      "|    total_timesteps      | 3913728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016480898 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 23990        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | 5.8866134    |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1912         |\n",
      "|    time_elapsed         | 37159        |\n",
      "|    total_timesteps      | 3915776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038844796 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 24000        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    reward               | 2.9375582    |\n",
      "|    std                  | 28.4         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1913         |\n",
      "|    time_elapsed         | 37178        |\n",
      "|    total_timesteps      | 3917824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030241993 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 24010        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 1.5529845    |\n",
      "|    std                  | 28.6         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1914         |\n",
      "|    time_elapsed         | 37197        |\n",
      "|    total_timesteps      | 3919872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025626319 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 24020        |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    reward               | 0.41763598   |\n",
      "|    std                  | 28.6         |\n",
      "|    value_loss           | 47.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1915        |\n",
      "|    time_elapsed         | 37216       |\n",
      "|    total_timesteps      | 3921920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003712002 |\n",
      "|    clip_fraction        | 0.00967     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 24030       |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -0.53241616 |\n",
      "|    std                  | 28.7        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1916         |\n",
      "|    time_elapsed         | 37235        |\n",
      "|    total_timesteps      | 3923968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045289425 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.74         |\n",
      "|    n_updates            | 24040        |\n",
      "|    policy_gradient_loss | -0.00738     |\n",
      "|    reward               | -0.8372045   |\n",
      "|    std                  | 28.8         |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1917         |\n",
      "|    time_elapsed         | 37254        |\n",
      "|    total_timesteps      | 3926016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025644016 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 24050        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 2.0410812    |\n",
      "|    std                  | 28.8         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1918          |\n",
      "|    time_elapsed         | 37273         |\n",
      "|    total_timesteps      | 3928064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040496414 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.567         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.4          |\n",
      "|    n_updates            | 24060         |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    reward               | -0.025208367  |\n",
      "|    std                  | 28.8          |\n",
      "|    value_loss           | 51.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1919        |\n",
      "|    time_elapsed         | 37293       |\n",
      "|    total_timesteps      | 3930112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007068139 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 24070       |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | 1.4402906   |\n",
      "|    std                  | 28.9        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1920         |\n",
      "|    time_elapsed         | 37312        |\n",
      "|    total_timesteps      | 3932160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026243036 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 24080        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | -1.3476685   |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 48.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1921         |\n",
      "|    time_elapsed         | 37331        |\n",
      "|    total_timesteps      | 3934208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007603009 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 24090        |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    reward               | 5.5737453    |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1922         |\n",
      "|    time_elapsed         | 37350        |\n",
      "|    total_timesteps      | 3936256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017325667 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 24100        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | -1.5984021   |\n",
      "|    std                  | 29           |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3424479.84\n",
      "total_reward: 2424479.84\n",
      "total_cost: 222858.03\n",
      "total_trades: 63445\n",
      "Sharpe: 0.706\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 1923       |\n",
      "|    time_elapsed         | 37369      |\n",
      "|    total_timesteps      | 3938304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00818704 |\n",
      "|    clip_fraction        | 0.0427     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -138       |\n",
      "|    explained_variance   | 0.637      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.22       |\n",
      "|    n_updates            | 24110      |\n",
      "|    policy_gradient_loss | -0.00742   |\n",
      "|    reward               | 0.3143034  |\n",
      "|    std                  | 29         |\n",
      "|    value_loss           | 23.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1924         |\n",
      "|    time_elapsed         | 37388        |\n",
      "|    total_timesteps      | 3940352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020672167 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 24120        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -0.9691775   |\n",
      "|    std                  | 29           |\n",
      "|    value_loss           | 39.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1925        |\n",
      "|    time_elapsed         | 37407       |\n",
      "|    total_timesteps      | 3942400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001909043 |\n",
      "|    clip_fraction        | 0.00303     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 24130       |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | -0.22004855 |\n",
      "|    std                  | 29.1        |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1926        |\n",
      "|    time_elapsed         | 37426       |\n",
      "|    total_timesteps      | 3944448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004311254 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.65        |\n",
      "|    n_updates            | 24140       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | -1.1791515  |\n",
      "|    std                  | 29          |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1927         |\n",
      "|    time_elapsed         | 37445        |\n",
      "|    total_timesteps      | 3946496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024398998 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 24150        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | -0.19375494  |\n",
      "|    std                  | 29           |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1928        |\n",
      "|    time_elapsed         | 37464       |\n",
      "|    total_timesteps      | 3948544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001709234 |\n",
      "|    clip_fraction        | 0.0019      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 24160       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    reward               | 0.1312757   |\n",
      "|    std                  | 29.1        |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1929         |\n",
      "|    time_elapsed         | 37484        |\n",
      "|    total_timesteps      | 3950592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028175411 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 24170        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | -0.11506514  |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1930         |\n",
      "|    time_elapsed         | 37503        |\n",
      "|    total_timesteps      | 3952640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027146847 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 24180        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | 0.15040177   |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1931          |\n",
      "|    time_elapsed         | 37522         |\n",
      "|    total_timesteps      | 3954688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077272556 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.601         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.28          |\n",
      "|    n_updates            | 24190         |\n",
      "|    policy_gradient_loss | -0.002        |\n",
      "|    reward               | -0.58479387   |\n",
      "|    std                  | 29.2          |\n",
      "|    value_loss           | 45.3          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1932         |\n",
      "|    time_elapsed         | 37541        |\n",
      "|    total_timesteps      | 3956736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009015921 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 24200        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | 0.32394746   |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 47.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1933         |\n",
      "|    time_elapsed         | 37560        |\n",
      "|    total_timesteps      | 3958784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023573192 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.61         |\n",
      "|    n_updates            | 24210        |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    reward               | 1.2781516    |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 16.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1934         |\n",
      "|    time_elapsed         | 37580        |\n",
      "|    total_timesteps      | 3960832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019432398 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 24220        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | -0.032612257 |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1935         |\n",
      "|    time_elapsed         | 37599        |\n",
      "|    total_timesteps      | 3962880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016518291 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 24230        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | 1.3460816    |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 39.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1936         |\n",
      "|    time_elapsed         | 37618        |\n",
      "|    total_timesteps      | 3964928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023163755 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 24240        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | -1.8791536   |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3725464.38\n",
      "total_reward: 2725464.38\n",
      "total_cost: 156231.34\n",
      "total_trades: 58128\n",
      "Sharpe: 0.727\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1937         |\n",
      "|    time_elapsed         | 37637        |\n",
      "|    total_timesteps      | 3966976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045894366 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28           |\n",
      "|    n_updates            | 24250        |\n",
      "|    policy_gradient_loss | -0.00749     |\n",
      "|    reward               | -3.4321291   |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1938         |\n",
      "|    time_elapsed         | 37656        |\n",
      "|    total_timesteps      | 3969024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016578271 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 24260        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | -6.698319    |\n",
      "|    std                  | 29.4         |\n",
      "|    value_loss           | 45           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1939         |\n",
      "|    time_elapsed         | 37675        |\n",
      "|    total_timesteps      | 3971072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018077119 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 24270        |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    reward               | 0.6230248    |\n",
      "|    std                  | 29.4         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1940         |\n",
      "|    time_elapsed         | 37694        |\n",
      "|    total_timesteps      | 3973120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031716512 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 24280        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | -0.41857597  |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1941         |\n",
      "|    time_elapsed         | 37713        |\n",
      "|    total_timesteps      | 3975168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007029394 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37           |\n",
      "|    n_updates            | 24290        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | -0.35862622  |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 52.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1942          |\n",
      "|    time_elapsed         | 37732         |\n",
      "|    total_timesteps      | 3977216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032201633 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.566         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.5          |\n",
      "|    n_updates            | 24300         |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    reward               | -1.0474434    |\n",
      "|    std                  | 29.5          |\n",
      "|    value_loss           | 49.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1943         |\n",
      "|    time_elapsed         | 37751        |\n",
      "|    total_timesteps      | 3979264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067801736 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.88         |\n",
      "|    n_updates            | 24310        |\n",
      "|    policy_gradient_loss | -0.0079      |\n",
      "|    reward               | -0.81929237  |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 19.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1944         |\n",
      "|    time_elapsed         | 37770        |\n",
      "|    total_timesteps      | 3981312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065976833 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 24320        |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    reward               | -0.19041196  |\n",
      "|    std                  | 29.6         |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1945         |\n",
      "|    time_elapsed         | 37789        |\n",
      "|    total_timesteps      | 3983360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014542157 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 24330        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | 4.9601965    |\n",
      "|    std                  | 29.7         |\n",
      "|    value_loss           | 49.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1946         |\n",
      "|    time_elapsed         | 37807        |\n",
      "|    total_timesteps      | 3985408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023052162 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 24340        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 1.1308063    |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1947        |\n",
      "|    time_elapsed         | 37827       |\n",
      "|    total_timesteps      | 3987456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004171239 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 24350       |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    reward               | 0.07880066  |\n",
      "|    std                  | 29.8        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1948        |\n",
      "|    time_elapsed         | 37845       |\n",
      "|    total_timesteps      | 3989504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003113488 |\n",
      "|    clip_fraction        | 0.00552     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 24360       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | 1.0644689   |\n",
      "|    std                  | 29.8        |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1949         |\n",
      "|    time_elapsed         | 37865        |\n",
      "|    total_timesteps      | 3991552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010109533 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 24370        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 8.01503      |\n",
      "|    std                  | 29.9         |\n",
      "|    value_loss           | 50.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1950        |\n",
      "|    time_elapsed         | 37884       |\n",
      "|    total_timesteps      | 3993600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006701213 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.4         |\n",
      "|    n_updates            | 24380       |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    reward               | -0.7417845  |\n",
      "|    std                  | 30          |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3338899.03\n",
      "total_reward: 2338899.03\n",
      "total_cost: 239466.32\n",
      "total_trades: 65129\n",
      "Sharpe: 0.683\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1951        |\n",
      "|    time_elapsed         | 37903       |\n",
      "|    total_timesteps      | 3995648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00481923  |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 24390       |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    reward               | -0.79045355 |\n",
      "|    std                  | 30          |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1952         |\n",
      "|    time_elapsed         | 37922        |\n",
      "|    total_timesteps      | 3997696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029375013 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 24400        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    reward               | 0.18340437   |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 46.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1953         |\n",
      "|    time_elapsed         | 37941        |\n",
      "|    total_timesteps      | 3999744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059616985 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 24410        |\n",
      "|    policy_gradient_loss | -0.00792     |\n",
      "|    reward               | 0.4736909    |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1954         |\n",
      "|    time_elapsed         | 37960        |\n",
      "|    total_timesteps      | 4001792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028122305 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 24420        |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    reward               | 0.30568072   |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1955         |\n",
      "|    time_elapsed         | 37979        |\n",
      "|    total_timesteps      | 4003840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031765588 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 24430        |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    reward               | -21.856716   |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1956         |\n",
      "|    time_elapsed         | 37999        |\n",
      "|    total_timesteps      | 4005888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026413472 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 24440        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | 4.306008     |\n",
      "|    std                  | 30.4         |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1957         |\n",
      "|    time_elapsed         | 38019        |\n",
      "|    total_timesteps      | 4007936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065087406 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.78         |\n",
      "|    n_updates            | 24450        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    reward               | -2.4375775   |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1958         |\n",
      "|    time_elapsed         | 38038        |\n",
      "|    total_timesteps      | 4009984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030229723 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 24460        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    reward               | -0.89545697  |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1959        |\n",
      "|    time_elapsed         | 38057       |\n",
      "|    total_timesteps      | 4012032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002661528 |\n",
      "|    clip_fraction        | 0.00356     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 24470       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    reward               | 1.8620175   |\n",
      "|    std                  | 30.6        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1960         |\n",
      "|    time_elapsed         | 38076        |\n",
      "|    total_timesteps      | 4014080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067216605 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 24480        |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    reward               | 1.0810511    |\n",
      "|    std                  | 30.7         |\n",
      "|    value_loss           | 19.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1961         |\n",
      "|    time_elapsed         | 38095        |\n",
      "|    total_timesteps      | 4016128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030997442 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 24490        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    reward               | -0.7372173   |\n",
      "|    std                  | 30.7         |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1962         |\n",
      "|    time_elapsed         | 38114        |\n",
      "|    total_timesteps      | 4018176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011567766 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 24500        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.87359357   |\n",
      "|    std                  | 30.7         |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1963        |\n",
      "|    time_elapsed         | 38133       |\n",
      "|    total_timesteps      | 4020224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002495681 |\n",
      "|    clip_fraction        | 0.00518     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 24510       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    reward               | 1.713372    |\n",
      "|    std                  | 30.8        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1964         |\n",
      "|    time_elapsed         | 38152        |\n",
      "|    total_timesteps      | 4022272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023505732 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 24520        |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    reward               | 0.04438296   |\n",
      "|    std                  | 30.8         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3491561.06\n",
      "total_reward: 2491561.06\n",
      "total_cost: 153786.06\n",
      "total_trades: 59057\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1965         |\n",
      "|    time_elapsed         | 38171        |\n",
      "|    total_timesteps      | 4024320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029842693 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 24530        |\n",
      "|    policy_gradient_loss | -0.00743     |\n",
      "|    reward               | 0.836277     |\n",
      "|    std                  | 30.9         |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1966         |\n",
      "|    time_elapsed         | 38191        |\n",
      "|    total_timesteps      | 4026368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013353494 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 24540        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | 0.9175308    |\n",
      "|    std                  | 30.9         |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1967        |\n",
      "|    time_elapsed         | 38209       |\n",
      "|    total_timesteps      | 4028416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007982747 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.22        |\n",
      "|    n_updates            | 24550       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | 1.4857312   |\n",
      "|    std                  | 31          |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1968         |\n",
      "|    time_elapsed         | 38228        |\n",
      "|    total_timesteps      | 4030464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029131977 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.354        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 24560        |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    reward               | 0.24710204   |\n",
      "|    std                  | 31           |\n",
      "|    value_loss           | 53.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1969         |\n",
      "|    time_elapsed         | 38248        |\n",
      "|    total_timesteps      | 4032512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015854414 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 24570        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 1.6059687    |\n",
      "|    std                  | 31.1         |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1970         |\n",
      "|    time_elapsed         | 38267        |\n",
      "|    total_timesteps      | 4034560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020686425 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 24580        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | 1.8381454    |\n",
      "|    std                  | 31.1         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1971        |\n",
      "|    time_elapsed         | 38286       |\n",
      "|    total_timesteps      | 4036608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004929552 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 24590       |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | 0.3578423   |\n",
      "|    std                  | 31.2        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1972         |\n",
      "|    time_elapsed         | 38305        |\n",
      "|    total_timesteps      | 4038656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025169228 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 24600        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | 0.087076195  |\n",
      "|    std                  | 31.2         |\n",
      "|    value_loss           | 49.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1973         |\n",
      "|    time_elapsed         | 38324        |\n",
      "|    total_timesteps      | 4040704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010785738 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 24610        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 0.27917755   |\n",
      "|    std                  | 31.2         |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1974         |\n",
      "|    time_elapsed         | 38343        |\n",
      "|    total_timesteps      | 4042752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072132675 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.63         |\n",
      "|    n_updates            | 24620        |\n",
      "|    policy_gradient_loss | -0.00855     |\n",
      "|    reward               | 0.54755294   |\n",
      "|    std                  | 31.3         |\n",
      "|    value_loss           | 13.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1975         |\n",
      "|    time_elapsed         | 38362        |\n",
      "|    total_timesteps      | 4044800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030346937 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 24630        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | -2.5566735   |\n",
      "|    std                  | 31.3         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1976         |\n",
      "|    time_elapsed         | 38381        |\n",
      "|    total_timesteps      | 4046848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013453688 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 24640        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | -2.5832484   |\n",
      "|    std                  | 31.3         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1977         |\n",
      "|    time_elapsed         | 38400        |\n",
      "|    total_timesteps      | 4048896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031925384 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 24650        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | 0.941088     |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1978        |\n",
      "|    time_elapsed         | 38419       |\n",
      "|    total_timesteps      | 4050944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004958673 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 24660       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | -1.2485794  |\n",
      "|    std                  | 31.4        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1979         |\n",
      "|    time_elapsed         | 38439        |\n",
      "|    total_timesteps      | 4052992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011399203 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 24670        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | -1.3033782   |\n",
      "|    std                  | 31.5         |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3924120.15\n",
      "total_reward: 2924120.15\n",
      "total_cost: 144002.13\n",
      "total_trades: 57000\n",
      "Sharpe: 0.751\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1980         |\n",
      "|    time_elapsed         | 38458        |\n",
      "|    total_timesteps      | 4055040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029523927 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.7         |\n",
      "|    n_updates            | 24680        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | 2.9594774    |\n",
      "|    std                  | 31.6         |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1981         |\n",
      "|    time_elapsed         | 38477        |\n",
      "|    total_timesteps      | 4057088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047853533 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.53         |\n",
      "|    n_updates            | 24690        |\n",
      "|    policy_gradient_loss | -0.00892     |\n",
      "|    reward               | -0.049358666 |\n",
      "|    std                  | 31.6         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1982         |\n",
      "|    time_elapsed         | 38496        |\n",
      "|    total_timesteps      | 4059136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016132834 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 24700        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | -0.23202975  |\n",
      "|    std                  | 31.7         |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1983         |\n",
      "|    time_elapsed         | 38515        |\n",
      "|    total_timesteps      | 4061184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007116855 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 24710        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | -6.6474614   |\n",
      "|    std                  | 31.7         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1984        |\n",
      "|    time_elapsed         | 38534       |\n",
      "|    total_timesteps      | 4063232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003708298 |\n",
      "|    clip_fraction        | 0.00825     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.63        |\n",
      "|    n_updates            | 24720       |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | 3.934646    |\n",
      "|    std                  | 31.7        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1985         |\n",
      "|    time_elapsed         | 38553        |\n",
      "|    total_timesteps      | 4065280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038430574 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 24730        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    reward               | 0.6140288    |\n",
      "|    std                  | 31.9         |\n",
      "|    value_loss           | 35           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1986         |\n",
      "|    time_elapsed         | 38572        |\n",
      "|    total_timesteps      | 4067328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019996627 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 24740        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | 1.2658446    |\n",
      "|    std                  | 31.9         |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1987         |\n",
      "|    time_elapsed         | 38590        |\n",
      "|    total_timesteps      | 4069376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030847664 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 24750        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -0.4916875   |\n",
      "|    std                  | 32           |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1988         |\n",
      "|    time_elapsed         | 38609        |\n",
      "|    total_timesteps      | 4071424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033699342 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 24760        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | -0.7445043   |\n",
      "|    std                  | 32.1         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1989         |\n",
      "|    time_elapsed         | 38628        |\n",
      "|    total_timesteps      | 4073472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015271299 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 24770        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 0.67083675   |\n",
      "|    std                  | 32.1         |\n",
      "|    value_loss           | 45.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1990        |\n",
      "|    time_elapsed         | 38648       |\n",
      "|    total_timesteps      | 4075520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002532872 |\n",
      "|    clip_fraction        | 0.0022      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 24780       |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    reward               | 0.20237988  |\n",
      "|    std                  | 32.2        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1991         |\n",
      "|    time_elapsed         | 38667        |\n",
      "|    total_timesteps      | 4077568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068863854 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.78         |\n",
      "|    n_updates            | 24790        |\n",
      "|    policy_gradient_loss | -0.00841     |\n",
      "|    reward               | -0.35657626  |\n",
      "|    std                  | 32.1         |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1992         |\n",
      "|    time_elapsed         | 38687        |\n",
      "|    total_timesteps      | 4079616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029995078 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 24800        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 0.026331076  |\n",
      "|    std                  | 32.3         |\n",
      "|    value_loss           | 54.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1993         |\n",
      "|    time_elapsed         | 38706        |\n",
      "|    total_timesteps      | 4081664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027464703 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 24810        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 3.4482605    |\n",
      "|    std                  | 32.3         |\n",
      "|    value_loss           | 56.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3880360.06\n",
      "total_reward: 2880360.06\n",
      "total_cost: 187410.78\n",
      "total_trades: 60283\n",
      "Sharpe: 0.756\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1994         |\n",
      "|    time_elapsed         | 38726        |\n",
      "|    total_timesteps      | 4083712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012700935 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 24820        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | -4.837024    |\n",
      "|    std                  | 32.3         |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 1995        |\n",
      "|    time_elapsed         | 38745       |\n",
      "|    total_timesteps      | 4085760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002605877 |\n",
      "|    clip_fraction        | 0.00454     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.21        |\n",
      "|    n_updates            | 24830       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -1.6156647  |\n",
      "|    std                  | 32.3        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 1996       |\n",
      "|    time_elapsed         | 38763      |\n",
      "|    total_timesteps      | 4087808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00248548 |\n",
      "|    clip_fraction        | 0.00542    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -141       |\n",
      "|    explained_variance   | 0.659      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.7       |\n",
      "|    n_updates            | 24840      |\n",
      "|    policy_gradient_loss | -0.00512   |\n",
      "|    reward               | 4.2123785  |\n",
      "|    std                  | 32.4       |\n",
      "|    value_loss           | 48.1       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 1997          |\n",
      "|    time_elapsed         | 38782         |\n",
      "|    total_timesteps      | 4089856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093070825 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.686         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32.7          |\n",
      "|    n_updates            | 24850         |\n",
      "|    policy_gradient_loss | -0.00264      |\n",
      "|    reward               | 1.8037018     |\n",
      "|    std                  | 32.4          |\n",
      "|    value_loss           | 46.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1998         |\n",
      "|    time_elapsed         | 38801        |\n",
      "|    total_timesteps      | 4091904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081081325 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.32         |\n",
      "|    n_updates            | 24860        |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    reward               | 3.0530436    |\n",
      "|    std                  | 32.3         |\n",
      "|    value_loss           | 14.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1999         |\n",
      "|    time_elapsed         | 38821        |\n",
      "|    total_timesteps      | 4093952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013143376 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.56         |\n",
      "|    n_updates            | 24870        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | -3.804267    |\n",
      "|    std                  | 32.3         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2000         |\n",
      "|    time_elapsed         | 38840        |\n",
      "|    total_timesteps      | 4096000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024914779 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 24880        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 6.799366     |\n",
      "|    std                  | 32.4         |\n",
      "|    value_loss           | 46.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2001         |\n",
      "|    time_elapsed         | 38859        |\n",
      "|    total_timesteps      | 4098048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038766507 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.75         |\n",
      "|    n_updates            | 24890        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    reward               | -3.0471604   |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2002         |\n",
      "|    time_elapsed         | 38877        |\n",
      "|    total_timesteps      | 4100096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019194315 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 24900        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 1.6038195    |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2003         |\n",
      "|    time_elapsed         | 38896        |\n",
      "|    total_timesteps      | 4102144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013621096 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 24910        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -1.4093386   |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2004        |\n",
      "|    time_elapsed         | 38915       |\n",
      "|    total_timesteps      | 4104192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003930948 |\n",
      "|    clip_fraction        | 0.00669     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 24920       |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | -4.8351126  |\n",
      "|    std                  | 32.5        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2005         |\n",
      "|    time_elapsed         | 38935        |\n",
      "|    total_timesteps      | 4106240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038538561 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.58         |\n",
      "|    n_updates            | 24930        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    reward               | 1.7562944    |\n",
      "|    std                  | 32.6         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2006         |\n",
      "|    time_elapsed         | 38954        |\n",
      "|    total_timesteps      | 4108288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038516573 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 24940        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | -1.7400899   |\n",
      "|    std                  | 32.7         |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2007          |\n",
      "|    time_elapsed         | 38973         |\n",
      "|    total_timesteps      | 4110336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074041146 |\n",
      "|    clip_fraction        | 0.00103       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.626         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.5          |\n",
      "|    n_updates            | 24950         |\n",
      "|    policy_gradient_loss | -0.00192      |\n",
      "|    reward               | -0.13472667   |\n",
      "|    std                  | 32.7          |\n",
      "|    value_loss           | 50.6          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3514522.25\n",
      "total_reward: 2514522.25\n",
      "total_cost: 181618.45\n",
      "total_trades: 60108\n",
      "Sharpe: 0.706\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2008       |\n",
      "|    time_elapsed         | 38992      |\n",
      "|    total_timesteps      | 4112384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00742994 |\n",
      "|    clip_fraction        | 0.0361     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -141       |\n",
      "|    explained_variance   | 0.611      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.25       |\n",
      "|    n_updates            | 24960      |\n",
      "|    policy_gradient_loss | -0.00942   |\n",
      "|    reward               | 1.6240354  |\n",
      "|    std                  | 32.8       |\n",
      "|    value_loss           | 17.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2009         |\n",
      "|    time_elapsed         | 39012        |\n",
      "|    total_timesteps      | 4114432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028128955 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 24970        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 0.31457183   |\n",
      "|    std                  | 32.9         |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2010         |\n",
      "|    time_elapsed         | 39030        |\n",
      "|    total_timesteps      | 4116480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022583953 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 24980        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -0.3988987   |\n",
      "|    std                  | 32.9         |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2011         |\n",
      "|    time_elapsed         | 39050        |\n",
      "|    total_timesteps      | 4118528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040771696 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 24990        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | -0.69648886  |\n",
      "|    std                  | 33           |\n",
      "|    value_loss           | 54.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2012         |\n",
      "|    time_elapsed         | 39069        |\n",
      "|    total_timesteps      | 4120576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038420674 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 25000        |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    reward               | 1.2295043    |\n",
      "|    std                  | 33.1         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2013        |\n",
      "|    time_elapsed         | 39088       |\n",
      "|    total_timesteps      | 4122624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001345424 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 25010       |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    reward               | -1.7944608  |\n",
      "|    std                  | 33.1        |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2014         |\n",
      "|    time_elapsed         | 39107        |\n",
      "|    total_timesteps      | 4124672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021150182 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 25020        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | 1.9308547    |\n",
      "|    std                  | 33.1         |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2015        |\n",
      "|    time_elapsed         | 39127       |\n",
      "|    total_timesteps      | 4126720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004760785 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.87        |\n",
      "|    n_updates            | 25030       |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | 1.209653    |\n",
      "|    std                  | 33.3        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2016         |\n",
      "|    time_elapsed         | 39146        |\n",
      "|    total_timesteps      | 4128768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012955253 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 25040        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | 0.28608814   |\n",
      "|    std                  | 33.3         |\n",
      "|    value_loss           | 48.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2017         |\n",
      "|    time_elapsed         | 39165        |\n",
      "|    total_timesteps      | 4130816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012090921 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 25050        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | -36.630623   |\n",
      "|    std                  | 33.4         |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2018        |\n",
      "|    time_elapsed         | 39184       |\n",
      "|    total_timesteps      | 4132864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003287805 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 25060       |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | -0.59869593 |\n",
      "|    std                  | 33.5        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2019        |\n",
      "|    time_elapsed         | 39203       |\n",
      "|    total_timesteps      | 4134912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006824791 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.4         |\n",
      "|    n_updates            | 25070       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    reward               | -0.63676035 |\n",
      "|    std                  | 33.6        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2020         |\n",
      "|    time_elapsed         | 39222        |\n",
      "|    total_timesteps      | 4136960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024494496 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 25080        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | -4.5794945   |\n",
      "|    std                  | 33.7         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2021         |\n",
      "|    time_elapsed         | 39242        |\n",
      "|    total_timesteps      | 4139008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032273184 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 25090        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    reward               | 0.012451797  |\n",
      "|    std                  | 33.8         |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3475553.61\n",
      "total_reward: 2475553.61\n",
      "total_cost: 167138.06\n",
      "total_trades: 59062\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2022        |\n",
      "|    time_elapsed         | 39261       |\n",
      "|    total_timesteps      | 4141056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007436649 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.97        |\n",
      "|    n_updates            | 25100       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | -0.81442976 |\n",
      "|    std                  | 33.8        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2023         |\n",
      "|    time_elapsed         | 39280        |\n",
      "|    total_timesteps      | 4143104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032518285 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 25110        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    reward               | 0.2029741    |\n",
      "|    std                  | 33.8         |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2024        |\n",
      "|    time_elapsed         | 39299       |\n",
      "|    total_timesteps      | 4145152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002250372 |\n",
      "|    clip_fraction        | 0.00527     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 25120       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    reward               | 0.11641503  |\n",
      "|    std                  | 33.9        |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2025       |\n",
      "|    time_elapsed         | 39318      |\n",
      "|    total_timesteps      | 4147200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00835035 |\n",
      "|    clip_fraction        | 0.0366     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -142       |\n",
      "|    explained_variance   | 0.413      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.31       |\n",
      "|    n_updates            | 25130      |\n",
      "|    policy_gradient_loss | -0.00766   |\n",
      "|    reward               | 3.5321968  |\n",
      "|    std                  | 34         |\n",
      "|    value_loss           | 18.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2026         |\n",
      "|    time_elapsed         | 39337        |\n",
      "|    total_timesteps      | 4149248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037058678 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 25140        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | -5.006081    |\n",
      "|    std                  | 34           |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2027         |\n",
      "|    time_elapsed         | 39356        |\n",
      "|    total_timesteps      | 4151296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012622217 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 25150        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -1.6618291   |\n",
      "|    std                  | 34.1         |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2028         |\n",
      "|    time_elapsed         | 39374        |\n",
      "|    total_timesteps      | 4153344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017407695 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 25160        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | 1.6031733    |\n",
      "|    std                  | 34.1         |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2029        |\n",
      "|    time_elapsed         | 39394       |\n",
      "|    total_timesteps      | 4155392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004277002 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.17        |\n",
      "|    n_updates            | 25170       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | 2.1754081   |\n",
      "|    std                  | 34.2        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2030         |\n",
      "|    time_elapsed         | 39413        |\n",
      "|    total_timesteps      | 4157440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015157689 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 25180        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | -0.15267122  |\n",
      "|    std                  | 34.3         |\n",
      "|    value_loss           | 46.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2031         |\n",
      "|    time_elapsed         | 39432        |\n",
      "|    total_timesteps      | 4159488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020529889 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 25190        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | 0.62029374   |\n",
      "|    std                  | 34.4         |\n",
      "|    value_loss           | 48.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2032         |\n",
      "|    time_elapsed         | 39451        |\n",
      "|    total_timesteps      | 4161536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063522886 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.26         |\n",
      "|    n_updates            | 25200        |\n",
      "|    policy_gradient_loss | -0.00968     |\n",
      "|    reward               | 0.31238288   |\n",
      "|    std                  | 34.4         |\n",
      "|    value_loss           | 14.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2033         |\n",
      "|    time_elapsed         | 39470        |\n",
      "|    total_timesteps      | 4163584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028093727 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 25210        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | 1.6206334    |\n",
      "|    std                  | 34.5         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2034         |\n",
      "|    time_elapsed         | 39489        |\n",
      "|    total_timesteps      | 4165632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030431252 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.142        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 25220        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | 1.5997319    |\n",
      "|    std                  | 34.5         |\n",
      "|    value_loss           | 81.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2035        |\n",
      "|    time_elapsed         | 39508       |\n",
      "|    total_timesteps      | 4167680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005555492 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 25230       |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | -1.567955   |\n",
      "|    std                  | 34.5        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5349839.99\n",
      "total_reward: 4349839.99\n",
      "total_cost: 268191.74\n",
      "total_trades: 65247\n",
      "Sharpe: 0.922\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2036        |\n",
      "|    time_elapsed         | 39527       |\n",
      "|    total_timesteps      | 4169728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004059162 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.09        |\n",
      "|    n_updates            | 25240       |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -0.20999342 |\n",
      "|    std                  | 34.6        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2037         |\n",
      "|    time_elapsed         | 39547        |\n",
      "|    total_timesteps      | 4171776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016770663 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.4         |\n",
      "|    n_updates            | 25250        |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    reward               | 1.1078124    |\n",
      "|    std                  | 34.6         |\n",
      "|    value_loss           | 86.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2038         |\n",
      "|    time_elapsed         | 39565        |\n",
      "|    total_timesteps      | 4173824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021860283 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 25260        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | 3.3419752    |\n",
      "|    std                  | 34.6         |\n",
      "|    value_loss           | 58.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2039         |\n",
      "|    time_elapsed         | 39585        |\n",
      "|    total_timesteps      | 4175872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076788496 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.21         |\n",
      "|    n_updates            | 25270        |\n",
      "|    policy_gradient_loss | -0.00965     |\n",
      "|    reward               | -2.497065    |\n",
      "|    std                  | 34.7         |\n",
      "|    value_loss           | 13.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2040         |\n",
      "|    time_elapsed         | 39604        |\n",
      "|    total_timesteps      | 4177920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017537777 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 25280        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | 0.3857376    |\n",
      "|    std                  | 34.8         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2041         |\n",
      "|    time_elapsed         | 39623        |\n",
      "|    total_timesteps      | 4179968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016355879 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 25290        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | 1.1976647    |\n",
      "|    std                  | 34.8         |\n",
      "|    value_loss           | 65.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2042       |\n",
      "|    time_elapsed         | 39642      |\n",
      "|    total_timesteps      | 4182016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00532654 |\n",
      "|    clip_fraction        | 0.0174     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -143       |\n",
      "|    explained_variance   | 0.587      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.17       |\n",
      "|    n_updates            | 25300      |\n",
      "|    policy_gradient_loss | -0.00691   |\n",
      "|    reward               | 0.24666928 |\n",
      "|    std                  | 34.8       |\n",
      "|    value_loss           | 18.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2043        |\n",
      "|    time_elapsed         | 39661       |\n",
      "|    total_timesteps      | 4184064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002808075 |\n",
      "|    clip_fraction        | 0.00659     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 25310       |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | -1.1890849  |\n",
      "|    std                  | 34.9        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2044       |\n",
      "|    time_elapsed         | 39680      |\n",
      "|    total_timesteps      | 4186112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00292247 |\n",
      "|    clip_fraction        | 0.00396    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -143       |\n",
      "|    explained_variance   | 0.218      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.2       |\n",
      "|    n_updates            | 25320      |\n",
      "|    policy_gradient_loss | -0.00418   |\n",
      "|    reward               | -4.487778  |\n",
      "|    std                  | 34.9       |\n",
      "|    value_loss           | 96.8       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2045          |\n",
      "|    time_elapsed         | 39698         |\n",
      "|    total_timesteps      | 4188160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072503474 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.448         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.8          |\n",
      "|    n_updates            | 25330         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | 1.6628087     |\n",
      "|    std                  | 35            |\n",
      "|    value_loss           | 55.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2046         |\n",
      "|    time_elapsed         | 39717        |\n",
      "|    total_timesteps      | 4190208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057590776 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.71         |\n",
      "|    n_updates            | 25340        |\n",
      "|    policy_gradient_loss | -0.00801     |\n",
      "|    reward               | -0.017512385 |\n",
      "|    std                  | 35.1         |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2047       |\n",
      "|    time_elapsed         | 39736      |\n",
      "|    total_timesteps      | 4192256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00434051 |\n",
      "|    clip_fraction        | 0.0187     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -143       |\n",
      "|    explained_variance   | 0.424      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.2       |\n",
      "|    n_updates            | 25350      |\n",
      "|    policy_gradient_loss | -0.00516   |\n",
      "|    reward               | 0.43296313 |\n",
      "|    std                  | 35.2       |\n",
      "|    value_loss           | 61.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2048         |\n",
      "|    time_elapsed         | 39755        |\n",
      "|    total_timesteps      | 4194304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010388847 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 25360        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | -0.51848316  |\n",
      "|    std                  | 35.2         |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2049         |\n",
      "|    time_elapsed         | 39774        |\n",
      "|    total_timesteps      | 4196352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042334036 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.26         |\n",
      "|    n_updates            | 25370        |\n",
      "|    policy_gradient_loss | -0.00764     |\n",
      "|    reward               | -1.4989637   |\n",
      "|    std                  | 35.3         |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3789194.55\n",
      "total_reward: 2789194.55\n",
      "total_cost: 224939.17\n",
      "total_trades: 61628\n",
      "Sharpe: 0.759\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2050        |\n",
      "|    time_elapsed         | 39793       |\n",
      "|    total_timesteps      | 4198400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003022995 |\n",
      "|    clip_fraction        | 0.00986     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 25380       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | 3.9422517   |\n",
      "|    std                  | 35.3        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2051         |\n",
      "|    time_elapsed         | 39812        |\n",
      "|    total_timesteps      | 4200448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006935734 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 25390        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 1.6193134    |\n",
      "|    std                  | 35.4         |\n",
      "|    value_loss           | 51.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2052         |\n",
      "|    time_elapsed         | 39831        |\n",
      "|    total_timesteps      | 4202496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031689624 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 25400        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | 2.229197     |\n",
      "|    std                  | 35.4         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2053         |\n",
      "|    time_elapsed         | 39850        |\n",
      "|    total_timesteps      | 4204544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051622204 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.5          |\n",
      "|    n_updates            | 25410        |\n",
      "|    policy_gradient_loss | -0.00749     |\n",
      "|    reward               | 0.10966834   |\n",
      "|    std                  | 35.5         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2054         |\n",
      "|    time_elapsed         | 39869        |\n",
      "|    total_timesteps      | 4206592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019081032 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 25420        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 0.6329929    |\n",
      "|    std                  | 35.5         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2055         |\n",
      "|    time_elapsed         | 39889        |\n",
      "|    total_timesteps      | 4208640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013468703 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 25430        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | -3.2875173   |\n",
      "|    std                  | 35.6         |\n",
      "|    value_loss           | 53.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2056         |\n",
      "|    time_elapsed         | 39908        |\n",
      "|    total_timesteps      | 4210688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046931067 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.18         |\n",
      "|    n_updates            | 25440        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    reward               | 0.63183385   |\n",
      "|    std                  | 35.6         |\n",
      "|    value_loss           | 14.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2057        |\n",
      "|    time_elapsed         | 39927       |\n",
      "|    total_timesteps      | 4212736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001150753 |\n",
      "|    clip_fraction        | 0.00498     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 25450       |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    reward               | 0.35401025  |\n",
      "|    std                  | 35.7        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2058         |\n",
      "|    time_elapsed         | 39947        |\n",
      "|    total_timesteps      | 4214784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009749433 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 25460        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | 1.9470305    |\n",
      "|    std                  | 35.7         |\n",
      "|    value_loss           | 51.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2059        |\n",
      "|    time_elapsed         | 39966       |\n",
      "|    total_timesteps      | 4216832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003377947 |\n",
      "|    clip_fraction        | 0.00542     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 25470       |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | 0.052483972 |\n",
      "|    std                  | 35.8        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2060         |\n",
      "|    time_elapsed         | 39985        |\n",
      "|    total_timesteps      | 4218880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016797057 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 25480        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | -1.7820004   |\n",
      "|    std                  | 35.9         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2061         |\n",
      "|    time_elapsed         | 40004        |\n",
      "|    total_timesteps      | 4220928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020915894 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 25490        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | 0.6772303    |\n",
      "|    std                  | 35.9         |\n",
      "|    value_loss           | 46.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2062         |\n",
      "|    time_elapsed         | 40023        |\n",
      "|    total_timesteps      | 4222976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019604086 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 25500        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 2.1740603    |\n",
      "|    std                  | 36           |\n",
      "|    value_loss           | 45.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2063        |\n",
      "|    time_elapsed         | 40042       |\n",
      "|    total_timesteps      | 4225024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006642599 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.45        |\n",
      "|    n_updates            | 25510       |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | -3.547656   |\n",
      "|    std                  | 36.1        |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4007364.25\n",
      "total_reward: 3007364.25\n",
      "total_cost: 273161.42\n",
      "total_trades: 64619\n",
      "Sharpe: 0.737\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2064         |\n",
      "|    time_elapsed         | 40061        |\n",
      "|    total_timesteps      | 4227072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019256793 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 25520        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | 0.5549554    |\n",
      "|    std                  | 36.2         |\n",
      "|    value_loss           | 49.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2065        |\n",
      "|    time_elapsed         | 40081       |\n",
      "|    total_timesteps      | 4229120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002656791 |\n",
      "|    clip_fraction        | 0.00518     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 25530       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 1.8930652   |\n",
      "|    std                  | 36.2        |\n",
      "|    value_loss           | 68.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2066         |\n",
      "|    time_elapsed         | 40100        |\n",
      "|    total_timesteps      | 4231168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041575637 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.27         |\n",
      "|    n_updates            | 25540        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | 0.82898617   |\n",
      "|    std                  | 36.3         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2067        |\n",
      "|    time_elapsed         | 40119       |\n",
      "|    total_timesteps      | 4233216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002259226 |\n",
      "|    clip_fraction        | 0.00786     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 25550       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    reward               | -0.37764087 |\n",
      "|    std                  | 36.4        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2068        |\n",
      "|    time_elapsed         | 40138       |\n",
      "|    total_timesteps      | 4235264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003220115 |\n",
      "|    clip_fraction        | 0.00742     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 25560       |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | -2.1582768  |\n",
      "|    std                  | 36.5        |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2069         |\n",
      "|    time_elapsed         | 40192        |\n",
      "|    total_timesteps      | 4237312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020512308 |\n",
      "|    clip_fraction        | 0.00747      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 25570        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | 0.35914746   |\n",
      "|    std                  | 36.6         |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2070        |\n",
      "|    time_elapsed         | 40211       |\n",
      "|    total_timesteps      | 4239360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00457503  |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 25580       |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | -0.55446166 |\n",
      "|    std                  | 36.6        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2071         |\n",
      "|    time_elapsed         | 40231        |\n",
      "|    total_timesteps      | 4241408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016714328 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 25590        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | -0.5860107   |\n",
      "|    std                  | 36.7         |\n",
      "|    value_loss           | 46.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2072         |\n",
      "|    time_elapsed         | 40250        |\n",
      "|    total_timesteps      | 4243456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006442656 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 25600        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | 2.3017046    |\n",
      "|    std                  | 36.7         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2073         |\n",
      "|    time_elapsed         | 40269        |\n",
      "|    total_timesteps      | 4245504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038687317 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.81         |\n",
      "|    n_updates            | 25610        |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    reward               | -0.9612448   |\n",
      "|    std                  | 36.7         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2074         |\n",
      "|    time_elapsed         | 40288        |\n",
      "|    total_timesteps      | 4247552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026631823 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 25620        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | 1.9187986    |\n",
      "|    std                  | 36.8         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2075         |\n",
      "|    time_elapsed         | 40307        |\n",
      "|    total_timesteps      | 4249600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009676867 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 25630        |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    reward               | 2.7605715    |\n",
      "|    std                  | 36.8         |\n",
      "|    value_loss           | 49           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2076         |\n",
      "|    time_elapsed         | 40326        |\n",
      "|    total_timesteps      | 4251648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029078922 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 25640        |\n",
      "|    policy_gradient_loss | -0.00699     |\n",
      "|    reward               | 2.0494368    |\n",
      "|    std                  | 36.8         |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2077         |\n",
      "|    time_elapsed         | 40345        |\n",
      "|    total_timesteps      | 4253696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030222745 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 25650        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    reward               | -1.0644153   |\n",
      "|    std                  | 36.9         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3580886.27\n",
      "total_reward: 2580886.27\n",
      "total_cost: 281698.43\n",
      "total_trades: 65356\n",
      "Sharpe: 0.724\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2078        |\n",
      "|    time_elapsed         | 40364       |\n",
      "|    total_timesteps      | 4255744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002279582 |\n",
      "|    clip_fraction        | 0.00498     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 25660       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | 0.02061191  |\n",
      "|    std                  | 37          |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2079         |\n",
      "|    time_elapsed         | 40383        |\n",
      "|    total_timesteps      | 4257792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005814004 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 25670        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    reward               | -0.24206127  |\n",
      "|    std                  | 37           |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2080        |\n",
      "|    time_elapsed         | 40402       |\n",
      "|    total_timesteps      | 4259840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008671868 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.33        |\n",
      "|    n_updates            | 25680       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | 2.5105894   |\n",
      "|    std                  | 37.3        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2081          |\n",
      "|    time_elapsed         | 40422         |\n",
      "|    total_timesteps      | 4261888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078405783 |\n",
      "|    clip_fraction        | 0.00151       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.478         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.1          |\n",
      "|    n_updates            | 25690         |\n",
      "|    policy_gradient_loss | -0.00189      |\n",
      "|    reward               | -0.29980674   |\n",
      "|    std                  | 37.3          |\n",
      "|    value_loss           | 49.1          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2082         |\n",
      "|    time_elapsed         | 40441        |\n",
      "|    total_timesteps      | 4263936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008876801 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 25700        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | 5.255908     |\n",
      "|    std                  | 37.3         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2083         |\n",
      "|    time_elapsed         | 40461        |\n",
      "|    total_timesteps      | 4265984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047566993 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 25710        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    reward               | 2.9896977    |\n",
      "|    std                  | 37.4         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2084         |\n",
      "|    time_elapsed         | 40481        |\n",
      "|    total_timesteps      | 4268032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023268806 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 25720        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | 0.75633454   |\n",
      "|    std                  | 37.5         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2085         |\n",
      "|    time_elapsed         | 40500        |\n",
      "|    total_timesteps      | 4270080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037589907 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 25730        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | 0.46230003   |\n",
      "|    std                  | 37.6         |\n",
      "|    value_loss           | 62           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2086          |\n",
      "|    time_elapsed         | 40519         |\n",
      "|    total_timesteps      | 4272128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095827534 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.563         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.5          |\n",
      "|    n_updates            | 25740         |\n",
      "|    policy_gradient_loss | -0.00229      |\n",
      "|    reward               | 0.9063168     |\n",
      "|    std                  | 37.6          |\n",
      "|    value_loss           | 49            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2087        |\n",
      "|    time_elapsed         | 40538       |\n",
      "|    total_timesteps      | 4274176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006270617 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.01        |\n",
      "|    n_updates            | 25750       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -1.1517017  |\n",
      "|    std                  | 37.7        |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2088         |\n",
      "|    time_elapsed         | 40557        |\n",
      "|    total_timesteps      | 4276224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010289038 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 25760        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | 0.22633815   |\n",
      "|    std                  | 37.7         |\n",
      "|    value_loss           | 52.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2089          |\n",
      "|    time_elapsed         | 40576         |\n",
      "|    total_timesteps      | 4278272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083734916 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.628         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.1          |\n",
      "|    n_updates            | 25770         |\n",
      "|    policy_gradient_loss | -0.00272      |\n",
      "|    reward               | -2.0889878    |\n",
      "|    std                  | 37.7          |\n",
      "|    value_loss           | 51.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2090         |\n",
      "|    time_elapsed         | 40595        |\n",
      "|    total_timesteps      | 4280320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038328562 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 25780        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    reward               | 2.2867484    |\n",
      "|    std                  | 37.7         |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2091         |\n",
      "|    time_elapsed         | 40614        |\n",
      "|    total_timesteps      | 4282368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015927383 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 25790        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | -2.5137815   |\n",
      "|    std                  | 37.8         |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2092         |\n",
      "|    time_elapsed         | 40633        |\n",
      "|    total_timesteps      | 4284416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012335307 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.5         |\n",
      "|    n_updates            | 25800        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | -0.38189456  |\n",
      "|    std                  | 37.8         |\n",
      "|    value_loss           | 69.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4892494.53\n",
      "total_reward: 3892494.53\n",
      "total_cost: 279863.12\n",
      "total_trades: 65381\n",
      "Sharpe: 0.853\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2093         |\n",
      "|    time_elapsed         | 40653        |\n",
      "|    total_timesteps      | 4286464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030931528 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.71         |\n",
      "|    n_updates            | 25810        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | 0.5542339    |\n",
      "|    std                  | 37.9         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2094        |\n",
      "|    time_elapsed         | 40672       |\n",
      "|    total_timesteps      | 4288512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002905143 |\n",
      "|    clip_fraction        | 0.00566     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.1         |\n",
      "|    n_updates            | 25820       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | 0.98772335  |\n",
      "|    std                  | 38          |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2095          |\n",
      "|    time_elapsed         | 40691         |\n",
      "|    total_timesteps      | 4290560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088656857 |\n",
      "|    clip_fraction        | 0.00356       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.622         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.5          |\n",
      "|    n_updates            | 25830         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | -0.34253865   |\n",
      "|    std                  | 38            |\n",
      "|    value_loss           | 57.2          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2096       |\n",
      "|    time_elapsed         | 40711      |\n",
      "|    total_timesteps      | 4292608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00114428 |\n",
      "|    clip_fraction        | 0.000977   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -145       |\n",
      "|    explained_variance   | 0.672      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.7       |\n",
      "|    n_updates            | 25840      |\n",
      "|    policy_gradient_loss | -0.00336   |\n",
      "|    reward               | 6.7257504  |\n",
      "|    std                  | 38         |\n",
      "|    value_loss           | 54.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2097        |\n",
      "|    time_elapsed         | 40730       |\n",
      "|    total_timesteps      | 4294656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005868277 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.58        |\n",
      "|    n_updates            | 25850       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | -0.18002364 |\n",
      "|    std                  | 38          |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2098         |\n",
      "|    time_elapsed         | 40750        |\n",
      "|    total_timesteps      | 4296704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019993852 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.3         |\n",
      "|    n_updates            | 25860        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 0.28510737   |\n",
      "|    std                  | 38           |\n",
      "|    value_loss           | 54           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2099         |\n",
      "|    time_elapsed         | 40769        |\n",
      "|    total_timesteps      | 4298752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026759151 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.241        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 98.5         |\n",
      "|    n_updates            | 25870        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -0.6204987   |\n",
      "|    std                  | 38.1         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2100         |\n",
      "|    time_elapsed         | 40788        |\n",
      "|    total_timesteps      | 4300800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035938611 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 25880        |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | 0.42651492   |\n",
      "|    std                  | 38.1         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2101       |\n",
      "|    time_elapsed         | 40807      |\n",
      "|    total_timesteps      | 4302848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00210706 |\n",
      "|    clip_fraction        | 0.00708    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -145       |\n",
      "|    explained_variance   | 0.496      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 36.3       |\n",
      "|    n_updates            | 25890      |\n",
      "|    policy_gradient_loss | -0.00329   |\n",
      "|    reward               | 0.1860568  |\n",
      "|    std                  | 38.1       |\n",
      "|    value_loss           | 42         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2102         |\n",
      "|    time_elapsed         | 40827        |\n",
      "|    total_timesteps      | 4304896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015886839 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 25900        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | -1.4658412   |\n",
      "|    std                  | 38.2         |\n",
      "|    value_loss           | 74.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2103        |\n",
      "|    time_elapsed         | 40846       |\n",
      "|    total_timesteps      | 4306944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005411812 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 25910       |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | 0.2664733   |\n",
      "|    std                  | 38.2        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2104         |\n",
      "|    time_elapsed         | 40865        |\n",
      "|    total_timesteps      | 4308992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074308496 |\n",
      "|    clip_fraction        | 0.0366       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.59         |\n",
      "|    n_updates            | 25920        |\n",
      "|    policy_gradient_loss | -0.00969     |\n",
      "|    reward               | -2.1243925   |\n",
      "|    std                  | 38.4         |\n",
      "|    value_loss           | 11.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2105         |\n",
      "|    time_elapsed         | 40885        |\n",
      "|    total_timesteps      | 4311040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017768363 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 25930        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | -1.0704327   |\n",
      "|    std                  | 38.5         |\n",
      "|    value_loss           | 53.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2106         |\n",
      "|    time_elapsed         | 40904        |\n",
      "|    total_timesteps      | 4313088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014945767 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 25940        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 7.1105204    |\n",
      "|    std                  | 38.5         |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3852789.93\n",
      "total_reward: 2852789.93\n",
      "total_cost: 236765.43\n",
      "total_trades: 63200\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2107         |\n",
      "|    time_elapsed         | 40923        |\n",
      "|    total_timesteps      | 4315136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029625152 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 25950        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    reward               | 10.239611    |\n",
      "|    std                  | 38.6         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2108         |\n",
      "|    time_elapsed         | 40942        |\n",
      "|    total_timesteps      | 4317184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032199565 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 25960        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    reward               | 1.5377578    |\n",
      "|    std                  | 38.7         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2109         |\n",
      "|    time_elapsed         | 40961        |\n",
      "|    total_timesteps      | 4319232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027189013 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.3         |\n",
      "|    n_updates            | 25970        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 1.3343546    |\n",
      "|    std                  | 38.7         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2110          |\n",
      "|    time_elapsed         | 40981         |\n",
      "|    total_timesteps      | 4321280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080152135 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.566         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.7          |\n",
      "|    n_updates            | 25980         |\n",
      "|    policy_gradient_loss | -0.00234      |\n",
      "|    reward               | 3.8714027     |\n",
      "|    std                  | 38.8          |\n",
      "|    value_loss           | 51.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2111         |\n",
      "|    time_elapsed         | 41000        |\n",
      "|    total_timesteps      | 4323328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038750642 |\n",
      "|    clip_fraction        | 0.00864      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 25990        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    reward               | 0.63402957   |\n",
      "|    std                  | 38.7         |\n",
      "|    value_loss           | 19           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2112         |\n",
      "|    time_elapsed         | 41019        |\n",
      "|    total_timesteps      | 4325376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041828593 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 26000        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    reward               | 1.129358     |\n",
      "|    std                  | 38.8         |\n",
      "|    value_loss           | 91.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2113         |\n",
      "|    time_elapsed         | 41039        |\n",
      "|    total_timesteps      | 4327424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008619715 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 26010        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | -0.9969648   |\n",
      "|    std                  | 38.9         |\n",
      "|    value_loss           | 74.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2114        |\n",
      "|    time_elapsed         | 41058       |\n",
      "|    total_timesteps      | 4329472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00253638  |\n",
      "|    clip_fraction        | 0.00591     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.34        |\n",
      "|    n_updates            | 26020       |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | -0.95649064 |\n",
      "|    std                  | 39          |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2115          |\n",
      "|    time_elapsed         | 41077         |\n",
      "|    total_timesteps      | 4331520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084860565 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.408         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 44.9          |\n",
      "|    n_updates            | 26030         |\n",
      "|    policy_gradient_loss | -0.00313      |\n",
      "|    reward               | 0.008456452   |\n",
      "|    std                  | 39.1          |\n",
      "|    value_loss           | 60.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2116         |\n",
      "|    time_elapsed         | 41097        |\n",
      "|    total_timesteps      | 4333568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012570277 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.1         |\n",
      "|    n_updates            | 26040        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -2.5231767   |\n",
      "|    std                  | 39.1         |\n",
      "|    value_loss           | 69.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2117        |\n",
      "|    time_elapsed         | 41116       |\n",
      "|    total_timesteps      | 4335616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001947358 |\n",
      "|    clip_fraction        | 0.00229     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 26050       |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    reward               | -0.07004139 |\n",
      "|    std                  | 39.2        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2118         |\n",
      "|    time_elapsed         | 41135        |\n",
      "|    total_timesteps      | 4337664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043036086 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 26060        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | -0.07362095  |\n",
      "|    std                  | 39.3         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2119         |\n",
      "|    time_elapsed         | 41154        |\n",
      "|    total_timesteps      | 4339712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045538438 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46           |\n",
      "|    n_updates            | 26070        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    reward               | 0.38257122   |\n",
      "|    std                  | 39.3         |\n",
      "|    value_loss           | 92.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2120         |\n",
      "|    time_elapsed         | 41173        |\n",
      "|    total_timesteps      | 4341760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014212902 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.3         |\n",
      "|    n_updates            | 26080        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | -1.445746    |\n",
      "|    std                  | 39.5         |\n",
      "|    value_loss           | 59.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4916053.30\n",
      "total_reward: 3916053.30\n",
      "total_cost: 292308.61\n",
      "total_trades: 65725\n",
      "Sharpe: 0.829\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2121         |\n",
      "|    time_elapsed         | 41193        |\n",
      "|    total_timesteps      | 4343808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049147718 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.54         |\n",
      "|    n_updates            | 26090        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    reward               | 2.6270344    |\n",
      "|    std                  | 39.5         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2122         |\n",
      "|    time_elapsed         | 41213        |\n",
      "|    total_timesteps      | 4345856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019638883 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 26100        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | 0.3040689    |\n",
      "|    std                  | 39.5         |\n",
      "|    value_loss           | 51.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2123         |\n",
      "|    time_elapsed         | 41232        |\n",
      "|    total_timesteps      | 4347904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011762939 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 26110        |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    reward               | 1.7302451    |\n",
      "|    std                  | 39.6         |\n",
      "|    value_loss           | 77.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2124         |\n",
      "|    time_elapsed         | 41251        |\n",
      "|    total_timesteps      | 4349952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023972075 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 26120        |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    reward               | -2.4478893   |\n",
      "|    std                  | 39.7         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2125         |\n",
      "|    time_elapsed         | 41270        |\n",
      "|    total_timesteps      | 4352000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032293191 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.408        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.76         |\n",
      "|    n_updates            | 26130        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    reward               | 0.42043516   |\n",
      "|    std                  | 39.7         |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2126        |\n",
      "|    time_elapsed         | 41289       |\n",
      "|    total_timesteps      | 4354048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002086271 |\n",
      "|    clip_fraction        | 0.00293     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 26140       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 1.0312828   |\n",
      "|    std                  | 39.7        |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2127         |\n",
      "|    time_elapsed         | 41308        |\n",
      "|    total_timesteps      | 4356096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018034116 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 26150        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | 1.3588098    |\n",
      "|    std                  | 39.8         |\n",
      "|    value_loss           | 49           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2128        |\n",
      "|    time_elapsed         | 41328       |\n",
      "|    total_timesteps      | 4358144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005555059 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.19        |\n",
      "|    n_updates            | 26160       |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    reward               | -0.06438664 |\n",
      "|    std                  | 40          |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2129         |\n",
      "|    time_elapsed         | 41347        |\n",
      "|    total_timesteps      | 4360192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016571827 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.58         |\n",
      "|    n_updates            | 26170        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | -0.67118263  |\n",
      "|    std                  | 40.1         |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2130         |\n",
      "|    time_elapsed         | 41366        |\n",
      "|    total_timesteps      | 4362240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008166378 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 26180        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | -5.455087    |\n",
      "|    std                  | 40.2         |\n",
      "|    value_loss           | 75.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2131         |\n",
      "|    time_elapsed         | 41385        |\n",
      "|    total_timesteps      | 4364288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018206455 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 26190        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | 1.6591382    |\n",
      "|    std                  | 40.3         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2132         |\n",
      "|    time_elapsed         | 41404        |\n",
      "|    total_timesteps      | 4366336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015086872 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 26200        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -1.8827633   |\n",
      "|    std                  | 40.4         |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2133         |\n",
      "|    time_elapsed         | 41423        |\n",
      "|    total_timesteps      | 4368384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017220787 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 26210        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 1.0265869    |\n",
      "|    std                  | 40.4         |\n",
      "|    value_loss           | 39.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2134         |\n",
      "|    time_elapsed         | 41442        |\n",
      "|    total_timesteps      | 4370432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018041795 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 26220        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | -2.895784    |\n",
      "|    std                  | 40.5         |\n",
      "|    value_loss           | 59           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4480481.31\n",
      "total_reward: 3480481.31\n",
      "total_cost: 300403.76\n",
      "total_trades: 66039\n",
      "Sharpe: 0.839\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2135        |\n",
      "|    time_elapsed         | 41462       |\n",
      "|    total_timesteps      | 4372480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006600461 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 26230       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | 0.43232945  |\n",
      "|    std                  | 40.6        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2136         |\n",
      "|    time_elapsed         | 41481        |\n",
      "|    total_timesteps      | 4374528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027642138 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 26240        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | -0.6401641   |\n",
      "|    std                  | 40.7         |\n",
      "|    value_loss           | 58.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2137         |\n",
      "|    time_elapsed         | 41500        |\n",
      "|    total_timesteps      | 4376576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012437352 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 26250        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 1.083948     |\n",
      "|    std                  | 40.8         |\n",
      "|    value_loss           | 60.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2138       |\n",
      "|    time_elapsed         | 41519      |\n",
      "|    total_timesteps      | 4378624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00612369 |\n",
      "|    clip_fraction        | 0.0223     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -148       |\n",
      "|    explained_variance   | 0.483      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.44       |\n",
      "|    n_updates            | 26260      |\n",
      "|    policy_gradient_loss | -0.00838   |\n",
      "|    reward               | -3.5557232 |\n",
      "|    std                  | 41.1       |\n",
      "|    value_loss           | 16.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2139         |\n",
      "|    time_elapsed         | 41539        |\n",
      "|    total_timesteps      | 4380672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025157826 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 26270        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 0.26548293   |\n",
      "|    std                  | 41.1         |\n",
      "|    value_loss           | 45.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2140         |\n",
      "|    time_elapsed         | 41558        |\n",
      "|    total_timesteps      | 4382720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009302122 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 26280        |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    reward               | 2.5407648    |\n",
      "|    std                  | 41.2         |\n",
      "|    value_loss           | 53           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2141          |\n",
      "|    time_elapsed         | 41577         |\n",
      "|    total_timesteps      | 4384768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084745063 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.582         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.3          |\n",
      "|    n_updates            | 26290         |\n",
      "|    policy_gradient_loss | -0.00239      |\n",
      "|    reward               | -1.8762828    |\n",
      "|    std                  | 41.2          |\n",
      "|    value_loss           | 32.6          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2142         |\n",
      "|    time_elapsed         | 41597        |\n",
      "|    total_timesteps      | 4386816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036015837 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.2          |\n",
      "|    n_updates            | 26300        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | -1.2281302   |\n",
      "|    std                  | 41.2         |\n",
      "|    value_loss           | 21.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2143         |\n",
      "|    time_elapsed         | 41616        |\n",
      "|    total_timesteps      | 4388864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014540583 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 26310        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | -0.24500161  |\n",
      "|    std                  | 41.3         |\n",
      "|    value_loss           | 46.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2144         |\n",
      "|    time_elapsed         | 41634        |\n",
      "|    total_timesteps      | 4390912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015659452 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 26320        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | -1.0893062   |\n",
      "|    std                  | 41.4         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2145        |\n",
      "|    time_elapsed         | 41654       |\n",
      "|    total_timesteps      | 4392960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004320954 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.35        |\n",
      "|    n_updates            | 26330       |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | -1.0382005  |\n",
      "|    std                  | 41.5        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2146         |\n",
      "|    time_elapsed         | 41673        |\n",
      "|    total_timesteps      | 4395008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016446162 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 26340        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | 1.2222288    |\n",
      "|    std                  | 41.5         |\n",
      "|    value_loss           | 55.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2147         |\n",
      "|    time_elapsed         | 41692        |\n",
      "|    total_timesteps      | 4397056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022262137 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 26350        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | 0.868219     |\n",
      "|    std                  | 41.6         |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2148         |\n",
      "|    time_elapsed         | 41712        |\n",
      "|    total_timesteps      | 4399104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062360936 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.243        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 26360        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    reward               | -0.22541925  |\n",
      "|    std                  | 41.6         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3922547.76\n",
      "total_reward: 2922547.76\n",
      "total_cost: 345905.50\n",
      "total_trades: 69175\n",
      "Sharpe: 0.750\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2149         |\n",
      "|    time_elapsed         | 41731        |\n",
      "|    total_timesteps      | 4401152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015395264 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 26370        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 3.031867     |\n",
      "|    std                  | 41.7         |\n",
      "|    value_loss           | 53.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2150          |\n",
      "|    time_elapsed         | 41750         |\n",
      "|    total_timesteps      | 4403200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066939986 |\n",
      "|    clip_fraction        | 0.00195       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.652         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27            |\n",
      "|    n_updates            | 26380         |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    reward               | 1.5204762     |\n",
      "|    std                  | 41.7          |\n",
      "|    value_loss           | 50.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2151        |\n",
      "|    time_elapsed         | 41770       |\n",
      "|    total_timesteps      | 4405248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004366085 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 26390       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | -0.31806952 |\n",
      "|    std                  | 41.9        |\n",
      "|    value_loss           | 90.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2152        |\n",
      "|    time_elapsed         | 41789       |\n",
      "|    total_timesteps      | 4407296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009115999 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.31        |\n",
      "|    n_updates            | 26400       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | -0.43295693 |\n",
      "|    std                  | 42.1        |\n",
      "|    value_loss           | 8.5         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2153          |\n",
      "|    time_elapsed         | 41809         |\n",
      "|    total_timesteps      | 4409344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057884585 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.742         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.1          |\n",
      "|    n_updates            | 26410         |\n",
      "|    policy_gradient_loss | -0.00205      |\n",
      "|    reward               | -0.45205742   |\n",
      "|    std                  | 42.1          |\n",
      "|    value_loss           | 50.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2154         |\n",
      "|    time_elapsed         | 41828        |\n",
      "|    total_timesteps      | 4411392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022486886 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.348        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 26420        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | -5.7358813   |\n",
      "|    std                  | 42.2         |\n",
      "|    value_loss           | 54.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2155         |\n",
      "|    time_elapsed         | 41847        |\n",
      "|    total_timesteps      | 4413440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067338543 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.98         |\n",
      "|    n_updates            | 26430        |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    reward               | -2.2962127   |\n",
      "|    std                  | 42.1         |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2156         |\n",
      "|    time_elapsed         | 41867        |\n",
      "|    total_timesteps      | 4415488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029849089 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 26440        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | -0.36686337  |\n",
      "|    std                  | 42.1         |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2157       |\n",
      "|    time_elapsed         | 41886      |\n",
      "|    total_timesteps      | 4417536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00260258 |\n",
      "|    clip_fraction        | 0.0146     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -148       |\n",
      "|    explained_variance   | 0.537      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.8       |\n",
      "|    n_updates            | 26450      |\n",
      "|    policy_gradient_loss | -0.00432   |\n",
      "|    reward               | -25.954727 |\n",
      "|    std                  | 42.2       |\n",
      "|    value_loss           | 35.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2158         |\n",
      "|    time_elapsed         | 41906        |\n",
      "|    total_timesteps      | 4419584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018224977 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 26460        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    reward               | -1.2505728   |\n",
      "|    std                  | 42.3         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2159        |\n",
      "|    time_elapsed         | 41925       |\n",
      "|    total_timesteps      | 4421632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006659697 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.05        |\n",
      "|    n_updates            | 26470       |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    reward               | 0.5322008   |\n",
      "|    std                  | 42.4        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2160         |\n",
      "|    time_elapsed         | 41945        |\n",
      "|    total_timesteps      | 4423680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017825096 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 26480        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 0.24701218   |\n",
      "|    std                  | 42.5         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2161         |\n",
      "|    time_elapsed         | 41964        |\n",
      "|    total_timesteps      | 4425728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005787808 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 26490        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 1.9540019    |\n",
      "|    std                  | 42.5         |\n",
      "|    value_loss           | 47.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2162         |\n",
      "|    time_elapsed         | 41983        |\n",
      "|    total_timesteps      | 4427776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031401874 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.35         |\n",
      "|    n_updates            | 26500        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | 0.7685442    |\n",
      "|    std                  | 42.6         |\n",
      "|    value_loss           | 14.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3764119.51\n",
      "total_reward: 2764119.51\n",
      "total_cost: 367190.54\n",
      "total_trades: 71233\n",
      "Sharpe: 0.749\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2163         |\n",
      "|    time_elapsed         | 42002        |\n",
      "|    total_timesteps      | 4429824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024621445 |\n",
      "|    clip_fraction        | 0.00928      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.77         |\n",
      "|    n_updates            | 26510        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | -0.079720564 |\n",
      "|    std                  | 42.7         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2164         |\n",
      "|    time_elapsed         | 42021        |\n",
      "|    total_timesteps      | 4431872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012450719 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 26520        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 4.5564632    |\n",
      "|    std                  | 42.7         |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2165        |\n",
      "|    time_elapsed         | 42041       |\n",
      "|    total_timesteps      | 4433920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002846293 |\n",
      "|    clip_fraction        | 0.00386     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 26530       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | 1.2346159   |\n",
      "|    std                  | 42.9        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2166        |\n",
      "|    time_elapsed         | 42060       |\n",
      "|    total_timesteps      | 4435968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004719238 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 26540       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | 1.0941843   |\n",
      "|    std                  | 42.9        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2167         |\n",
      "|    time_elapsed         | 42079        |\n",
      "|    total_timesteps      | 4438016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012103078 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 26550        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | 0.41760054   |\n",
      "|    std                  | 42.8         |\n",
      "|    value_loss           | 44.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2168         |\n",
      "|    time_elapsed         | 42098        |\n",
      "|    total_timesteps      | 4440064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012548678 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 26560        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 1.5501322    |\n",
      "|    std                  | 42.9         |\n",
      "|    value_loss           | 44.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2169         |\n",
      "|    time_elapsed         | 42117        |\n",
      "|    total_timesteps      | 4442112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031904005 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.03         |\n",
      "|    n_updates            | 26570        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | 0.080658175  |\n",
      "|    std                  | 43           |\n",
      "|    value_loss           | 10.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2170         |\n",
      "|    time_elapsed         | 42136        |\n",
      "|    total_timesteps      | 4444160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011491898 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 26580        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | -0.2331122   |\n",
      "|    std                  | 43.1         |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2171          |\n",
      "|    time_elapsed         | 42156         |\n",
      "|    total_timesteps      | 4446208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060976564 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.727         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.5          |\n",
      "|    n_updates            | 26590         |\n",
      "|    policy_gradient_loss | -0.0026       |\n",
      "|    reward               | -2.5982683    |\n",
      "|    std                  | 43.1          |\n",
      "|    value_loss           | 37.4          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2172         |\n",
      "|    time_elapsed         | 42175        |\n",
      "|    total_timesteps      | 4448256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032110424 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.66         |\n",
      "|    n_updates            | 26600        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | 0.14810877   |\n",
      "|    std                  | 43.2         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2173         |\n",
      "|    time_elapsed         | 42194        |\n",
      "|    total_timesteps      | 4450304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036048274 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 26610        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 1.9285393    |\n",
      "|    std                  | 43.2         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2174         |\n",
      "|    time_elapsed         | 42213        |\n",
      "|    total_timesteps      | 4452352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007825779 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 26620        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    reward               | 0.035909045  |\n",
      "|    std                  | 43.3         |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2175         |\n",
      "|    time_elapsed         | 42233        |\n",
      "|    total_timesteps      | 4454400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006787083 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 26630        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    reward               | -1.0554667   |\n",
      "|    std                  | 43.3         |\n",
      "|    value_loss           | 40.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2176        |\n",
      "|    time_elapsed         | 42252       |\n",
      "|    total_timesteps      | 4456448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008887864 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.42        |\n",
      "|    n_updates            | 26640       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -1.517873   |\n",
      "|    std                  | 43.4        |\n",
      "|    value_loss           | 9.29        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4035737.07\n",
      "total_reward: 3035737.07\n",
      "total_cost: 301221.23\n",
      "total_trades: 66876\n",
      "Sharpe: 0.771\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2177         |\n",
      "|    time_elapsed         | 42271        |\n",
      "|    total_timesteps      | 4458496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012501448 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 26650        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | 1.7686794    |\n",
      "|    std                  | 43.4         |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2178          |\n",
      "|    time_elapsed         | 42290         |\n",
      "|    total_timesteps      | 4460544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021546564 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.313         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.5          |\n",
      "|    n_updates            | 26660         |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    reward               | 0.96158516    |\n",
      "|    std                  | 43.4          |\n",
      "|    value_loss           | 60.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2179         |\n",
      "|    time_elapsed         | 42309        |\n",
      "|    total_timesteps      | 4462592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018234333 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.07         |\n",
      "|    n_updates            | 26670        |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | 1.1433424    |\n",
      "|    std                  | 43.4         |\n",
      "|    value_loss           | 17.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2180         |\n",
      "|    time_elapsed         | 42329        |\n",
      "|    total_timesteps      | 4464640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012073875 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 26680        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | 2.127518     |\n",
      "|    std                  | 43.5         |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2181          |\n",
      "|    time_elapsed         | 42348         |\n",
      "|    total_timesteps      | 4466688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086104043 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.678         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.5          |\n",
      "|    n_updates            | 26690         |\n",
      "|    policy_gradient_loss | -0.00241      |\n",
      "|    reward               | -1.2737443    |\n",
      "|    std                  | 43.5          |\n",
      "|    value_loss           | 44.6          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2182          |\n",
      "|    time_elapsed         | 42368         |\n",
      "|    total_timesteps      | 4468736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091875985 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.682         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20            |\n",
      "|    n_updates            | 26700         |\n",
      "|    policy_gradient_loss | -0.00212      |\n",
      "|    reward               | 1.6453174     |\n",
      "|    std                  | 43.6          |\n",
      "|    value_loss           | 34.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2183         |\n",
      "|    time_elapsed         | 42387        |\n",
      "|    total_timesteps      | 4470784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031273027 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 26710        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | -0.68550724  |\n",
      "|    std                  | 43.6         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2184         |\n",
      "|    time_elapsed         | 42407        |\n",
      "|    total_timesteps      | 4472832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009325067 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 26720        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | -0.6410823   |\n",
      "|    std                  | 43.7         |\n",
      "|    value_loss           | 52.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2185         |\n",
      "|    time_elapsed         | 42426        |\n",
      "|    total_timesteps      | 4474880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017909906 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 26730        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 2.4039938    |\n",
      "|    std                  | 43.7         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2186        |\n",
      "|    time_elapsed         | 42445       |\n",
      "|    total_timesteps      | 4476928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005620489 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.92        |\n",
      "|    n_updates            | 26740       |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | -0.7883901  |\n",
      "|    std                  | 43.8        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2187         |\n",
      "|    time_elapsed         | 42465        |\n",
      "|    total_timesteps      | 4478976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017305911 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.11         |\n",
      "|    n_updates            | 26750        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | -0.18786749  |\n",
      "|    std                  | 43.8         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2188          |\n",
      "|    time_elapsed         | 42484         |\n",
      "|    total_timesteps      | 4481024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044280727 |\n",
      "|    clip_fraction        | 0.00083       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.741         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.1          |\n",
      "|    n_updates            | 26760         |\n",
      "|    policy_gradient_loss | -0.00126      |\n",
      "|    reward               | -1.4062436    |\n",
      "|    std                  | 43.9          |\n",
      "|    value_loss           | 38.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2189         |\n",
      "|    time_elapsed         | 42503        |\n",
      "|    total_timesteps      | 4483072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00281008   |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.85         |\n",
      "|    n_updates            | 26770        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -0.093974985 |\n",
      "|    std                  | 43.9         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2190        |\n",
      "|    time_elapsed         | 42522       |\n",
      "|    total_timesteps      | 4485120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005742379 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 26780       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | -1.6460071  |\n",
      "|    std                  | 44.2        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2548869.44\n",
      "total_reward: 1548869.44\n",
      "total_cost: 369920.98\n",
      "total_trades: 69891\n",
      "Sharpe: 0.544\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2191          |\n",
      "|    time_elapsed         | 42542         |\n",
      "|    total_timesteps      | 4487168       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079864997 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.594         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.2          |\n",
      "|    n_updates            | 26790         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | -2.3284693    |\n",
      "|    std                  | 44.2          |\n",
      "|    value_loss           | 33.6          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2192         |\n",
      "|    time_elapsed         | 42561        |\n",
      "|    total_timesteps      | 4489216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014181603 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 26800        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | 1.4142858    |\n",
      "|    std                  | 44.3         |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2193        |\n",
      "|    time_elapsed         | 42580       |\n",
      "|    total_timesteps      | 4491264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005500689 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.62        |\n",
      "|    n_updates            | 26810       |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    reward               | 1.3107243   |\n",
      "|    std                  | 44.4        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2194        |\n",
      "|    time_elapsed         | 42599       |\n",
      "|    total_timesteps      | 4493312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002452541 |\n",
      "|    clip_fraction        | 0.00322     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 26820       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | 1.094855    |\n",
      "|    std                  | 44.4        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2195          |\n",
      "|    time_elapsed         | 42618         |\n",
      "|    total_timesteps      | 4495360       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028479492 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.502         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.8          |\n",
      "|    n_updates            | 26830         |\n",
      "|    policy_gradient_loss | -0.00173      |\n",
      "|    reward               | -1.7409823    |\n",
      "|    std                  | 44.5          |\n",
      "|    value_loss           | 54.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2196         |\n",
      "|    time_elapsed         | 42638        |\n",
      "|    total_timesteps      | 4497408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032014395 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.62         |\n",
      "|    n_updates            | 26840        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | 2.1851344    |\n",
      "|    std                  | 44.6         |\n",
      "|    value_loss           | 17.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2197         |\n",
      "|    time_elapsed         | 42657        |\n",
      "|    total_timesteps      | 4499456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021372023 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.93         |\n",
      "|    n_updates            | 26850        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | -2.6367414   |\n",
      "|    std                  | 44.6         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2198         |\n",
      "|    time_elapsed         | 42676        |\n",
      "|    total_timesteps      | 4501504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015072711 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 26860        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 5.560298     |\n",
      "|    std                  | 44.7         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2199         |\n",
      "|    time_elapsed         | 42696        |\n",
      "|    total_timesteps      | 4503552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018898833 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 26870        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 1.4214147    |\n",
      "|    std                  | 44.7         |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2200        |\n",
      "|    time_elapsed         | 42715       |\n",
      "|    total_timesteps      | 4505600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009067001 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 26880       |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    reward               | -2.7615955  |\n",
      "|    std                  | 44.8        |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2201        |\n",
      "|    time_elapsed         | 42734       |\n",
      "|    total_timesteps      | 4507648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002780044 |\n",
      "|    clip_fraction        | 0.00679     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 26890       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    reward               | -1.178146   |\n",
      "|    std                  | 44.9        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2202          |\n",
      "|    time_elapsed         | 42754         |\n",
      "|    total_timesteps      | 4509696       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047358347 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.62          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.6          |\n",
      "|    n_updates            | 26900         |\n",
      "|    policy_gradient_loss | -0.00211      |\n",
      "|    reward               | -3.858677     |\n",
      "|    std                  | 44.9          |\n",
      "|    value_loss           | 44.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2203         |\n",
      "|    time_elapsed         | 42773        |\n",
      "|    total_timesteps      | 4511744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028312146 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.93         |\n",
      "|    n_updates            | 26910        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    reward               | 2.471849     |\n",
      "|    std                  | 45           |\n",
      "|    value_loss           | 14.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2204        |\n",
      "|    time_elapsed         | 42793       |\n",
      "|    total_timesteps      | 4513792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001333094 |\n",
      "|    clip_fraction        | 0.00464     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 26920       |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | 0.01882102  |\n",
      "|    std                  | 45.1        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2205         |\n",
      "|    time_elapsed         | 42812        |\n",
      "|    total_timesteps      | 4515840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008789105 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 26930        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 4.109584     |\n",
      "|    std                  | 45.2         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3090961.32\n",
      "total_reward: 2090961.32\n",
      "total_cost: 333641.99\n",
      "total_trades: 68591\n",
      "Sharpe: 0.653\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2206         |\n",
      "|    time_elapsed         | 42831        |\n",
      "|    total_timesteps      | 4517888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023156449 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.42         |\n",
      "|    n_updates            | 26940        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | 1.1311007    |\n",
      "|    std                  | 45.3         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2207         |\n",
      "|    time_elapsed         | 42850        |\n",
      "|    total_timesteps      | 4519936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053438502 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 26950        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | -0.86170423  |\n",
      "|    std                  | 45.3         |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2208          |\n",
      "|    time_elapsed         | 42869         |\n",
      "|    total_timesteps      | 4521984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022481894 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.76          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.65          |\n",
      "|    n_updates            | 26960         |\n",
      "|    policy_gradient_loss | -0.00104      |\n",
      "|    reward               | 1.2750553     |\n",
      "|    std                  | 45.4          |\n",
      "|    value_loss           | 39.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2209         |\n",
      "|    time_elapsed         | 42888        |\n",
      "|    total_timesteps      | 4524032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011785986 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 26970        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | 2.7324722    |\n",
      "|    std                  | 45.5         |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2210         |\n",
      "|    time_elapsed         | 42908        |\n",
      "|    total_timesteps      | 4526080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065588905 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.63         |\n",
      "|    n_updates            | 26980        |\n",
      "|    policy_gradient_loss | -0.00867     |\n",
      "|    reward               | 1.3948141    |\n",
      "|    std                  | 45.6         |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2211         |\n",
      "|    time_elapsed         | 42927        |\n",
      "|    total_timesteps      | 4528128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025734454 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.201        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 26990        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | 0.34681433   |\n",
      "|    std                  | 45.7         |\n",
      "|    value_loss           | 54.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2212         |\n",
      "|    time_elapsed         | 42946        |\n",
      "|    total_timesteps      | 4530176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025055604 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 27000        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | 2.8644748    |\n",
      "|    std                  | 45.8         |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2213        |\n",
      "|    time_elapsed         | 42965       |\n",
      "|    total_timesteps      | 4532224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003255176 |\n",
      "|    clip_fraction        | 0.00386     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.58        |\n",
      "|    n_updates            | 27010       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | 1.8756171   |\n",
      "|    std                  | 45.9        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2214         |\n",
      "|    time_elapsed         | 42984        |\n",
      "|    total_timesteps      | 4534272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035128025 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.46         |\n",
      "|    n_updates            | 27020        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | -0.31987634  |\n",
      "|    std                  | 46.1         |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2215         |\n",
      "|    time_elapsed         | 43004        |\n",
      "|    total_timesteps      | 4536320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009803986 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 27030        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | -0.7834892   |\n",
      "|    std                  | 46.2         |\n",
      "|    value_loss           | 27.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2216         |\n",
      "|    time_elapsed         | 43023        |\n",
      "|    total_timesteps      | 4538368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010239092 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.54         |\n",
      "|    n_updates            | 27040        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | -0.3009434   |\n",
      "|    std                  | 46.2         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2217        |\n",
      "|    time_elapsed         | 43042       |\n",
      "|    total_timesteps      | 4540416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007426919 |\n",
      "|    clip_fraction        | 0.0386      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.1         |\n",
      "|    n_updates            | 27050       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 2.776617    |\n",
      "|    std                  | 46.4        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2218         |\n",
      "|    time_elapsed         | 43061        |\n",
      "|    total_timesteps      | 4542464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017168813 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.08         |\n",
      "|    n_updates            | 27060        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 0.6635663    |\n",
      "|    std                  | 46.5         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2219         |\n",
      "|    time_elapsed         | 43081        |\n",
      "|    total_timesteps      | 4544512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012661928 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 27070        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | 1.8035183    |\n",
      "|    std                  | 46.5         |\n",
      "|    value_loss           | 25.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3317401.72\n",
      "total_reward: 2317401.72\n",
      "total_cost: 365044.89\n",
      "total_trades: 70294\n",
      "Sharpe: 0.702\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2220         |\n",
      "|    time_elapsed         | 43100        |\n",
      "|    total_timesteps      | 4546560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040351646 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.13         |\n",
      "|    n_updates            | 27080        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    reward               | -0.040183794 |\n",
      "|    std                  | 46.5         |\n",
      "|    value_loss           | 13.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2221        |\n",
      "|    time_elapsed         | 43119       |\n",
      "|    total_timesteps      | 4548608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002372248 |\n",
      "|    clip_fraction        | 0.00737     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 27090       |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    reward               | 0.34861222  |\n",
      "|    std                  | 46.6        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2222         |\n",
      "|    time_elapsed         | 43138        |\n",
      "|    total_timesteps      | 4550656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006698868 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 27100        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 4.2589297    |\n",
      "|    std                  | 46.6         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2223         |\n",
      "|    time_elapsed         | 43158        |\n",
      "|    total_timesteps      | 4552704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022778967 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 27110        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 0.21364234   |\n",
      "|    std                  | 46.7         |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2224        |\n",
      "|    time_elapsed         | 43177       |\n",
      "|    total_timesteps      | 4554752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005580931 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.89        |\n",
      "|    n_updates            | 27120       |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    reward               | -3.0732594  |\n",
      "|    std                  | 46.9        |\n",
      "|    value_loss           | 9.31        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2225         |\n",
      "|    time_elapsed         | 43196        |\n",
      "|    total_timesteps      | 4556800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007179355 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 27130        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | 0.08961453   |\n",
      "|    std                  | 47           |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2226         |\n",
      "|    time_elapsed         | 43215        |\n",
      "|    total_timesteps      | 4558848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008237435 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.808        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.76         |\n",
      "|    n_updates            | 27140        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | 1.6168387    |\n",
      "|    std                  | 47.1         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2227         |\n",
      "|    time_elapsed         | 43234        |\n",
      "|    total_timesteps      | 4560896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060594752 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.14         |\n",
      "|    n_updates            | 27150        |\n",
      "|    policy_gradient_loss | -0.00928     |\n",
      "|    reward               | 2.3908985    |\n",
      "|    std                  | 47.2         |\n",
      "|    value_loss           | 12.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2228         |\n",
      "|    time_elapsed         | 43253        |\n",
      "|    total_timesteps      | 4562944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008736589 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.24         |\n",
      "|    n_updates            | 27160        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | -0.8179851   |\n",
      "|    std                  | 47.2         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2229         |\n",
      "|    time_elapsed         | 43273        |\n",
      "|    total_timesteps      | 4564992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007721573 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 27170        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | 0.7771547    |\n",
      "|    std                  | 47.3         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2230         |\n",
      "|    time_elapsed         | 43293        |\n",
      "|    total_timesteps      | 4567040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008368433 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.92         |\n",
      "|    n_updates            | 27180        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | 3.2233853    |\n",
      "|    std                  | 47.3         |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2231         |\n",
      "|    time_elapsed         | 43312        |\n",
      "|    total_timesteps      | 4569088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031910075 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.46         |\n",
      "|    n_updates            | 27190        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | 1.0458941    |\n",
      "|    std                  | 47.3         |\n",
      "|    value_loss           | 18.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2232         |\n",
      "|    time_elapsed         | 43331        |\n",
      "|    total_timesteps      | 4571136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005653334 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 27200        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | -1.0840558   |\n",
      "|    std                  | 47.4         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2233         |\n",
      "|    time_elapsed         | 43350        |\n",
      "|    total_timesteps      | 4573184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005653446 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.44         |\n",
      "|    n_updates            | 27210        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    reward               | 2.7484882    |\n",
      "|    std                  | 47.4         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2963666.12\n",
      "total_reward: 1963666.12\n",
      "total_cost: 420559.83\n",
      "total_trades: 73807\n",
      "Sharpe: 0.625\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2234         |\n",
      "|    time_elapsed         | 43369        |\n",
      "|    total_timesteps      | 4575232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004305199  |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.16         |\n",
      "|    n_updates            | 27220        |\n",
      "|    policy_gradient_loss | -0.00845     |\n",
      "|    reward               | 0.0059977635 |\n",
      "|    std                  | 47.5         |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2235         |\n",
      "|    time_elapsed         | 43389        |\n",
      "|    total_timesteps      | 4577280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013812165 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 27230        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | -2.5853078   |\n",
      "|    std                  | 47.5         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2236         |\n",
      "|    time_elapsed         | 43408        |\n",
      "|    total_timesteps      | 4579328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006887703 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 27240        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | -5.967733    |\n",
      "|    std                  | 47.5         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2237         |\n",
      "|    time_elapsed         | 43428        |\n",
      "|    total_timesteps      | 4581376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017508873 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.79         |\n",
      "|    n_updates            | 27250        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | -0.26621878  |\n",
      "|    std                  | 47.6         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2238         |\n",
      "|    time_elapsed         | 43447        |\n",
      "|    total_timesteps      | 4583424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018019513 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 27260        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    reward               | 0.12281464   |\n",
      "|    std                  | 47.7         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2239         |\n",
      "|    time_elapsed         | 43466        |\n",
      "|    total_timesteps      | 4585472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017805472 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 27270        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | 1.3590641    |\n",
      "|    std                  | 47.8         |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2240          |\n",
      "|    time_elapsed         | 43485         |\n",
      "|    total_timesteps      | 4587520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025800389 |\n",
      "|    clip_fraction        | 0.00137       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.257         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32            |\n",
      "|    n_updates            | 27280         |\n",
      "|    policy_gradient_loss | -0.000684     |\n",
      "|    reward               | -0.4231439    |\n",
      "|    std                  | 47.8          |\n",
      "|    value_loss           | 80.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2241         |\n",
      "|    time_elapsed         | 43505        |\n",
      "|    total_timesteps      | 4589568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031047568 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.65         |\n",
      "|    n_updates            | 27290        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | -0.18650301  |\n",
      "|    std                  | 48           |\n",
      "|    value_loss           | 10.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2242        |\n",
      "|    time_elapsed         | 43524       |\n",
      "|    total_timesteps      | 4591616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001294265 |\n",
      "|    clip_fraction        | 0.000879    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -152        |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.89        |\n",
      "|    n_updates            | 27300       |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    reward               | 0.43218926  |\n",
      "|    std                  | 48.1        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2243         |\n",
      "|    time_elapsed         | 43543        |\n",
      "|    total_timesteps      | 4593664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010886872 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 27310        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | -1.9820707   |\n",
      "|    std                  | 48.1         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2244         |\n",
      "|    time_elapsed         | 43563        |\n",
      "|    total_timesteps      | 4595712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032059879 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.32         |\n",
      "|    n_updates            | 27320        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    reward               | -0.7319776   |\n",
      "|    std                  | 48.2         |\n",
      "|    value_loss           | 15.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2245         |\n",
      "|    time_elapsed         | 43582        |\n",
      "|    total_timesteps      | 4597760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020475923 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.75         |\n",
      "|    n_updates            | 27330        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | -0.69211876  |\n",
      "|    std                  | 48.4         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2246        |\n",
      "|    time_elapsed         | 43602       |\n",
      "|    total_timesteps      | 4599808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000377312 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -152        |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 27340       |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    reward               | 8.985247    |\n",
      "|    std                  | 48.4        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2247         |\n",
      "|    time_elapsed         | 43621        |\n",
      "|    total_timesteps      | 4601856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011470618 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.54         |\n",
      "|    n_updates            | 27350        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | -0.045243997 |\n",
      "|    std                  | 48.4         |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3206748.04\n",
      "total_reward: 2206748.04\n",
      "total_cost: 404036.89\n",
      "total_trades: 72105\n",
      "Sharpe: 0.701\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2248          |\n",
      "|    time_elapsed         | 43640         |\n",
      "|    total_timesteps      | 4603904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0051596756  |\n",
      "|    clip_fraction        | 0.0156        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.587         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.37          |\n",
      "|    n_updates            | 27360         |\n",
      "|    policy_gradient_loss | -0.00633      |\n",
      "|    reward               | -0.0084158415 |\n",
      "|    std                  | 48.6          |\n",
      "|    value_loss           | 10.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2249         |\n",
      "|    time_elapsed         | 43659        |\n",
      "|    total_timesteps      | 4605952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017671247 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 27370        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | -0.052193422 |\n",
      "|    std                  | 48.6         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2250          |\n",
      "|    time_elapsed         | 43678         |\n",
      "|    total_timesteps      | 4608000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083442463 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.565         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.8          |\n",
      "|    n_updates            | 27380         |\n",
      "|    policy_gradient_loss | -0.00159      |\n",
      "|    reward               | 2.7697785     |\n",
      "|    std                  | 48.7          |\n",
      "|    value_loss           | 44.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2251         |\n",
      "|    time_elapsed         | 43697        |\n",
      "|    total_timesteps      | 4610048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036124564 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.41         |\n",
      "|    n_updates            | 27390        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | -1.6180242   |\n",
      "|    std                  | 48.9         |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2252         |\n",
      "|    time_elapsed         | 43716        |\n",
      "|    total_timesteps      | 4612096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009461454 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 27400        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | -6.9769154   |\n",
      "|    std                  | 49           |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2253          |\n",
      "|    time_elapsed         | 43735         |\n",
      "|    total_timesteps      | 4614144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090639316 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.688         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.2          |\n",
      "|    n_updates            | 27410         |\n",
      "|    policy_gradient_loss | -0.00235      |\n",
      "|    reward               | -1.2162727    |\n",
      "|    std                  | 49            |\n",
      "|    value_loss           | 35.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2254         |\n",
      "|    time_elapsed         | 43755        |\n",
      "|    total_timesteps      | 4616192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010393136 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.85         |\n",
      "|    n_updates            | 27420        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    reward               | -0.012684404 |\n",
      "|    std                  | 49           |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2255         |\n",
      "|    time_elapsed         | 43775        |\n",
      "|    total_timesteps      | 4618240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048128907 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.63         |\n",
      "|    n_updates            | 27430        |\n",
      "|    policy_gradient_loss | -0.00748     |\n",
      "|    reward               | 0.79376376   |\n",
      "|    std                  | 49.3         |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2256         |\n",
      "|    time_elapsed         | 43794        |\n",
      "|    total_timesteps      | 4620288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027073643 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.144        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.9         |\n",
      "|    n_updates            | 27440        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | -1.8024218   |\n",
      "|    std                  | 49.4         |\n",
      "|    value_loss           | 64.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2257         |\n",
      "|    time_elapsed         | 43813        |\n",
      "|    total_timesteps      | 4622336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003517394 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 27450        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    reward               | 0.33806154   |\n",
      "|    std                  | 49.4         |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2258         |\n",
      "|    time_elapsed         | 43833        |\n",
      "|    total_timesteps      | 4624384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043727783 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.408        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.59         |\n",
      "|    n_updates            | 27460        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    reward               | 1.2173605    |\n",
      "|    std                  | 49.4         |\n",
      "|    value_loss           | 10.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2259         |\n",
      "|    time_elapsed         | 43852        |\n",
      "|    total_timesteps      | 4626432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025596586 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.29         |\n",
      "|    n_updates            | 27470        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    reward               | 0.26855645   |\n",
      "|    std                  | 49.6         |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2260         |\n",
      "|    time_elapsed         | 43871        |\n",
      "|    total_timesteps      | 4628480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009639707 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 27480        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | 0.17555124   |\n",
      "|    std                  | 49.6         |\n",
      "|    value_loss           | 41.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2261         |\n",
      "|    time_elapsed         | 43890        |\n",
      "|    total_timesteps      | 4630528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019855388 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.142        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 27490        |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | -3.7057774   |\n",
      "|    std                  | 49.7         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3473394.88\n",
      "total_reward: 2473394.88\n",
      "total_cost: 459950.59\n",
      "total_trades: 75633\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2262         |\n",
      "|    time_elapsed         | 43909        |\n",
      "|    total_timesteps      | 4632576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023832382 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.5         |\n",
      "|    n_updates            | 27500        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | -0.06910513  |\n",
      "|    std                  | 49.8         |\n",
      "|    value_loss           | 55.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2263         |\n",
      "|    time_elapsed         | 43928        |\n",
      "|    total_timesteps      | 4634624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010068172 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 27510        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | -0.22538695  |\n",
      "|    std                  | 49.9         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2264         |\n",
      "|    time_elapsed         | 43947        |\n",
      "|    total_timesteps      | 4636672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014150813 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34           |\n",
      "|    n_updates            | 27520        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | -1.2629613   |\n",
      "|    std                  | 49.9         |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2265         |\n",
      "|    time_elapsed         | 43967        |\n",
      "|    total_timesteps      | 4638720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069603003 |\n",
      "|    clip_fraction        | 0.0448       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.236        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.1          |\n",
      "|    n_updates            | 27530        |\n",
      "|    policy_gradient_loss | -0.00983     |\n",
      "|    reward               | 2.8677642    |\n",
      "|    std                  | 50.1         |\n",
      "|    value_loss           | 15.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2266          |\n",
      "|    time_elapsed         | 43986         |\n",
      "|    total_timesteps      | 4640768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044524827 |\n",
      "|    clip_fraction        | 0.00273       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.329         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.1          |\n",
      "|    n_updates            | 27540         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    reward               | -0.20673      |\n",
      "|    std                  | 50.2          |\n",
      "|    value_loss           | 55.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2267         |\n",
      "|    time_elapsed         | 44005        |\n",
      "|    total_timesteps      | 4642816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010097321 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.8         |\n",
      "|    n_updates            | 27550        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | 1.8835042    |\n",
      "|    std                  | 50.2         |\n",
      "|    value_loss           | 66.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2268         |\n",
      "|    time_elapsed         | 44025        |\n",
      "|    total_timesteps      | 4644864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040475996 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.49         |\n",
      "|    n_updates            | 27560        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | 0.24373291   |\n",
      "|    std                  | 50.3         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2269         |\n",
      "|    time_elapsed         | 44044        |\n",
      "|    total_timesteps      | 4646912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012338653 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 27570        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | 1.7286288    |\n",
      "|    std                  | 50.4         |\n",
      "|    value_loss           | 58           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2270          |\n",
      "|    time_elapsed         | 44063         |\n",
      "|    total_timesteps      | 4648960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067512284 |\n",
      "|    clip_fraction        | 0.000684      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.331         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 39.6          |\n",
      "|    n_updates            | 27580         |\n",
      "|    policy_gradient_loss | -0.00145      |\n",
      "|    reward               | -8.0223875    |\n",
      "|    std                  | 50.4          |\n",
      "|    value_loss           | 97.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2271          |\n",
      "|    time_elapsed         | 44082         |\n",
      "|    total_timesteps      | 4651008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038129822 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.56          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.2          |\n",
      "|    n_updates            | 27590         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | -4.2983627    |\n",
      "|    std                  | 50.4          |\n",
      "|    value_loss           | 49.2          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2272         |\n",
      "|    time_elapsed         | 44102        |\n",
      "|    total_timesteps      | 4653056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021514087 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 27600        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | -2.303152    |\n",
      "|    std                  | 50.5         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2273         |\n",
      "|    time_elapsed         | 44122        |\n",
      "|    total_timesteps      | 4655104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012861814 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 27610        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | 0.16751458   |\n",
      "|    std                  | 50.5         |\n",
      "|    value_loss           | 56.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2274          |\n",
      "|    time_elapsed         | 44141         |\n",
      "|    total_timesteps      | 4657152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060587726 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.363         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.8          |\n",
      "|    n_updates            | 27620         |\n",
      "|    policy_gradient_loss | -0.00189      |\n",
      "|    reward               | -0.91458404   |\n",
      "|    std                  | 50.6          |\n",
      "|    value_loss           | 79.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2275         |\n",
      "|    time_elapsed         | 44161        |\n",
      "|    total_timesteps      | 4659200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042525916 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | -0.0783      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.24         |\n",
      "|    n_updates            | 27630        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | 0.496781     |\n",
      "|    std                  | 50.8         |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3601276.19\n",
      "total_reward: 2601276.19\n",
      "total_cost: 526339.75\n",
      "total_trades: 77900\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2276         |\n",
      "|    time_elapsed         | 44180        |\n",
      "|    total_timesteps      | 4661248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022665532 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.00997      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 27640        |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    reward               | 1.2261914    |\n",
      "|    std                  | 50.9         |\n",
      "|    value_loss           | 95.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2277          |\n",
      "|    time_elapsed         | 44200         |\n",
      "|    total_timesteps      | 4663296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085073744 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.601         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.1          |\n",
      "|    n_updates            | 27650         |\n",
      "|    policy_gradient_loss | -0.0015       |\n",
      "|    reward               | 4.911883      |\n",
      "|    std                  | 51            |\n",
      "|    value_loss           | 78.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2278        |\n",
      "|    time_elapsed         | 44219       |\n",
      "|    total_timesteps      | 4665344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004739253 |\n",
      "|    clip_fraction        | 0.0145      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 27660       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | 0.09543779  |\n",
      "|    std                  | 51.1        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2279         |\n",
      "|    time_elapsed         | 44239        |\n",
      "|    total_timesteps      | 4667392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027082367 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.7         |\n",
      "|    n_updates            | 27670        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    reward               | 1.5020794    |\n",
      "|    std                  | 51.3         |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2280          |\n",
      "|    time_elapsed         | 44258         |\n",
      "|    total_timesteps      | 4669440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060498517 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.366         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 33            |\n",
      "|    n_updates            | 27680         |\n",
      "|    policy_gradient_loss | -0.00195      |\n",
      "|    reward               | 0.1634299     |\n",
      "|    std                  | 51.3          |\n",
      "|    value_loss           | 85.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2281         |\n",
      "|    time_elapsed         | 44278        |\n",
      "|    total_timesteps      | 4671488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009220708 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.9         |\n",
      "|    n_updates            | 27690        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | -0.7940902   |\n",
      "|    std                  | 51.4         |\n",
      "|    value_loss           | 68.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2282         |\n",
      "|    time_elapsed         | 44297        |\n",
      "|    total_timesteps      | 4673536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063567283 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.193        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.64         |\n",
      "|    n_updates            | 27700        |\n",
      "|    policy_gradient_loss | -0.00892     |\n",
      "|    reward               | 0.3663111    |\n",
      "|    std                  | 51.6         |\n",
      "|    value_loss           | 13.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2283          |\n",
      "|    time_elapsed         | 44316         |\n",
      "|    total_timesteps      | 4675584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081358175 |\n",
      "|    clip_fraction        | 0.00317       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.495         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25            |\n",
      "|    n_updates            | 27710         |\n",
      "|    policy_gradient_loss | -0.00187      |\n",
      "|    reward               | 1.117619      |\n",
      "|    std                  | 51.7          |\n",
      "|    value_loss           | 61.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2284         |\n",
      "|    time_elapsed         | 44336        |\n",
      "|    total_timesteps      | 4677632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005202248 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.1         |\n",
      "|    n_updates            | 27720        |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | 2.8833907    |\n",
      "|    std                  | 51.8         |\n",
      "|    value_loss           | 68.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2285         |\n",
      "|    time_elapsed         | 44355        |\n",
      "|    total_timesteps      | 4679680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017451812 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.15         |\n",
      "|    n_updates            | 27730        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | 2.5339146    |\n",
      "|    std                  | 51.8         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2286         |\n",
      "|    time_elapsed         | 44375        |\n",
      "|    total_timesteps      | 4681728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018430836 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 27740        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 0.0008382233 |\n",
      "|    std                  | 51.9         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2287          |\n",
      "|    time_elapsed         | 44394         |\n",
      "|    total_timesteps      | 4683776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082857476 |\n",
      "|    clip_fraction        | 0.0019        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.521         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.2          |\n",
      "|    n_updates            | 27750         |\n",
      "|    policy_gradient_loss | -0.00224      |\n",
      "|    reward               | -0.05774592   |\n",
      "|    std                  | 51.9          |\n",
      "|    value_loss           | 50.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2288         |\n",
      "|    time_elapsed         | 44413        |\n",
      "|    total_timesteps      | 4685824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016498041 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 27760        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | 0.08930543   |\n",
      "|    std                  | 52           |\n",
      "|    value_loss           | 65.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2289         |\n",
      "|    time_elapsed         | 44433        |\n",
      "|    total_timesteps      | 4687872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078957975 |\n",
      "|    clip_fraction        | 0.058        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | -0.0355      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.58         |\n",
      "|    n_updates            | 27770        |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    reward               | 0.43711752   |\n",
      "|    std                  | 52.1         |\n",
      "|    value_loss           | 16.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3925117.64\n",
      "total_reward: 2925117.64\n",
      "total_cost: 504532.58\n",
      "total_trades: 76991\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2290          |\n",
      "|    time_elapsed         | 44452         |\n",
      "|    total_timesteps      | 4689920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039120848 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.194         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.5          |\n",
      "|    n_updates            | 27780         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | -0.103866905  |\n",
      "|    std                  | 52.2          |\n",
      "|    value_loss           | 82.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2291         |\n",
      "|    time_elapsed         | 44472        |\n",
      "|    total_timesteps      | 4691968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010134957 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 27790        |\n",
      "|    policy_gradient_loss | -0.000967    |\n",
      "|    reward               | 3.640562     |\n",
      "|    std                  | 52.2         |\n",
      "|    value_loss           | 67.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2292         |\n",
      "|    time_elapsed         | 44491        |\n",
      "|    total_timesteps      | 4694016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031199888 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 27800        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -1.5165535   |\n",
      "|    std                  | 52.3         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2293        |\n",
      "|    time_elapsed         | 44511       |\n",
      "|    total_timesteps      | 4696064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001678458 |\n",
      "|    clip_fraction        | 0.00234     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 27810       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | -2.6114216  |\n",
      "|    std                  | 52.4        |\n",
      "|    value_loss           | 62.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2294         |\n",
      "|    time_elapsed         | 44530        |\n",
      "|    total_timesteps      | 4698112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012000386 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 27820        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 3.50088      |\n",
      "|    std                  | 52.5         |\n",
      "|    value_loss           | 56.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2295         |\n",
      "|    time_elapsed         | 44549        |\n",
      "|    total_timesteps      | 4700160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016299766 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 27830        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | -0.6234827   |\n",
      "|    std                  | 52.5         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2296         |\n",
      "|    time_elapsed         | 44568        |\n",
      "|    total_timesteps      | 4702208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050852816 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.36         |\n",
      "|    n_updates            | 27840        |\n",
      "|    policy_gradient_loss | -0.00873     |\n",
      "|    reward               | -0.7727439   |\n",
      "|    std                  | 52.7         |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2297         |\n",
      "|    time_elapsed         | 44588        |\n",
      "|    total_timesteps      | 4704256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011093167 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.359        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 27850        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 0.22983783   |\n",
      "|    std                  | 52.8         |\n",
      "|    value_loss           | 59.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2298         |\n",
      "|    time_elapsed         | 44607        |\n",
      "|    total_timesteps      | 4706304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014509897 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 27860        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | -1.623266    |\n",
      "|    std                  | 52.9         |\n",
      "|    value_loss           | 55.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2299         |\n",
      "|    time_elapsed         | 44627        |\n",
      "|    total_timesteps      | 4708352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056357267 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.68         |\n",
      "|    n_updates            | 27870        |\n",
      "|    policy_gradient_loss | -0.0081      |\n",
      "|    reward               | 2.2915676    |\n",
      "|    std                  | 53.1         |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2300         |\n",
      "|    time_elapsed         | 44646        |\n",
      "|    total_timesteps      | 4710400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016924539 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.0986       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 27880        |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    reward               | -0.5721315   |\n",
      "|    std                  | 53.2         |\n",
      "|    value_loss           | 75.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2301          |\n",
      "|    time_elapsed         | 44665         |\n",
      "|    total_timesteps      | 4712448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022148172 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.636         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.4          |\n",
      "|    n_updates            | 27890         |\n",
      "|    policy_gradient_loss | -0.000799     |\n",
      "|    reward               | -1.6597747    |\n",
      "|    std                  | 53.3          |\n",
      "|    value_loss           | 64.9          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2302        |\n",
      "|    time_elapsed         | 44685       |\n",
      "|    total_timesteps      | 4714496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001994954 |\n",
      "|    clip_fraction        | 0.00615     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.07        |\n",
      "|    n_updates            | 27900       |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    reward               | -1.3194056  |\n",
      "|    std                  | 53.3        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2303        |\n",
      "|    time_elapsed         | 44704       |\n",
      "|    total_timesteps      | 4716544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004913116 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.66        |\n",
      "|    n_updates            | 27910       |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    reward               | 1.533269    |\n",
      "|    std                  | 53.3        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3751461.09\n",
      "total_reward: 2751461.09\n",
      "total_cost: 500665.55\n",
      "total_trades: 76779\n",
      "Sharpe: 0.722\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2304         |\n",
      "|    time_elapsed         | 44723        |\n",
      "|    total_timesteps      | 4718592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018499612 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.137        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39           |\n",
      "|    n_updates            | 27920        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | -0.37022388  |\n",
      "|    std                  | 53.4         |\n",
      "|    value_loss           | 86.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2305         |\n",
      "|    time_elapsed         | 44742        |\n",
      "|    total_timesteps      | 4720640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009396301 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 27930        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | 0.88313794   |\n",
      "|    std                  | 53.5         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2306        |\n",
      "|    time_elapsed         | 44761       |\n",
      "|    total_timesteps      | 4722688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007385508 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.07        |\n",
      "|    n_updates            | 27940       |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    reward               | -0.7474547  |\n",
      "|    std                  | 53.8        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2307         |\n",
      "|    time_elapsed         | 44780        |\n",
      "|    total_timesteps      | 4724736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012428261 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 27950        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | -0.4612905   |\n",
      "|    std                  | 54           |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2308          |\n",
      "|    time_elapsed         | 44800         |\n",
      "|    total_timesteps      | 4726784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040245612 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.555         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.5          |\n",
      "|    n_updates            | 27960         |\n",
      "|    policy_gradient_loss | -0.00119      |\n",
      "|    reward               | 4.464825      |\n",
      "|    std                  | 54            |\n",
      "|    value_loss           | 57.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2309         |\n",
      "|    time_elapsed         | 44820        |\n",
      "|    total_timesteps      | 4728832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016407615 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 27970        |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    reward               | -4.9384494   |\n",
      "|    std                  | 54.1         |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2310         |\n",
      "|    time_elapsed         | 44839        |\n",
      "|    total_timesteps      | 4730880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013179611 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 27980        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 0.62845373   |\n",
      "|    std                  | 54.1         |\n",
      "|    value_loss           | 75.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2311          |\n",
      "|    time_elapsed         | 44859         |\n",
      "|    total_timesteps      | 4732928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058337767 |\n",
      "|    clip_fraction        | 0.00107       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.493         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43.9          |\n",
      "|    n_updates            | 27990         |\n",
      "|    policy_gradient_loss | -0.00221      |\n",
      "|    reward               | 4.1319823     |\n",
      "|    std                  | 54.1          |\n",
      "|    value_loss           | 55.6          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2312         |\n",
      "|    time_elapsed         | 44878        |\n",
      "|    total_timesteps      | 4734976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003249647 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 28000        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | 1.1433364    |\n",
      "|    std                  | 54.2         |\n",
      "|    value_loss           | 56.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2313         |\n",
      "|    time_elapsed         | 44897        |\n",
      "|    total_timesteps      | 4737024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064095454 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.39         |\n",
      "|    n_updates            | 28010        |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    reward               | 1.0730867    |\n",
      "|    std                  | 54.3         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2314         |\n",
      "|    time_elapsed         | 44916        |\n",
      "|    total_timesteps      | 4739072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015865171 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.2         |\n",
      "|    n_updates            | 28020        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | -1.0449488   |\n",
      "|    std                  | 54.3         |\n",
      "|    value_loss           | 84.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2315          |\n",
      "|    time_elapsed         | 44936         |\n",
      "|    total_timesteps      | 4741120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070725556 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.422         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.3          |\n",
      "|    n_updates            | 28030         |\n",
      "|    policy_gradient_loss | -0.00304      |\n",
      "|    reward               | 1.2376182     |\n",
      "|    std                  | 54.3          |\n",
      "|    value_loss           | 53.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2316        |\n",
      "|    time_elapsed         | 44955       |\n",
      "|    total_timesteps      | 4743168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005747958 |\n",
      "|    clip_fraction        | 0.022       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.8         |\n",
      "|    n_updates            | 28040       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | 1.1194222   |\n",
      "|    std                  | 54.5        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2317         |\n",
      "|    time_elapsed         | 44974        |\n",
      "|    total_timesteps      | 4745216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012094765 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 28050        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | 1.8122066    |\n",
      "|    std                  | 54.6         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2318         |\n",
      "|    time_elapsed         | 44993        |\n",
      "|    total_timesteps      | 4747264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006810501 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 28060        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 1.27892      |\n",
      "|    std                  | 54.6         |\n",
      "|    value_loss           | 47.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3511557.52\n",
      "total_reward: 2511557.52\n",
      "total_cost: 517680.96\n",
      "total_trades: 77729\n",
      "Sharpe: 0.708\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2319         |\n",
      "|    time_elapsed         | 45013        |\n",
      "|    total_timesteps      | 4749312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021466028 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.83         |\n",
      "|    n_updates            | 28070        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | 2.1208463    |\n",
      "|    std                  | 54.8         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2320         |\n",
      "|    time_elapsed         | 45032        |\n",
      "|    total_timesteps      | 4751360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025676328 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 28080        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 0.15253772   |\n",
      "|    std                  | 54.8         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2321         |\n",
      "|    time_elapsed         | 45051        |\n",
      "|    total_timesteps      | 4753408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027530044 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.7         |\n",
      "|    n_updates            | 28090        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | -2.577602    |\n",
      "|    std                  | 54.9         |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2322         |\n",
      "|    time_elapsed         | 45070        |\n",
      "|    total_timesteps      | 4755456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006978448 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.8         |\n",
      "|    n_updates            | 28100        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | -1.2769817   |\n",
      "|    std                  | 54.9         |\n",
      "|    value_loss           | 96.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2323         |\n",
      "|    time_elapsed         | 45090        |\n",
      "|    total_timesteps      | 4757504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032036568 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.88         |\n",
      "|    n_updates            | 28110        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    reward               | 1.2801027    |\n",
      "|    std                  | 54.9         |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2324        |\n",
      "|    time_elapsed         | 45109       |\n",
      "|    total_timesteps      | 4759552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002261904 |\n",
      "|    clip_fraction        | 0.00273     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -156        |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 28120       |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    reward               | 0.37538907  |\n",
      "|    std                  | 54.9        |\n",
      "|    value_loss           | 76.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2325         |\n",
      "|    time_elapsed         | 45128        |\n",
      "|    total_timesteps      | 4761600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025309543 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.1         |\n",
      "|    n_updates            | 28130        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | 1.128166     |\n",
      "|    std                  | 55.1         |\n",
      "|    value_loss           | 94           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2326         |\n",
      "|    time_elapsed         | 45148        |\n",
      "|    total_timesteps      | 4763648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021579575 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 28140        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 4.6400642    |\n",
      "|    std                  | 55.3         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2327         |\n",
      "|    time_elapsed         | 45167        |\n",
      "|    total_timesteps      | 4765696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030619577 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 28150        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -0.3528827   |\n",
      "|    std                  | 55.3         |\n",
      "|    value_loss           | 73.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2328         |\n",
      "|    time_elapsed         | 45185        |\n",
      "|    total_timesteps      | 4767744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019210164 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32           |\n",
      "|    n_updates            | 28160        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | 1.0843215    |\n",
      "|    std                  | 55.4         |\n",
      "|    value_loss           | 60.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2329          |\n",
      "|    time_elapsed         | 45205         |\n",
      "|    total_timesteps      | 4769792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039260724 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.505         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15            |\n",
      "|    n_updates            | 28170         |\n",
      "|    policy_gradient_loss | -0.00174      |\n",
      "|    reward               | 0.6223454     |\n",
      "|    std                  | 55.4          |\n",
      "|    value_loss           | 68            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2330         |\n",
      "|    time_elapsed         | 45225        |\n",
      "|    total_timesteps      | 4771840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054699546 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.63         |\n",
      "|    n_updates            | 28180        |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    reward               | 1.521092     |\n",
      "|    std                  | 55.6         |\n",
      "|    value_loss           | 14           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2331         |\n",
      "|    time_elapsed         | 45244        |\n",
      "|    total_timesteps      | 4773888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037048906 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.153        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.5         |\n",
      "|    n_updates            | 28190        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    reward               | -0.72220135  |\n",
      "|    std                  | 55.7         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2332          |\n",
      "|    time_elapsed         | 45263         |\n",
      "|    total_timesteps      | 4775936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085049716 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.478         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.1          |\n",
      "|    n_updates            | 28200         |\n",
      "|    policy_gradient_loss | -0.00301      |\n",
      "|    reward               | 4.465859      |\n",
      "|    std                  | 55.8          |\n",
      "|    value_loss           | 47.8          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2949197.76\n",
      "total_reward: 1949197.76\n",
      "total_cost: 459641.45\n",
      "total_trades: 75636\n",
      "Sharpe: 0.633\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2333        |\n",
      "|    time_elapsed         | 45282       |\n",
      "|    total_timesteps      | 4777984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003634661 |\n",
      "|    clip_fraction        | 0.0063      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -156        |\n",
      "|    explained_variance   | 0.0581      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.55        |\n",
      "|    n_updates            | 28210       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | 2.5666301   |\n",
      "|    std                  | 56          |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2334         |\n",
      "|    time_elapsed         | 45302        |\n",
      "|    total_timesteps      | 4780032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020244997 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 28220        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | 0.73893446   |\n",
      "|    std                  | 56           |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2335         |\n",
      "|    time_elapsed         | 45321        |\n",
      "|    total_timesteps      | 4782080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032787414 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.123        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.2         |\n",
      "|    n_updates            | 28230        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | 5.515923     |\n",
      "|    std                  | 56.1         |\n",
      "|    value_loss           | 87           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2336         |\n",
      "|    time_elapsed         | 45340        |\n",
      "|    total_timesteps      | 4784128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030625458 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 28240        |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    reward               | 1.5633206    |\n",
      "|    std                  | 56.3         |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2337         |\n",
      "|    time_elapsed         | 45359        |\n",
      "|    total_timesteps      | 4786176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046049547 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.45         |\n",
      "|    n_updates            | 28250        |\n",
      "|    policy_gradient_loss | -0.00718     |\n",
      "|    reward               | -0.47669455  |\n",
      "|    std                  | 56.5         |\n",
      "|    value_loss           | 13.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2338         |\n",
      "|    time_elapsed         | 45379        |\n",
      "|    total_timesteps      | 4788224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016722798 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.0433       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.7         |\n",
      "|    n_updates            | 28260        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    reward               | 0.15342893   |\n",
      "|    std                  | 56.7         |\n",
      "|    value_loss           | 61.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2339        |\n",
      "|    time_elapsed         | 45398       |\n",
      "|    total_timesteps      | 4790272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001181957 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 28270       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | -1.664797   |\n",
      "|    std                  | 56.8        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2340        |\n",
      "|    time_elapsed         | 45417       |\n",
      "|    total_timesteps      | 4792320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004639185 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 28280       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -1.3955137  |\n",
      "|    std                  | 57          |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2341         |\n",
      "|    time_elapsed         | 45438        |\n",
      "|    total_timesteps      | 4794368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009250567 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 28290        |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | -2.0624747   |\n",
      "|    std                  | 57.1         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2342        |\n",
      "|    time_elapsed         | 45457       |\n",
      "|    total_timesteps      | 4796416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001316371 |\n",
      "|    clip_fraction        | 0.00415     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 28300       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | -2.0087035  |\n",
      "|    std                  | 57.1        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2343         |\n",
      "|    time_elapsed         | 45476        |\n",
      "|    total_timesteps      | 4798464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013713699 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.196        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 28310        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 0.4773259    |\n",
      "|    std                  | 57.1         |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2344        |\n",
      "|    time_elapsed         | 45495       |\n",
      "|    total_timesteps      | 4800512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002804587 |\n",
      "|    clip_fraction        | 0.00684     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.0317      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.7        |\n",
      "|    n_updates            | 28320       |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | -0.40030587 |\n",
      "|    std                  | 57.2        |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2345         |\n",
      "|    time_elapsed         | 45514        |\n",
      "|    total_timesteps      | 4802560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011185901 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 28330        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -0.8971502   |\n",
      "|    std                  | 57.3         |\n",
      "|    value_loss           | 46.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2346        |\n",
      "|    time_elapsed         | 45534       |\n",
      "|    total_timesteps      | 4804608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000969892 |\n",
      "|    clip_fraction        | 0.00366     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 28340       |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    reward               | 0.21847372  |\n",
      "|    std                  | 57.4        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3934140.45\n",
      "total_reward: 2934140.45\n",
      "total_cost: 523942.19\n",
      "total_trades: 78158\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2347         |\n",
      "|    time_elapsed         | 45553        |\n",
      "|    total_timesteps      | 4806656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070175766 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.89         |\n",
      "|    n_updates            | 28350        |\n",
      "|    policy_gradient_loss | -0.0098      |\n",
      "|    reward               | -0.19595653  |\n",
      "|    std                  | 57.4         |\n",
      "|    value_loss           | 14.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2348         |\n",
      "|    time_elapsed         | 45572        |\n",
      "|    total_timesteps      | 4808704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011771766 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.8         |\n",
      "|    n_updates            | 28360        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | -2.984859    |\n",
      "|    std                  | 57.5         |\n",
      "|    value_loss           | 69.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2349        |\n",
      "|    time_elapsed         | 45591       |\n",
      "|    total_timesteps      | 4810752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002549514 |\n",
      "|    clip_fraction        | 0.00884     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 28370       |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    reward               | 5.3391905   |\n",
      "|    std                  | 57.8        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2350         |\n",
      "|    time_elapsed         | 45610        |\n",
      "|    total_timesteps      | 4812800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027425007 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | -0.0275      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.41         |\n",
      "|    n_updates            | 28380        |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    reward               | -1.9127179   |\n",
      "|    std                  | 58           |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2351         |\n",
      "|    time_elapsed         | 45630        |\n",
      "|    total_timesteps      | 4814848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016048683 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 28390        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -0.9056717   |\n",
      "|    std                  | 58           |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2352         |\n",
      "|    time_elapsed         | 45649        |\n",
      "|    total_timesteps      | 4816896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015229452 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.328        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.7         |\n",
      "|    n_updates            | 28400        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | 1.3190199    |\n",
      "|    std                  | 58           |\n",
      "|    value_loss           | 76.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2353          |\n",
      "|    time_elapsed         | 45668         |\n",
      "|    total_timesteps      | 4818944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0008029101  |\n",
      "|    clip_fraction        | 0.00229       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.279         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.8          |\n",
      "|    n_updates            | 28410         |\n",
      "|    policy_gradient_loss | -0.00234      |\n",
      "|    reward               | -0.0016733811 |\n",
      "|    std                  | 58.1          |\n",
      "|    value_loss           | 69.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2354         |\n",
      "|    time_elapsed         | 45687        |\n",
      "|    total_timesteps      | 4820992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044291373 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.88         |\n",
      "|    n_updates            | 28420        |\n",
      "|    policy_gradient_loss | -0.00888     |\n",
      "|    reward               | 0.9749569    |\n",
      "|    std                  | 58.2         |\n",
      "|    value_loss           | 12           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2355         |\n",
      "|    time_elapsed         | 45706        |\n",
      "|    total_timesteps      | 4823040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013999149 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.4         |\n",
      "|    n_updates            | 28430        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | 0.30459827   |\n",
      "|    std                  | 58.2         |\n",
      "|    value_loss           | 49.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2356         |\n",
      "|    time_elapsed         | 45725        |\n",
      "|    total_timesteps      | 4825088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024806813 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 28440        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | -0.9737498   |\n",
      "|    std                  | 58.4         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2357         |\n",
      "|    time_elapsed         | 45745        |\n",
      "|    total_timesteps      | 4827136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038298937 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.79         |\n",
      "|    n_updates            | 28450        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | 0.59214646   |\n",
      "|    std                  | 58.5         |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2358         |\n",
      "|    time_elapsed         | 45764        |\n",
      "|    total_timesteps      | 4829184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014492917 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 28460        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | 0.81277907   |\n",
      "|    std                  | 58.7         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2359         |\n",
      "|    time_elapsed         | 45783        |\n",
      "|    total_timesteps      | 4831232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004703827 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 28470        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    reward               | -22.612944   |\n",
      "|    std                  | 58.7         |\n",
      "|    value_loss           | 47.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2360         |\n",
      "|    time_elapsed         | 45803        |\n",
      "|    total_timesteps      | 4833280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016245081 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.1         |\n",
      "|    n_updates            | 28480        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 0.5536825    |\n",
      "|    std                  | 58.8         |\n",
      "|    value_loss           | 54           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4396690.09\n",
      "total_reward: 3396690.09\n",
      "total_cost: 472012.18\n",
      "total_trades: 76081\n",
      "Sharpe: 0.814\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2361        |\n",
      "|    time_elapsed         | 45822       |\n",
      "|    total_timesteps      | 4835328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003317122 |\n",
      "|    clip_fraction        | 0.00835     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.35        |\n",
      "|    n_updates            | 28490       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | -1.3052146  |\n",
      "|    std                  | 58.9        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2362         |\n",
      "|    time_elapsed         | 45841        |\n",
      "|    total_timesteps      | 4837376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042775203 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.4         |\n",
      "|    n_updates            | 28500        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | -0.23371513  |\n",
      "|    std                  | 59.1         |\n",
      "|    value_loss           | 72.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2363         |\n",
      "|    time_elapsed         | 45860        |\n",
      "|    total_timesteps      | 4839424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033622854 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 28510        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    reward               | 5.3909297    |\n",
      "|    std                  | 59.3         |\n",
      "|    value_loss           | 79.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2364         |\n",
      "|    time_elapsed         | 45879        |\n",
      "|    total_timesteps      | 4841472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044297725 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.07         |\n",
      "|    n_updates            | 28520        |\n",
      "|    policy_gradient_loss | -0.00741     |\n",
      "|    reward               | -0.11857955  |\n",
      "|    std                  | 59.4         |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2365         |\n",
      "|    time_elapsed         | 45898        |\n",
      "|    total_timesteps      | 4843520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020885358 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.172        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 28530        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | 0.6593145    |\n",
      "|    std                  | 59.7         |\n",
      "|    value_loss           | 68.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2366         |\n",
      "|    time_elapsed         | 45917        |\n",
      "|    total_timesteps      | 4845568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016924598 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.204        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.6         |\n",
      "|    n_updates            | 28540        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | 6.718738     |\n",
      "|    std                  | 59.8         |\n",
      "|    value_loss           | 76.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2367         |\n",
      "|    time_elapsed         | 45937        |\n",
      "|    total_timesteps      | 4847616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030130502 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 28550        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    reward               | 0.7545154    |\n",
      "|    std                  | 59.9         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2368         |\n",
      "|    time_elapsed         | 45956        |\n",
      "|    total_timesteps      | 4849664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014379343 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.132        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.6         |\n",
      "|    n_updates            | 28560        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    reward               | 1.4161325    |\n",
      "|    std                  | 60           |\n",
      "|    value_loss           | 77.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2369         |\n",
      "|    time_elapsed         | 45975        |\n",
      "|    total_timesteps      | 4851712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010476926 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.6         |\n",
      "|    n_updates            | 28570        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | 0.13464166   |\n",
      "|    std                  | 60.1         |\n",
      "|    value_loss           | 74.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2370         |\n",
      "|    time_elapsed         | 45994        |\n",
      "|    total_timesteps      | 4853760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015755496 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 28580        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | -0.55069256  |\n",
      "|    std                  | 60.1         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2371         |\n",
      "|    time_elapsed         | 46013        |\n",
      "|    total_timesteps      | 4855808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036924742 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.19         |\n",
      "|    n_updates            | 28590        |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    reward               | 0.30407465   |\n",
      "|    std                  | 60.2         |\n",
      "|    value_loss           | 11.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2372         |\n",
      "|    time_elapsed         | 46033        |\n",
      "|    total_timesteps      | 4857856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016502424 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 28600        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | -0.3721807   |\n",
      "|    std                  | 60.2         |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2373         |\n",
      "|    time_elapsed         | 46052        |\n",
      "|    total_timesteps      | 4859904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015834722 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.136        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 28610        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -1.5299084   |\n",
      "|    std                  | 60.3         |\n",
      "|    value_loss           | 55.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2374        |\n",
      "|    time_elapsed         | 46071       |\n",
      "|    total_timesteps      | 4861952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006000469 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.69        |\n",
      "|    n_updates            | 28620       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | -0.18438073 |\n",
      "|    std                  | 60.4        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2751551.97\n",
      "total_reward: 1751551.97\n",
      "total_cost: 404031.67\n",
      "total_trades: 72151\n",
      "Sharpe: 0.589\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2375         |\n",
      "|    time_elapsed         | 46091        |\n",
      "|    total_timesteps      | 4864000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019837595 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 28630        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | 1.3649651    |\n",
      "|    std                  | 60.7         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2376         |\n",
      "|    time_elapsed         | 46110        |\n",
      "|    total_timesteps      | 4866048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010354769 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 28640        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | -0.24228111  |\n",
      "|    std                  | 60.7         |\n",
      "|    value_loss           | 41.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2377         |\n",
      "|    time_elapsed         | 46130        |\n",
      "|    total_timesteps      | 4868096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016250564 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.81         |\n",
      "|    n_updates            | 28650        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | -0.4871168   |\n",
      "|    std                  | 60.8         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2378         |\n",
      "|    time_elapsed         | 46149        |\n",
      "|    total_timesteps      | 4870144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053106374 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.252        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.85         |\n",
      "|    n_updates            | 28660        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    reward               | 0.89575446   |\n",
      "|    std                  | 61.1         |\n",
      "|    value_loss           | 10.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2379         |\n",
      "|    time_elapsed         | 46168        |\n",
      "|    total_timesteps      | 4872192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016035382 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 28670        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | 1.1133455    |\n",
      "|    std                  | 61.2         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2380         |\n",
      "|    time_elapsed         | 46187        |\n",
      "|    total_timesteps      | 4874240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001590625 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 28680        |\n",
      "|    policy_gradient_loss | -0.000714    |\n",
      "|    reward               | 0.9573519    |\n",
      "|    std                  | 61.2         |\n",
      "|    value_loss           | 67.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2381         |\n",
      "|    time_elapsed         | 46207        |\n",
      "|    total_timesteps      | 4876288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056125624 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.86         |\n",
      "|    n_updates            | 28690        |\n",
      "|    policy_gradient_loss | -0.00908     |\n",
      "|    reward               | 2.4582357    |\n",
      "|    std                  | 61.5         |\n",
      "|    value_loss           | 11.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2382         |\n",
      "|    time_elapsed         | 46226        |\n",
      "|    total_timesteps      | 4878336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011230789 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 28700        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | 0.37009335   |\n",
      "|    std                  | 61.7         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2383         |\n",
      "|    time_elapsed         | 46245        |\n",
      "|    total_timesteps      | 4880384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018464635 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 28710        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    reward               | -1.3543688   |\n",
      "|    std                  | 61.9         |\n",
      "|    value_loss           | 43.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2384         |\n",
      "|    time_elapsed         | 46265        |\n",
      "|    total_timesteps      | 4882432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004756484 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 28720        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | -0.011262697 |\n",
      "|    std                  | 61.9         |\n",
      "|    value_loss           | 40.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2385         |\n",
      "|    time_elapsed         | 46284        |\n",
      "|    total_timesteps      | 4884480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032490706 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.1          |\n",
      "|    n_updates            | 28730        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    reward               | -0.088868275 |\n",
      "|    std                  | 62           |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2386        |\n",
      "|    time_elapsed         | 46303       |\n",
      "|    total_timesteps      | 4886528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001629197 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.85        |\n",
      "|    n_updates            | 28740       |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    reward               | -0.8976702  |\n",
      "|    std                  | 62.2        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2387         |\n",
      "|    time_elapsed         | 46322        |\n",
      "|    total_timesteps      | 4888576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004470825 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 28750        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | -2.1970944   |\n",
      "|    std                  | 62.3         |\n",
      "|    value_loss           | 46.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2388        |\n",
      "|    time_elapsed         | 46341       |\n",
      "|    total_timesteps      | 4890624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004290345 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.0791      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 28760       |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | -3.3546045  |\n",
      "|    std                  | 62.4        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2589066.95\n",
      "total_reward: 1589066.95\n",
      "total_cost: 413512.46\n",
      "total_trades: 72737\n",
      "Sharpe: 0.556\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2389         |\n",
      "|    time_elapsed         | 46360        |\n",
      "|    total_timesteps      | 4892672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016734736 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 28770        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -1.2295841   |\n",
      "|    std                  | 62.5         |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2390         |\n",
      "|    time_elapsed         | 46380        |\n",
      "|    total_timesteps      | 4894720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004475387 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 28780        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | -0.5934437   |\n",
      "|    std                  | 62.5         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2391        |\n",
      "|    time_elapsed         | 46399       |\n",
      "|    total_timesteps      | 4896768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005558662 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.82        |\n",
      "|    n_updates            | 28790       |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | 0.8730942   |\n",
      "|    std                  | 62.9        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2392         |\n",
      "|    time_elapsed         | 46418        |\n",
      "|    total_timesteps      | 4898816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022346387 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.26         |\n",
      "|    n_updates            | 28800        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | -0.29564157  |\n",
      "|    std                  | 63           |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2393         |\n",
      "|    time_elapsed         | 46438        |\n",
      "|    total_timesteps      | 4900864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009925748 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 28810        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | 0.6556879    |\n",
      "|    std                  | 63.1         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2394         |\n",
      "|    time_elapsed         | 46457        |\n",
      "|    total_timesteps      | 4902912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012501545 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.187        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.1         |\n",
      "|    n_updates            | 28820        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 1.9203893    |\n",
      "|    std                  | 63.2         |\n",
      "|    value_loss           | 64.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2395       |\n",
      "|    time_elapsed         | 46476      |\n",
      "|    total_timesteps      | 4904960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00407355 |\n",
      "|    clip_fraction        | 0.011      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -160       |\n",
      "|    explained_variance   | 0.311      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.66       |\n",
      "|    n_updates            | 28830      |\n",
      "|    policy_gradient_loss | -0.00635   |\n",
      "|    reward               | 2.2860463  |\n",
      "|    std                  | 63.5       |\n",
      "|    value_loss           | 16.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2396         |\n",
      "|    time_elapsed         | 46495        |\n",
      "|    total_timesteps      | 4907008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024436042 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.311        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56           |\n",
      "|    n_updates            | 28840        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | -0.22433639  |\n",
      "|    std                  | 63.8         |\n",
      "|    value_loss           | 70.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2397          |\n",
      "|    time_elapsed         | 46515         |\n",
      "|    total_timesteps      | 4909056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027632443 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.163         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.6          |\n",
      "|    n_updates            | 28850         |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | 6.142303      |\n",
      "|    std                  | 63.8          |\n",
      "|    value_loss           | 84.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2398        |\n",
      "|    time_elapsed         | 46534       |\n",
      "|    total_timesteps      | 4911104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002283264 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -160        |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 28860       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    reward               | 1.2110345   |\n",
      "|    std                  | 64          |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2399          |\n",
      "|    time_elapsed         | 46553         |\n",
      "|    total_timesteps      | 4913152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047943334 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.141         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.8          |\n",
      "|    n_updates            | 28870         |\n",
      "|    policy_gradient_loss | -0.0021       |\n",
      "|    reward               | 0.5041913     |\n",
      "|    std                  | 64            |\n",
      "|    value_loss           | 97.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2400         |\n",
      "|    time_elapsed         | 46572        |\n",
      "|    total_timesteps      | 4915200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010350721 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 28880        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | -0.33562547  |\n",
      "|    std                  | 64.2         |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2401         |\n",
      "|    time_elapsed         | 46591        |\n",
      "|    total_timesteps      | 4917248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016250017 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 28890        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.4277238    |\n",
      "|    std                  | 64.2         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2402         |\n",
      "|    time_elapsed         | 46610        |\n",
      "|    total_timesteps      | 4919296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057171523 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.87         |\n",
      "|    n_updates            | 28900        |\n",
      "|    policy_gradient_loss | -0.00795     |\n",
      "|    reward               | -1.5241826   |\n",
      "|    std                  | 64.3         |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4385356.69\n",
      "total_reward: 3385356.69\n",
      "total_cost: 463994.07\n",
      "total_trades: 75095\n",
      "Sharpe: 0.788\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2403         |\n",
      "|    time_elapsed         | 46630        |\n",
      "|    total_timesteps      | 4921344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011026819 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.5         |\n",
      "|    n_updates            | 28910        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | -0.9124397   |\n",
      "|    std                  | 64.4         |\n",
      "|    value_loss           | 67.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2404          |\n",
      "|    time_elapsed         | 46649         |\n",
      "|    total_timesteps      | 4923392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043962945 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.164         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 37.3          |\n",
      "|    n_updates            | 28920         |\n",
      "|    policy_gradient_loss | -0.00143      |\n",
      "|    reward               | -1.2854677    |\n",
      "|    std                  | 64.5          |\n",
      "|    value_loss           | 89.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2405        |\n",
      "|    time_elapsed         | 46669       |\n",
      "|    total_timesteps      | 4925440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004372456 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -160        |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.88        |\n",
      "|    n_updates            | 28930       |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | 1.7589295   |\n",
      "|    std                  | 64.5        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2406         |\n",
      "|    time_elapsed         | 46688        |\n",
      "|    total_timesteps      | 4927488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009851655 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.209        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.6         |\n",
      "|    n_updates            | 28940        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | -2.0630307   |\n",
      "|    std                  | 64.5         |\n",
      "|    value_loss           | 81.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2407         |\n",
      "|    time_elapsed         | 46708        |\n",
      "|    total_timesteps      | 4929536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010562037 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.158        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 28950        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | 1.0228727    |\n",
      "|    std                  | 64.7         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2408        |\n",
      "|    time_elapsed         | 46727       |\n",
      "|    total_timesteps      | 4931584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003515824 |\n",
      "|    clip_fraction        | 0.00986     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -160        |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 28960       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | 0.22174639  |\n",
      "|    std                  | 64.8        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2409         |\n",
      "|    time_elapsed         | 46747        |\n",
      "|    total_timesteps      | 4933632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013860748 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.0811       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 28970        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 1.0696269    |\n",
      "|    std                  | 64.7         |\n",
      "|    value_loss           | 67.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2410         |\n",
      "|    time_elapsed         | 46766        |\n",
      "|    total_timesteps      | 4935680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008104661 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 28980        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | 0.047592636  |\n",
      "|    std                  | 64.8         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2411         |\n",
      "|    time_elapsed         | 46785        |\n",
      "|    total_timesteps      | 4937728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008191699 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.0422       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 28990        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 1.7700269    |\n",
      "|    std                  | 64.9         |\n",
      "|    value_loss           | 98.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2412        |\n",
      "|    time_elapsed         | 46804       |\n",
      "|    total_timesteps      | 4939776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004220535 |\n",
      "|    clip_fraction        | 0.00981     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -160        |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.13        |\n",
      "|    n_updates            | 29000       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | -1.228063   |\n",
      "|    std                  | 65          |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2413         |\n",
      "|    time_elapsed         | 46823        |\n",
      "|    total_timesteps      | 4941824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014728797 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.0245       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.4         |\n",
      "|    n_updates            | 29010        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 0.15746897   |\n",
      "|    std                  | 65.1         |\n",
      "|    value_loss           | 79.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2414          |\n",
      "|    time_elapsed         | 46843         |\n",
      "|    total_timesteps      | 4943872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048205897 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.189         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46.4          |\n",
      "|    n_updates            | 29020         |\n",
      "|    policy_gradient_loss | -0.00201      |\n",
      "|    reward               | 0.8808965     |\n",
      "|    std                  | 65.2          |\n",
      "|    value_loss           | 77.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2415        |\n",
      "|    time_elapsed         | 46862       |\n",
      "|    total_timesteps      | 4945920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001408127 |\n",
      "|    clip_fraction        | 0.00195     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -161        |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 29030       |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    reward               | 0.7894408   |\n",
      "|    std                  | 65.2        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2416         |\n",
      "|    time_elapsed         | 46881        |\n",
      "|    total_timesteps      | 4947968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015554335 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 29040        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | -0.62056077  |\n",
      "|    std                  | 65.4         |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3175109.40\n",
      "total_reward: 2175109.40\n",
      "total_cost: 467192.91\n",
      "total_trades: 75317\n",
      "Sharpe: 0.628\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2417         |\n",
      "|    time_elapsed         | 46901        |\n",
      "|    total_timesteps      | 4950016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010609943 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 29050        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | 3.0392504    |\n",
      "|    std                  | 65.5         |\n",
      "|    value_loss           | 73.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2418          |\n",
      "|    time_elapsed         | 46920         |\n",
      "|    total_timesteps      | 4952064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043176187 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.177         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 37.6          |\n",
      "|    n_updates            | 29060         |\n",
      "|    policy_gradient_loss | -0.00137      |\n",
      "|    reward               | -2.658146     |\n",
      "|    std                  | 65.5          |\n",
      "|    value_loss           | 89.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2419         |\n",
      "|    time_elapsed         | 46939        |\n",
      "|    total_timesteps      | 4954112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032428093 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | -0.0551      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.84         |\n",
      "|    n_updates            | 29070        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    reward               | 1.1893544    |\n",
      "|    std                  | 65.5         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2420         |\n",
      "|    time_elapsed         | 46958        |\n",
      "|    total_timesteps      | 4956160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014821966 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76           |\n",
      "|    n_updates            | 29080        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 0.5275839    |\n",
      "|    std                  | 65.6         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2421         |\n",
      "|    time_elapsed         | 46978        |\n",
      "|    total_timesteps      | 4958208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011314584 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 29090        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | 0.22565499   |\n",
      "|    std                  | 65.7         |\n",
      "|    value_loss           | 53.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2422         |\n",
      "|    time_elapsed         | 46998        |\n",
      "|    total_timesteps      | 4960256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023829432 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | -0.132       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.63         |\n",
      "|    n_updates            | 29100        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    reward               | 0.013779099  |\n",
      "|    std                  | 65.8         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2423         |\n",
      "|    time_elapsed         | 47017        |\n",
      "|    total_timesteps      | 4962304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026201634 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 29110        |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    reward               | 0.09248198   |\n",
      "|    std                  | 66           |\n",
      "|    value_loss           | 49.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2424         |\n",
      "|    time_elapsed         | 47036        |\n",
      "|    total_timesteps      | 4964352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016815928 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 29120        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | -1.6225269   |\n",
      "|    std                  | 66.1         |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2425         |\n",
      "|    time_elapsed         | 47056        |\n",
      "|    total_timesteps      | 4966400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016448356 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.0779       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37           |\n",
      "|    n_updates            | 29130        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | -0.06651384  |\n",
      "|    std                  | 66.2         |\n",
      "|    value_loss           | 82.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2426       |\n",
      "|    time_elapsed         | 47076      |\n",
      "|    total_timesteps      | 4968448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00878438 |\n",
      "|    clip_fraction        | 0.0527     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -161       |\n",
      "|    explained_variance   | -0.0184    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.6       |\n",
      "|    n_updates            | 29140      |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | 0.66197705 |\n",
      "|    std                  | 66.5       |\n",
      "|    value_loss           | 18.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2427         |\n",
      "|    time_elapsed         | 47095        |\n",
      "|    total_timesteps      | 4970496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022424352 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.0285       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.5         |\n",
      "|    n_updates            | 29150        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | 0.17490406   |\n",
      "|    std                  | 66.6         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2428          |\n",
      "|    time_elapsed         | 47115         |\n",
      "|    total_timesteps      | 4972544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042085283 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.205         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.1          |\n",
      "|    n_updates            | 29160         |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    reward               | 1.6879832     |\n",
      "|    std                  | 66.7          |\n",
      "|    value_loss           | 78.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2429         |\n",
      "|    time_elapsed         | 47134        |\n",
      "|    total_timesteps      | 4974592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055290293 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.68         |\n",
      "|    n_updates            | 29170        |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    reward               | 0.96732116   |\n",
      "|    std                  | 66.9         |\n",
      "|    value_loss           | 14.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2430         |\n",
      "|    time_elapsed         | 47153        |\n",
      "|    total_timesteps      | 4976640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021176003 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.12         |\n",
      "|    n_updates            | 29180        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | 1.5770599    |\n",
      "|    std                  | 67           |\n",
      "|    value_loss           | 48           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2431         |\n",
      "|    time_elapsed         | 47172        |\n",
      "|    total_timesteps      | 4978688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005108098 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 29190        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | 3.256921     |\n",
      "|    std                  | 67           |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3281806.14\n",
      "total_reward: 2281806.14\n",
      "total_cost: 447509.02\n",
      "total_trades: 74091\n",
      "Sharpe: 0.671\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2432        |\n",
      "|    time_elapsed         | 47192       |\n",
      "|    total_timesteps      | 4980736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003251205 |\n",
      "|    clip_fraction        | 0.0063      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -161        |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 29200       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | -3.1432378  |\n",
      "|    std                  | 67.1        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2433         |\n",
      "|    time_elapsed         | 47211        |\n",
      "|    total_timesteps      | 4982784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008910431 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 29210        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | 1.1981642    |\n",
      "|    std                  | 67.2         |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2434       |\n",
      "|    time_elapsed         | 47230      |\n",
      "|    total_timesteps      | 4984832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00205037 |\n",
      "|    clip_fraction        | 0.000879   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -161       |\n",
      "|    explained_variance   | 0.503      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13         |\n",
      "|    n_updates            | 29220      |\n",
      "|    policy_gradient_loss | -0.00451   |\n",
      "|    reward               | 0.72859156 |\n",
      "|    std                  | 67.3       |\n",
      "|    value_loss           | 33.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2435        |\n",
      "|    time_elapsed         | 47250       |\n",
      "|    total_timesteps      | 4986880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001428376 |\n",
      "|    clip_fraction        | 0.00244     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -161        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 29230       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | 0.030055733 |\n",
      "|    std                  | 67.5        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2436         |\n",
      "|    time_elapsed         | 47269        |\n",
      "|    total_timesteps      | 4988928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034996192 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.92         |\n",
      "|    n_updates            | 29240        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | 0.4783078    |\n",
      "|    std                  | 67.9         |\n",
      "|    value_loss           | 11.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2437         |\n",
      "|    time_elapsed         | 47289        |\n",
      "|    total_timesteps      | 4990976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007648448 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 29250        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | 0.96279716   |\n",
      "|    std                  | 68           |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2438         |\n",
      "|    time_elapsed         | 47308        |\n",
      "|    total_timesteps      | 4993024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009680543 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 29260        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | -3.4231198   |\n",
      "|    std                  | 68           |\n",
      "|    value_loss           | 63.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2439         |\n",
      "|    time_elapsed         | 47327        |\n",
      "|    total_timesteps      | 4995072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023533213 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 29270        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | 0.88202304   |\n",
      "|    std                  | 68.1         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2440         |\n",
      "|    time_elapsed         | 47346        |\n",
      "|    total_timesteps      | 4997120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017910239 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 29280        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 0.3408481    |\n",
      "|    std                  | 68.1         |\n",
      "|    value_loss           | 62.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2441         |\n",
      "|    time_elapsed         | 47365        |\n",
      "|    total_timesteps      | 4999168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013611903 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 29290        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -0.2579404   |\n",
      "|    std                  | 68.3         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2442         |\n",
      "|    time_elapsed         | 47385        |\n",
      "|    total_timesteps      | 5001216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011969053 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 29300        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | 0.3467741    |\n",
      "|    std                  | 68.4         |\n",
      "|    value_loss           | 50.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2443        |\n",
      "|    time_elapsed         | 47404       |\n",
      "|    total_timesteps      | 5003264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003913344 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -162        |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.69        |\n",
      "|    n_updates            | 29310       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 0.4927523   |\n",
      "|    std                  | 68.6        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2444         |\n",
      "|    time_elapsed         | 47423        |\n",
      "|    total_timesteps      | 5005312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010936096 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 29320        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | -0.8338397   |\n",
      "|    std                  | 68.7         |\n",
      "|    value_loss           | 43.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2445         |\n",
      "|    time_elapsed         | 47443        |\n",
      "|    total_timesteps      | 5007360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006068753 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38           |\n",
      "|    n_updates            | 29330        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | -10.192821   |\n",
      "|    std                  | 68.8         |\n",
      "|    value_loss           | 63.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3556475.86\n",
      "total_reward: 2556475.86\n",
      "total_cost: 416983.57\n",
      "total_trades: 72891\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2446         |\n",
      "|    time_elapsed         | 47462        |\n",
      "|    total_timesteps      | 5009408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026649176 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.41         |\n",
      "|    n_updates            | 29340        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | 1.6773586    |\n",
      "|    std                  | 69.2         |\n",
      "|    value_loss           | 15.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2447         |\n",
      "|    time_elapsed         | 47481        |\n",
      "|    total_timesteps      | 5011456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021097036 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 29350        |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    reward               | 0.11595746   |\n",
      "|    std                  | 69.2         |\n",
      "|    value_loss           | 42.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2448          |\n",
      "|    time_elapsed         | 47501         |\n",
      "|    total_timesteps      | 5013504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062297296 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.322         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.1          |\n",
      "|    n_updates            | 29360         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    reward               | 18.12793      |\n",
      "|    std                  | 69.3          |\n",
      "|    value_loss           | 49.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2449          |\n",
      "|    time_elapsed         | 47520         |\n",
      "|    total_timesteps      | 5015552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078274694 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.245         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 41.9          |\n",
      "|    n_updates            | 29370         |\n",
      "|    policy_gradient_loss | -0.00289      |\n",
      "|    reward               | 0.8900193     |\n",
      "|    std                  | 69.4          |\n",
      "|    value_loss           | 59.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2450        |\n",
      "|    time_elapsed         | 47539       |\n",
      "|    total_timesteps      | 5017600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003222715 |\n",
      "|    clip_fraction        | 0.00542     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -162        |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.12        |\n",
      "|    n_updates            | 29380       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 0.03531164  |\n",
      "|    std                  | 69.9        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2451        |\n",
      "|    time_elapsed         | 47558       |\n",
      "|    total_timesteps      | 5019648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002067155 |\n",
      "|    clip_fraction        | 0.00649     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -163        |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 29390       |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    reward               | 0.7265781   |\n",
      "|    std                  | 70          |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2452        |\n",
      "|    time_elapsed         | 47578       |\n",
      "|    total_timesteps      | 5021696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001170541 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -163        |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 29400       |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | 0.6169306   |\n",
      "|    std                  | 70.2        |\n",
      "|    value_loss           | 75.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2453         |\n",
      "|    time_elapsed         | 47597        |\n",
      "|    total_timesteps      | 5023744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026610433 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.333        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.62         |\n",
      "|    n_updates            | 29410        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 0.5472148    |\n",
      "|    std                  | 70.4         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2454         |\n",
      "|    time_elapsed         | 47616        |\n",
      "|    total_timesteps      | 5025792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010260496 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.195        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.5         |\n",
      "|    n_updates            | 29420        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | 0.4173977    |\n",
      "|    std                  | 70.5         |\n",
      "|    value_loss           | 81           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2455         |\n",
      "|    time_elapsed         | 47635        |\n",
      "|    total_timesteps      | 5027840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003615303 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 29430        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | -2.4910278   |\n",
      "|    std                  | 70.6         |\n",
      "|    value_loss           | 65.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2456         |\n",
      "|    time_elapsed         | 47654        |\n",
      "|    total_timesteps      | 5029888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036831726 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 29440        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    reward               | 2.1818342    |\n",
      "|    std                  | 70.7         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2457         |\n",
      "|    time_elapsed         | 47674        |\n",
      "|    total_timesteps      | 5031936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021355655 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 29450        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | -0.6330834   |\n",
      "|    std                  | 70.9         |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2458         |\n",
      "|    time_elapsed         | 47693        |\n",
      "|    total_timesteps      | 5033984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008028402 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 29460        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 0.075838335  |\n",
      "|    std                  | 71.1         |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2459         |\n",
      "|    time_elapsed         | 47712        |\n",
      "|    total_timesteps      | 5036032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014825144 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 29470        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 0.88258207   |\n",
      "|    std                  | 71.3         |\n",
      "|    value_loss           | 56           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2054171.15\n",
      "total_reward: 1054171.15\n",
      "total_cost: 428547.98\n",
      "total_trades: 73273\n",
      "Sharpe: 0.422\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2460         |\n",
      "|    time_elapsed         | 47731        |\n",
      "|    total_timesteps      | 5038080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024580895 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.2          |\n",
      "|    n_updates            | 29480        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | 0.5747085    |\n",
      "|    std                  | 71.6         |\n",
      "|    value_loss           | 16.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2461         |\n",
      "|    time_elapsed         | 47750        |\n",
      "|    total_timesteps      | 5040128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011959212 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 29490        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | -1.9538506   |\n",
      "|    std                  | 71.7         |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2462         |\n",
      "|    time_elapsed         | 47770        |\n",
      "|    total_timesteps      | 5042176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009578783 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 29500        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | 2.7966335    |\n",
      "|    std                  | 71.8         |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2463         |\n",
      "|    time_elapsed         | 47789        |\n",
      "|    total_timesteps      | 5044224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034865467 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 29510        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -3.2445316   |\n",
      "|    std                  | 71.9         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2464          |\n",
      "|    time_elapsed         | 47808         |\n",
      "|    total_timesteps      | 5046272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087741646 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -163          |\n",
      "|    explained_variance   | 0.229         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.7          |\n",
      "|    n_updates            | 29520         |\n",
      "|    policy_gradient_loss | -0.00206      |\n",
      "|    reward               | 2.8700917     |\n",
      "|    std                  | 72.1          |\n",
      "|    value_loss           | 47.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2465         |\n",
      "|    time_elapsed         | 47828        |\n",
      "|    total_timesteps      | 5048320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018449307 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 29530        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | 0.62013614   |\n",
      "|    std                  | 72.3         |\n",
      "|    value_loss           | 68.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2466         |\n",
      "|    time_elapsed         | 47847        |\n",
      "|    total_timesteps      | 5050368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013011566 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 29540        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | -0.81115544  |\n",
      "|    std                  | 72.5         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2467         |\n",
      "|    time_elapsed         | 47865        |\n",
      "|    total_timesteps      | 5052416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029336037 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.216        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.63         |\n",
      "|    n_updates            | 29550        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | -0.6542896   |\n",
      "|    std                  | 72.7         |\n",
      "|    value_loss           | 17.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2468         |\n",
      "|    time_elapsed         | 47885        |\n",
      "|    total_timesteps      | 5054464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019052788 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.118        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.9         |\n",
      "|    n_updates            | 29560        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | -0.46780044  |\n",
      "|    std                  | 72.9         |\n",
      "|    value_loss           | 73.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2469          |\n",
      "|    time_elapsed         | 47904         |\n",
      "|    total_timesteps      | 5056512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041072586 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -164          |\n",
      "|    explained_variance   | 0.429         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.1          |\n",
      "|    n_updates            | 29570         |\n",
      "|    policy_gradient_loss | -0.00129      |\n",
      "|    reward               | 1.8329794     |\n",
      "|    std                  | 73            |\n",
      "|    value_loss           | 77.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2470         |\n",
      "|    time_elapsed         | 47923        |\n",
      "|    total_timesteps      | 5058560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042178687 |\n",
      "|    clip_fraction        | 0.00928      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.67         |\n",
      "|    n_updates            | 29580        |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    reward               | 0.4703958    |\n",
      "|    std                  | 73.3         |\n",
      "|    value_loss           | 15.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2471         |\n",
      "|    time_elapsed         | 47942        |\n",
      "|    total_timesteps      | 5060608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023480156 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.06         |\n",
      "|    n_updates            | 29590        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | 1.2554533    |\n",
      "|    std                  | 73.5         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2472         |\n",
      "|    time_elapsed         | 47962        |\n",
      "|    total_timesteps      | 5062656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018428362 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 29600        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | 1.2849739    |\n",
      "|    std                  | 73.5         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2473         |\n",
      "|    time_elapsed         | 47981        |\n",
      "|    total_timesteps      | 5064704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024558622 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 29610        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    reward               | 0.35743213   |\n",
      "|    std                  | 73.8         |\n",
      "|    value_loss           | 37.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3863593.86\n",
      "total_reward: 2863593.86\n",
      "total_cost: 458881.81\n",
      "total_trades: 74666\n",
      "Sharpe: 0.718\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2474        |\n",
      "|    time_elapsed         | 48000       |\n",
      "|    total_timesteps      | 5066752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001514497 |\n",
      "|    clip_fraction        | 0.000635    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -164        |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 29620       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | -2.151875   |\n",
      "|    std                  | 74          |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2475          |\n",
      "|    time_elapsed         | 48019         |\n",
      "|    total_timesteps      | 5068800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074256293 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -164          |\n",
      "|    explained_variance   | 0.386         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22            |\n",
      "|    n_updates            | 29630         |\n",
      "|    policy_gradient_loss | -0.00219      |\n",
      "|    reward               | -2.2055533    |\n",
      "|    std                  | 74            |\n",
      "|    value_loss           | 45.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2476         |\n",
      "|    time_elapsed         | 48038        |\n",
      "|    total_timesteps      | 5070848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012396167 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 29640        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -0.9072958   |\n",
      "|    std                  | 74.1         |\n",
      "|    value_loss           | 37.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2477         |\n",
      "|    time_elapsed         | 48058        |\n",
      "|    total_timesteps      | 5072896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039822985 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.32         |\n",
      "|    n_updates            | 29650        |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    reward               | 0.640776     |\n",
      "|    std                  | 74.3         |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2478         |\n",
      "|    time_elapsed         | 48077        |\n",
      "|    total_timesteps      | 5074944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013989487 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 29660        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -0.82733566  |\n",
      "|    std                  | 74.5         |\n",
      "|    value_loss           | 97.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2479         |\n",
      "|    time_elapsed         | 48097        |\n",
      "|    total_timesteps      | 5076992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008308065 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.318        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 29670        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | 5.281293     |\n",
      "|    std                  | 74.7         |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2480         |\n",
      "|    time_elapsed         | 48116        |\n",
      "|    total_timesteps      | 5079040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029629264 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.317        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.71         |\n",
      "|    n_updates            | 29680        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    reward               | -2.5350933   |\n",
      "|    std                  | 74.7         |\n",
      "|    value_loss           | 18           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2481         |\n",
      "|    time_elapsed         | 48135        |\n",
      "|    total_timesteps      | 5081088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023336033 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 29690        |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    reward               | 2.06145      |\n",
      "|    std                  | 74.7         |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2482         |\n",
      "|    time_elapsed         | 48154        |\n",
      "|    total_timesteps      | 5083136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021614097 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -164         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.89         |\n",
      "|    n_updates            | 29700        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 0.15716033   |\n",
      "|    std                  | 75           |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2483         |\n",
      "|    time_elapsed         | 48173        |\n",
      "|    total_timesteps      | 5085184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015275542 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 29710        |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    reward               | -0.96377707  |\n",
      "|    std                  | 75           |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2484         |\n",
      "|    time_elapsed         | 48193        |\n",
      "|    total_timesteps      | 5087232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054075094 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.5          |\n",
      "|    n_updates            | 29720        |\n",
      "|    policy_gradient_loss | -0.00955     |\n",
      "|    reward               | 0.05932705   |\n",
      "|    std                  | 75.2         |\n",
      "|    value_loss           | 10           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2485         |\n",
      "|    time_elapsed         | 48212        |\n",
      "|    total_timesteps      | 5089280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013827916 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 29730        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | 0.83089024   |\n",
      "|    std                  | 75.4         |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2486          |\n",
      "|    time_elapsed         | 48231         |\n",
      "|    total_timesteps      | 5091328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083494064 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -165          |\n",
      "|    explained_variance   | 0.474         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32.6          |\n",
      "|    n_updates            | 29740         |\n",
      "|    policy_gradient_loss | -0.00218      |\n",
      "|    reward               | -1.4927071    |\n",
      "|    std                  | 75.4          |\n",
      "|    value_loss           | 62.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2487         |\n",
      "|    time_elapsed         | 48250        |\n",
      "|    total_timesteps      | 5093376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022466753 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.354        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.36         |\n",
      "|    n_updates            | 29750        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | 0.25535345   |\n",
      "|    std                  | 75.6         |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3034325.58\n",
      "total_reward: 2034325.58\n",
      "total_cost: 468029.53\n",
      "total_trades: 75367\n",
      "Sharpe: 0.620\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2488         |\n",
      "|    time_elapsed         | 48270        |\n",
      "|    total_timesteps      | 5095424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027925735 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 29760        |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    reward               | -0.9730746   |\n",
      "|    std                  | 75.8         |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2489         |\n",
      "|    time_elapsed         | 48289        |\n",
      "|    total_timesteps      | 5097472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009886553 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.47         |\n",
      "|    n_updates            | 29770        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | -0.17218983  |\n",
      "|    std                  | 76           |\n",
      "|    value_loss           | 45           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2490         |\n",
      "|    time_elapsed         | 48308        |\n",
      "|    total_timesteps      | 5099520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004968003 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 29780        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    reward               | -1.8547323   |\n",
      "|    std                  | 76           |\n",
      "|    value_loss           | 68.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2491         |\n",
      "|    time_elapsed         | 48328        |\n",
      "|    total_timesteps      | 5101568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036227296 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.1          |\n",
      "|    n_updates            | 29790        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | 0.23345308   |\n",
      "|    std                  | 76           |\n",
      "|    value_loss           | 11           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2492        |\n",
      "|    time_elapsed         | 48347       |\n",
      "|    total_timesteps      | 5103616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001466197 |\n",
      "|    clip_fraction        | 0.000684    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -165        |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 29800       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    reward               | 2.5980997   |\n",
      "|    std                  | 76.1        |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2493          |\n",
      "|    time_elapsed         | 48365         |\n",
      "|    total_timesteps      | 5105664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068197073 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -165          |\n",
      "|    explained_variance   | 0.332         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.1          |\n",
      "|    n_updates            | 29810         |\n",
      "|    policy_gradient_loss | -0.00208      |\n",
      "|    reward               | 0.35270447    |\n",
      "|    std                  | 76            |\n",
      "|    value_loss           | 43.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2494        |\n",
      "|    time_elapsed         | 48385       |\n",
      "|    total_timesteps      | 5107712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003484724 |\n",
      "|    clip_fraction        | 0.0082      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -165        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.02        |\n",
      "|    n_updates            | 29820       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | -0.5670588  |\n",
      "|    std                  | 76.2        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2495         |\n",
      "|    time_elapsed         | 48404        |\n",
      "|    total_timesteps      | 5109760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020157266 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.209        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.6         |\n",
      "|    n_updates            | 29830        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 2.213518     |\n",
      "|    std                  | 76.5         |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2496         |\n",
      "|    time_elapsed         | 48423        |\n",
      "|    total_timesteps      | 5111808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017144538 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 29840        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 0.22161391   |\n",
      "|    std                  | 76.6         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2497         |\n",
      "|    time_elapsed         | 48442        |\n",
      "|    total_timesteps      | 5113856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020662087 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.66         |\n",
      "|    n_updates            | 29850        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | -0.53057206  |\n",
      "|    std                  | 76.7         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2498        |\n",
      "|    time_elapsed         | 48461       |\n",
      "|    total_timesteps      | 5115904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003070864 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -165        |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 29860       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | 1.7438132   |\n",
      "|    std                  | 76.9        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2499         |\n",
      "|    time_elapsed         | 48481        |\n",
      "|    total_timesteps      | 5117952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012033354 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 29870        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -0.7518564   |\n",
      "|    std                  | 77.1         |\n",
      "|    value_loss           | 43.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2500         |\n",
      "|    time_elapsed         | 48500        |\n",
      "|    total_timesteps      | 5120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013173892 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -165         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 29880        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | -1.9957526   |\n",
      "|    std                  | 77.2         |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2501        |\n",
      "|    time_elapsed         | 48520       |\n",
      "|    total_timesteps      | 5122048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002168769 |\n",
      "|    clip_fraction        | 0.00229     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -165        |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.38        |\n",
      "|    n_updates            | 29890       |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | 1.5198662   |\n",
      "|    std                  | 77.4        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4241122.58\n",
      "total_reward: 3241122.58\n",
      "total_cost: 469865.66\n",
      "total_trades: 75631\n",
      "Sharpe: 0.792\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2502         |\n",
      "|    time_elapsed         | 48539        |\n",
      "|    total_timesteps      | 5124096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013893861 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 29900        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -0.96892464  |\n",
      "|    std                  | 77.5         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2503         |\n",
      "|    time_elapsed         | 48558        |\n",
      "|    total_timesteps      | 5126144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012671666 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 29910        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | 0.5592491    |\n",
      "|    std                  | 77.7         |\n",
      "|    value_loss           | 60.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2504         |\n",
      "|    time_elapsed         | 48577        |\n",
      "|    total_timesteps      | 5128192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032375015 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.12         |\n",
      "|    n_updates            | 29920        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | -3.3762834   |\n",
      "|    std                  | 77.9         |\n",
      "|    value_loss           | 16.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2505        |\n",
      "|    time_elapsed         | 48596       |\n",
      "|    total_timesteps      | 5130240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002203018 |\n",
      "|    clip_fraction        | 0.00566     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -166        |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.99        |\n",
      "|    n_updates            | 29930       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | -2.042464   |\n",
      "|    std                  | 78.1        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2506          |\n",
      "|    time_elapsed         | 48616         |\n",
      "|    total_timesteps      | 5132288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039392625 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.558         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.8           |\n",
      "|    n_updates            | 29940         |\n",
      "|    policy_gradient_loss | -0.00175      |\n",
      "|    reward               | 0.0016613457  |\n",
      "|    std                  | 78.1          |\n",
      "|    value_loss           | 36.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2507         |\n",
      "|    time_elapsed         | 48636        |\n",
      "|    total_timesteps      | 5134336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016175065 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.124        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 29950        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | 3.2283452    |\n",
      "|    std                  | 78.3         |\n",
      "|    value_loss           | 79.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2508        |\n",
      "|    time_elapsed         | 48655       |\n",
      "|    total_timesteps      | 5136384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004942021 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -166        |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.05        |\n",
      "|    n_updates            | 29960       |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | 1.9390217   |\n",
      "|    std                  | 78.1        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2509         |\n",
      "|    time_elapsed         | 48674        |\n",
      "|    total_timesteps      | 5138432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011240544 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.105        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.8         |\n",
      "|    n_updates            | 29970        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | 2.0017226    |\n",
      "|    std                  | 78.4         |\n",
      "|    value_loss           | 78.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2510          |\n",
      "|    time_elapsed         | 48693         |\n",
      "|    total_timesteps      | 5140480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065847556 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.575         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.7          |\n",
      "|    n_updates            | 29980         |\n",
      "|    policy_gradient_loss | -0.00276      |\n",
      "|    reward               | 14.664034     |\n",
      "|    std                  | 78.5          |\n",
      "|    value_loss           | 34.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2511        |\n",
      "|    time_elapsed         | 48712       |\n",
      "|    total_timesteps      | 5142528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003688878 |\n",
      "|    clip_fraction        | 0.00557     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -166        |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.62        |\n",
      "|    n_updates            | 29990       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | -0.196606   |\n",
      "|    std                  | 79          |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2512         |\n",
      "|    time_elapsed         | 48732        |\n",
      "|    total_timesteps      | 5144576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021242704 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.91         |\n",
      "|    n_updates            | 30000        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | -1.2550293   |\n",
      "|    std                  | 79.4         |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2513          |\n",
      "|    time_elapsed         | 48751         |\n",
      "|    total_timesteps      | 5146624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052884256 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -166          |\n",
      "|    explained_variance   | 0.503         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.3          |\n",
      "|    n_updates            | 30010         |\n",
      "|    policy_gradient_loss | -0.00204      |\n",
      "|    reward               | 4.092927      |\n",
      "|    std                  | 79.5          |\n",
      "|    value_loss           | 32.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2514         |\n",
      "|    time_elapsed         | 48770        |\n",
      "|    total_timesteps      | 5148672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014775149 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 30020        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | -0.94313556  |\n",
      "|    std                  | 79.6         |\n",
      "|    value_loss           | 61.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2515         |\n",
      "|    time_elapsed         | 48789        |\n",
      "|    total_timesteps      | 5150720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029214122 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.55         |\n",
      "|    n_updates            | 30030        |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    reward               | 0.43489867   |\n",
      "|    std                  | 79.8         |\n",
      "|    value_loss           | 11.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4968195.07\n",
      "total_reward: 3968195.07\n",
      "total_cost: 496021.48\n",
      "total_trades: 76896\n",
      "Sharpe: 0.843\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2516         |\n",
      "|    time_elapsed         | 48808        |\n",
      "|    total_timesteps      | 5152768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008458011 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 30040        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | -2.1005785   |\n",
      "|    std                  | 80           |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2517         |\n",
      "|    time_elapsed         | 48827        |\n",
      "|    total_timesteps      | 5154816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013558976 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -166         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 30050        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | -3.5506172   |\n",
      "|    std                  | 80.1         |\n",
      "|    value_loss           | 78.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2518         |\n",
      "|    time_elapsed         | 48847        |\n",
      "|    total_timesteps      | 5156864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017342963 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.15         |\n",
      "|    n_updates            | 30060        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 2.21936      |\n",
      "|    std                  | 80.3         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2519         |\n",
      "|    time_elapsed         | 48866        |\n",
      "|    total_timesteps      | 5158912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015013155 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 30070        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | -2.9238343   |\n",
      "|    std                  | 80.7         |\n",
      "|    value_loss           | 66.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2520         |\n",
      "|    time_elapsed         | 48885        |\n",
      "|    total_timesteps      | 5160960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013786713 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 30080        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | -1.2135099   |\n",
      "|    std                  | 81           |\n",
      "|    value_loss           | 71           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2521         |\n",
      "|    time_elapsed         | 48905        |\n",
      "|    total_timesteps      | 5163008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032432936 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 30090        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    reward               | 0.1279865    |\n",
      "|    std                  | 81.2         |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2522         |\n",
      "|    time_elapsed         | 48924        |\n",
      "|    total_timesteps      | 5165056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009803117 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.3         |\n",
      "|    n_updates            | 30100        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | 0.4441236    |\n",
      "|    std                  | 81.4         |\n",
      "|    value_loss           | 74.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2523          |\n",
      "|    time_elapsed         | 48943         |\n",
      "|    total_timesteps      | 5167104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061735115 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -167          |\n",
      "|    explained_variance   | 0.517         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.81          |\n",
      "|    n_updates            | 30110         |\n",
      "|    policy_gradient_loss | -0.00186      |\n",
      "|    reward               | 0.33400407    |\n",
      "|    std                  | 81.5          |\n",
      "|    value_loss           | 35.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2524         |\n",
      "|    time_elapsed         | 48962        |\n",
      "|    total_timesteps      | 5169152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007451782 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.32         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 30120        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | -2.2106395   |\n",
      "|    std                  | 81.6         |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2525         |\n",
      "|    time_elapsed         | 48981        |\n",
      "|    total_timesteps      | 5171200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069535836 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | -0.0254      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.18         |\n",
      "|    n_updates            | 30130        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | 2.2496834    |\n",
      "|    std                  | 81.9         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2526        |\n",
      "|    time_elapsed         | 49000       |\n",
      "|    total_timesteps      | 5173248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000602533 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -167        |\n",
      "|    explained_variance   | 0.0705      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 30140       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    reward               | 1.2782242   |\n",
      "|    std                  | 82          |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2527          |\n",
      "|    time_elapsed         | 49019         |\n",
      "|    total_timesteps      | 5175296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044900808 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -167          |\n",
      "|    explained_variance   | 0.439         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.5          |\n",
      "|    n_updates            | 30150         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | 1.4494171     |\n",
      "|    std                  | 82.1          |\n",
      "|    value_loss           | 37.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2528        |\n",
      "|    time_elapsed         | 49039       |\n",
      "|    total_timesteps      | 5177344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003276189 |\n",
      "|    clip_fraction        | 0.00747     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -167        |\n",
      "|    explained_variance   | 0.0276      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 30160       |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | -0.33590654 |\n",
      "|    std                  | 82.1        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2529         |\n",
      "|    time_elapsed         | 49058        |\n",
      "|    total_timesteps      | 5179392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012185535 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.32         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 30170        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -0.24363121  |\n",
      "|    std                  | 82.3         |\n",
      "|    value_loss           | 42.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2363547.80\n",
      "total_reward: 1363547.80\n",
      "total_cost: 465921.94\n",
      "total_trades: 75546\n",
      "Sharpe: 0.516\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2530        |\n",
      "|    time_elapsed         | 49077       |\n",
      "|    total_timesteps      | 5181440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000287357 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -167        |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 30180       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    reward               | 0.4266846   |\n",
      "|    std                  | 82.4        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2531          |\n",
      "|    time_elapsed         | 49096         |\n",
      "|    total_timesteps      | 5183488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067447324 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -167          |\n",
      "|    explained_variance   | 0.6           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.2          |\n",
      "|    n_updates            | 30190         |\n",
      "|    policy_gradient_loss | -0.00241      |\n",
      "|    reward               | 1.2089779     |\n",
      "|    std                  | 82.4          |\n",
      "|    value_loss           | 31.9          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2532         |\n",
      "|    time_elapsed         | 49115        |\n",
      "|    total_timesteps      | 5185536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051450124 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.148        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.27         |\n",
      "|    n_updates            | 30200        |\n",
      "|    policy_gradient_loss | -0.0093      |\n",
      "|    reward               | 0.9313772    |\n",
      "|    std                  | 82.7         |\n",
      "|    value_loss           | 12.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2533          |\n",
      "|    time_elapsed         | 49135         |\n",
      "|    total_timesteps      | 5187584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090378587 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -167          |\n",
      "|    explained_variance   | 0.456         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18            |\n",
      "|    n_updates            | 30210         |\n",
      "|    policy_gradient_loss | -0.00275      |\n",
      "|    reward               | 2.4749782     |\n",
      "|    std                  | 83            |\n",
      "|    value_loss           | 37.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2534         |\n",
      "|    time_elapsed         | 49154        |\n",
      "|    total_timesteps      | 5189632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008484926 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -167         |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 30220        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | -5.696066    |\n",
      "|    std                  | 83.1         |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2535         |\n",
      "|    time_elapsed         | 49174        |\n",
      "|    total_timesteps      | 5191680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052972496 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.00772      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.29         |\n",
      "|    n_updates            | 30230        |\n",
      "|    policy_gradient_loss | -0.00789     |\n",
      "|    reward               | -2.7635224   |\n",
      "|    std                  | 83.4         |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2536         |\n",
      "|    time_elapsed         | 49193        |\n",
      "|    total_timesteps      | 5193728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004717942 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 30240        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | 0.106799155  |\n",
      "|    std                  | 83.6         |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2537         |\n",
      "|    time_elapsed         | 49212        |\n",
      "|    total_timesteps      | 5195776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006230913 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 30250        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 6.2509623    |\n",
      "|    std                  | 83.6         |\n",
      "|    value_loss           | 41.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2538         |\n",
      "|    time_elapsed         | 49231        |\n",
      "|    total_timesteps      | 5197824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005084858 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 30260        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | -0.07193554  |\n",
      "|    std                  | 83.7         |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2539         |\n",
      "|    time_elapsed         | 49251        |\n",
      "|    total_timesteps      | 5199872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053956527 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | -0.265       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.13         |\n",
      "|    n_updates            | 30270        |\n",
      "|    policy_gradient_loss | -0.0084      |\n",
      "|    reward               | -0.2882688   |\n",
      "|    std                  | 84.1         |\n",
      "|    value_loss           | 15.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2540         |\n",
      "|    time_elapsed         | 49270        |\n",
      "|    total_timesteps      | 5201920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005261901 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.0283       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.6         |\n",
      "|    n_updates            | 30280        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 0.727562     |\n",
      "|    std                  | 84.3         |\n",
      "|    value_loss           | 68.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2541          |\n",
      "|    time_elapsed         | 49290         |\n",
      "|    total_timesteps      | 5203968       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049884454 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -168          |\n",
      "|    explained_variance   | 0.355         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.91          |\n",
      "|    n_updates            | 30290         |\n",
      "|    policy_gradient_loss | -0.00214      |\n",
      "|    reward               | 2.0950017     |\n",
      "|    std                  | 84.5          |\n",
      "|    value_loss           | 40.9          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2542         |\n",
      "|    time_elapsed         | 49309        |\n",
      "|    total_timesteps      | 5206016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047125695 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.0729       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.03         |\n",
      "|    n_updates            | 30300        |\n",
      "|    policy_gradient_loss | -0.00737     |\n",
      "|    reward               | -1.9546947   |\n",
      "|    std                  | 84.6         |\n",
      "|    value_loss           | 15           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2543          |\n",
      "|    time_elapsed         | 49328         |\n",
      "|    total_timesteps      | 5208064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074770773 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -168          |\n",
      "|    explained_variance   | 0.402         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.3          |\n",
      "|    n_updates            | 30310         |\n",
      "|    policy_gradient_loss | -0.0019       |\n",
      "|    reward               | 0.23434249    |\n",
      "|    std                  | 84.7          |\n",
      "|    value_loss           | 41.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2544          |\n",
      "|    time_elapsed         | 49347         |\n",
      "|    total_timesteps      | 5210112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060512393 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -168          |\n",
      "|    explained_variance   | 0.476         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.54          |\n",
      "|    n_updates            | 30320         |\n",
      "|    policy_gradient_loss | -0.00228      |\n",
      "|    reward               | 2.5251863     |\n",
      "|    std                  | 84.8          |\n",
      "|    value_loss           | 27.7          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3083470.15\n",
      "total_reward: 2083470.15\n",
      "total_cost: 500239.99\n",
      "total_trades: 77529\n",
      "Sharpe: 0.682\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2545        |\n",
      "|    time_elapsed         | 49367       |\n",
      "|    total_timesteps      | 5212160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005223085 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -168        |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 30330       |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    reward               | -0.6609738  |\n",
      "|    std                  | 85.1        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2546        |\n",
      "|    time_elapsed         | 49386       |\n",
      "|    total_timesteps      | 5214208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003829063 |\n",
      "|    clip_fraction        | 0.00615     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -168        |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 30340       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | 0.770453    |\n",
      "|    std                  | 85.4        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2547         |\n",
      "|    time_elapsed         | 49405        |\n",
      "|    total_timesteps      | 5216256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010678795 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 30350        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | 0.5002811    |\n",
      "|    std                  | 85.5         |\n",
      "|    value_loss           | 48           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2548       |\n",
      "|    time_elapsed         | 49425      |\n",
      "|    total_timesteps      | 5218304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00066656 |\n",
      "|    clip_fraction        | 0.000342   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -168       |\n",
      "|    explained_variance   | 0.194      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.4       |\n",
      "|    n_updates            | 30360      |\n",
      "|    policy_gradient_loss | -0.00253   |\n",
      "|    reward               | 0.33261988 |\n",
      "|    std                  | 85.7       |\n",
      "|    value_loss           | 84         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2549        |\n",
      "|    time_elapsed         | 49445       |\n",
      "|    total_timesteps      | 5220352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004591341 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -168        |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.13        |\n",
      "|    n_updates            | 30370       |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    reward               | 0.4574296   |\n",
      "|    std                  | 85.8        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2550          |\n",
      "|    time_elapsed         | 49464         |\n",
      "|    total_timesteps      | 5222400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041925727 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -168          |\n",
      "|    explained_variance   | 0.601         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13            |\n",
      "|    n_updates            | 30380         |\n",
      "|    policy_gradient_loss | -0.00146      |\n",
      "|    reward               | 0.31730166    |\n",
      "|    std                  | 86            |\n",
      "|    value_loss           | 42.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2551         |\n",
      "|    time_elapsed         | 49483        |\n",
      "|    total_timesteps      | 5224448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011262759 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -168         |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.4         |\n",
      "|    n_updates            | 30390        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | -3.1595929   |\n",
      "|    std                  | 86.1         |\n",
      "|    value_loss           | 64.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2552         |\n",
      "|    time_elapsed         | 49502        |\n",
      "|    total_timesteps      | 5226496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025526877 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.0621       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 30400        |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | -0.7968198   |\n",
      "|    std                  | 86.3         |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2553          |\n",
      "|    time_elapsed         | 49521         |\n",
      "|    total_timesteps      | 5228544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086166715 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -169          |\n",
      "|    explained_variance   | 0.422         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.4          |\n",
      "|    n_updates            | 30410         |\n",
      "|    policy_gradient_loss | -0.00313      |\n",
      "|    reward               | 0.9048876     |\n",
      "|    std                  | 86.3          |\n",
      "|    value_loss           | 37.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2554         |\n",
      "|    time_elapsed         | 49541        |\n",
      "|    total_timesteps      | 5230592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014881724 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.348        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 30420        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | 0.1401948    |\n",
      "|    std                  | 86.4         |\n",
      "|    value_loss           | 75.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2555        |\n",
      "|    time_elapsed         | 49560       |\n",
      "|    total_timesteps      | 5232640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000296204 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -169        |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.1        |\n",
      "|    n_updates            | 30430       |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    reward               | 0.75662804  |\n",
      "|    std                  | 86.5        |\n",
      "|    value_loss           | 79.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2556        |\n",
      "|    time_elapsed         | 49580       |\n",
      "|    total_timesteps      | 5234688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004079628 |\n",
      "|    clip_fraction        | 0.00835     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -169        |\n",
      "|    explained_variance   | -0.0654     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.63        |\n",
      "|    n_updates            | 30440       |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 1.5543395   |\n",
      "|    std                  | 86.9        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2557         |\n",
      "|    time_elapsed         | 49599        |\n",
      "|    total_timesteps      | 5236736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007164326 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 30450        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | -0.22676446  |\n",
      "|    std                  | 86.9         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2558         |\n",
      "|    time_elapsed         | 49618        |\n",
      "|    total_timesteps      | 5238784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005931588 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 30460        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | 0.13885897   |\n",
      "|    std                  | 87           |\n",
      "|    value_loss           | 48           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3390035.48\n",
      "total_reward: 2390035.48\n",
      "total_cost: 491420.91\n",
      "total_trades: 76866\n",
      "Sharpe: 0.704\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2559          |\n",
      "|    time_elapsed         | 49637         |\n",
      "|    total_timesteps      | 5240832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094683183 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -169          |\n",
      "|    explained_variance   | 0.0146        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.66          |\n",
      "|    n_updates            | 30470         |\n",
      "|    policy_gradient_loss | -0.00273      |\n",
      "|    reward               | 1.0341825     |\n",
      "|    std                  | 86.9          |\n",
      "|    value_loss           | 18.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2560          |\n",
      "|    time_elapsed         | 49657         |\n",
      "|    total_timesteps      | 5242880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068348367 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -169          |\n",
      "|    explained_variance   | 0.585         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.2          |\n",
      "|    n_updates            | 30480         |\n",
      "|    policy_gradient_loss | -0.00208      |\n",
      "|    reward               | -0.5345366    |\n",
      "|    std                  | 86.9          |\n",
      "|    value_loss           | 34.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2561         |\n",
      "|    time_elapsed         | 49676        |\n",
      "|    total_timesteps      | 5244928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020344735 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 30490        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | -5.2812977   |\n",
      "|    std                  | 87.1         |\n",
      "|    value_loss           | 48           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2562        |\n",
      "|    time_elapsed         | 49696       |\n",
      "|    total_timesteps      | 5246976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00185297  |\n",
      "|    clip_fraction        | 0.00146     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -169        |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 30500       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | -0.43828547 |\n",
      "|    std                  | 87.5        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2563         |\n",
      "|    time_elapsed         | 49717        |\n",
      "|    total_timesteps      | 5249024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031956304 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | -0.0302      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.6          |\n",
      "|    n_updates            | 30510        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | -2.0084722   |\n",
      "|    std                  | 87.9         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2564         |\n",
      "|    time_elapsed         | 49736        |\n",
      "|    total_timesteps      | 5251072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013873016 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 30520        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | 1.1696883    |\n",
      "|    std                  | 88.1         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2565         |\n",
      "|    time_elapsed         | 49756        |\n",
      "|    total_timesteps      | 5253120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004972287 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.4         |\n",
      "|    n_updates            | 30530        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 4.4581423    |\n",
      "|    std                  | 88.3         |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2566         |\n",
      "|    time_elapsed         | 49775        |\n",
      "|    total_timesteps      | 5255168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025754897 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.24         |\n",
      "|    n_updates            | 30540        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | 0.7162583    |\n",
      "|    std                  | 88.5         |\n",
      "|    value_loss           | 17           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2567         |\n",
      "|    time_elapsed         | 49794        |\n",
      "|    total_timesteps      | 5257216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019135685 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 30550        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | -0.3469936   |\n",
      "|    std                  | 88.6         |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2568         |\n",
      "|    time_elapsed         | 49814        |\n",
      "|    total_timesteps      | 5259264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007552975 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.173        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 30560        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | -0.22985534  |\n",
      "|    std                  | 88.6         |\n",
      "|    value_loss           | 53.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2569          |\n",
      "|    time_elapsed         | 49833         |\n",
      "|    total_timesteps      | 5261312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044560374 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -169          |\n",
      "|    explained_variance   | -0.896        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.5          |\n",
      "|    n_updates            | 30570         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | -0.14210406   |\n",
      "|    std                  | 88.7          |\n",
      "|    value_loss           | 29.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2570         |\n",
      "|    time_elapsed         | 49852        |\n",
      "|    total_timesteps      | 5263360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008857672 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36           |\n",
      "|    n_updates            | 30580        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | -0.025020858 |\n",
      "|    std                  | 88.7         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2571         |\n",
      "|    time_elapsed         | 49871        |\n",
      "|    total_timesteps      | 5265408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011043167 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -169         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 30590        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | 0.2317859    |\n",
      "|    std                  | 89           |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2572         |\n",
      "|    time_elapsed         | 49890        |\n",
      "|    total_timesteps      | 5267456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023381421 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0.0868       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 30600        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | 0.508848     |\n",
      "|    std                  | 89.4         |\n",
      "|    value_loss           | 64.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3047376.56\n",
      "total_reward: 2047376.56\n",
      "total_cost: 524182.57\n",
      "total_trades: 78493\n",
      "Sharpe: 0.650\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2573         |\n",
      "|    time_elapsed         | 49910        |\n",
      "|    total_timesteps      | 5269504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031468226 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.98         |\n",
      "|    n_updates            | 30610        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    reward               | 0.48934832   |\n",
      "|    std                  | 89.5         |\n",
      "|    value_loss           | 13.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2574          |\n",
      "|    time_elapsed         | 49929         |\n",
      "|    total_timesteps      | 5271552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094218954 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -170          |\n",
      "|    explained_variance   | 0.125         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20            |\n",
      "|    n_updates            | 30620         |\n",
      "|    policy_gradient_loss | -0.00335      |\n",
      "|    reward               | 0.82701075    |\n",
      "|    std                  | 89.7          |\n",
      "|    value_loss           | 51.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2575         |\n",
      "|    time_elapsed         | 49948        |\n",
      "|    total_timesteps      | 5273600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006297034 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 30630        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | -0.055926308 |\n",
      "|    std                  | 89.9         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2576         |\n",
      "|    time_elapsed         | 49968        |\n",
      "|    total_timesteps      | 5275648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012852737 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | -0.00945     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.78         |\n",
      "|    n_updates            | 30640        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | 0.40319008   |\n",
      "|    std                  | 90.1         |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2577         |\n",
      "|    time_elapsed         | 49987        |\n",
      "|    total_timesteps      | 5277696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010521624 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0.0317       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 30650        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 0.059672352  |\n",
      "|    std                  | 90.4         |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2578         |\n",
      "|    time_elapsed         | 50006        |\n",
      "|    total_timesteps      | 5279744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009392133 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 30660        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -0.24068895  |\n",
      "|    std                  | 90.4         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2579          |\n",
      "|    time_elapsed         | 50026         |\n",
      "|    total_timesteps      | 5281792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00059150637 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -170          |\n",
      "|    explained_variance   | 0.143         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 33.3          |\n",
      "|    n_updates            | 30670         |\n",
      "|    policy_gradient_loss | -0.00243      |\n",
      "|    reward               | -1.4315507    |\n",
      "|    std                  | 90.4          |\n",
      "|    value_loss           | 57.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2580         |\n",
      "|    time_elapsed         | 50045        |\n",
      "|    total_timesteps      | 5283840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026177254 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | -0.000344    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.58         |\n",
      "|    n_updates            | 30680        |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    reward               | 2.2320807    |\n",
      "|    std                  | 90.6         |\n",
      "|    value_loss           | 13.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2581         |\n",
      "|    time_elapsed         | 50064        |\n",
      "|    total_timesteps      | 5285888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009877805 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.06         |\n",
      "|    n_updates            | 30690        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | -0.4588415   |\n",
      "|    std                  | 90.8         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2582         |\n",
      "|    time_elapsed         | 50084        |\n",
      "|    total_timesteps      | 5287936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009043075 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 30700        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | -0.67979157  |\n",
      "|    std                  | 90.9         |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2583         |\n",
      "|    time_elapsed         | 50103        |\n",
      "|    total_timesteps      | 5289984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053599915 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | -0.01        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.77         |\n",
      "|    n_updates            | 30710        |\n",
      "|    policy_gradient_loss | -0.00839     |\n",
      "|    reward               | 0.9015448    |\n",
      "|    std                  | 91           |\n",
      "|    value_loss           | 14.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2584         |\n",
      "|    time_elapsed         | 50123        |\n",
      "|    total_timesteps      | 5292032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006990138 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.58         |\n",
      "|    n_updates            | 30720        |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | -0.7757149   |\n",
      "|    std                  | 91           |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2585         |\n",
      "|    time_elapsed         | 50143        |\n",
      "|    total_timesteps      | 5294080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005481583 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.88         |\n",
      "|    n_updates            | 30730        |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    reward               | -3.8642972   |\n",
      "|    std                  | 91.2         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2586          |\n",
      "|    time_elapsed         | 50162         |\n",
      "|    total_timesteps      | 5296128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077320484 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -170          |\n",
      "|    explained_variance   | 0.225         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.6          |\n",
      "|    n_updates            | 30740         |\n",
      "|    policy_gradient_loss | -0.00292      |\n",
      "|    reward               | -0.65001535   |\n",
      "|    std                  | 91.3          |\n",
      "|    value_loss           | 37.2          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4352466.32\n",
      "total_reward: 3352466.32\n",
      "total_cost: 522461.07\n",
      "total_trades: 78054\n",
      "Sharpe: 0.796\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2587         |\n",
      "|    time_elapsed         | 50181        |\n",
      "|    total_timesteps      | 5298176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014190208 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.4         |\n",
      "|    n_updates            | 30750        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 0.09937571   |\n",
      "|    std                  | 91.4         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2588         |\n",
      "|    time_elapsed         | 50200        |\n",
      "|    total_timesteps      | 5300224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012306676 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -170         |\n",
      "|    explained_variance   | 0.00184      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 30760        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 0.23381732   |\n",
      "|    std                  | 91.4         |\n",
      "|    value_loss           | 84.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2589          |\n",
      "|    time_elapsed         | 50220         |\n",
      "|    total_timesteps      | 5302272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079966296 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -170          |\n",
      "|    explained_variance   | 0.379         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.6          |\n",
      "|    n_updates            | 30770         |\n",
      "|    policy_gradient_loss | -0.00271      |\n",
      "|    reward               | 6.7420144     |\n",
      "|    std                  | 91.6          |\n",
      "|    value_loss           | 43.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2590        |\n",
      "|    time_elapsed         | 50239       |\n",
      "|    total_timesteps      | 5304320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004855778 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -170        |\n",
      "|    explained_variance   | 0.00514     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.37        |\n",
      "|    n_updates            | 30780       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 2.9596384   |\n",
      "|    std                  | 92.3        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2591          |\n",
      "|    time_elapsed         | 50258         |\n",
      "|    total_timesteps      | 5306368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045103638 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -171          |\n",
      "|    explained_variance   | 0.419         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.4          |\n",
      "|    n_updates            | 30790         |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    reward               | 1.1426644     |\n",
      "|    std                  | 92.5          |\n",
      "|    value_loss           | 59.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2592          |\n",
      "|    time_elapsed         | 50277         |\n",
      "|    total_timesteps      | 5308416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014287079 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -171          |\n",
      "|    explained_variance   | 0.475         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6             |\n",
      "|    n_updates            | 30800         |\n",
      "|    policy_gradient_loss | -0.000758     |\n",
      "|    reward               | -0.0043016626 |\n",
      "|    std                  | 92.5          |\n",
      "|    value_loss           | 44.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2593         |\n",
      "|    time_elapsed         | 50296        |\n",
      "|    total_timesteps      | 5310464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012064619 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -171         |\n",
      "|    explained_variance   | -0.244       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.26         |\n",
      "|    n_updates            | 30810        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | 2.211421     |\n",
      "|    std                  | 92.7         |\n",
      "|    value_loss           | 16.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2594         |\n",
      "|    time_elapsed         | 50315        |\n",
      "|    total_timesteps      | 5312512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010588279 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -171         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 30820        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | -0.07776885  |\n",
      "|    std                  | 92.8         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2595         |\n",
      "|    time_elapsed         | 50335        |\n",
      "|    total_timesteps      | 5314560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009495504 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -171         |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 30830        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | -0.25934434  |\n",
      "|    std                  | 93.1         |\n",
      "|    value_loss           | 38.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2596          |\n",
      "|    time_elapsed         | 50354         |\n",
      "|    total_timesteps      | 5316608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035123742 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -171          |\n",
      "|    explained_variance   | 0.519         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.6          |\n",
      "|    n_updates            | 30840         |\n",
      "|    policy_gradient_loss | -0.00134      |\n",
      "|    reward               | 0.8571379     |\n",
      "|    std                  | 93.2          |\n",
      "|    value_loss           | 42.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2597         |\n",
      "|    time_elapsed         | 50373        |\n",
      "|    total_timesteps      | 5318656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034095512 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -171         |\n",
      "|    explained_variance   | 0.000305     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.66         |\n",
      "|    n_updates            | 30850        |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | -1.707148    |\n",
      "|    std                  | 93.6         |\n",
      "|    value_loss           | 15.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2598          |\n",
      "|    time_elapsed         | 50392         |\n",
      "|    total_timesteps      | 5320704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077616214 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -171          |\n",
      "|    explained_variance   | 0.427         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.7          |\n",
      "|    n_updates            | 30860         |\n",
      "|    policy_gradient_loss | -0.00275      |\n",
      "|    reward               | -1.6473659    |\n",
      "|    std                  | 93.7          |\n",
      "|    value_loss           | 42.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2599         |\n",
      "|    time_elapsed         | 50411        |\n",
      "|    total_timesteps      | 5322752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007928407 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -171         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 30870        |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    reward               | 2.2157373    |\n",
      "|    std                  | 93.8         |\n",
      "|    value_loss           | 51.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2600         |\n",
      "|    time_elapsed         | 50431        |\n",
      "|    total_timesteps      | 5324800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016434595 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -171         |\n",
      "|    explained_variance   | -0.0647      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 30880        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -3.308951    |\n",
      "|    std                  | 94           |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2997013.37\n",
      "total_reward: 1997013.37\n",
      "total_cost: 500401.49\n",
      "total_trades: 77440\n",
      "Sharpe: 0.637\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2601         |\n",
      "|    time_elapsed         | 50450        |\n",
      "|    total_timesteps      | 5326848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033599227 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -171         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 30890        |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    reward               | 1.6630782    |\n",
      "|    std                  | 94           |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2602          |\n",
      "|    time_elapsed         | 50469         |\n",
      "|    total_timesteps      | 5328896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038968245 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -171          |\n",
      "|    explained_variance   | 0.626         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.6          |\n",
      "|    n_updates            | 30900         |\n",
      "|    policy_gradient_loss | -0.00166      |\n",
      "|    reward               | -1.0467641    |\n",
      "|    std                  | 94.2          |\n",
      "|    value_loss           | 42.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2603          |\n",
      "|    time_elapsed         | 50489         |\n",
      "|    total_timesteps      | 5330944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065200886 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -171          |\n",
      "|    explained_variance   | 0.604         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.7          |\n",
      "|    n_updates            | 30910         |\n",
      "|    policy_gradient_loss | -0.00256      |\n",
      "|    reward               | 0.85719377    |\n",
      "|    std                  | 94.2          |\n",
      "|    value_loss           | 46.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2604        |\n",
      "|    time_elapsed         | 50508       |\n",
      "|    total_timesteps      | 5332992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004088335 |\n",
      "|    clip_fraction        | 0.00908     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -171        |\n",
      "|    explained_variance   | -0.272      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.62        |\n",
      "|    n_updates            | 30920       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -1.2253832  |\n",
      "|    std                  | 94.2        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2605        |\n",
      "|    time_elapsed         | 50528       |\n",
      "|    total_timesteps      | 5335040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001322729 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -171        |\n",
      "|    explained_variance   | -0.0352     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 30930       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    reward               | 1.4109033   |\n",
      "|    std                  | 94.6        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2606        |\n",
      "|    time_elapsed         | 50546       |\n",
      "|    total_timesteps      | 5337088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001188469 |\n",
      "|    clip_fraction        | 9.77e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -171        |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 30940       |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | -0.79985565 |\n",
      "|    std                  | 94.6        |\n",
      "|    value_loss           | 50          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2607        |\n",
      "|    time_elapsed         | 50566       |\n",
      "|    total_timesteps      | 5339136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005279595 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -171        |\n",
      "|    explained_variance   | 0.000295    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.06        |\n",
      "|    n_updates            | 30950       |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    reward               | -1.6830467  |\n",
      "|    std                  | 95.1        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2608         |\n",
      "|    time_elapsed         | 50585        |\n",
      "|    total_timesteps      | 5341184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013895619 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -171         |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 30960        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | 0.30719042   |\n",
      "|    std                  | 95.3         |\n",
      "|    value_loss           | 35           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2609         |\n",
      "|    time_elapsed         | 50605        |\n",
      "|    total_timesteps      | 5343232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018532015 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -171         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 30970        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | 0.19761741   |\n",
      "|    std                  | 95.6         |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2610         |\n",
      "|    time_elapsed         | 50624        |\n",
      "|    total_timesteps      | 5345280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028209602 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 30980        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | 0.13835542   |\n",
      "|    std                  | 95.9         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2611         |\n",
      "|    time_elapsed         | 50643        |\n",
      "|    total_timesteps      | 5347328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013195132 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 30990        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -0.22328342  |\n",
      "|    std                  | 96.1         |\n",
      "|    value_loss           | 68.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2612          |\n",
      "|    time_elapsed         | 50662         |\n",
      "|    total_timesteps      | 5349376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037913403 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -172          |\n",
      "|    explained_variance   | 0.511         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.9          |\n",
      "|    n_updates            | 31000         |\n",
      "|    policy_gradient_loss | -0.0018       |\n",
      "|    reward               | 0.64592546    |\n",
      "|    std                  | 96.1          |\n",
      "|    value_loss           | 52.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2613         |\n",
      "|    time_elapsed         | 50682        |\n",
      "|    total_timesteps      | 5351424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006217711 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0.113        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 31010        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 0.992988     |\n",
      "|    std                  | 96.3         |\n",
      "|    value_loss           | 53.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2614        |\n",
      "|    time_elapsed         | 50701       |\n",
      "|    total_timesteps      | 5353472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001857344 |\n",
      "|    clip_fraction        | 0.00151     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -172        |\n",
      "|    explained_variance   | -0.625      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.58        |\n",
      "|    n_updates            | 31020       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | 0.1406552   |\n",
      "|    std                  | 96.5        |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4001999.50\n",
      "total_reward: 3001999.50\n",
      "total_cost: 524482.04\n",
      "total_trades: 78206\n",
      "Sharpe: 0.770\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2615         |\n",
      "|    time_elapsed         | 50720        |\n",
      "|    total_timesteps      | 5355520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002837647 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 31030        |\n",
      "|    policy_gradient_loss | -0.000846    |\n",
      "|    reward               | -1.1329572   |\n",
      "|    std                  | 96.6         |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2616         |\n",
      "|    time_elapsed         | 50739        |\n",
      "|    total_timesteps      | 5357568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023090276 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0.00165      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 31040        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | 1.0694684    |\n",
      "|    std                  | 96.9         |\n",
      "|    value_loss           | 83           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2617        |\n",
      "|    time_elapsed         | 50759       |\n",
      "|    total_timesteps      | 5359616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003338404 |\n",
      "|    clip_fraction        | 0.00483     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -172        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.47        |\n",
      "|    n_updates            | 31050       |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    reward               | 4.1778383   |\n",
      "|    std                  | 97.5        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2618         |\n",
      "|    time_elapsed         | 50778        |\n",
      "|    total_timesteps      | 5361664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008135537 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 31060        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | 0.03596502   |\n",
      "|    std                  | 97.7         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2619         |\n",
      "|    time_elapsed         | 50798        |\n",
      "|    total_timesteps      | 5363712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007705069 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 31070        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -1.1204447   |\n",
      "|    std                  | 97.8         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2620         |\n",
      "|    time_elapsed         | 50817        |\n",
      "|    total_timesteps      | 5365760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010808636 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 31080        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | 0.5023697    |\n",
      "|    std                  | 98           |\n",
      "|    value_loss           | 53.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2621         |\n",
      "|    time_elapsed         | 50837        |\n",
      "|    total_timesteps      | 5367808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039017566 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.57         |\n",
      "|    n_updates            | 31090        |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    reward               | 0.6379249    |\n",
      "|    std                  | 98.5         |\n",
      "|    value_loss           | 13.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2622          |\n",
      "|    time_elapsed         | 50856         |\n",
      "|    total_timesteps      | 5369856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041707983 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -172          |\n",
      "|    explained_variance   | 0.0548        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.7          |\n",
      "|    n_updates            | 31100         |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    reward               | 0.4773693     |\n",
      "|    std                  | 98.6          |\n",
      "|    value_loss           | 46.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2623         |\n",
      "|    time_elapsed         | 50876        |\n",
      "|    total_timesteps      | 5371904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009761018 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0.0927       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 31110        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 3.3265321    |\n",
      "|    std                  | 98.9         |\n",
      "|    value_loss           | 65           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2624         |\n",
      "|    time_elapsed         | 50895        |\n",
      "|    total_timesteps      | 5373952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017859233 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | -0.868       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.42         |\n",
      "|    n_updates            | 31120        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -1.8326244   |\n",
      "|    std                  | 99.1         |\n",
      "|    value_loss           | 15           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2625         |\n",
      "|    time_elapsed         | 50914        |\n",
      "|    total_timesteps      | 5376000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014272174 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 31130        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 0.6222337    |\n",
      "|    std                  | 99.1         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2626         |\n",
      "|    time_elapsed         | 50933        |\n",
      "|    total_timesteps      | 5378048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008101999 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -172         |\n",
      "|    explained_variance   | 0.0784       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 31140        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | -2.4893851   |\n",
      "|    std                  | 99.2         |\n",
      "|    value_loss           | 86.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2627         |\n",
      "|    time_elapsed         | 50952        |\n",
      "|    total_timesteps      | 5380096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017721937 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 31150        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | 0.15886681   |\n",
      "|    std                  | 99.3         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2628         |\n",
      "|    time_elapsed         | 50971        |\n",
      "|    total_timesteps      | 5382144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013659056 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.0588       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.68         |\n",
      "|    n_updates            | 31160        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | -0.71272576  |\n",
      "|    std                  | 99.5         |\n",
      "|    value_loss           | 15.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3136427.94\n",
      "total_reward: 2136427.94\n",
      "total_cost: 516996.95\n",
      "total_trades: 77927\n",
      "Sharpe: 0.664\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2629         |\n",
      "|    time_elapsed         | 50990        |\n",
      "|    total_timesteps      | 5384192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005423181 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.28         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 31170        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | -0.2322522   |\n",
      "|    std                  | 99.4         |\n",
      "|    value_loss           | 53.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2630         |\n",
      "|    time_elapsed         | 51009        |\n",
      "|    total_timesteps      | 5386240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011007218 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 31180        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | 3.4603894    |\n",
      "|    std                  | 99.6         |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2631         |\n",
      "|    time_elapsed         | 51028        |\n",
      "|    total_timesteps      | 5388288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019245937 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | -0.0199      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.86         |\n",
      "|    n_updates            | 31190        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | 0.9652773    |\n",
      "|    std                  | 99.9         |\n",
      "|    value_loss           | 12.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2632          |\n",
      "|    time_elapsed         | 51048         |\n",
      "|    total_timesteps      | 5390336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036256088 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -173          |\n",
      "|    explained_variance   | 0.554         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.73          |\n",
      "|    n_updates            | 31200         |\n",
      "|    policy_gradient_loss | -0.00146      |\n",
      "|    reward               | -2.7113016    |\n",
      "|    std                  | 99.9          |\n",
      "|    value_loss           | 41            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2633         |\n",
      "|    time_elapsed         | 51067        |\n",
      "|    total_timesteps      | 5392384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015504619 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.0981       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 31210        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | 2.2162743    |\n",
      "|    std                  | 100          |\n",
      "|    value_loss           | 73.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2634         |\n",
      "|    time_elapsed         | 51086        |\n",
      "|    total_timesteps      | 5394432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018028297 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.00393      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.91         |\n",
      "|    n_updates            | 31220        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | -0.99962306  |\n",
      "|    std                  | 100          |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2635         |\n",
      "|    time_elapsed         | 51106        |\n",
      "|    total_timesteps      | 5396480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008109033 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 31230        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | -0.5067646   |\n",
      "|    std                  | 101          |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2636         |\n",
      "|    time_elapsed         | 51125        |\n",
      "|    total_timesteps      | 5398528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010621806 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 31240        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | 1.1701584    |\n",
      "|    std                  | 101          |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2637          |\n",
      "|    time_elapsed         | 51144         |\n",
      "|    total_timesteps      | 5400576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053355895 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -173          |\n",
      "|    explained_variance   | 0.164         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.17          |\n",
      "|    n_updates            | 31250         |\n",
      "|    policy_gradient_loss | -0.00168      |\n",
      "|    reward               | 2.199938      |\n",
      "|    std                  | 101           |\n",
      "|    value_loss           | 53.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2638         |\n",
      "|    time_elapsed         | 51164        |\n",
      "|    total_timesteps      | 5402624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018102233 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.15         |\n",
      "|    n_updates            | 31260        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -2.3746958   |\n",
      "|    std                  | 101          |\n",
      "|    value_loss           | 13.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2639          |\n",
      "|    time_elapsed         | 51183         |\n",
      "|    total_timesteps      | 5404672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019332446 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -173          |\n",
      "|    explained_variance   | 0.465         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 37.5          |\n",
      "|    n_updates            | 31270         |\n",
      "|    policy_gradient_loss | -0.000776     |\n",
      "|    reward               | 0.7256856     |\n",
      "|    std                  | 101           |\n",
      "|    value_loss           | 65.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2640          |\n",
      "|    time_elapsed         | 51203         |\n",
      "|    total_timesteps      | 5406720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045229687 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -173          |\n",
      "|    explained_variance   | 0.341         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.2          |\n",
      "|    n_updates            | 31280         |\n",
      "|    policy_gradient_loss | -0.00229      |\n",
      "|    reward               | -0.86806655   |\n",
      "|    std                  | 101           |\n",
      "|    value_loss           | 56.7          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2641        |\n",
      "|    time_elapsed         | 51223       |\n",
      "|    total_timesteps      | 5408768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004471685 |\n",
      "|    clip_fraction        | 0.00854     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -173        |\n",
      "|    explained_variance   | -0.000431   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 31290       |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    reward               | 2.647003    |\n",
      "|    std                  | 102         |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2642         |\n",
      "|    time_elapsed         | 51242        |\n",
      "|    total_timesteps      | 5410816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005030073 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 31300        |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    reward               | 0.7127113    |\n",
      "|    std                  | 102          |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3342882.09\n",
      "total_reward: 2342882.09\n",
      "total_cost: 498768.00\n",
      "total_trades: 77224\n",
      "Sharpe: 0.722\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2643         |\n",
      "|    time_elapsed         | 51261        |\n",
      "|    total_timesteps      | 5412864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006173555 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.82         |\n",
      "|    n_updates            | 31310        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | 0.9465673    |\n",
      "|    std                  | 102          |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2644          |\n",
      "|    time_elapsed         | 51280         |\n",
      "|    total_timesteps      | 5414912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043052112 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -173          |\n",
      "|    explained_variance   | 0.394         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.4          |\n",
      "|    n_updates            | 31320         |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    reward               | 0.4243943     |\n",
      "|    std                  | 102           |\n",
      "|    value_loss           | 62.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2645         |\n",
      "|    time_elapsed         | 51299        |\n",
      "|    total_timesteps      | 5416960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039030889 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | -0.156       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.47         |\n",
      "|    n_updates            | 31330        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    reward               | -0.3995313   |\n",
      "|    std                  | 102          |\n",
      "|    value_loss           | 12.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2646          |\n",
      "|    time_elapsed         | 51318         |\n",
      "|    total_timesteps      | 5419008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054689404 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -173          |\n",
      "|    explained_variance   | 0.3           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10            |\n",
      "|    n_updates            | 31340         |\n",
      "|    policy_gradient_loss | -0.00158      |\n",
      "|    reward               | 3.137023      |\n",
      "|    std                  | 102           |\n",
      "|    value_loss           | 41.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2647          |\n",
      "|    time_elapsed         | 51338         |\n",
      "|    total_timesteps      | 5421056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058066816 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -173          |\n",
      "|    explained_variance   | 0.534         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.17          |\n",
      "|    n_updates            | 31350         |\n",
      "|    policy_gradient_loss | -0.002        |\n",
      "|    reward               | -0.30016556   |\n",
      "|    std                  | 102           |\n",
      "|    value_loss           | 41.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2648         |\n",
      "|    time_elapsed         | 51358        |\n",
      "|    total_timesteps      | 5423104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013049226 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | -0.000177    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.26         |\n",
      "|    n_updates            | 31360        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -0.4687016   |\n",
      "|    std                  | 103          |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2649        |\n",
      "|    time_elapsed         | 51377       |\n",
      "|    total_timesteps      | 5425152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000984406 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -173        |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 31370       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    reward               | -0.21272689 |\n",
      "|    std                  | 103         |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2650         |\n",
      "|    time_elapsed         | 51396        |\n",
      "|    total_timesteps      | 5427200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006949033 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 31380        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | -0.5929923   |\n",
      "|    std                  | 103          |\n",
      "|    value_loss           | 89.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2651         |\n",
      "|    time_elapsed         | 51415        |\n",
      "|    total_timesteps      | 5429248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011856954 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -173         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 31390        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 1.0565113    |\n",
      "|    std                  | 103          |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2652         |\n",
      "|    time_elapsed         | 51434        |\n",
      "|    total_timesteps      | 5431296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021762766 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | -0.0348      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.2          |\n",
      "|    n_updates            | 31400        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    reward               | 1.0054618    |\n",
      "|    std                  | 103          |\n",
      "|    value_loss           | 16.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2653         |\n",
      "|    time_elapsed         | 51453        |\n",
      "|    total_timesteps      | 5433344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.469143e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 31410        |\n",
      "|    policy_gradient_loss | -0.000422    |\n",
      "|    reward               | 0.5774733    |\n",
      "|    std                  | 103          |\n",
      "|    value_loss           | 94           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2654         |\n",
      "|    time_elapsed         | 51472        |\n",
      "|    total_timesteps      | 5435392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011265024 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.4         |\n",
      "|    n_updates            | 31420        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -1.102601    |\n",
      "|    std                  | 103          |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2655         |\n",
      "|    time_elapsed         | 51492        |\n",
      "|    total_timesteps      | 5437440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023313654 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | -0.0649      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.38         |\n",
      "|    n_updates            | 31430        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -2.6660137   |\n",
      "|    std                  | 103          |\n",
      "|    value_loss           | 13.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2656          |\n",
      "|    time_elapsed         | 51511         |\n",
      "|    total_timesteps      | 5439488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071917137 |\n",
      "|    clip_fraction        | 0.00107       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -174          |\n",
      "|    explained_variance   | 0.451         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.4          |\n",
      "|    n_updates            | 31440         |\n",
      "|    policy_gradient_loss | -0.0033       |\n",
      "|    reward               | -0.8500402    |\n",
      "|    std                  | 104           |\n",
      "|    value_loss           | 36.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2657         |\n",
      "|    time_elapsed         | 51530        |\n",
      "|    total_timesteps      | 5441536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005989058 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | 0.0341       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.1         |\n",
      "|    n_updates            | 31450        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | 0.028557861  |\n",
      "|    std                  | 104          |\n",
      "|    value_loss           | 81.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2517095.21\n",
      "total_reward: 1517095.21\n",
      "total_cost: 535129.27\n",
      "total_trades: 78722\n",
      "Sharpe: 0.551\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2658         |\n",
      "|    time_elapsed         | 51549        |\n",
      "|    total_timesteps      | 5443584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032311724 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | -0.067       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.43         |\n",
      "|    n_updates            | 31460        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | -2.322324    |\n",
      "|    std                  | 104          |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2659          |\n",
      "|    time_elapsed         | 51568         |\n",
      "|    total_timesteps      | 5445632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084466883 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -174          |\n",
      "|    explained_variance   | 0.27          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.56          |\n",
      "|    n_updates            | 31470         |\n",
      "|    policy_gradient_loss | -0.00277      |\n",
      "|    reward               | 3.5074255     |\n",
      "|    std                  | 104           |\n",
      "|    value_loss           | 32.2          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2660       |\n",
      "|    time_elapsed         | 51588      |\n",
      "|    total_timesteps      | 5447680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00014682 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -174       |\n",
      "|    explained_variance   | 0.164      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.2       |\n",
      "|    n_updates            | 31480      |\n",
      "|    policy_gradient_loss | -0.000633  |\n",
      "|    reward               | -0.2758521 |\n",
      "|    std                  | 104        |\n",
      "|    value_loss           | 80         |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2661          |\n",
      "|    time_elapsed         | 51607         |\n",
      "|    total_timesteps      | 5449728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038113628 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -174          |\n",
      "|    explained_variance   | 0.298         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.8          |\n",
      "|    n_updates            | 31490         |\n",
      "|    policy_gradient_loss | -0.000693     |\n",
      "|    reward               | 1.3522513     |\n",
      "|    std                  | 104           |\n",
      "|    value_loss           | 85.1          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2662         |\n",
      "|    time_elapsed         | 51626        |\n",
      "|    total_timesteps      | 5451776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015502826 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | -0.0175      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.72         |\n",
      "|    n_updates            | 31500        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | 1.1341411    |\n",
      "|    std                  | 105          |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2663         |\n",
      "|    time_elapsed         | 51646        |\n",
      "|    total_timesteps      | 5453824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012710559 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 31510        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | -0.17675452  |\n",
      "|    std                  | 105          |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2664          |\n",
      "|    time_elapsed         | 51666         |\n",
      "|    total_timesteps      | 5455872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036518314 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -174          |\n",
      "|    explained_variance   | 0.00529       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.1          |\n",
      "|    n_updates            | 31520         |\n",
      "|    policy_gradient_loss | -0.00273      |\n",
      "|    reward               | 1.0246928     |\n",
      "|    std                  | 105           |\n",
      "|    value_loss           | 87.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2665        |\n",
      "|    time_elapsed         | 51685       |\n",
      "|    total_timesteps      | 5457920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000919357 |\n",
      "|    clip_fraction        | 0.000684    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -174        |\n",
      "|    explained_variance   | -0.0338     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 31530       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    reward               | -0.758889   |\n",
      "|    std                  | 105         |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2666          |\n",
      "|    time_elapsed         | 51704         |\n",
      "|    total_timesteps      | 5459968       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030077336 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -174          |\n",
      "|    explained_variance   | 0.0984        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28            |\n",
      "|    n_updates            | 31540         |\n",
      "|    policy_gradient_loss | -0.00191      |\n",
      "|    reward               | 0.62509894    |\n",
      "|    std                  | 105           |\n",
      "|    value_loss           | 54.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2667          |\n",
      "|    time_elapsed         | 51724         |\n",
      "|    total_timesteps      | 5462016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033085956 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -174          |\n",
      "|    explained_variance   | 0.411         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.9          |\n",
      "|    n_updates            | 31550         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | -0.17104301   |\n",
      "|    std                  | 105           |\n",
      "|    value_loss           | 72.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2668          |\n",
      "|    time_elapsed         | 51743         |\n",
      "|    total_timesteps      | 5464064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028544056 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -174          |\n",
      "|    explained_variance   | 0.0268        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46.1          |\n",
      "|    n_updates            | 31560         |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    reward               | 0.08730717    |\n",
      "|    std                  | 105           |\n",
      "|    value_loss           | 113           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2669         |\n",
      "|    time_elapsed         | 51763        |\n",
      "|    total_timesteps      | 5466112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029385053 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | 0.00319      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.96         |\n",
      "|    n_updates            | 31570        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | 0.77367204   |\n",
      "|    std                  | 106          |\n",
      "|    value_loss           | 14.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2670         |\n",
      "|    time_elapsed         | 51782        |\n",
      "|    total_timesteps      | 5468160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009472617 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 31580        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 2.5055037    |\n",
      "|    std                  | 106          |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2671         |\n",
      "|    time_elapsed         | 51800        |\n",
      "|    total_timesteps      | 5470208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008621375 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 31590        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | 0.98203826   |\n",
      "|    std                  | 106          |\n",
      "|    value_loss           | 49.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4544973.61\n",
      "total_reward: 3544973.61\n",
      "total_cost: 508660.29\n",
      "total_trades: 77650\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2672         |\n",
      "|    time_elapsed         | 51819        |\n",
      "|    total_timesteps      | 5472256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029482292 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | -0.0198      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 31600        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    reward               | -1.0244257   |\n",
      "|    std                  | 106          |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2673         |\n",
      "|    time_elapsed         | 51838        |\n",
      "|    total_timesteps      | 5474304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004727023 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -174         |\n",
      "|    explained_variance   | 0.128        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.9         |\n",
      "|    n_updates            | 31610        |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    reward               | 2.8693018    |\n",
      "|    std                  | 106          |\n",
      "|    value_loss           | 94           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2674          |\n",
      "|    time_elapsed         | 51857         |\n",
      "|    total_timesteps      | 5476352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035138553 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -174          |\n",
      "|    explained_variance   | 0.526         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 44            |\n",
      "|    n_updates            | 31620         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | 1.2344093     |\n",
      "|    std                  | 106           |\n",
      "|    value_loss           | 52.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2675         |\n",
      "|    time_elapsed         | 51875        |\n",
      "|    total_timesteps      | 5478400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018724918 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -175         |\n",
      "|    explained_variance   | 0.0652       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 31630        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | -1.1612904   |\n",
      "|    std                  | 106          |\n",
      "|    value_loss           | 56.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2676         |\n",
      "|    time_elapsed         | 51894        |\n",
      "|    total_timesteps      | 5480448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006914281 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -175         |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 31640        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | -0.7721737   |\n",
      "|    std                  | 106          |\n",
      "|    value_loss           | 61.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2677         |\n",
      "|    time_elapsed         | 51913        |\n",
      "|    total_timesteps      | 5482496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011848077 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -175         |\n",
      "|    explained_variance   | 0.172        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.6         |\n",
      "|    n_updates            | 31650        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | -1.0894876   |\n",
      "|    std                  | 106          |\n",
      "|    value_loss           | 63.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2678          |\n",
      "|    time_elapsed         | 51931         |\n",
      "|    total_timesteps      | 5484544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045314868 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -175          |\n",
      "|    explained_variance   | 0.332         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.8          |\n",
      "|    n_updates            | 31660         |\n",
      "|    policy_gradient_loss | -0.00202      |\n",
      "|    reward               | 0.1491631     |\n",
      "|    std                  | 107           |\n",
      "|    value_loss           | 83.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2679         |\n",
      "|    time_elapsed         | 51950        |\n",
      "|    total_timesteps      | 5486592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030678476 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -175         |\n",
      "|    explained_variance   | -0.0102      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 31670        |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    reward               | -0.22640455  |\n",
      "|    std                  | 107          |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2680        |\n",
      "|    time_elapsed         | 51969       |\n",
      "|    total_timesteps      | 5488640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001360953 |\n",
      "|    clip_fraction        | 0.00151     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -175        |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 31680       |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    reward               | 0.5457327   |\n",
      "|    std                  | 107         |\n",
      "|    value_loss           | 89.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2681          |\n",
      "|    time_elapsed         | 51988         |\n",
      "|    total_timesteps      | 5490688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070786546 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -175          |\n",
      "|    explained_variance   | 0.492         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.2          |\n",
      "|    n_updates            | 31690         |\n",
      "|    policy_gradient_loss | -0.00235      |\n",
      "|    reward               | 4.4419923     |\n",
      "|    std                  | 108           |\n",
      "|    value_loss           | 54.9          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2682        |\n",
      "|    time_elapsed         | 52006       |\n",
      "|    total_timesteps      | 5492736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003360798 |\n",
      "|    clip_fraction        | 0.00913     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -175        |\n",
      "|    explained_variance   | -0.00199    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 31700       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | -0.39301416 |\n",
      "|    std                  | 108         |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2683         |\n",
      "|    time_elapsed         | 52025        |\n",
      "|    total_timesteps      | 5494784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005151801 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -175         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 31710        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 2.0882022    |\n",
      "|    std                  | 108          |\n",
      "|    value_loss           | 49.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2684         |\n",
      "|    time_elapsed         | 52044        |\n",
      "|    total_timesteps      | 5496832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007469945 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -175         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.5         |\n",
      "|    n_updates            | 31720        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    reward               | 0.22151619   |\n",
      "|    std                  | 108          |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2685         |\n",
      "|    time_elapsed         | 52062        |\n",
      "|    total_timesteps      | 5498880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012974035 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -175         |\n",
      "|    explained_variance   | 0.201        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.8         |\n",
      "|    n_updates            | 31730        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 1.7834396    |\n",
      "|    std                  | 108          |\n",
      "|    value_loss           | 88.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4137061.96\n",
      "total_reward: 3137061.96\n",
      "total_cost: 521720.40\n",
      "total_trades: 78168\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2686        |\n",
      "|    time_elapsed         | 52081       |\n",
      "|    total_timesteps      | 5500928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003643992 |\n",
      "|    clip_fraction        | 0.00757     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -175        |\n",
      "|    explained_variance   | -0.00216    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.28        |\n",
      "|    n_updates            | 31740       |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | -0.4133388  |\n",
      "|    std                  | 109         |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2687          |\n",
      "|    time_elapsed         | 52099         |\n",
      "|    total_timesteps      | 5502976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030437845 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -175          |\n",
      "|    explained_variance   | 0.189         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 123           |\n",
      "|    n_updates            | 31750         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | -0.19449499   |\n",
      "|    std                  | 109           |\n",
      "|    value_loss           | 93            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2688          |\n",
      "|    time_elapsed         | 52118         |\n",
      "|    total_timesteps      | 5505024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038366354 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -175          |\n",
      "|    explained_variance   | 0.292         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 138           |\n",
      "|    n_updates            | 31760         |\n",
      "|    policy_gradient_loss | -0.00228      |\n",
      "|    reward               | 2.707591      |\n",
      "|    std                  | 109           |\n",
      "|    value_loss           | 89.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2689         |\n",
      "|    time_elapsed         | 52136        |\n",
      "|    total_timesteps      | 5507072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012879568 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -175         |\n",
      "|    explained_variance   | -0.396       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 31770        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | -0.5442146   |\n",
      "|    std                  | 109          |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2690         |\n",
      "|    time_elapsed         | 52155        |\n",
      "|    total_timesteps      | 5509120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006227513 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -175         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 31780        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | -0.34985608  |\n",
      "|    std                  | 109          |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2691         |\n",
      "|    time_elapsed         | 52174        |\n",
      "|    total_timesteps      | 5511168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.908876e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -175         |\n",
      "|    explained_variance   | -0.0958      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 31790        |\n",
      "|    policy_gradient_loss | -0.000752    |\n",
      "|    reward               | -0.2426016   |\n",
      "|    std                  | 109          |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2692          |\n",
      "|    time_elapsed         | 52193         |\n",
      "|    total_timesteps      | 5513216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029465594 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -175          |\n",
      "|    explained_variance   | 0.0685        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 56.3          |\n",
      "|    n_updates            | 31800         |\n",
      "|    policy_gradient_loss | -0.00127      |\n",
      "|    reward               | -0.3719672    |\n",
      "|    std                  | 109           |\n",
      "|    value_loss           | 158           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2693        |\n",
      "|    time_elapsed         | 52211       |\n",
      "|    total_timesteps      | 5515264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005376756 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -175        |\n",
      "|    explained_variance   | 0.00305     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.76        |\n",
      "|    n_updates            | 31810       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | 0.102814265 |\n",
      "|    std                  | 110         |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2694          |\n",
      "|    time_elapsed         | 52230         |\n",
      "|    total_timesteps      | 5517312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040422866 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -175          |\n",
      "|    explained_variance   | 0.149         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16            |\n",
      "|    n_updates            | 31820         |\n",
      "|    policy_gradient_loss | -0.00122      |\n",
      "|    reward               | 2.7617998     |\n",
      "|    std                  | 110           |\n",
      "|    value_loss           | 63.9          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2695       |\n",
      "|    time_elapsed         | 52249      |\n",
      "|    total_timesteps      | 5519360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00052018 |\n",
      "|    clip_fraction        | 0.000439   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -175       |\n",
      "|    explained_variance   | 0.482      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.1       |\n",
      "|    n_updates            | 31830      |\n",
      "|    policy_gradient_loss | -0.00229   |\n",
      "|    reward               | -10.79851  |\n",
      "|    std                  | 110        |\n",
      "|    value_loss           | 42.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2696         |\n",
      "|    time_elapsed         | 52268        |\n",
      "|    total_timesteps      | 5521408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012638511 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | -0.0389      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 31840        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -0.5379845   |\n",
      "|    std                  | 110          |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2697         |\n",
      "|    time_elapsed         | 52287        |\n",
      "|    total_timesteps      | 5523456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003939734 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.3         |\n",
      "|    n_updates            | 31850        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | 1.1676055    |\n",
      "|    std                  | 110          |\n",
      "|    value_loss           | 80.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2698          |\n",
      "|    time_elapsed         | 52306         |\n",
      "|    total_timesteps      | 5525504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046786794 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -176          |\n",
      "|    explained_variance   | 0.433         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 67.1          |\n",
      "|    n_updates            | 31860         |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | 0.72198004    |\n",
      "|    std                  | 110           |\n",
      "|    value_loss           | 75.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2699         |\n",
      "|    time_elapsed         | 52325        |\n",
      "|    total_timesteps      | 5527552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025779796 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | -0.448       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 31870        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -0.14161877  |\n",
      "|    std                  | 110          |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4017101.62\n",
      "total_reward: 3017101.62\n",
      "total_cost: 525636.03\n",
      "total_trades: 78005\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2700         |\n",
      "|    time_elapsed         | 52343        |\n",
      "|    total_timesteps      | 5529600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015888646 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.2         |\n",
      "|    n_updates            | 31880        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 1.9850729    |\n",
      "|    std                  | 110          |\n",
      "|    value_loss           | 37.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2701         |\n",
      "|    time_elapsed         | 52362        |\n",
      "|    total_timesteps      | 5531648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004210707 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.7         |\n",
      "|    n_updates            | 31890        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | -1.3209131   |\n",
      "|    std                  | 111          |\n",
      "|    value_loss           | 78.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2702          |\n",
      "|    time_elapsed         | 52382         |\n",
      "|    total_timesteps      | 5533696       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066109264 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -176          |\n",
      "|    explained_variance   | 0.625         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.1          |\n",
      "|    n_updates            | 31900         |\n",
      "|    policy_gradient_loss | -0.00215      |\n",
      "|    reward               | -0.2317869    |\n",
      "|    std                  | 111           |\n",
      "|    value_loss           | 56.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2703         |\n",
      "|    time_elapsed         | 52400        |\n",
      "|    total_timesteps      | 5535744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025213251 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.00799      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.18         |\n",
      "|    n_updates            | 31910        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | 0.9402299    |\n",
      "|    std                  | 111          |\n",
      "|    value_loss           | 15.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2704          |\n",
      "|    time_elapsed         | 52419         |\n",
      "|    total_timesteps      | 5537792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032325622 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -176          |\n",
      "|    explained_variance   | 0.558         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.7          |\n",
      "|    n_updates            | 31920         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | 0.49975517    |\n",
      "|    std                  | 111           |\n",
      "|    value_loss           | 63.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2705         |\n",
      "|    time_elapsed         | 52438        |\n",
      "|    total_timesteps      | 5539840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006171081 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.317        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 31930        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | 0.45975697   |\n",
      "|    std                  | 111          |\n",
      "|    value_loss           | 47.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2706         |\n",
      "|    time_elapsed         | 52456        |\n",
      "|    total_timesteps      | 5541888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009938169 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | -0.0964      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.88         |\n",
      "|    n_updates            | 31940        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | -3.0646708   |\n",
      "|    std                  | 111          |\n",
      "|    value_loss           | 27.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2707         |\n",
      "|    time_elapsed         | 52475        |\n",
      "|    total_timesteps      | 5543936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014693923 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 31950        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | -0.53821117  |\n",
      "|    std                  | 112          |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2708          |\n",
      "|    time_elapsed         | 52493         |\n",
      "|    total_timesteps      | 5545984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030128632 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -176          |\n",
      "|    explained_variance   | 0.411         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32.3          |\n",
      "|    n_updates            | 31960         |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    reward               | 0.19522698    |\n",
      "|    std                  | 112           |\n",
      "|    value_loss           | 70.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2709         |\n",
      "|    time_elapsed         | 52512        |\n",
      "|    total_timesteps      | 5548032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007587098 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.6         |\n",
      "|    n_updates            | 31970        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | -0.47989485  |\n",
      "|    std                  | 112          |\n",
      "|    value_loss           | 54           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2710        |\n",
      "|    time_elapsed         | 52531       |\n",
      "|    total_timesteps      | 5550080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003230682 |\n",
      "|    clip_fraction        | 0.0061      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -176        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.64        |\n",
      "|    n_updates            | 31980       |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | -3.4124877  |\n",
      "|    std                  | 112         |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2711         |\n",
      "|    time_elapsed         | 52550        |\n",
      "|    total_timesteps      | 5552128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006617411 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 31990        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 0.035169214  |\n",
      "|    std                  | 112          |\n",
      "|    value_loss           | 77.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2712         |\n",
      "|    time_elapsed         | 52569        |\n",
      "|    total_timesteps      | 5554176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014710369 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 32000        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | -8.025751    |\n",
      "|    std                  | 113          |\n",
      "|    value_loss           | 54.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2713        |\n",
      "|    time_elapsed         | 52587       |\n",
      "|    total_timesteps      | 5556224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002211899 |\n",
      "|    clip_fraction        | 0.00322     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -176        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 32010       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | 0.6434615   |\n",
      "|    std                  | 113         |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3333723.01\n",
      "total_reward: 2333723.01\n",
      "total_cost: 495804.34\n",
      "total_trades: 76871\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2714         |\n",
      "|    time_elapsed         | 52606        |\n",
      "|    total_timesteps      | 5558272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014880777 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 32020        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -1.0057818   |\n",
      "|    std                  | 113          |\n",
      "|    value_loss           | 57.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2715         |\n",
      "|    time_elapsed         | 52625        |\n",
      "|    total_timesteps      | 5560320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016785325 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -176         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 32030        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    reward               | 5.228471     |\n",
      "|    std                  | 114          |\n",
      "|    value_loss           | 71.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2716          |\n",
      "|    time_elapsed         | 52643         |\n",
      "|    total_timesteps      | 5562368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0013870205  |\n",
      "|    clip_fraction        | 0.00229       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -177          |\n",
      "|    explained_variance   | 0.421         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 82.5          |\n",
      "|    n_updates            | 32040         |\n",
      "|    policy_gradient_loss | -0.00287      |\n",
      "|    reward               | -0.0040990664 |\n",
      "|    std                  | 114           |\n",
      "|    value_loss           | 108           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2717         |\n",
      "|    time_elapsed         | 52662        |\n",
      "|    total_timesteps      | 5564416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038800733 |\n",
      "|    clip_fraction        | 0.00864      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0.013        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.97         |\n",
      "|    n_updates            | 32050        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    reward               | -0.1431631   |\n",
      "|    std                  | 114          |\n",
      "|    value_loss           | 10.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2718         |\n",
      "|    time_elapsed         | 52680        |\n",
      "|    total_timesteps      | 5566464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003647066 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0.143        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 32060        |\n",
      "|    policy_gradient_loss | -0.000962    |\n",
      "|    reward               | 1.4792407    |\n",
      "|    std                  | 114          |\n",
      "|    value_loss           | 56.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2719         |\n",
      "|    time_elapsed         | 52699        |\n",
      "|    total_timesteps      | 5568512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007686288 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 32070        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | -1.5529183   |\n",
      "|    std                  | 114          |\n",
      "|    value_loss           | 64.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2720         |\n",
      "|    time_elapsed         | 52717        |\n",
      "|    total_timesteps      | 5570560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032340533 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.42         |\n",
      "|    n_updates            | 32080        |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | -1.5779731   |\n",
      "|    std                  | 114          |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2721         |\n",
      "|    time_elapsed         | 52736        |\n",
      "|    total_timesteps      | 5572608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004681946 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 32090        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | -2.2002327   |\n",
      "|    std                  | 115          |\n",
      "|    value_loss           | 71.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2722         |\n",
      "|    time_elapsed         | 52754        |\n",
      "|    total_timesteps      | 5574656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004444346 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 32100        |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    reward               | 1.0851526    |\n",
      "|    std                  | 115          |\n",
      "|    value_loss           | 71.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2723        |\n",
      "|    time_elapsed         | 52773       |\n",
      "|    total_timesteps      | 5576704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000640008 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -177        |\n",
      "|    explained_variance   | -0.178      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.74        |\n",
      "|    n_updates            | 32110       |\n",
      "|    policy_gradient_loss | -0.00121    |\n",
      "|    reward               | 0.8383531   |\n",
      "|    std                  | 115         |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2724        |\n",
      "|    time_elapsed         | 52791       |\n",
      "|    total_timesteps      | 5578752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000993515 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -177        |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 32120       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | 0.91644126  |\n",
      "|    std                  | 115         |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2725         |\n",
      "|    time_elapsed         | 52810        |\n",
      "|    total_timesteps      | 5580800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003633487 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 32130        |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    reward               | 1.4464345    |\n",
      "|    std                  | 115          |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2726         |\n",
      "|    time_elapsed         | 52883        |\n",
      "|    total_timesteps      | 5582848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005973092 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 32140        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | 0.54666936   |\n",
      "|    std                  | 115          |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2727         |\n",
      "|    time_elapsed         | 52902        |\n",
      "|    total_timesteps      | 5584896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028382067 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.34         |\n",
      "|    n_updates            | 32150        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | -0.9246839   |\n",
      "|    std                  | 115          |\n",
      "|    value_loss           | 15.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2966165.55\n",
      "total_reward: 1966165.55\n",
      "total_cost: 490097.91\n",
      "total_trades: 76358\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2728          |\n",
      "|    time_elapsed         | 52920         |\n",
      "|    total_timesteps      | 5586944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063348224 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -177          |\n",
      "|    explained_variance   | 0.028         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.4          |\n",
      "|    n_updates            | 32160         |\n",
      "|    policy_gradient_loss | -0.00234      |\n",
      "|    reward               | 0.16648427    |\n",
      "|    std                  | 115           |\n",
      "|    value_loss           | 65.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2729         |\n",
      "|    time_elapsed         | 52938        |\n",
      "|    total_timesteps      | 5588992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013188163 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 32170        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 4.113198     |\n",
      "|    std                  | 116          |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2730        |\n",
      "|    time_elapsed         | 52957       |\n",
      "|    total_timesteps      | 5591040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002314039 |\n",
      "|    clip_fraction        | 0.00298     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -177        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.08        |\n",
      "|    n_updates            | 32180       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -2.6141405  |\n",
      "|    std                  | 116         |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2731          |\n",
      "|    time_elapsed         | 52976         |\n",
      "|    total_timesteps      | 5593088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055902003 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -177          |\n",
      "|    explained_variance   | 0.0366        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.7          |\n",
      "|    n_updates            | 32190         |\n",
      "|    policy_gradient_loss | -0.00287      |\n",
      "|    reward               | 1.0829288     |\n",
      "|    std                  | 116           |\n",
      "|    value_loss           | 46.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2732          |\n",
      "|    time_elapsed         | 52994         |\n",
      "|    total_timesteps      | 5595136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040277356 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -177          |\n",
      "|    explained_variance   | 0.158         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 81.8          |\n",
      "|    n_updates            | 32200         |\n",
      "|    policy_gradient_loss | -0.00159      |\n",
      "|    reward               | 1.7760502     |\n",
      "|    std                  | 116           |\n",
      "|    value_loss           | 82.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2733         |\n",
      "|    time_elapsed         | 53013        |\n",
      "|    total_timesteps      | 5597184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023882566 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | -0.00212     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 32210        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | 0.12351998   |\n",
      "|    std                  | 116          |\n",
      "|    value_loss           | 49           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2734       |\n",
      "|    time_elapsed         | 53031      |\n",
      "|    total_timesteps      | 5599232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00278734 |\n",
      "|    clip_fraction        | 0.00542    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -177       |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.44       |\n",
      "|    n_updates            | 32220      |\n",
      "|    policy_gradient_loss | -0.00476   |\n",
      "|    reward               | 2.0742354  |\n",
      "|    std                  | 116        |\n",
      "|    value_loss           | 17.5       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2735          |\n",
      "|    time_elapsed         | 53050         |\n",
      "|    total_timesteps      | 5601280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016227775 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -177          |\n",
      "|    explained_variance   | 0.217         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.8          |\n",
      "|    n_updates            | 32230         |\n",
      "|    policy_gradient_loss | -0.000363     |\n",
      "|    reward               | -0.3684014    |\n",
      "|    std                  | 116           |\n",
      "|    value_loss           | 52.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2736         |\n",
      "|    time_elapsed         | 53068        |\n",
      "|    total_timesteps      | 5603328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006898418 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 32240        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | 9.69615      |\n",
      "|    std                  | 117          |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2737        |\n",
      "|    time_elapsed         | 53087       |\n",
      "|    total_timesteps      | 5605376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002795908 |\n",
      "|    clip_fraction        | 0.00654     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -177        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.71        |\n",
      "|    n_updates            | 32250       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | -0.33248374 |\n",
      "|    std                  | 117         |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2738         |\n",
      "|    time_elapsed         | 53105        |\n",
      "|    total_timesteps      | 5607424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014503805 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -177         |\n",
      "|    explained_variance   | 0.0132       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.5         |\n",
      "|    n_updates            | 32260        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | -0.595766    |\n",
      "|    std                  | 117          |\n",
      "|    value_loss           | 79.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2739          |\n",
      "|    time_elapsed         | 53124         |\n",
      "|    total_timesteps      | 5609472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045398995 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -177          |\n",
      "|    explained_variance   | 0.0319        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.4          |\n",
      "|    n_updates            | 32270         |\n",
      "|    policy_gradient_loss | -0.00154      |\n",
      "|    reward               | 7.625271      |\n",
      "|    std                  | 117           |\n",
      "|    value_loss           | 90.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2740          |\n",
      "|    time_elapsed         | 53142         |\n",
      "|    total_timesteps      | 5611520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013173476 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -178          |\n",
      "|    explained_variance   | 0.273         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.7          |\n",
      "|    n_updates            | 32280         |\n",
      "|    policy_gradient_loss | -0.000941     |\n",
      "|    reward               | -3.0224981    |\n",
      "|    std                  | 117           |\n",
      "|    value_loss           | 97.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2741         |\n",
      "|    time_elapsed         | 53161        |\n",
      "|    total_timesteps      | 5613568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014775482 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.0129       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.57         |\n",
      "|    n_updates            | 32290        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -0.09279231  |\n",
      "|    std                  | 118          |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4614873.22\n",
      "total_reward: 3614873.22\n",
      "total_cost: 524357.02\n",
      "total_trades: 78257\n",
      "Sharpe: 0.770\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2742        |\n",
      "|    time_elapsed         | 53179       |\n",
      "|    total_timesteps      | 5615616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000984571 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -178        |\n",
      "|    explained_variance   | 0.0556      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 32300       |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    reward               | 0.7962871   |\n",
      "|    std                  | 118         |\n",
      "|    value_loss           | 81          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2743          |\n",
      "|    time_elapsed         | 53198         |\n",
      "|    total_timesteps      | 5617664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015605797 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -178          |\n",
      "|    explained_variance   | 0.0923        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 63.2          |\n",
      "|    n_updates            | 32310         |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    reward               | 2.0637345     |\n",
      "|    std                  | 118           |\n",
      "|    value_loss           | 123           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2744         |\n",
      "|    time_elapsed         | 53216        |\n",
      "|    total_timesteps      | 5619712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018661704 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 32320        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | 1.3607589    |\n",
      "|    std                  | 118          |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2745          |\n",
      "|    time_elapsed         | 53235         |\n",
      "|    total_timesteps      | 5621760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00097152346 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -178          |\n",
      "|    explained_variance   | 0.00133       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.6          |\n",
      "|    n_updates            | 32330         |\n",
      "|    policy_gradient_loss | -0.00313      |\n",
      "|    reward               | -1.3212724    |\n",
      "|    std                  | 118           |\n",
      "|    value_loss           | 96.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2746         |\n",
      "|    time_elapsed         | 53254        |\n",
      "|    total_timesteps      | 5623808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015402134 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.0123       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 32340        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | -6.1394315   |\n",
      "|    std                  | 118          |\n",
      "|    value_loss           | 77.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2747         |\n",
      "|    time_elapsed         | 53272        |\n",
      "|    total_timesteps      | 5625856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007881974 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.136        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 32350        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | -0.9127527   |\n",
      "|    std                  | 119          |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2748         |\n",
      "|    time_elapsed         | 53291        |\n",
      "|    total_timesteps      | 5627904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006715101 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.0845       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.8         |\n",
      "|    n_updates            | 32360        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | -0.31441593  |\n",
      "|    std                  | 119          |\n",
      "|    value_loss           | 57.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2749         |\n",
      "|    time_elapsed         | 53309        |\n",
      "|    total_timesteps      | 5629952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008594509 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.2         |\n",
      "|    n_updates            | 32370        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -0.33256215  |\n",
      "|    std                  | 119          |\n",
      "|    value_loss           | 93.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2750         |\n",
      "|    time_elapsed         | 53328        |\n",
      "|    total_timesteps      | 5632000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016600583 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.0105       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 32380        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    reward               | -0.20324527  |\n",
      "|    std                  | 119          |\n",
      "|    value_loss           | 88.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2751         |\n",
      "|    time_elapsed         | 53347        |\n",
      "|    total_timesteps      | 5634048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029541664 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.18         |\n",
      "|    n_updates            | 32390        |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    reward               | -1.4587178   |\n",
      "|    std                  | 120          |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2752         |\n",
      "|    time_elapsed         | 53365        |\n",
      "|    total_timesteps      | 5636096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003347192 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.1         |\n",
      "|    n_updates            | 32400        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | 0.7230543    |\n",
      "|    std                  | 120          |\n",
      "|    value_loss           | 79.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2753         |\n",
      "|    time_elapsed         | 53384        |\n",
      "|    total_timesteps      | 5638144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014456948 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.264        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 32410        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -5.1509986   |\n",
      "|    std                  | 120          |\n",
      "|    value_loss           | 51           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2754         |\n",
      "|    time_elapsed         | 53403        |\n",
      "|    total_timesteps      | 5640192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008059005 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | -0.00205     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 32420        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | 0.072457366  |\n",
      "|    std                  | 120          |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2755          |\n",
      "|    time_elapsed         | 53421         |\n",
      "|    total_timesteps      | 5642240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029002328 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -178          |\n",
      "|    explained_variance   | 0.109         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55.8          |\n",
      "|    n_updates            | 32430         |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    reward               | -0.8727644    |\n",
      "|    std                  | 120           |\n",
      "|    value_loss           | 73.4          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3259634.32\n",
      "total_reward: 2259634.32\n",
      "total_cost: 484448.23\n",
      "total_trades: 76289\n",
      "Sharpe: 0.597\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2756          |\n",
      "|    time_elapsed         | 53440         |\n",
      "|    total_timesteps      | 5644288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085288216 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -178          |\n",
      "|    explained_variance   | 0.106         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.5          |\n",
      "|    n_updates            | 32440         |\n",
      "|    policy_gradient_loss | -0.00263      |\n",
      "|    reward               | 1.491039      |\n",
      "|    std                  | 120           |\n",
      "|    value_loss           | 73.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2757         |\n",
      "|    time_elapsed         | 53458        |\n",
      "|    total_timesteps      | 5646336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003143065 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 32450        |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    reward               | 1.3199394    |\n",
      "|    std                  | 120          |\n",
      "|    value_loss           | 57.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2758         |\n",
      "|    time_elapsed         | 53476        |\n",
      "|    total_timesteps      | 5648384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022807294 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.00126      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.99         |\n",
      "|    n_updates            | 32460        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    reward               | 0.24441464   |\n",
      "|    std                  | 120          |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2759         |\n",
      "|    time_elapsed         | 53494        |\n",
      "|    total_timesteps      | 5650432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010985057 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.00341      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.6         |\n",
      "|    n_updates            | 32470        |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    reward               | -0.9268004   |\n",
      "|    std                  | 121          |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2760         |\n",
      "|    time_elapsed         | 53513        |\n",
      "|    total_timesteps      | 5652480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012364979 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 32480        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 4.3908315    |\n",
      "|    std                  | 121          |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2761          |\n",
      "|    time_elapsed         | 53531         |\n",
      "|    total_timesteps      | 5654528       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062634016 |\n",
      "|    clip_fraction        | 0.00103       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -178          |\n",
      "|    explained_variance   | -0.0123       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.2          |\n",
      "|    n_updates            | 32490         |\n",
      "|    policy_gradient_loss | -0.00189      |\n",
      "|    reward               | 3.0749974     |\n",
      "|    std                  | 121           |\n",
      "|    value_loss           | 43            |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2762          |\n",
      "|    time_elapsed         | 53550         |\n",
      "|    total_timesteps      | 5656576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022151918 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -178          |\n",
      "|    explained_variance   | 0.0249        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 51.6          |\n",
      "|    n_updates            | 32500         |\n",
      "|    policy_gradient_loss | -0.000944     |\n",
      "|    reward               | 1.2984768     |\n",
      "|    std                  | 121           |\n",
      "|    value_loss           | 150           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2763         |\n",
      "|    time_elapsed         | 53568        |\n",
      "|    total_timesteps      | 5658624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023963586 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -178         |\n",
      "|    explained_variance   | 0.00905      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 32510        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -11.486205   |\n",
      "|    std                  | 122          |\n",
      "|    value_loss           | 75.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2764         |\n",
      "|    time_elapsed         | 53587        |\n",
      "|    total_timesteps      | 5660672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014422629 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.172        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 32520        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | -0.30820817  |\n",
      "|    std                  | 122          |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2765         |\n",
      "|    time_elapsed         | 53605        |\n",
      "|    total_timesteps      | 5662720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028260292 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.0229       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.87         |\n",
      "|    n_updates            | 32530        |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | -1.5598416   |\n",
      "|    std                  | 122          |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2766         |\n",
      "|    time_elapsed         | 53624        |\n",
      "|    total_timesteps      | 5664768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005282317 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.109        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 32540        |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    reward               | -3.012206    |\n",
      "|    std                  | 122          |\n",
      "|    value_loss           | 68.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2767          |\n",
      "|    time_elapsed         | 53642         |\n",
      "|    total_timesteps      | 5666816       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028363187 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -179          |\n",
      "|    explained_variance   | -0.0106       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 89.9          |\n",
      "|    n_updates            | 32550         |\n",
      "|    policy_gradient_loss | -0.0017       |\n",
      "|    reward               | 11.093948     |\n",
      "|    std                  | 122           |\n",
      "|    value_loss           | 110           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 2768       |\n",
      "|    time_elapsed         | 53661      |\n",
      "|    total_timesteps      | 5668864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00210333 |\n",
      "|    clip_fraction        | 0.0019     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -179       |\n",
      "|    explained_variance   | -0.0165    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 32560      |\n",
      "|    policy_gradient_loss | -0.0035    |\n",
      "|    reward               | 0.914691   |\n",
      "|    std                  | 122        |\n",
      "|    value_loss           | 21.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2769         |\n",
      "|    time_elapsed         | 53679        |\n",
      "|    total_timesteps      | 5670912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007446887 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.014        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 32570        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | 1.2558712    |\n",
      "|    std                  | 123          |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2770          |\n",
      "|    time_elapsed         | 53697         |\n",
      "|    total_timesteps      | 5672960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095029455 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -179          |\n",
      "|    explained_variance   | 0.000248      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 86.2          |\n",
      "|    n_updates            | 32580         |\n",
      "|    policy_gradient_loss | -0.00297      |\n",
      "|    reward               | -3.0712056    |\n",
      "|    std                  | 123           |\n",
      "|    value_loss           | 157           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4899843.17\n",
      "total_reward: 3899843.17\n",
      "total_cost: 536609.47\n",
      "total_trades: 79071\n",
      "Sharpe: 0.841\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2771         |\n",
      "|    time_elapsed         | 53715        |\n",
      "|    total_timesteps      | 5675008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016828547 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | -0.000121    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 32590        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | -0.06586177  |\n",
      "|    std                  | 123          |\n",
      "|    value_loss           | 57.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2772          |\n",
      "|    time_elapsed         | 53734         |\n",
      "|    total_timesteps      | 5677056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054584694 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -179          |\n",
      "|    explained_variance   | 0.00292       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 87.2          |\n",
      "|    n_updates            | 32600         |\n",
      "|    policy_gradient_loss | -0.00216      |\n",
      "|    reward               | 0.46413895    |\n",
      "|    std                  | 123           |\n",
      "|    value_loss           | 95            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2773          |\n",
      "|    time_elapsed         | 53752         |\n",
      "|    total_timesteps      | 5679104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077598216 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -179          |\n",
      "|    explained_variance   | 0.028         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.1          |\n",
      "|    n_updates            | 32610         |\n",
      "|    policy_gradient_loss | -0.00213      |\n",
      "|    reward               | -0.40715146   |\n",
      "|    std                  | 123           |\n",
      "|    value_loss           | 53.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2774         |\n",
      "|    time_elapsed         | 53771        |\n",
      "|    total_timesteps      | 5681152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011486062 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.0992       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 32620        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -0.4086497   |\n",
      "|    std                  | 124          |\n",
      "|    value_loss           | 50.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2775         |\n",
      "|    time_elapsed         | 53790        |\n",
      "|    total_timesteps      | 5683200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024761865 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | -0.0227      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.1          |\n",
      "|    n_updates            | 32630        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | -0.9041061   |\n",
      "|    std                  | 124          |\n",
      "|    value_loss           | 13.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2776         |\n",
      "|    time_elapsed         | 53808        |\n",
      "|    total_timesteps      | 5685248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002903568 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 32640        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    reward               | -0.12594855  |\n",
      "|    std                  | 124          |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2777          |\n",
      "|    time_elapsed         | 53827         |\n",
      "|    total_timesteps      | 5687296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025985832 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -179          |\n",
      "|    explained_variance   | 0.224         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.8          |\n",
      "|    n_updates            | 32650         |\n",
      "|    policy_gradient_loss | -0.00149      |\n",
      "|    reward               | 3.6948342     |\n",
      "|    std                  | 124           |\n",
      "|    value_loss           | 61.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2778         |\n",
      "|    time_elapsed         | 53845        |\n",
      "|    total_timesteps      | 5689344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011400483 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | -3.39e-05    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.4         |\n",
      "|    n_updates            | 32660        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 0.15300493   |\n",
      "|    std                  | 124          |\n",
      "|    value_loss           | 59.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2779         |\n",
      "|    time_elapsed         | 53864        |\n",
      "|    total_timesteps      | 5691392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005740698 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.063        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 32670        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | -0.36332563  |\n",
      "|    std                  | 124          |\n",
      "|    value_loss           | 92           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2780          |\n",
      "|    time_elapsed         | 53882         |\n",
      "|    total_timesteps      | 5693440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046727285 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -179          |\n",
      "|    explained_variance   | 0.00426       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.1          |\n",
      "|    n_updates            | 32680         |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    reward               | 0.17377213    |\n",
      "|    std                  | 124           |\n",
      "|    value_loss           | 109           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2781          |\n",
      "|    time_elapsed         | 53901         |\n",
      "|    total_timesteps      | 5695488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045269888 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -179          |\n",
      "|    explained_variance   | 0.103         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.3          |\n",
      "|    n_updates            | 32690         |\n",
      "|    policy_gradient_loss | -0.00119      |\n",
      "|    reward               | -0.07686126   |\n",
      "|    std                  | 124           |\n",
      "|    value_loss           | 83            |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2782         |\n",
      "|    time_elapsed         | 53920        |\n",
      "|    total_timesteps      | 5697536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025961145 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.0922       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.03         |\n",
      "|    n_updates            | 32700        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | -0.061053064 |\n",
      "|    std                  | 125          |\n",
      "|    value_loss           | 12.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2783         |\n",
      "|    time_elapsed         | 53939        |\n",
      "|    total_timesteps      | 5699584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009977955 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 32710        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | -3.0785508   |\n",
      "|    std                  | 125          |\n",
      "|    value_loss           | 56           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2784         |\n",
      "|    time_elapsed         | 53957        |\n",
      "|    total_timesteps      | 5701632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011722657 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.0881       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 32720        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | 4.946651     |\n",
      "|    std                  | 125          |\n",
      "|    value_loss           | 81.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3538363.49\n",
      "total_reward: 2538363.49\n",
      "total_cost: 498361.77\n",
      "total_trades: 77435\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2785         |\n",
      "|    time_elapsed         | 53976        |\n",
      "|    total_timesteps      | 5703680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027035223 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -179         |\n",
      "|    explained_variance   | 0.00469      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.88         |\n",
      "|    n_updates            | 32730        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | 0.49287608   |\n",
      "|    std                  | 126          |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2786         |\n",
      "|    time_elapsed         | 53995        |\n",
      "|    total_timesteps      | 5705728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010166918 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -180         |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.7         |\n",
      "|    n_updates            | 32740        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 3.29439      |\n",
      "|    std                  | 126          |\n",
      "|    value_loss           | 61.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2787          |\n",
      "|    time_elapsed         | 54013         |\n",
      "|    total_timesteps      | 5707776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062470406 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -180          |\n",
      "|    explained_variance   | 0.235         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.3          |\n",
      "|    n_updates            | 32750         |\n",
      "|    policy_gradient_loss | -0.00195      |\n",
      "|    reward               | -0.9242829    |\n",
      "|    std                  | 126           |\n",
      "|    value_loss           | 87.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2788          |\n",
      "|    time_elapsed         | 54032         |\n",
      "|    total_timesteps      | 5709824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086409453 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -180          |\n",
      "|    explained_variance   | 0.603         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.9          |\n",
      "|    n_updates            | 32760         |\n",
      "|    policy_gradient_loss | -0.002        |\n",
      "|    reward               | -3.3397424    |\n",
      "|    std                  | 126           |\n",
      "|    value_loss           | 32.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2789         |\n",
      "|    time_elapsed         | 54050        |\n",
      "|    total_timesteps      | 5711872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013524557 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -180         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 32770        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | 1.034508     |\n",
      "|    std                  | 126          |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2790          |\n",
      "|    time_elapsed         | 54069         |\n",
      "|    total_timesteps      | 5713920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031471683 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -180          |\n",
      "|    explained_variance   | 0.457         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21            |\n",
      "|    n_updates            | 32780         |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | 0.28359723    |\n",
      "|    std                  | 126           |\n",
      "|    value_loss           | 52.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2791         |\n",
      "|    time_elapsed         | 54088        |\n",
      "|    total_timesteps      | 5715968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013378786 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -180         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 32790        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | 4.9297266    |\n",
      "|    std                  | 127          |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2792         |\n",
      "|    time_elapsed         | 54107        |\n",
      "|    total_timesteps      | 5718016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035379822 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -180         |\n",
      "|    explained_variance   | -0.0199      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 32800        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | 2.1615922    |\n",
      "|    std                  | 127          |\n",
      "|    value_loss           | 24.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2793         |\n",
      "|    time_elapsed         | 54126        |\n",
      "|    total_timesteps      | 5720064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017478516 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -180         |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.85         |\n",
      "|    n_updates            | 32810        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | 0.21381833   |\n",
      "|    std                  | 127          |\n",
      "|    value_loss           | 71.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2794         |\n",
      "|    time_elapsed         | 54144        |\n",
      "|    total_timesteps      | 5722112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005856864 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -180         |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 32820        |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    reward               | -0.48595187  |\n",
      "|    std                  | 128          |\n",
      "|    value_loss           | 43.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2795         |\n",
      "|    time_elapsed         | 54163        |\n",
      "|    total_timesteps      | 5724160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028597165 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -180         |\n",
      "|    explained_variance   | 0.0245       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 32830        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | -0.5343912   |\n",
      "|    std                  | 128          |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2796          |\n",
      "|    time_elapsed         | 54182         |\n",
      "|    total_timesteps      | 5726208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060506514 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -180          |\n",
      "|    explained_variance   | 0.193         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43.9          |\n",
      "|    n_updates            | 32840         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | -0.4174984    |\n",
      "|    std                  | 128           |\n",
      "|    value_loss           | 59            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2797          |\n",
      "|    time_elapsed         | 54200         |\n",
      "|    total_timesteps      | 5728256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067556644 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -180          |\n",
      "|    explained_variance   | 0.0303        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.2          |\n",
      "|    n_updates            | 32850         |\n",
      "|    policy_gradient_loss | -0.00237      |\n",
      "|    reward               | -0.14295642   |\n",
      "|    std                  | 129           |\n",
      "|    value_loss           | 67.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2798          |\n",
      "|    time_elapsed         | 54219         |\n",
      "|    total_timesteps      | 5730304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074236264 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -180          |\n",
      "|    explained_variance   | 0.563         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.3          |\n",
      "|    n_updates            | 32860         |\n",
      "|    policy_gradient_loss | -0.0019       |\n",
      "|    reward               | -0.09920817   |\n",
      "|    std                  | 129           |\n",
      "|    value_loss           | 45.8          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3377195.47\n",
      "total_reward: 2377195.47\n",
      "total_cost: 521342.92\n",
      "total_trades: 78548\n",
      "Sharpe: 0.657\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2799        |\n",
      "|    time_elapsed         | 54237       |\n",
      "|    total_timesteps      | 5732352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004755724 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -180        |\n",
      "|    explained_variance   | -0.0419     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.34        |\n",
      "|    n_updates            | 32870       |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | 1.9873512   |\n",
      "|    std                  | 129         |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2800        |\n",
      "|    time_elapsed         | 54256       |\n",
      "|    total_timesteps      | 5734400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001026033 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -180        |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 32880       |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    reward               | 2.122458    |\n",
      "|    std                  | 129         |\n",
      "|    value_loss           | 63.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2801        |\n",
      "|    time_elapsed         | 54275       |\n",
      "|    total_timesteps      | 5736448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000263171 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -180        |\n",
      "|    explained_variance   | 0.0734      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.1        |\n",
      "|    n_updates            | 32890       |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    reward               | 1.272059    |\n",
      "|    std                  | 129         |\n",
      "|    value_loss           | 93.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2802         |\n",
      "|    time_elapsed         | 54293        |\n",
      "|    total_timesteps      | 5738496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023410332 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -180         |\n",
      "|    explained_variance   | 0.00213      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 32900        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | -4.6744537   |\n",
      "|    std                  | 130          |\n",
      "|    value_loss           | 43.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2803          |\n",
      "|    time_elapsed         | 54312         |\n",
      "|    total_timesteps      | 5740544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027617728 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -181          |\n",
      "|    explained_variance   | 0.195         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.7          |\n",
      "|    n_updates            | 32910         |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    reward               | -1.3232329    |\n",
      "|    std                  | 130           |\n",
      "|    value_loss           | 87            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2804          |\n",
      "|    time_elapsed         | 54331         |\n",
      "|    total_timesteps      | 5742592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045873056 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -181          |\n",
      "|    explained_variance   | 0.501         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 39.3          |\n",
      "|    n_updates            | 32920         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | 5.5750923     |\n",
      "|    std                  | 130           |\n",
      "|    value_loss           | 79.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2805        |\n",
      "|    time_elapsed         | 54349       |\n",
      "|    total_timesteps      | 5744640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000791574 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -181        |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 32930       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    reward               | 2.1339743   |\n",
      "|    std                  | 130         |\n",
      "|    value_loss           | 60.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2806         |\n",
      "|    time_elapsed         | 54368        |\n",
      "|    total_timesteps      | 5746688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034570252 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -181         |\n",
      "|    explained_variance   | 0.00338      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.08         |\n",
      "|    n_updates            | 32940        |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | -0.4247276   |\n",
      "|    std                  | 130          |\n",
      "|    value_loss           | 12.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2807          |\n",
      "|    time_elapsed         | 54387         |\n",
      "|    total_timesteps      | 5748736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041124877 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -181          |\n",
      "|    explained_variance   | 0.637         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.5          |\n",
      "|    n_updates            | 32950         |\n",
      "|    policy_gradient_loss | -0.0017       |\n",
      "|    reward               | -1.852846     |\n",
      "|    std                  | 131           |\n",
      "|    value_loss           | 45.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2808          |\n",
      "|    time_elapsed         | 54405         |\n",
      "|    total_timesteps      | 5750784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017151542 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -181          |\n",
      "|    explained_variance   | 0.591         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.6          |\n",
      "|    n_updates            | 32960         |\n",
      "|    policy_gradient_loss | -0.00168      |\n",
      "|    reward               | 0.8049596     |\n",
      "|    std                  | 131           |\n",
      "|    value_loss           | 48.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2809         |\n",
      "|    time_elapsed         | 54424        |\n",
      "|    total_timesteps      | 5752832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026022785 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -181         |\n",
      "|    explained_variance   | 0.0302       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.49         |\n",
      "|    n_updates            | 32970        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | -1.2671206   |\n",
      "|    std                  | 131          |\n",
      "|    value_loss           | 16           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2810          |\n",
      "|    time_elapsed         | 54443         |\n",
      "|    total_timesteps      | 5754880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062540686 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -181          |\n",
      "|    explained_variance   | 0.342         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.2          |\n",
      "|    n_updates            | 32980         |\n",
      "|    policy_gradient_loss | -0.00265      |\n",
      "|    reward               | -2.5939662    |\n",
      "|    std                  | 131           |\n",
      "|    value_loss           | 35            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2811         |\n",
      "|    time_elapsed         | 54462        |\n",
      "|    total_timesteps      | 5756928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010778644 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -181         |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 32990        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | 2.659858     |\n",
      "|    std                  | 132          |\n",
      "|    value_loss           | 76.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2812         |\n",
      "|    time_elapsed         | 54481        |\n",
      "|    total_timesteps      | 5758976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023589744 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -181         |\n",
      "|    explained_variance   | 0.00953      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 33000        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 0.06597008   |\n",
      "|    std                  | 132          |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3998280.44\n",
      "total_reward: 2998280.44\n",
      "total_cost: 517144.77\n",
      "total_trades: 78061\n",
      "Sharpe: 0.739\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2813         |\n",
      "|    time_elapsed         | 54500        |\n",
      "|    total_timesteps      | 5761024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014754846 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -181         |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.2         |\n",
      "|    n_updates            | 33010        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 1.7386769    |\n",
      "|    std                  | 133          |\n",
      "|    value_loss           | 56.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2814         |\n",
      "|    time_elapsed         | 54519        |\n",
      "|    total_timesteps      | 5763072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022123787 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -181         |\n",
      "|    explained_variance   | -0.00348     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.1         |\n",
      "|    n_updates            | 33020        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 0.08036301   |\n",
      "|    std                  | 133          |\n",
      "|    value_loss           | 85.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2815         |\n",
      "|    time_elapsed         | 54537        |\n",
      "|    total_timesteps      | 5765120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009753664 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -181         |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 33030        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | -1.8241574   |\n",
      "|    std                  | 134          |\n",
      "|    value_loss           | 49.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2816         |\n",
      "|    time_elapsed         | 54556        |\n",
      "|    total_timesteps      | 5767168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034139394 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -181         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.87         |\n",
      "|    n_updates            | 33040        |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    reward               | -0.014115439 |\n",
      "|    std                  | 134          |\n",
      "|    value_loss           | 15.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2817          |\n",
      "|    time_elapsed         | 54574         |\n",
      "|    total_timesteps      | 5769216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071266363 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -181          |\n",
      "|    explained_variance   | -0.000349     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 41.9          |\n",
      "|    n_updates            | 33050         |\n",
      "|    policy_gradient_loss | -0.00175      |\n",
      "|    reward               | 0.15781224    |\n",
      "|    std                  | 134           |\n",
      "|    value_loss           | 87.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2818          |\n",
      "|    time_elapsed         | 54593         |\n",
      "|    total_timesteps      | 5771264       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029991724 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -181          |\n",
      "|    explained_variance   | 0.397         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.1          |\n",
      "|    n_updates            | 33060         |\n",
      "|    policy_gradient_loss | -0.00115      |\n",
      "|    reward               | 4.670391      |\n",
      "|    std                  | 135           |\n",
      "|    value_loss           | 48.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2819         |\n",
      "|    time_elapsed         | 54612        |\n",
      "|    total_timesteps      | 5773312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024002786 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -181         |\n",
      "|    explained_variance   | 0.0434       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.65         |\n",
      "|    n_updates            | 33070        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | 3.1572158    |\n",
      "|    std                  | 135          |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2820         |\n",
      "|    time_elapsed         | 54630        |\n",
      "|    total_timesteps      | 5775360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005943129 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.196        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 33080        |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    reward               | 2.1942427    |\n",
      "|    std                  | 135          |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2821          |\n",
      "|    time_elapsed         | 54649         |\n",
      "|    total_timesteps      | 5777408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023868334 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -182          |\n",
      "|    explained_variance   | 0.22          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.97          |\n",
      "|    n_updates            | 33090         |\n",
      "|    policy_gradient_loss | -0.00138      |\n",
      "|    reward               | 1.7358264     |\n",
      "|    std                  | 135           |\n",
      "|    value_loss           | 44.4          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2822         |\n",
      "|    time_elapsed         | 54667        |\n",
      "|    total_timesteps      | 5779456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013156943 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.000559     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.8         |\n",
      "|    n_updates            | 33100        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | -1.2756495   |\n",
      "|    std                  | 135          |\n",
      "|    value_loss           | 91.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2823        |\n",
      "|    time_elapsed         | 54686       |\n",
      "|    total_timesteps      | 5781504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002808278 |\n",
      "|    clip_fraction        | 0.00439     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -182        |\n",
      "|    explained_variance   | -0.000186   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 33110       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | -1.263157   |\n",
      "|    std                  | 135         |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2824         |\n",
      "|    time_elapsed         | 54704        |\n",
      "|    total_timesteps      | 5783552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008412887 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.00336      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 33120        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 0.46499252   |\n",
      "|    std                  | 135          |\n",
      "|    value_loss           | 60.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2825         |\n",
      "|    time_elapsed         | 54723        |\n",
      "|    total_timesteps      | 5785600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010475117 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 33130        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | 1.4902995    |\n",
      "|    std                  | 136          |\n",
      "|    value_loss           | 50.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2826         |\n",
      "|    time_elapsed         | 54741        |\n",
      "|    total_timesteps      | 5787648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020825546 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.07         |\n",
      "|    n_updates            | 33140        |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | -0.2713429   |\n",
      "|    std                  | 136          |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3969984.85\n",
      "total_reward: 2969984.85\n",
      "total_cost: 552815.32\n",
      "total_trades: 79749\n",
      "Sharpe: 0.819\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2827         |\n",
      "|    time_elapsed         | 54760        |\n",
      "|    total_timesteps      | 5789696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017358018 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.00293      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 33150        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.0011436627 |\n",
      "|    std                  | 136          |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2828          |\n",
      "|    time_elapsed         | 54779         |\n",
      "|    total_timesteps      | 5791744       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066757505 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -182          |\n",
      "|    explained_variance   | 0.00241       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.5          |\n",
      "|    n_updates            | 33160         |\n",
      "|    policy_gradient_loss | -0.00257      |\n",
      "|    reward               | -11.056627    |\n",
      "|    std                  | 136           |\n",
      "|    value_loss           | 67.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2829         |\n",
      "|    time_elapsed         | 54797        |\n",
      "|    total_timesteps      | 5793792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011606325 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.00517      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 33170        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | 0.6410549    |\n",
      "|    std                  | 136          |\n",
      "|    value_loss           | 78.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2830        |\n",
      "|    time_elapsed         | 54816       |\n",
      "|    total_timesteps      | 5795840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002311622 |\n",
      "|    clip_fraction        | 0.00249     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -182        |\n",
      "|    explained_variance   | 0.00967     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.01        |\n",
      "|    n_updates            | 33180       |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | -1.1609398  |\n",
      "|    std                  | 137         |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2831         |\n",
      "|    time_elapsed         | 54834        |\n",
      "|    total_timesteps      | 5797888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005754258 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.00705      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 33190        |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    reward               | -0.19662015  |\n",
      "|    std                  | 137          |\n",
      "|    value_loss           | 70.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2832         |\n",
      "|    time_elapsed         | 54853        |\n",
      "|    total_timesteps      | 5799936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011625122 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 33200        |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    reward               | -0.4794189   |\n",
      "|    std                  | 137          |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2833         |\n",
      "|    time_elapsed         | 54872        |\n",
      "|    total_timesteps      | 5801984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022441065 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.00805      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.48         |\n",
      "|    n_updates            | 33210        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -4.073769    |\n",
      "|    std                  | 137          |\n",
      "|    value_loss           | 16.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2834         |\n",
      "|    time_elapsed         | 54891        |\n",
      "|    total_timesteps      | 5804032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005894223 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.00103      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.5         |\n",
      "|    n_updates            | 33220        |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    reward               | -0.71707636  |\n",
      "|    std                  | 138          |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2835          |\n",
      "|    time_elapsed         | 54909         |\n",
      "|    total_timesteps      | 5806080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016418306 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -182          |\n",
      "|    explained_variance   | 0.00638       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 79            |\n",
      "|    n_updates            | 33230         |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | 1.7360829     |\n",
      "|    std                  | 138           |\n",
      "|    value_loss           | 129           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2836        |\n",
      "|    time_elapsed         | 54928       |\n",
      "|    total_timesteps      | 5808128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001424806 |\n",
      "|    clip_fraction        | 0.00137     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -182        |\n",
      "|    explained_variance   | 0.00227     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 33240       |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    reward               | -1.2316036  |\n",
      "|    std                  | 138         |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2837         |\n",
      "|    time_elapsed         | 54947        |\n",
      "|    total_timesteps      | 5810176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012319394 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.00408      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 33250        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 0.72829163   |\n",
      "|    std                  | 138          |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2838         |\n",
      "|    time_elapsed         | 54966        |\n",
      "|    total_timesteps      | 5812224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006422489 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.117        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47           |\n",
      "|    n_updates            | 33260        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | -0.20394522  |\n",
      "|    std                  | 138          |\n",
      "|    value_loss           | 63.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2839          |\n",
      "|    time_elapsed         | 54985         |\n",
      "|    total_timesteps      | 5814272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038388764 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -182          |\n",
      "|    explained_variance   | 0.00262       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.7          |\n",
      "|    n_updates            | 33270         |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    reward               | 6.5741467     |\n",
      "|    std                  | 138           |\n",
      "|    value_loss           | 74.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2840         |\n",
      "|    time_elapsed         | 55003        |\n",
      "|    total_timesteps      | 5816320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016805653 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.00907      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.84         |\n",
      "|    n_updates            | 33280        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | 0.55969405   |\n",
      "|    std                  | 139          |\n",
      "|    value_loss           | 19.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3483109.24\n",
      "total_reward: 2483109.24\n",
      "total_cost: 523979.81\n",
      "total_trades: 78566\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2841         |\n",
      "|    time_elapsed         | 55022        |\n",
      "|    total_timesteps      | 5818368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013111066 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.00237      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.3         |\n",
      "|    n_updates            | 33290        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | 2.0906873    |\n",
      "|    std                  | 139          |\n",
      "|    value_loss           | 82.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2842         |\n",
      "|    time_elapsed         | 55041        |\n",
      "|    total_timesteps      | 5820416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005498836 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -182         |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 33300        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | -1.1158599   |\n",
      "|    std                  | 139          |\n",
      "|    value_loss           | 59.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2843         |\n",
      "|    time_elapsed         | 55059        |\n",
      "|    total_timesteps      | 5822464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010427826 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.00221      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.7          |\n",
      "|    n_updates            | 33310        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | -4.09004     |\n",
      "|    std                  | 139          |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2844         |\n",
      "|    time_elapsed         | 55078        |\n",
      "|    total_timesteps      | 5824512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014201496 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.00109      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.1         |\n",
      "|    n_updates            | 33320        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -1.1445466   |\n",
      "|    std                  | 140          |\n",
      "|    value_loss           | 65.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2845         |\n",
      "|    time_elapsed         | 55096        |\n",
      "|    total_timesteps      | 5826560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012486628 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.00949      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 33330        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | -1.1852994   |\n",
      "|    std                  | 140          |\n",
      "|    value_loss           | 71.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2846         |\n",
      "|    time_elapsed         | 55115        |\n",
      "|    total_timesteps      | 5828608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005291429 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.0032       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45           |\n",
      "|    n_updates            | 33340        |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    reward               | 0.22709051   |\n",
      "|    std                  | 140          |\n",
      "|    value_loss           | 64.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2847        |\n",
      "|    time_elapsed         | 55134       |\n",
      "|    total_timesteps      | 5830656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003692199 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -183        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.8         |\n",
      "|    n_updates            | 33350       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | 1.5848229   |\n",
      "|    std                  | 140         |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2848         |\n",
      "|    time_elapsed         | 55152        |\n",
      "|    total_timesteps      | 5832704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012640938 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.00387      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.3         |\n",
      "|    n_updates            | 33360        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | 1.0058752    |\n",
      "|    std                  | 141          |\n",
      "|    value_loss           | 57           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2849          |\n",
      "|    time_elapsed         | 55172         |\n",
      "|    total_timesteps      | 5834752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031564292 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -183          |\n",
      "|    explained_variance   | 0.0115        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 38.4          |\n",
      "|    n_updates            | 33370         |\n",
      "|    policy_gradient_loss | -0.00118      |\n",
      "|    reward               | 11.01279      |\n",
      "|    std                  | 141           |\n",
      "|    value_loss           | 124           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2850          |\n",
      "|    time_elapsed         | 55191         |\n",
      "|    total_timesteps      | 5836800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072788366 |\n",
      "|    clip_fraction        | 0.000977      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -183          |\n",
      "|    explained_variance   | 0.0629        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.9          |\n",
      "|    n_updates            | 33380         |\n",
      "|    policy_gradient_loss | -0.00245      |\n",
      "|    reward               | 2.2376084     |\n",
      "|    std                  | 141           |\n",
      "|    value_loss           | 30.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2851          |\n",
      "|    time_elapsed         | 55209         |\n",
      "|    total_timesteps      | 5838848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029326728 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -183          |\n",
      "|    explained_variance   | 0.00263       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 65.3          |\n",
      "|    n_updates            | 33390         |\n",
      "|    policy_gradient_loss | -0.00108      |\n",
      "|    reward               | -0.30656192   |\n",
      "|    std                  | 141           |\n",
      "|    value_loss           | 109           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2852         |\n",
      "|    time_elapsed         | 55228        |\n",
      "|    total_timesteps      | 5840896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003591977 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.119        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 33400        |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    reward               | -7.6783915   |\n",
      "|    std                  | 141          |\n",
      "|    value_loss           | 69.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2853         |\n",
      "|    time_elapsed         | 55247        |\n",
      "|    total_timesteps      | 5842944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005325714 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.00234      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.6         |\n",
      "|    n_updates            | 33410        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    reward               | 0.6973782    |\n",
      "|    std                  | 141          |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2854         |\n",
      "|    time_elapsed         | 55266        |\n",
      "|    total_timesteps      | 5844992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036179563 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.00449      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.68         |\n",
      "|    n_updates            | 33420        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    reward               | 0.6767387    |\n",
      "|    std                  | 142          |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3785789.55\n",
      "total_reward: 2785789.55\n",
      "total_cost: 498679.32\n",
      "total_trades: 76899\n",
      "Sharpe: 0.701\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2855         |\n",
      "|    time_elapsed         | 55284        |\n",
      "|    total_timesteps      | 5847040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011680792 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.00328      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 33430        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | 1.2220101    |\n",
      "|    std                  | 142          |\n",
      "|    value_loss           | 58.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2856         |\n",
      "|    time_elapsed         | 55304        |\n",
      "|    total_timesteps      | 5849088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017940826 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.000791     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.3         |\n",
      "|    n_updates            | 33440        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | -1.946955    |\n",
      "|    std                  | 142          |\n",
      "|    value_loss           | 91.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2857         |\n",
      "|    time_elapsed         | 55322        |\n",
      "|    total_timesteps      | 5851136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042562596 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.91         |\n",
      "|    n_updates            | 33450        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 0.33049864   |\n",
      "|    std                  | 142          |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2858         |\n",
      "|    time_elapsed         | 55341        |\n",
      "|    total_timesteps      | 5853184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008338003 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.0108       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.3         |\n",
      "|    n_updates            | 33460        |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | -1.1671745   |\n",
      "|    std                  | 143          |\n",
      "|    value_loss           | 59.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2859         |\n",
      "|    time_elapsed         | 55360        |\n",
      "|    total_timesteps      | 5855232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012059464 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.00195      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.7         |\n",
      "|    n_updates            | 33470        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | -1.679696    |\n",
      "|    std                  | 143          |\n",
      "|    value_loss           | 63.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2860         |\n",
      "|    time_elapsed         | 55379        |\n",
      "|    total_timesteps      | 5857280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029140466 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.00066      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 33480        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | 1.4488609    |\n",
      "|    std                  | 143          |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2861         |\n",
      "|    time_elapsed         | 55398        |\n",
      "|    total_timesteps      | 5859328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010174122 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -183         |\n",
      "|    explained_variance   | 0.00175      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 33490        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | -0.19732244  |\n",
      "|    std                  | 144          |\n",
      "|    value_loss           | 59.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2862         |\n",
      "|    time_elapsed         | 55416        |\n",
      "|    total_timesteps      | 5861376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012107561 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.0035       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 33500        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | 0.40037572   |\n",
      "|    std                  | 144          |\n",
      "|    value_loss           | 44.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2863          |\n",
      "|    time_elapsed         | 55435         |\n",
      "|    total_timesteps      | 5863424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081371644 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -184          |\n",
      "|    explained_variance   | 0.00144       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 48.7          |\n",
      "|    n_updates            | 33510         |\n",
      "|    policy_gradient_loss | -0.00228      |\n",
      "|    reward               | 0.37191722    |\n",
      "|    std                  | 144           |\n",
      "|    value_loss           | 97.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2864         |\n",
      "|    time_elapsed         | 55454        |\n",
      "|    total_timesteps      | 5865472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022899744 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.23         |\n",
      "|    n_updates            | 33520        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | 0.17785451   |\n",
      "|    std                  | 144          |\n",
      "|    value_loss           | 14           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2865         |\n",
      "|    time_elapsed         | 55473        |\n",
      "|    total_timesteps      | 5867520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012326688 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.00165      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.1         |\n",
      "|    n_updates            | 33530        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    reward               | -0.40994298  |\n",
      "|    std                  | 145          |\n",
      "|    value_loss           | 62.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2866         |\n",
      "|    time_elapsed         | 55491        |\n",
      "|    total_timesteps      | 5869568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009771877 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.00206      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.1         |\n",
      "|    n_updates            | 33540        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 2.4439812    |\n",
      "|    std                  | 145          |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2867         |\n",
      "|    time_elapsed         | 55510        |\n",
      "|    total_timesteps      | 5871616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020854413 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 33550        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | -1.771606    |\n",
      "|    std                  | 145          |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2868         |\n",
      "|    time_elapsed         | 55528        |\n",
      "|    total_timesteps      | 5873664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009746538 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.0391       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.78         |\n",
      "|    n_updates            | 33560        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | -2.8233979   |\n",
      "|    std                  | 145          |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2713880.22\n",
      "total_reward: 1713880.22\n",
      "total_cost: 490124.02\n",
      "total_trades: 76436\n",
      "Sharpe: 0.563\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2869         |\n",
      "|    time_elapsed         | 55547        |\n",
      "|    total_timesteps      | 5875712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008631812 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.00165      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 33570        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | -0.31178445  |\n",
      "|    std                  | 146          |\n",
      "|    value_loss           | 83.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2870          |\n",
      "|    time_elapsed         | 55566         |\n",
      "|    total_timesteps      | 5877760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011699961 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -184          |\n",
      "|    explained_variance   | 0.294         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.7          |\n",
      "|    n_updates            | 33580         |\n",
      "|    policy_gradient_loss | -0.000586     |\n",
      "|    reward               | 0.89580226    |\n",
      "|    std                  | 146           |\n",
      "|    value_loss           | 45            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2871         |\n",
      "|    time_elapsed         | 55585        |\n",
      "|    total_timesteps      | 5879808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009950455 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.0388       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.64         |\n",
      "|    n_updates            | 33590        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 0.18624629   |\n",
      "|    std                  | 146          |\n",
      "|    value_loss           | 14           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2872          |\n",
      "|    time_elapsed         | 55603         |\n",
      "|    total_timesteps      | 5881856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020680213 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -184          |\n",
      "|    explained_variance   | 0.134         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32.1          |\n",
      "|    n_updates            | 33600         |\n",
      "|    policy_gradient_loss | -0.000703     |\n",
      "|    reward               | 0.50677264    |\n",
      "|    std                  | 146           |\n",
      "|    value_loss           | 60.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2873         |\n",
      "|    time_elapsed         | 55622        |\n",
      "|    total_timesteps      | 5883904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.773585e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.0214       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.5         |\n",
      "|    n_updates            | 33610        |\n",
      "|    policy_gradient_loss | -0.000425    |\n",
      "|    reward               | -3.0176027   |\n",
      "|    std                  | 146          |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2874         |\n",
      "|    time_elapsed         | 55641        |\n",
      "|    total_timesteps      | 5885952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010119169 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | -0.0445      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.42         |\n",
      "|    n_updates            | 33620        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | 1.1630532    |\n",
      "|    std                  | 147          |\n",
      "|    value_loss           | 19.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2875          |\n",
      "|    time_elapsed         | 55660         |\n",
      "|    total_timesteps      | 5888000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014499575 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -184          |\n",
      "|    explained_variance   | 0.0372        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.5          |\n",
      "|    n_updates            | 33630         |\n",
      "|    policy_gradient_loss | -0.00112      |\n",
      "|    reward               | 0.47111848    |\n",
      "|    std                  | 147           |\n",
      "|    value_loss           | 46.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2876         |\n",
      "|    time_elapsed         | 55679        |\n",
      "|    total_timesteps      | 5890048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.719955e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.0471       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 33640        |\n",
      "|    policy_gradient_loss | -0.000549    |\n",
      "|    reward               | -4.167128    |\n",
      "|    std                  | 147          |\n",
      "|    value_loss           | 68.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2877         |\n",
      "|    time_elapsed         | 55697        |\n",
      "|    total_timesteps      | 5892096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005959311 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | -0.0833      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 33650        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | 1.522151     |\n",
      "|    std                  | 147          |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2878         |\n",
      "|    time_elapsed         | 55716        |\n",
      "|    total_timesteps      | 5894144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008065329 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.0204       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.65         |\n",
      "|    n_updates            | 33660        |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    reward               | -0.85768795  |\n",
      "|    std                  | 147          |\n",
      "|    value_loss           | 45           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2879         |\n",
      "|    time_elapsed         | 55735        |\n",
      "|    total_timesteps      | 5896192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001323213 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.161        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 33670        |\n",
      "|    policy_gradient_loss | -0.00088     |\n",
      "|    reward               | -0.46361092  |\n",
      "|    std                  | 148          |\n",
      "|    value_loss           | 76           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2880         |\n",
      "|    time_elapsed         | 55754        |\n",
      "|    total_timesteps      | 5898240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005727661 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.00291      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.1         |\n",
      "|    n_updates            | 33680        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | 1.2963537    |\n",
      "|    std                  | 148          |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2881         |\n",
      "|    time_elapsed         | 55773        |\n",
      "|    total_timesteps      | 5900288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022940733 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.184        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.71         |\n",
      "|    n_updates            | 33690        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | -2.138472    |\n",
      "|    std                  | 148          |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2882         |\n",
      "|    time_elapsed         | 55792        |\n",
      "|    total_timesteps      | 5902336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004828494 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | -0.00459     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 33700        |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    reward               | 1.6105647    |\n",
      "|    std                  | 148          |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2883         |\n",
      "|    time_elapsed         | 55810        |\n",
      "|    total_timesteps      | 5904384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010666528 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | -0.00453     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 33710        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | -10.50614    |\n",
      "|    std                  | 149          |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3387240.70\n",
      "total_reward: 2387240.70\n",
      "total_cost: 502858.48\n",
      "total_trades: 77176\n",
      "Sharpe: 0.652\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2884         |\n",
      "|    time_elapsed         | 55829        |\n",
      "|    total_timesteps      | 5906432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034473655 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -184         |\n",
      "|    explained_variance   | 0.00118      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 33720        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | -0.67714757  |\n",
      "|    std                  | 150          |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2885         |\n",
      "|    time_elapsed         | 55848        |\n",
      "|    total_timesteps      | 5908480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027043459 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | 0.0416       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 33730        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | -1.2471936   |\n",
      "|    std                  | 150          |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2886         |\n",
      "|    time_elapsed         | 55867        |\n",
      "|    total_timesteps      | 5910528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016649037 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | -0.0057      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.8         |\n",
      "|    n_updates            | 33740        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | 0.10626353   |\n",
      "|    std                  | 150          |\n",
      "|    value_loss           | 66.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2887         |\n",
      "|    time_elapsed         | 55886        |\n",
      "|    total_timesteps      | 5912576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013908909 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | -0.00552     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.5         |\n",
      "|    n_updates            | 33750        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 0.62852836   |\n",
      "|    std                  | 150          |\n",
      "|    value_loss           | 85.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2888         |\n",
      "|    time_elapsed         | 55905        |\n",
      "|    total_timesteps      | 5914624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024745762 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | 0.000785     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.09         |\n",
      "|    n_updates            | 33760        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | 0.31477067   |\n",
      "|    std                  | 150          |\n",
      "|    value_loss           | 12.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2889         |\n",
      "|    time_elapsed         | 55924        |\n",
      "|    total_timesteps      | 5916672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018222464 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | 0.0929       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 33770        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 0.6305857    |\n",
      "|    std                  | 151          |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2890         |\n",
      "|    time_elapsed         | 55946        |\n",
      "|    total_timesteps      | 5918720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014984754 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | 0.065        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 33780        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | 4.178093     |\n",
      "|    std                  | 151          |\n",
      "|    value_loss           | 60.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 2891        |\n",
      "|    time_elapsed         | 55964       |\n",
      "|    total_timesteps      | 5920768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001815673 |\n",
      "|    clip_fraction        | 0.00146     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -185        |\n",
      "|    explained_variance   | 0.00649     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 33790       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 1.0362715   |\n",
      "|    std                  | 151         |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2892         |\n",
      "|    time_elapsed         | 55984        |\n",
      "|    total_timesteps      | 5922816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009131188 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | 0.0949       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 33800        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | -2.6284242   |\n",
      "|    std                  | 151          |\n",
      "|    value_loss           | 41.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2893         |\n",
      "|    time_elapsed         | 56003        |\n",
      "|    total_timesteps      | 5924864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018862443 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | -0.00224     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.3         |\n",
      "|    n_updates            | 33810        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | 5.6984167    |\n",
      "|    std                  | 152          |\n",
      "|    value_loss           | 92           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2894          |\n",
      "|    time_elapsed         | 56021         |\n",
      "|    total_timesteps      | 5926912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082566356 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -185          |\n",
      "|    explained_variance   | 0.00544       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 50.8          |\n",
      "|    n_updates            | 33820         |\n",
      "|    policy_gradient_loss | -0.0021       |\n",
      "|    reward               | 0.008210957   |\n",
      "|    std                  | 153           |\n",
      "|    value_loss           | 96.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2895         |\n",
      "|    time_elapsed         | 56040        |\n",
      "|    total_timesteps      | 5928960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038355326 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | 0.0161       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.46         |\n",
      "|    n_updates            | 33830        |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    reward               | 0.4667015    |\n",
      "|    std                  | 154          |\n",
      "|    value_loss           | 14.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2896         |\n",
      "|    time_elapsed         | 56059        |\n",
      "|    total_timesteps      | 5931008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021001068 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | 0.00177      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.4         |\n",
      "|    n_updates            | 33840        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | -1.3845309   |\n",
      "|    std                  | 154          |\n",
      "|    value_loss           | 65.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2897         |\n",
      "|    time_elapsed         | 56078        |\n",
      "|    total_timesteps      | 5933056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011010193 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | 0.0325       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 33850        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | 3.8649797    |\n",
      "|    std                  | 154          |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4496652.86\n",
      "total_reward: 3496652.86\n",
      "total_cost: 525703.94\n",
      "total_trades: 78469\n",
      "Sharpe: 0.798\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2898         |\n",
      "|    time_elapsed         | 56097        |\n",
      "|    total_timesteps      | 5935104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032840283 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -185         |\n",
      "|    explained_variance   | -0.000652    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 33860        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | 2.8919024    |\n",
      "|    std                  | 155          |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2899         |\n",
      "|    time_elapsed         | 56115        |\n",
      "|    total_timesteps      | 5937152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014652513 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.000171     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 33870        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | 2.2466435    |\n",
      "|    std                  | 155          |\n",
      "|    value_loss           | 97.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2900         |\n",
      "|    time_elapsed         | 56135        |\n",
      "|    total_timesteps      | 5939200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003633367 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.000403     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 33880        |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    reward               | 1.4118975    |\n",
      "|    std                  | 155          |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2901         |\n",
      "|    time_elapsed         | 56154        |\n",
      "|    total_timesteps      | 5941248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021045883 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.000935     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 33890        |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    reward               | -0.62957084  |\n",
      "|    std                  | 155          |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2902         |\n",
      "|    time_elapsed         | 56173        |\n",
      "|    total_timesteps      | 5943296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006471485 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.0241       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 33900        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | 0.26925892   |\n",
      "|    std                  | 156          |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2903         |\n",
      "|    time_elapsed         | 56192        |\n",
      "|    total_timesteps      | 5945344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001344159 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 33910        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | 0.6609141    |\n",
      "|    std                  | 156          |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2904          |\n",
      "|    time_elapsed         | 56211         |\n",
      "|    total_timesteps      | 5947392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073552004 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -186          |\n",
      "|    explained_variance   | 0.0279        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.9          |\n",
      "|    n_updates            | 33920         |\n",
      "|    policy_gradient_loss | -0.00201      |\n",
      "|    reward               | 0.98049784    |\n",
      "|    std                  | 156           |\n",
      "|    value_loss           | 53.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2905         |\n",
      "|    time_elapsed         | 56231        |\n",
      "|    total_timesteps      | 5949440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029987446 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.00173      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.57         |\n",
      "|    n_updates            | 33930        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 0.27538016   |\n",
      "|    std                  | 156          |\n",
      "|    value_loss           | 15.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2906          |\n",
      "|    time_elapsed         | 56249         |\n",
      "|    total_timesteps      | 5951488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016754447 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -186          |\n",
      "|    explained_variance   | 0.148         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.5          |\n",
      "|    n_updates            | 33940         |\n",
      "|    policy_gradient_loss | -0.0011       |\n",
      "|    reward               | -0.031198386  |\n",
      "|    std                  | 156           |\n",
      "|    value_loss           | 59            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2907          |\n",
      "|    time_elapsed         | 56268         |\n",
      "|    total_timesteps      | 5953536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027029295 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -186          |\n",
      "|    explained_variance   | 0.351         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.08          |\n",
      "|    n_updates            | 33950         |\n",
      "|    policy_gradient_loss | -0.00203      |\n",
      "|    reward               | -2.874351     |\n",
      "|    std                  | 156           |\n",
      "|    value_loss           | 42.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2908         |\n",
      "|    time_elapsed         | 56288        |\n",
      "|    total_timesteps      | 5955584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030025993 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | -0.03        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.12         |\n",
      "|    n_updates            | 33960        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | 3.9837973    |\n",
      "|    std                  | 157          |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2909         |\n",
      "|    time_elapsed         | 56307        |\n",
      "|    total_timesteps      | 5957632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010667383 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.00942      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 33970        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | -0.24905063  |\n",
      "|    std                  | 157          |\n",
      "|    value_loss           | 57.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2910         |\n",
      "|    time_elapsed         | 56326        |\n",
      "|    total_timesteps      | 5959680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010898038 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.000731     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75           |\n",
      "|    n_updates            | 33980        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | 1.4849001    |\n",
      "|    std                  | 157          |\n",
      "|    value_loss           | 87.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2911          |\n",
      "|    time_elapsed         | 56344         |\n",
      "|    total_timesteps      | 5961728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016954567 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -186          |\n",
      "|    explained_variance   | 0.0679        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.9          |\n",
      "|    n_updates            | 33990         |\n",
      "|    policy_gradient_loss | -0.000772     |\n",
      "|    reward               | -0.33650094   |\n",
      "|    std                  | 157           |\n",
      "|    value_loss           | 90            |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3445538.38\n",
      "total_reward: 2445538.38\n",
      "total_cost: 493391.59\n",
      "total_trades: 76988\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2912         |\n",
      "|    time_elapsed         | 56363        |\n",
      "|    total_timesteps      | 5963776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027270818 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.0178       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.68         |\n",
      "|    n_updates            | 34000        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | -0.5686666   |\n",
      "|    std                  | 157          |\n",
      "|    value_loss           | 13.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2913          |\n",
      "|    time_elapsed         | 56382         |\n",
      "|    total_timesteps      | 5965824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044134265 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -186          |\n",
      "|    explained_variance   | 0.27          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.1          |\n",
      "|    n_updates            | 34010         |\n",
      "|    policy_gradient_loss | -0.002        |\n",
      "|    reward               | -0.1582224    |\n",
      "|    std                  | 158           |\n",
      "|    value_loss           | 47.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2914         |\n",
      "|    time_elapsed         | 56402        |\n",
      "|    total_timesteps      | 5967872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006459623 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 34020        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | -12.727752   |\n",
      "|    std                  | 158          |\n",
      "|    value_loss           | 54.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2915         |\n",
      "|    time_elapsed         | 56421        |\n",
      "|    total_timesteps      | 5969920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009649844 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | -0.00151     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 34030        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | 2.0230782    |\n",
      "|    std                  | 158          |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2916         |\n",
      "|    time_elapsed         | 56440        |\n",
      "|    total_timesteps      | 5971968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015331218 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.00628      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 34040        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | 0.22162636   |\n",
      "|    std                  | 158          |\n",
      "|    value_loss           | 76.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2917         |\n",
      "|    time_elapsed         | 56459        |\n",
      "|    total_timesteps      | 5974016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008402488 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 34050        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | 5.786938     |\n",
      "|    std                  | 158          |\n",
      "|    value_loss           | 50.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2918          |\n",
      "|    time_elapsed         | 56478         |\n",
      "|    total_timesteps      | 5976064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056763395 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -186          |\n",
      "|    explained_variance   | 0.039         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.6          |\n",
      "|    n_updates            | 34060         |\n",
      "|    policy_gradient_loss | -0.00166      |\n",
      "|    reward               | 0.07524661    |\n",
      "|    std                  | 159           |\n",
      "|    value_loss           | 63.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2919         |\n",
      "|    time_elapsed         | 56497        |\n",
      "|    total_timesteps      | 5978112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017762219 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.0195       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.97         |\n",
      "|    n_updates            | 34070        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | 0.22699203   |\n",
      "|    std                  | 159          |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2920         |\n",
      "|    time_elapsed         | 56516        |\n",
      "|    total_timesteps      | 5980160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003480672 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | 0.161        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 34080        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    reward               | 0.077657655  |\n",
      "|    std                  | 159          |\n",
      "|    value_loss           | 73           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2921          |\n",
      "|    time_elapsed         | 56534         |\n",
      "|    total_timesteps      | 5982208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012382978 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -186          |\n",
      "|    explained_variance   | 0.49          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.6          |\n",
      "|    n_updates            | 34090         |\n",
      "|    policy_gradient_loss | -0.000974     |\n",
      "|    reward               | -0.868012     |\n",
      "|    std                  | 159           |\n",
      "|    value_loss           | 46.6          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2922         |\n",
      "|    time_elapsed         | 56553        |\n",
      "|    total_timesteps      | 5984256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045060576 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -186         |\n",
      "|    explained_variance   | -0.00139     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 34100        |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    reward               | -0.18824817  |\n",
      "|    std                  | 160          |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2923          |\n",
      "|    time_elapsed         | 56572         |\n",
      "|    total_timesteps      | 5986304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044865292 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -186          |\n",
      "|    explained_variance   | 0.297         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 44.1          |\n",
      "|    n_updates            | 34110         |\n",
      "|    policy_gradient_loss | -0.00216      |\n",
      "|    reward               | 1.1385366     |\n",
      "|    std                  | 160           |\n",
      "|    value_loss           | 59.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2924          |\n",
      "|    time_elapsed         | 56591         |\n",
      "|    total_timesteps      | 5988352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018286318 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -186          |\n",
      "|    explained_variance   | 0.32          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.3          |\n",
      "|    n_updates            | 34120         |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    reward               | 0.23211326    |\n",
      "|    std                  | 160           |\n",
      "|    value_loss           | 47.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2925         |\n",
      "|    time_elapsed         | 56610        |\n",
      "|    total_timesteps      | 5990400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009185167 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -187         |\n",
      "|    explained_variance   | -0.014       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 34130        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    reward               | 0.2335048    |\n",
      "|    std                  | 161          |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3615895.68\n",
      "total_reward: 2615895.68\n",
      "total_cost: 516669.58\n",
      "total_trades: 78088\n",
      "Sharpe: 0.708\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2926          |\n",
      "|    time_elapsed         | 56629         |\n",
      "|    total_timesteps      | 5992448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040507843 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -187          |\n",
      "|    explained_variance   | 0.0736        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.3          |\n",
      "|    n_updates            | 34140         |\n",
      "|    policy_gradient_loss | -0.00203      |\n",
      "|    reward               | -0.3393807    |\n",
      "|    std                  | 161           |\n",
      "|    value_loss           | 41.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2927          |\n",
      "|    time_elapsed         | 56648         |\n",
      "|    total_timesteps      | 5994496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046095942 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -187          |\n",
      "|    explained_variance   | 0.0504        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.9          |\n",
      "|    n_updates            | 34150         |\n",
      "|    policy_gradient_loss | -0.00125      |\n",
      "|    reward               | 1.0337305     |\n",
      "|    std                  | 161           |\n",
      "|    value_loss           | 60            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2928         |\n",
      "|    time_elapsed         | 56669        |\n",
      "|    total_timesteps      | 5996544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006186246 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -187         |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 34160        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | 0.20824315   |\n",
      "|    std                  | 161          |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 2929         |\n",
      "|    time_elapsed         | 56688        |\n",
      "|    total_timesteps      | 5998592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031326076 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -187         |\n",
      "|    explained_variance   | 0.00584      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.92         |\n",
      "|    n_updates            | 34170        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    reward               | -4.1678157   |\n",
      "|    std                  | 162          |\n",
      "|    value_loss           | 10           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 105           |\n",
      "|    iterations           | 2930          |\n",
      "|    time_elapsed         | 56706         |\n",
      "|    total_timesteps      | 6000640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048516784 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -187          |\n",
      "|    explained_variance   | 0.528         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.7          |\n",
      "|    n_updates            | 34180         |\n",
      "|    policy_gradient_loss | -0.00172      |\n",
      "|    reward               | -0.70020896   |\n",
      "|    std                  | 162           |\n",
      "|    value_loss           | 40.4          |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_ppo2.load('43')\n",
    "print('load')\n",
    "trained_ppo2 = agent_con.train_model(model=model_ppo2, \n",
    "                             tb_log_name=\"4\",\n",
    "                             total_timesteps=6000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23766/4244563930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_sac = agent.train_model(model=model_sac, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=60000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Select action according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mnext_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# Compute the next Q values: min over all critics targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnext_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/policies.py\u001b[0m in \u001b[0;36maction_log_prob\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_dist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# return action and associated log prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mlog_prob_from_params\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mactions_from_params\u001b[0;34m(self, mean_actions, log_std, deterministic)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Update the proba distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SquashedDiagGaussianDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSquashedDiagGaussianDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0maction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<'2020-07-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n",
    "\n",
    "trained_ppo2.save('44')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       18.824245\n",
       "std         8.489311\n",
       "min         9.140000\n",
       "25%        13.330000\n",
       "50%        16.139999\n",
       "75%        21.309999\n",
       "max        82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.40400183105453"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       34.574233\n",
       "std        43.787150\n",
       "min         0.000000\n",
       "25%        14.966105\n",
       "50%        24.124290\n",
       "75%        39.162080\n",
       "max       652.505555\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.45132359815483"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_ppo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_78883/536458364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     environment = e_trade_gym)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df_account_value, df_actions = DRLAgent.DRL_prediction(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_ppo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     environment = e_trade_gym)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_ppo' is not defined"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERxw3KqLkcP4"
   },
   "outputs": [],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qg1kvfemrrQH"
   },
   "outputs": [],
   "source": [
    "df_account_value.loc[0,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BzBaE63H3RLc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value2, df_actions2 = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo2, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ZYeOjax-7H_5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.303891\n",
      "Cumulative returns     0.424475\n",
      "Annual volatility      0.152805\n",
      "Sharpe ratio           1.818876\n",
      "Calmar ratio           2.859163\n",
      "Stability              0.953067\n",
      "Max drawdown          -0.106287\n",
      "Omega ratio            1.362944\n",
      "Sortino ratio          2.732559\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.121598\n",
      "Daily value at risk   -0.018149\n",
      "dtype: float64\n",
      "==============Get Baseline Stats===========\n",
      "Annual return          0.269722\n",
      "Cumulative returns     0.374922\n",
      "Annual volatility      0.139083\n",
      "Sharpe ratio           1.792302\n",
      "Calmar ratio           3.020136\n",
      "Stability              0.919220\n",
      "Max drawdown          -0.089308\n",
      "Omega ratio            1.347571\n",
      "Sortino ratio          2.655481\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.052781\n",
      "Daily value at risk   -0.016534\n",
      "dtype: float64\n",
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-10-28</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>16</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>30.389%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>42.448%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>15.281%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-10.629%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-1.815%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.63</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.22</td>\n",
       "      <td>2021-08-23</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.94</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.79</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.11%</td>\n",
       "      <td>-4.19%</td>\n",
       "      <td>4.44%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value2)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'2.csv')\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value2.loc[0,'date'],\n",
    "        end = df_account_value2.loc[len(df_account_value2)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value2, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value2.loc[0,'date'],\n",
    "             baseline_end = df_account_value2.loc[len(df_account_value2)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
